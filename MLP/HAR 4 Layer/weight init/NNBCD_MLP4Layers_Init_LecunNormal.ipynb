{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccc0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6113fe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 5 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 1.278249740600586 - sq_loss: 661.6724853515625 - tot_loss: 1028.818889358321 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 1.2605726718902588 - sq_loss: 294.0766296386719 - tot_loss: 485.82475444767624 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 1.2398607730865479 - sq_loss: 161.25238037109375 - tot_loss: 268.10302961058915 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 1.2554261684417725 - sq_loss: 87.3482666015625 - tot_loss: 152.4793573366478 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 1.2432985305786133 - sq_loss: 46.95746994018555 - tot_loss: 89.90317907370627 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 1.265305519104004 - sq_loss: 25.176353454589844 - tot_loss: 55.75292411260307 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 1.2377376556396484 - sq_loss: 13.505265235900879 - tot_loss: 36.872538486495614 - acc: 0.18770402611534276 - val_acc: 0.1808618934509671\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 1.2539465427398682 - sq_loss: 7.264782905578613 - tot_loss: 26.18645442579873 - acc: 0.35514145810663766 - val_acc: 0.35595520868680014\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 1.2451674938201904 - sq_loss: 3.9266257286071777 - tot_loss: 19.960809782380238 - acc: 0.286588683351469 - val_acc: 0.2901255514082117\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 1.2443811893463135 - sq_loss: 2.1370058059692383 - tot_loss: 16.1804533964023 - acc: 0.3256256800870511 - val_acc: 0.2952154733627418\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 1.2472326755523682 - sq_loss: 1.1739219427108765 - tot_loss: 13.74222196196206 - acc: 0.3532372143634385 - val_acc: 0.34034611469290804\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 1.2404484748840332 - sq_loss: 0.6528180837631226 - tot_loss: 12.065045735565946 - acc: 0.36547878128400435 - val_acc: 0.3647777400746522\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 1.241910696029663 - sq_loss: 0.3687940835952759 - tot_loss: 10.83080100780353 - acc: 0.3751360174102285 - val_acc: 0.37292161520190026\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 1.2751493453979492 - sq_loss: 0.21252524852752686 - tot_loss: 9.854499815730378 - acc: 0.390233949945593 - val_acc: 0.38954869358669836\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 1.2845637798309326 - sq_loss: 0.12552626430988312 - tot_loss: 9.030671538203023 - acc: 0.4158052230685528 - val_acc: 0.4231421784865965\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 1.2431509494781494 - sq_loss: 0.07637554407119751 - tot_loss: 8.312298452248797 - acc: 0.45973884657236125 - val_acc: 0.4658975229046488\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 1.2501416206359863 - sq_loss: 0.0481087788939476 - tot_loss: 7.680984983686358 - acc: 0.501088139281828 - val_acc: 0.501526976586359\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 1.235499382019043 - sq_loss: 0.031509097665548325 - tot_loss: 7.093997296818998 - acc: 0.529107725788901 - val_acc: 0.5215473362741772\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 1.2385036945343018 - sq_loss: 0.02152182348072529 - tot_loss: 6.569646878459025 - acc: 0.5401251360174102 - val_acc: 0.5249406175771971\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 1.228686809539795 - sq_loss: 0.015345331281423569 - tot_loss: 6.079321054625325 - acc: 0.5461099020674647 - val_acc: 0.5290125551408211\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 1.2649400234222412 - sq_loss: 0.011406158097088337 - tot_loss: 5.63382007018663 - acc: 0.5557671381936888 - val_acc: 0.5337631489650492\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 1.250497817993164 - sq_loss: 0.008809423074126244 - tot_loss: 5.218632858770434 - acc: 0.5752176278563657 - val_acc: 0.5469969460468272\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 1.238821029663086 - sq_loss: 0.007036954164505005 - tot_loss: 4.851650927419541 - acc: 0.6109902067464635 - val_acc: 0.5710892432982694\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 1.2349295616149902 - sq_loss: 0.005781980697065592 - tot_loss: 4.518849500105716 - acc: 0.6542437431991295 - val_acc: 0.6070580251102816\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 1.2394757270812988 - sq_loss: 0.004862403497099876 - tot_loss: 4.197596563681145 - acc: 0.6886561479869423 - val_acc: 0.6328469630132338\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 1.2407124042510986 - sq_loss: 0.0041654594242572784 - tot_loss: 3.9274193062301492 - acc: 0.719260065288357 - val_acc: 0.6576179165252799\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 1.2164747714996338 - sq_loss: 0.0036204771604388952 - tot_loss: 3.6663687375112204 - acc: 0.7419749727965179 - val_acc: 0.6783169324737021\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 1.2209248542785645 - sq_loss: 0.003183248918503523 - tot_loss: 3.4264560447918484 - acc: 0.7608813928182807 - val_acc: 0.6979979640312182\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 1.239879846572876 - sq_loss: 0.002824164927005768 - tot_loss: 3.2165386420529103 - acc: 0.7765233949945594 - val_acc: 0.7207329487614523\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 1.2296421527862549 - sq_loss: 0.0025234511122107506 - tot_loss: 3.01845907754614 - acc: 0.7891730141458106 - val_acc: 0.7373600271462504\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 1.2541897296905518 - sq_loss: 0.0022677064407616854 - tot_loss: 2.8306106712770998 - acc: 0.8029107725788901 - val_acc: 0.7533084492704445\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 1.2275800704956055 - sq_loss: 0.0020474877674132586 - tot_loss: 2.6655794918333413 - acc: 0.815152339499456 - val_acc: 0.7709535120461486\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 1.2307684421539307 - sq_loss: 0.0018562801415100694 - tot_loss: 2.5092221841259743 - acc: 0.8245375408052231 - val_acc: 0.7845266372582287\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 1.2305493354797363 - sq_loss: 0.0016890353290364146 - tot_loss: 2.362836924374278 - acc: 0.8337867247007617 - val_acc: 0.7936884967763828\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 1.237238883972168 - sq_loss: 0.0015415690140798688 - tot_loss: 2.230736420598987 - acc: 0.8404515778019587 - val_acc: 0.8048863250763488\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 1.251659631729126 - sq_loss: 0.0014112205244600773 - tot_loss: 2.1122350134392036 - acc: 0.8477965179542981 - val_acc: 0.8194774346793349\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 1.2335798740386963 - sq_loss: 0.001295090769417584 - tot_loss: 1.9950109860874363 - acc: 0.8529651795429815 - val_acc: 0.8245673566338649\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 1.2228994369506836 - sq_loss: 0.001191060058772564 - tot_loss: 1.8837021309263946 - acc: 0.8569096844396082 - val_acc: 0.831353919239905\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 1.2309520244598389 - sq_loss: 0.0010976535268127918 - tot_loss: 1.7812117826579197 - acc: 0.8604461371055495 - val_acc: 0.8391584662368511\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 1.2172081470489502 - sq_loss: 0.0010135992197319865 - tot_loss: 1.6908684104855638 - acc: 0.8649347116430903 - val_acc: 0.8435697319307771\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 1.229245662689209 - sq_loss: 0.0009374814690090716 - tot_loss: 1.6059523517651542 - acc: 0.8675190424374319 - val_acc: 0.8486596538853071\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 1.2260525226593018 - sq_loss: 0.0008683905471116304 - tot_loss: 1.5236813854717184 - acc: 0.8705114254624592 - val_acc: 0.8547675602307431\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 1.2267341613769531 - sq_loss: 0.0008052790071815252 - tot_loss: 1.4554209193083807 - acc: 0.873911860718172 - val_acc: 0.8571428571428571\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 1.2347187995910645 - sq_loss: 0.0007475340971723199 - tot_loss: 1.3881684337757179 - acc: 0.8773122959738846 - val_acc: 0.8605361384458772\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 1.2170586585998535 - sq_loss: 0.0006949096568860114 - tot_loss: 1.3174287293513771 - acc: 0.8797606093579978 - val_acc: 0.8625721072276892\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 1.2411401271820068 - sq_loss: 0.0006466299528256059 - tot_loss: 1.259222211461747 - acc: 0.8849292709466812 - val_acc: 0.8666440447913132\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 1.2444093227386475 - sq_loss: 0.0006023020832799375 - tot_loss: 1.2008143199454935 - acc: 0.8872415669205659 - val_acc: 0.8693586698337292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 1.2240910530090332 - sq_loss: 0.0005614866968244314 - tot_loss: 1.1465305273450213 - acc: 0.888873775843308 - val_acc: 0.8713946386155412\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 1.2276592254638672 - sq_loss: 0.0005240177270025015 - tot_loss: 1.0967890536285267 - acc: 0.89050598476605 - val_acc: 0.8730912792670512\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 1.2236816883087158 - sq_loss: 0.0004895291640423238 - tot_loss: 1.0425468868997996 - acc: 0.8936343852013058 - val_acc: 0.8761452324397693\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 1.2302687168121338 - sq_loss: 0.000457661779364571 - tot_loss: 0.9955724976862257 - acc: 0.8954026115342764 - val_acc: 0.8764845605700713\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 1.2179327011108398 - sq_loss: 0.00042797272908501327 - tot_loss: 0.9610044298569846 - acc: 0.8975788900979326 - val_acc: 0.8802171700033933\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 1.2267773151397705 - sq_loss: 0.0004005588998552412 - tot_loss: 0.9168558273904637 - acc: 0.8992110990206746 - val_acc: 0.8836104513064132\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 1.2295584678649902 - sq_loss: 0.0003750464820768684 - tot_loss: 0.8823897755628423 - acc: 0.9005712731229597 - val_acc: 0.8849677638276213\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 1.2303473949432373 - sq_loss: 0.00035142453270964324 - tot_loss: 0.8447256319486769 - acc: 0.9024755168661589 - val_acc: 0.8870037326094333\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 1.2237756252288818 - sq_loss: 0.00032949147862382233 - tot_loss: 0.8137711027193291 - acc: 0.904379760609358 - val_acc: 0.8897183576518494\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 1.2256832122802734 - sq_loss: 0.00030898922705091536 - tot_loss: 0.7826512766296219 - acc: 0.905739934711643 - val_acc: 0.8920936545639634\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 1.2432286739349365 - sq_loss: 0.00029000488575547934 - tot_loss: 0.7522341556887113 - acc: 0.9073721436343852 - val_acc: 0.8937902952154734\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 1.2316536903381348 - sq_loss: 0.00027241764473728836 - tot_loss: 0.7205673616526838 - acc: 0.9087323177366703 - val_acc: 0.8958262639972854\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 1.2231380939483643 - sq_loss: 0.0002560832945164293 - tot_loss: 0.687757587458691 - acc: 0.9099564744287268 - val_acc: 0.8992195453003053\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 1.2565815448760986 - sq_loss: 0.0002408931468380615 - tot_loss: 0.6766773442977865 - acc: 0.9114526659412405 - val_acc: 0.8995588734306074\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 1.2374475002288818 - sq_loss: 0.0002266397059429437 - tot_loss: 0.6459924864111599 - acc: 0.9136289445048966 - val_acc: 0.9022734984730234\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 1.2283446788787842 - sq_loss: 0.00021338241640478373 - tot_loss: 0.6217598667326456 - acc: 0.9163492927094669 - val_acc: 0.9049881235154394\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 1.2367451190948486 - sq_loss: 0.00020098790992051363 - tot_loss: 0.6030048851762331 - acc: 0.9179815016322089 - val_acc: 0.9046487953851374\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 1.2229299545288086 - sq_loss: 0.00018942810129374266 - tot_loss: 0.5813171951613185 - acc: 0.9194776931447225 - val_acc: 0.9056667797760435\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 1.2351152896881104 - sq_loss: 0.0001787172950571403 - tot_loss: 0.5630302841009325 - acc: 0.9211099020674647 - val_acc: 0.9060061079063454\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 1.2270195484161377 - sq_loss: 0.00016880332259461284 - tot_loss: 0.5520862039029453 - acc: 0.9223340587595212 - val_acc: 0.9077027485578555\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 1.250819444656372 - sq_loss: 0.00015951404930092394 - tot_loss: 0.530355497430719 - acc: 0.9238302502720348 - val_acc: 0.9100780454699695\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 1.2403979301452637 - sq_loss: 0.00015079388685990125 - tot_loss: 0.5072746438718241 - acc: 0.9251904243743199 - val_acc: 0.9127926705123854\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 1.2380521297454834 - sq_loss: 0.00014262949116528034 - tot_loss: 0.491491496476101 - acc: 0.9272306855277476 - val_acc: 0.9138106549032915\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 1.2392573356628418 - sq_loss: 0.00013506991672329605 - tot_loss: 0.48153348167261356 - acc: 0.9288628944504896 - val_acc: 0.9155072955548015\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 1.2330081462860107 - sq_loss: 0.00012798115494661033 - tot_loss: 0.47079385605866264 - acc: 0.9289989118607181 - val_acc: 0.9168646080760094\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 1.2472751140594482 - sq_loss: 0.00012131405674153939 - tot_loss: 0.45209443452949927 - acc: 0.9298150163220892 - val_acc: 0.9168646080760094\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 1.2561771869659424 - sq_loss: 0.0001150432217400521 - tot_loss: 0.43519756217528993 - acc: 0.9307671381936888 - val_acc: 0.9189005768578216\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 1.236875295639038 - sq_loss: 0.00010923492664005607 - tot_loss: 0.42994721897639465 - acc: 0.9311751904243744 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 1.2555766105651855 - sq_loss: 0.0001037650290527381 - tot_loss: 0.41542285923742384 - acc: 0.9326713819368879 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 1.2620594501495361 - sq_loss: 9.863284503808245e-05 - tot_loss: 0.40259468926478803 - acc: 0.934031556039173 - val_acc: 0.9236511706820495\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 1.2463123798370361 - sq_loss: 9.383950236951932e-05 - tot_loss: 0.38875273113262665 - acc: 0.9349836779107725 - val_acc: 0.9256871394638616\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 1.2385480403900146 - sq_loss: 8.929756586439908e-05 - tot_loss: 0.38255910075076827 - acc: 0.9359357997823722 - val_acc: 0.9267051238547676\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 1.236997127532959 - sq_loss: 8.505435107508674e-05 - tot_loss: 0.3712668450525598 - acc: 0.9371599564744287 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 1.2541050910949707 - sq_loss: 8.105304004857317e-05 - tot_loss: 0.3648162849444816 - acc: 0.9383841131664853 - val_acc: 0.9284017645062775\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 1.2473909854888916 - sq_loss: 7.729398930678144e-05 - tot_loss: 0.3465536000908287 - acc: 0.9397442872687704 - val_acc: 0.9297590770274856\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 1.2418394088745117 - sq_loss: 7.379749149549752e-05 - tot_loss: 0.3453689883763218 - acc: 0.94069640914037 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 1.2447054386138916 - sq_loss: 7.048683619359508e-05 - tot_loss: 0.3367657593655622 - acc: 0.9424646354733406 - val_acc: 0.9311163895486936\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 1.2452170848846436 - sq_loss: 6.737365038134158e-05 - tot_loss: 0.3266296565354878 - acc: 0.9430087051142546 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 1.2285568714141846 - sq_loss: 6.443023448809981e-05 - tot_loss: 0.31967310689697115 - acc: 0.9439608269858542 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 1.2201039791107178 - sq_loss: 6.167087121866643e-05 - tot_loss: 0.31524718355035475 - acc: 0.9451849836779108 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 1.2262609004974365 - sq_loss: 5.907449303776957e-05 - tot_loss: 0.31068470251420877 - acc: 0.9461371055495104 - val_acc: 0.9345096708517137\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 1.2394254207611084 - sq_loss: 5.662384137394838e-05 - tot_loss: 0.30478653705722536 - acc: 0.9464091403699674 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 1.2311339378356934 - sq_loss: 5.430245437310077e-05 - tot_loss: 0.2912875251877267 - acc: 0.9469532100108814 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 1.2241568565368652 - sq_loss: 5.2141345804557204e-05 - tot_loss: 0.28341363275262665 - acc: 0.9477693144722524 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 1.2324626445770264 - sq_loss: 5.0103328248951584e-05 - tot_loss: 0.27949528632302645 - acc: 0.9479053318824809 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 1.2254583835601807 - sq_loss: 4.8161917220568284e-05 - tot_loss: 0.2673417830760627 - acc: 0.9480413492927094 - val_acc: 0.9385816084153377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 1.2271745204925537 - sq_loss: 4.629102113540284e-05 - tot_loss: 0.2730415819751215 - acc: 0.948993471164309 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 1.2301928997039795 - sq_loss: 4.452470602700487e-05 - tot_loss: 0.2626119409284229 - acc: 0.9494015233949945 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 1.2353408336639404 - sq_loss: 4.287187766749412e-05 - tot_loss: 0.25895429881745713 - acc: 0.9504896626768227 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 1.2346460819244385 - sq_loss: 4.128071304876357e-05 - tot_loss: 0.25175482797214954 - acc: 0.9514417845484222 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 1.228027582168579 - sq_loss: 3.98117299482692e-05 - tot_loss: 0.2491811586140784 - acc: 0.9521218715995647 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 1.2401933670043945 - sq_loss: 3.8394042348954827e-05 - tot_loss: 0.24218714019468734 - acc: 0.9525299238302503 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 1.2284975051879883 - sq_loss: 3.707357245730236e-05 - tot_loss: 0.23840625908690072 - acc: 0.9526659412404788 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 1.2290387153625488 - sq_loss: 3.582912540878169e-05 - tot_loss: 0.23235233026457536 - acc: 0.9533460282916213 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 1.2376728057861328 - sq_loss: 3.463124085101299e-05 - tot_loss: 0.2373726710709434 - acc: 0.9538900979325353 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 1.26399827003479 - sq_loss: 3.347308302181773e-05 - tot_loss: 0.23036733227456807 - acc: 0.954570184983678 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 1.2408034801483154 - sq_loss: 3.238857607357204e-05 - tot_loss: 0.22277615351049462 - acc: 0.9557943416757345 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 1.2341954708099365 - sq_loss: 3.1331797799794e-05 - tot_loss: 0.217556641527608 - acc: 0.9560663764961915 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 1.222726583480835 - sq_loss: 3.0356020943145268e-05 - tot_loss: 0.2142115670039857 - acc: 0.9574265505984766 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 1.2286927700042725 - sq_loss: 2.9443652238114737e-05 - tot_loss: 0.21859103111012246 - acc: 0.9582426550598476 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 1.232511043548584 - sq_loss: 2.8567495974129997e-05 - tot_loss: 0.20904064861531424 - acc: 0.9585146898803046 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 1.2272391319274902 - sq_loss: 2.7741620215238072e-05 - tot_loss: 0.21568494416430894 - acc: 0.9596028291621328 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 1.2568047046661377 - sq_loss: 2.6936862923321314e-05 - tot_loss: 0.20660405731877063 - acc: 0.9601468988030468 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 1.2437098026275635 - sq_loss: 2.6161644200328737e-05 - tot_loss: 0.19914997466293016 - acc: 0.9602829162132753 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 1.2279767990112305 - sq_loss: 2.542366746638436e-05 - tot_loss: 0.20521963122087072 - acc: 0.9606909684439608 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 1.2533783912658691 - sq_loss: 2.4719887733226642e-05 - tot_loss: 0.19718202045061162 - acc: 0.9610990206746464 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 1.2505238056182861 - sq_loss: 2.4073460735962726e-05 - tot_loss: 0.1929348455790887 - acc: 0.9613710554951034 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 1.2528986930847168 - sq_loss: 2.3463899196940474e-05 - tot_loss: 0.19670144769651188 - acc: 0.9619151251360174 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 1.2404134273529053 - sq_loss: 2.288765972480178e-05 - tot_loss: 0.1883464627971989 - acc: 0.9624591947769314 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 1.2289302349090576 - sq_loss: 2.2327001715893857e-05 - tot_loss: 0.1856997867721475 - acc: 0.9630032644178455 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 1.2498347759246826 - sq_loss: 2.1787591322208755e-05 - tot_loss: 0.18540611542101715 - acc: 0.963411316648531 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 1.2507407665252686 - sq_loss: 2.1262880181893706e-05 - tot_loss: 0.1821886559383188 - acc: 0.9638193688792165 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 1.2365314960479736 - sq_loss: 2.076975943055004e-05 - tot_loss: 0.17478051924263127 - acc: 0.9639553862894451 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 1.270768642425537 - sq_loss: 2.0298248273320496e-05 - tot_loss: 0.18404226841460058 - acc: 0.9644994559303591 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 1.2564678192138672 - sq_loss: 1.985326707654167e-05 - tot_loss: 0.17480265025625386 - acc: 0.9647714907508161 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 1.2393341064453125 - sq_loss: 1.941655318660196e-05 - tot_loss: 0.17094440660122245 - acc: 0.9651795429815017 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 1.2297017574310303 - sq_loss: 1.901697578432504e-05 - tot_loss: 0.16879745395578993 - acc: 0.9651795429815017 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 1.241379737854004 - sq_loss: 1.863817851699423e-05 - tot_loss: 0.16732534424278356 - acc: 0.9661316648531012 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 1.233691930770874 - sq_loss: 1.8252832887810655e-05 - tot_loss: 0.1625844467127422 - acc: 0.9665397170837867 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 1.2248687744140625 - sq_loss: 1.7901655155583285e-05 - tot_loss: 0.15625280621657112 - acc: 0.9673558215451578 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 1.2550723552703857 - sq_loss: 1.754638651618734e-05 - tot_loss: 0.15629226001794905 - acc: 0.9677638737758433 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 1.2330100536346436 - sq_loss: 1.7216440028278157e-05 - tot_loss: 0.1650718294025353 - acc: 0.9683079434167573 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 1.2344396114349365 - sq_loss: 1.689489909040276e-05 - tot_loss: 0.16083956228459328 - acc: 0.9685799782372143 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 1.2397830486297607 - sq_loss: 1.659334338910412e-05 - tot_loss: 0.15972248205085293 - acc: 0.9685799782372143 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 1.2526333332061768 - sq_loss: 1.630675615160726e-05 - tot_loss: 0.15382878136227873 - acc: 0.9687159956474428 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 1.2547941207885742 - sq_loss: 1.6029940525186248e-05 - tot_loss: 0.15303152003082232 - acc: 0.9689880304678999 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 1.2389650344848633 - sq_loss: 1.5760937458253466e-05 - tot_loss: 0.15373490644489607 - acc: 0.9693960826985855 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 1.2411394119262695 - sq_loss: 1.5501016605412588e-05 - tot_loss: 0.1540244002338227 - acc: 0.9699401523394995 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 1.2309107780456543 - sq_loss: 1.526786400063429e-05 - tot_loss: 0.15168330052119927 - acc: 0.9702121871599565 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 1.243182897567749 - sq_loss: 1.5025674656499177e-05 - tot_loss: 0.14420531001812265 - acc: 0.970348204570185 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 1.250089406967163 - sq_loss: 1.4786501196795143e-05 - tot_loss: 0.14605392687371932 - acc: 0.970620239390642 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 1.233644723892212 - sq_loss: 1.4568167898687534e-05 - tot_loss: 0.1484081261938286 - acc: 0.970892274211099 - val_acc: 0.9548693586698337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 1.262101411819458 - sq_loss: 1.4371717952599283e-05 - tot_loss: 0.14259193111530521 - acc: 0.9710282916213275 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 1.2575187683105469 - sq_loss: 1.4184650353854522e-05 - tot_loss: 0.14646698387869606 - acc: 0.9710282916213275 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 1.222520351409912 - sq_loss: 1.3995626432006247e-05 - tot_loss: 0.13723831758241545 - acc: 0.971436343852013 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 1.2586424350738525 - sq_loss: 1.3808436960971449e-05 - tot_loss: 0.14044637250151482 - acc: 0.9715723612622416 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 1.257127285003662 - sq_loss: 1.3625073734147009e-05 - tot_loss: 0.14862841860588105 - acc: 0.9717083786724701 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 1.2379124164581299 - sq_loss: 1.3453839528665412e-05 - tot_loss: 0.1566831529362389 - acc: 0.9718443960826986 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 1.266284704208374 - sq_loss: 1.32797240439686e-05 - tot_loss: 0.1490468087426109 - acc: 0.9719804134929271 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 1.2313578128814697 - sq_loss: 1.3116302397975232e-05 - tot_loss: 0.13985739734660285 - acc: 0.9723884657236126 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 1.2260158061981201 - sq_loss: 1.2954224985151086e-05 - tot_loss: 0.13484194992911114 - acc: 0.9725244831338411 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 1.2286653518676758 - sq_loss: 1.2805944606952835e-05 - tot_loss: 0.1500031965984192 - acc: 0.9726605005440696 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 1.2428860664367676 - sq_loss: 1.2662038898270112e-05 - tot_loss: 0.13240524369106765 - acc: 0.9730685527747551 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 1.2352700233459473 - sq_loss: 1.252020138053922e-05 - tot_loss: 0.1326862240964175 - acc: 0.9732045701849836 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 1.232304334640503 - sq_loss: 1.2378006431390531e-05 - tot_loss: 0.13908041292459927 - acc: 0.9732045701849836 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 1.2331852912902832 - sq_loss: 1.2246159712958615e-05 - tot_loss: 0.1350945847706555 - acc: 0.9732045701849836 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 1.234654188156128 - sq_loss: 1.2117399819544517e-05 - tot_loss: 0.13051771199589268 - acc: 0.9738846572361263 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 1.2150545120239258 - sq_loss: 1.2001521099591628e-05 - tot_loss: 0.13060878424094824 - acc: 0.9740206746463548 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 1.2409441471099854 - sq_loss: 1.1889996130776126e-05 - tot_loss: 0.1344753916082908 - acc: 0.9741566920565833 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 1.2370154857635498 - sq_loss: 1.177312879008241e-05 - tot_loss: 0.12938881364564736 - acc: 0.9741566920565833 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 1.2338404655456543 - sq_loss: 1.1664045814541169e-05 - tot_loss: 0.13162570543371999 - acc: 0.9742927094668118 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 1.2379207611083984 - sq_loss: 1.1552039723028429e-05 - tot_loss: 0.12796992546780928 - acc: 0.9747007616974973 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 1.2305853366851807 - sq_loss: 1.1446648386481684e-05 - tot_loss: 0.12713967296842554 - acc: 0.9748367791077258 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 1.2160515785217285 - sq_loss: 1.1343245205353014e-05 - tot_loss: 0.13124712276152195 - acc: 0.9749727965179543 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 1.222177505493164 - sq_loss: 1.1237019862164743e-05 - tot_loss: 0.13656043295408438 - acc: 0.9756528835690969 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 1.2504048347473145 - sq_loss: 1.114644965127809e-05 - tot_loss: 0.12826793736394393 - acc: 0.9757889009793254 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 1.2323722839355469 - sq_loss: 1.10500641312683e-05 - tot_loss: 0.12265990198811494 - acc: 0.9759249183895539 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 1.2337958812713623 - sq_loss: 1.0960872714349534e-05 - tot_loss: 0.12802962061590506 - acc: 0.9760609357997824 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 1.2316455841064453 - sq_loss: 1.0874469808186404e-05 - tot_loss: 0.12366202545351257 - acc: 0.9761969532100109 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 1.2363507747650146 - sq_loss: 1.0795830348797608e-05 - tot_loss: 0.11869210778583295 - acc: 0.9760609357997824 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 1.2378628253936768 - sq_loss: 1.0715156349760946e-05 - tot_loss: 0.12907932490158203 - acc: 0.9760609357997824 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 1.2338993549346924 - sq_loss: 1.0633732927090023e-05 - tot_loss: 0.12430665511519123 - acc: 0.9761969532100109 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 1.2541413307189941 - sq_loss: 1.055415123119019e-05 - tot_loss: 0.12245558063517592 - acc: 0.9764689880304679 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 1.2284488677978516 - sq_loss: 1.0476913303136826e-05 - tot_loss: 0.1190270328255707 - acc: 0.9764689880304679 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 1.2367138862609863 - sq_loss: 1.0404904969618656e-05 - tot_loss: 0.12560117127608805 - acc: 0.9766050054406964 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 1.2308917045593262 - sq_loss: 1.033052376442356e-05 - tot_loss: 0.12503490220414903 - acc: 0.9766050054406964 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 1.2498676776885986 - sq_loss: 1.0257954272674397e-05 - tot_loss: 0.1211315685755352 - acc: 0.9766050054406964 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 1.2277302742004395 - sq_loss: 1.0183009180764202e-05 - tot_loss: 0.11908526187548318 - acc: 0.9766050054406964 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 1.237208604812622 - sq_loss: 1.0113427379110362e-05 - tot_loss: 0.11566411609092597 - acc: 0.9766050054406964 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 1.231128215789795 - sq_loss: 1.0046738680102862e-05 - tot_loss: 0.11629478865219767 - acc: 0.9768770402611534 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 1.2262394428253174 - sq_loss: 9.985805263568182e-06 - tot_loss: 0.11592895062629793 - acc: 0.9768770402611534 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 1.2329747676849365 - sq_loss: 9.925428457790986e-06 - tot_loss: 0.11992282645464769 - acc: 0.9768770402611534 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 1.2200348377227783 - sq_loss: 9.857991244643927e-06 - tot_loss: 0.12236445599140922 - acc: 0.9772850924918389 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 1.2255346775054932 - sq_loss: 9.792051969270688e-06 - tot_loss: 0.12482125250909348 - acc: 0.9779651795429815 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 1.2277212142944336 - sq_loss: 9.737714208313264e-06 - tot_loss: 0.12629722376176744 - acc: 0.9779651795429815 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 1.2380189895629883 - sq_loss: 9.679503818915691e-06 - tot_loss: 0.11975141077439844 - acc: 0.9782372143634385 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 1.2483139038085938 - sq_loss: 9.62603917287197e-06 - tot_loss: 0.12079875721667577 - acc: 0.9783732317736671 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 1.2277085781097412 - sq_loss: 9.56597341428278e-06 - tot_loss: 0.1149892047640435 - acc: 0.9783732317736671 - val_acc: 0.9586019681031558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 1.2372446060180664 - sq_loss: 9.512520591670182e-06 - tot_loss: 0.11153463821709408 - acc: 0.9789173014145811 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 1.2449934482574463 - sq_loss: 9.458338354306761e-06 - tot_loss: 0.11708549708685467 - acc: 0.9790533188248096 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 1.2773523330688477 - sq_loss: 9.404431693837978e-06 - tot_loss: 0.11025949060682905 - acc: 0.9789173014145811 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 1.2665555477142334 - sq_loss: 9.347408195026219e-06 - tot_loss: 0.10736447685264494 - acc: 0.9789173014145811 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 1.2415809631347656 - sq_loss: 9.298000804847106e-06 - tot_loss: 0.10780876385531712 - acc: 0.9791893362350381 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 1.2411887645721436 - sq_loss: 9.248606147593819e-06 - tot_loss: 0.11326708367798943 - acc: 0.9793253536452666 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 1.2430315017700195 - sq_loss: 9.20691127248574e-06 - tot_loss: 0.1151636871090318 - acc: 0.9793253536452666 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 1.2413568496704102 - sq_loss: 9.16240878723329e-06 - tot_loss: 0.10724167285304276 - acc: 0.9795973884657236 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 1.2580022811889648 - sq_loss: 9.112967745750211e-06 - tot_loss: 0.12114010545310805 - acc: 0.9798694232861807 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 1.2510862350463867 - sq_loss: 9.068718100024853e-06 - tot_loss: 0.11397105138441788 - acc: 0.9798694232861807 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 1.245699167251587 - sq_loss: 9.026566658576485e-06 - tot_loss: 0.11756716450773297 - acc: 0.9802774755168662 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 1.236438274383545 - sq_loss: 8.98805956239812e-06 - tot_loss: 0.11515026142399165 - acc: 0.9804134929270947 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 1.2313745021820068 - sq_loss: 8.946441084844992e-06 - tot_loss: 0.1099731472834975 - acc: 0.9805495103373232 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 1.2259418964385986 - sq_loss: 8.900836292013992e-06 - tot_loss: 0.11108719140344192 - acc: 0.9804134929270947 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 1.2352948188781738 - sq_loss: 8.860230082063936e-06 - tot_loss: 0.10311538325414205 - acc: 0.9805495103373232 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 1.243105411529541 - sq_loss: 8.813372915028594e-06 - tot_loss: 0.11015826508861437 - acc: 0.9805495103373232 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 1.223825216293335 - sq_loss: 8.767237886786461e-06 - tot_loss: 0.11351815324825054 - acc: 0.9808215451577802 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 1.2303893566131592 - sq_loss: 8.729346518521197e-06 - tot_loss: 0.10648339464405865 - acc: 0.9808215451577802 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 1.234194278717041 - sq_loss: 8.690823051438201e-06 - tot_loss: 0.12057952461946542 - acc: 0.9808215451577802 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 1.2355501651763916 - sq_loss: 8.650506060803309e-06 - tot_loss: 0.11099224913618144 - acc: 0.9808215451577802 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 1.2541511058807373 - sq_loss: 8.608931238995865e-06 - tot_loss: 0.11212824766327856 - acc: 0.9808215451577802 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 1.2359490394592285 - sq_loss: 8.570699719712138e-06 - tot_loss: 0.11562370594040772 - acc: 0.9805495103373232 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 1.2212512493133545 - sq_loss: 8.535449524060823e-06 - tot_loss: 0.1102448713432409 - acc: 0.9805495103373232 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 1.2196052074432373 - sq_loss: 8.499026989738923e-06 - tot_loss: 0.11357861493443266 - acc: 0.9806855277475517 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 1.2404217720031738 - sq_loss: 8.463641279377043e-06 - tot_loss: 0.10278356718773551 - acc: 0.9806855277475517 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 1.2208774089813232 - sq_loss: 8.426952263107523e-06 - tot_loss: 0.11196644534788902 - acc: 0.9806855277475517 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 1.2305455207824707 - sq_loss: 8.389934009755962e-06 - tot_loss: 0.10498922985051706 - acc: 0.9812295973884657 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 1.2465438842773438 - sq_loss: 8.35269565868657e-06 - tot_loss: 0.10849033849104472 - acc: 0.9815016322089227 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 1.224775791168213 - sq_loss: 8.3211616583867e-06 - tot_loss: 0.11615590088736383 - acc: 0.9810935799782372 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 1.2245821952819824 - sq_loss: 8.289836841868237e-06 - tot_loss: 0.11114654369544752 - acc: 0.9813656147986942 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 1.2203738689422607 - sq_loss: 8.260632057499606e-06 - tot_loss: 0.11524772135673089 - acc: 0.9815016322089227 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 1.2264671325683594 - sq_loss: 8.231189895013813e-06 - tot_loss: 0.10622462322567117 - acc: 0.9816376496191512 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 1.22031569480896 - sq_loss: 8.198719115171116e-06 - tot_loss: 0.10665113450470898 - acc: 0.9816376496191512 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 1.228564977645874 - sq_loss: 8.162367521435954e-06 - tot_loss: 0.10267086904647016 - acc: 0.9816376496191512 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 1.226961374282837 - sq_loss: 8.12660528026754e-06 - tot_loss: 0.1149127738655622 - acc: 0.9816376496191512 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 1.235851526260376 - sq_loss: 8.095084922388196e-06 - tot_loss: 0.1068773129826397 - acc: 0.9816376496191512 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 1.223109483718872 - sq_loss: 8.066642294579651e-06 - tot_loss: 0.09987697175049703 - acc: 0.9816376496191512 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 1.2304658889770508 - sq_loss: 8.03903731139144e-06 - tot_loss: 0.11684044838678176 - acc: 0.9816376496191512 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 1.2586045265197754 - sq_loss: 8.011317731870804e-06 - tot_loss: 0.12144258036048683 - acc: 0.9817736670293797 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 1.2753875255584717 - sq_loss: 7.981913768162485e-06 - tot_loss: 0.10565500658835703 - acc: 0.9819096844396082 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 1.2327709197998047 - sq_loss: 7.955321052577347e-06 - tot_loss: 0.11690518516252979 - acc: 0.9821817192600653 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 1.2429590225219727 - sq_loss: 7.928562808956485e-06 - tot_loss: 0.10194388600700677 - acc: 0.9821817192600653 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 1.2416515350341797 - sq_loss: 7.898101102910005e-06 - tot_loss: 0.10611698632956745 - acc: 0.9823177366702938 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 1.232435703277588 - sq_loss: 7.870432455092669e-06 - tot_loss: 0.10342876823158065 - acc: 0.9824537540805223 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 1.229611873626709 - sq_loss: 7.841522347007412e-06 - tot_loss: 0.10788901766451175 - acc: 0.9825897714907508 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 1.2266056537628174 - sq_loss: 7.8127886808943e-06 - tot_loss: 0.11180942936758242 - acc: 0.9827257889009793 - val_acc: 0.9606379368849678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 1.224677324295044 - sq_loss: 7.785981324559543e-06 - tot_loss: 0.10040259290168763 - acc: 0.9824537540805223 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 1.2502696514129639 - sq_loss: 7.7615923146368e-06 - tot_loss: 0.10965413722651363 - acc: 0.9828618063112078 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 1.2272357940673828 - sq_loss: 7.736654879408889e-06 - tot_loss: 0.10532449713642222 - acc: 0.9827257889009793 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 1.2262561321258545 - sq_loss: 7.71356098994147e-06 - tot_loss: 0.10205818706710801 - acc: 0.9828618063112078 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 1.2371060848236084 - sq_loss: 7.681620445509907e-06 - tot_loss: 0.10408251292153636 - acc: 0.9828618063112078 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 1.2363154888153076 - sq_loss: 7.653590728295967e-06 - tot_loss: 0.10115613166207993 - acc: 0.9828618063112078 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 1.2384588718414307 - sq_loss: 7.632557753822766e-06 - tot_loss: 0.10524796924208601 - acc: 0.9828618063112078 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 1.238083839416504 - sq_loss: 7.608743999298895e-06 - tot_loss: 0.10451751346279536 - acc: 0.9831338411316648 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 1.2436304092407227 - sq_loss: 7.581615591334412e-06 - tot_loss: 0.11019485170111665 - acc: 0.9829978237214363 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 1.2190320491790771 - sq_loss: 7.558518973382888e-06 - tot_loss: 0.09847724040952954 - acc: 0.9832698585418934 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 1.2381393909454346 - sq_loss: 7.5341822594054975e-06 - tot_loss: 0.10167440288044816 - acc: 0.9832698585418934 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 1.2249197959899902 - sq_loss: 7.507916052418295e-06 - tot_loss: 0.10300161044028755 - acc: 0.9832698585418934 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 1.244680404663086 - sq_loss: 7.484957677661441e-06 - tot_loss: 0.098546811310257 - acc: 0.9831338411316648 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 1.2256855964660645 - sq_loss: 7.462926078005694e-06 - tot_loss: 0.10401450810321933 - acc: 0.9832698585418934 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 1.2451093196868896 - sq_loss: 7.441321031365078e-06 - tot_loss: 0.10950966491813574 - acc: 0.9832698585418934 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 1.2202162742614746 - sq_loss: 7.417100277962163e-06 - tot_loss: 0.10703235151807178 - acc: 0.9832698585418934 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 1.2355859279632568 - sq_loss: 7.391598501271801e-06 - tot_loss: 0.09959547899491383 - acc: 0.9834058759521219 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 1.2485079765319824 - sq_loss: 7.371896117547294e-06 - tot_loss: 0.1112714716011638 - acc: 0.9834058759521219 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 1.2324695587158203 - sq_loss: 7.350163286901079e-06 - tot_loss: 0.09844799723737907 - acc: 0.9835418933623504 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 1.2394540309906006 - sq_loss: 7.325879778363742e-06 - tot_loss: 0.10421159699377469 - acc: 0.9836779107725789 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 1.237555980682373 - sq_loss: 7.3002597673621494e-06 - tot_loss: 0.10275531343713595 - acc: 0.9836779107725789 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 1.2260558605194092 - sq_loss: 7.278651537490077e-06 - tot_loss: 0.09720951513141074 - acc: 0.9838139281828074 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 1.2334346771240234 - sq_loss: 7.251826446008636e-06 - tot_loss: 0.10028143567117453 - acc: 0.9836779107725789 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 1.2327828407287598 - sq_loss: 7.233019914565375e-06 - tot_loss: 0.10775444544444568 - acc: 0.9836779107725789 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 1.25180983543396 - sq_loss: 7.210474905150477e-06 - tot_loss: 0.10135796407791275 - acc: 0.9836779107725789 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 1.2423427104949951 - sq_loss: 7.189246389316395e-06 - tot_loss: 0.10250471543618644 - acc: 0.9838139281828074 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 1.262448787689209 - sq_loss: 7.170840490289265e-06 - tot_loss: 0.10504450452211955 - acc: 0.9836779107725789 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 1.2251760959625244 - sq_loss: 7.149265456973808e-06 - tot_loss: 0.10617137983413016 - acc: 0.9840859630032645 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 1.2211341857910156 - sq_loss: 7.128929155442165e-06 - tot_loss: 0.10116705555785188 - acc: 0.984221980413493 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 1.2456693649291992 - sq_loss: 7.1077438406064175e-06 - tot_loss: 0.10686308936291411 - acc: 0.984221980413493 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 1.2498233318328857 - sq_loss: 7.087142876116559e-06 - tot_loss: 0.10967699166854672 - acc: 0.9840859630032645 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 1.2373747825622559 - sq_loss: 7.063034445309313e-06 - tot_loss: 0.10451530896498085 - acc: 0.9843579978237215 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 1.2428922653198242 - sq_loss: 7.044200174277648e-06 - tot_loss: 0.09766490772971181 - acc: 0.9843579978237215 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 1.2457404136657715 - sq_loss: 7.022361387498677e-06 - tot_loss: 0.1059418013461908 - acc: 0.9846300326441785 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 1.238637924194336 - sq_loss: 7.000514415267389e-06 - tot_loss: 0.0994291769642821 - acc: 0.9849020674646355 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 1.22794771194458 - sq_loss: 6.983684670558432e-06 - tot_loss: 0.10417570174337598 - acc: 0.984766050054407 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 1.2299845218658447 - sq_loss: 6.965091870370088e-06 - tot_loss: 0.0976674320290698 - acc: 0.985038084874864 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 1.2309999465942383 - sq_loss: 6.9462575993384235e-06 - tot_loss: 0.1012248659570858 - acc: 0.985038084874864 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 1.2376484870910645 - sq_loss: 6.9262869146768935e-06 - tot_loss: 0.09549148917620442 - acc: 0.985038084874864 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 1.2274045944213867 - sq_loss: 6.907701845193515e-06 - tot_loss: 0.1020231557192588 - acc: 0.985038084874864 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 1.2354423999786377 - sq_loss: 6.893061254231725e-06 - tot_loss: 0.0973066424393707 - acc: 0.985310119695321 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 1.221097469329834 - sq_loss: 6.87726378600928e-06 - tot_loss: 0.09573080402996226 - acc: 0.9851741022850925 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 1.225667953491211 - sq_loss: 6.860102075734176e-06 - tot_loss: 0.10618041615572693 - acc: 0.985310119695321 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 1.2296628952026367 - sq_loss: 6.8416989051911514e-06 - tot_loss: 0.09612298613307146 - acc: 0.9854461371055495 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 1.225529670715332 - sq_loss: 6.819028840254759e-06 - tot_loss: 0.09650830774275931 - acc: 0.9854461371055495 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 1.2212016582489014 - sq_loss: 6.798419690312585e-06 - tot_loss: 0.10484922488225479 - acc: 0.9854461371055495 - val_acc: 0.9613165931455717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 1.2205634117126465 - sq_loss: 6.7819073592545465e-06 - tot_loss: 0.10183749048830393 - acc: 0.9854461371055495 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 1.2388017177581787 - sq_loss: 6.763453257008223e-06 - tot_loss: 0.09782757872394399 - acc: 0.9854461371055495 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 1.2413408756256104 - sq_loss: 6.746367034793366e-06 - tot_loss: 0.10236440442871952 - acc: 0.9854461371055495 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 1.2415051460266113 - sq_loss: 6.729306733177509e-06 - tot_loss: 0.09971914876850363 - acc: 0.9854461371055495 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 1.2300364971160889 - sq_loss: 6.7114456214767415e-06 - tot_loss: 0.09989926837841523 - acc: 0.9854461371055495 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 1.2245397567749023 - sq_loss: 6.692128863505786e-06 - tot_loss: 0.10411808433569547 - acc: 0.9854461371055495 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 1.2170116901397705 - sq_loss: 6.675903932773508e-06 - tot_loss: 0.0986254005410494 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 1.2295682430267334 - sq_loss: 6.6616553340281826e-06 - tot_loss: 0.10048652288925908 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 1.2231571674346924 - sq_loss: 6.64444814901799e-06 - tot_loss: 0.09760452000233855 - acc: 0.985854189336235 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 1.2350285053253174 - sq_loss: 6.628180472034728e-06 - tot_loss: 0.1075321381116332 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 1.2350335121154785 - sq_loss: 6.612189281440806e-06 - tot_loss: 0.09671805339362649 - acc: 0.9857181719260065 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 1.2337141036987305 - sq_loss: 6.598051641049096e-06 - tot_loss: 0.09789891090062497 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 1.2389910221099854 - sq_loss: 6.582415608136216e-06 - tot_loss: 0.09585845359134737 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 1.2330005168914795 - sq_loss: 6.5649951466184575e-06 - tot_loss: 0.08906276580566796 - acc: 0.985582154515778 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 1.238417148590088 - sq_loss: 6.546445547428448e-06 - tot_loss: 0.09965019279156095 - acc: 0.985582154515778 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 1.2285206317901611 - sq_loss: 6.530603059218265e-06 - tot_loss: 0.0973500680487902 - acc: 0.9854461371055495 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 1.231734275817871 - sq_loss: 6.512743766506901e-06 - tot_loss: 0.1006143875233434 - acc: 0.985582154515778 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 1.2314436435699463 - sq_loss: 6.495637535408605e-06 - tot_loss: 0.09868775187160139 - acc: 0.9854461371055495 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 1.2264809608459473 - sq_loss: 6.478454452008009e-06 - tot_loss: 0.0993290178801054 - acc: 0.985582154515778 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 1.2410473823547363 - sq_loss: 6.459325959440321e-06 - tot_loss: 0.10026191166642562 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 1.237421989440918 - sq_loss: 6.442862286348827e-06 - tot_loss: 0.09644745614391326 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 1.2460319995880127 - sq_loss: 6.4296073105651885e-06 - tot_loss: 0.09873002248876972 - acc: 0.985582154515778 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 1.2579772472381592 - sq_loss: 6.412341917894082e-06 - tot_loss: 0.0940934579844388 - acc: 0.985582154515778 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 1.2447543144226074 - sq_loss: 6.398098321369616e-06 - tot_loss: 0.09938192342465513 - acc: 0.985582154515778 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 1.2546803951263428 - sq_loss: 6.381878847605549e-06 - tot_loss: 0.09481265868422639 - acc: 0.9854461371055495 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 1.260021448135376 - sq_loss: 6.3655343183199875e-06 - tot_loss: 0.09010773828450525 - acc: 0.9854461371055495 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 1.2686481475830078 - sq_loss: 6.349900559143862e-06 - tot_loss: 0.10038770829383736 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 1.2558519840240479 - sq_loss: 6.334103090921417e-06 - tot_loss: 0.09757332175571065 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 1.2439889907836914 - sq_loss: 6.321040473267203e-06 - tot_loss: 0.09171168870011215 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 1.2378385066986084 - sq_loss: 6.305739589151926e-06 - tot_loss: 0.10345355239763876 - acc: 0.9854461371055495 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 1.2359366416931152 - sq_loss: 6.29167016086285e-06 - tot_loss: 0.08900670890943374 - acc: 0.985582154515778 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 1.2332749366760254 - sq_loss: 6.275709438341437e-06 - tot_loss: 0.09272725150359307 - acc: 0.9857181719260065 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 1.2369940280914307 - sq_loss: 6.262486749619711e-06 - tot_loss: 0.0957366256891703 - acc: 0.985854189336235 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 1.2344861030578613 - sq_loss: 6.25107213636511e-06 - tot_loss: 0.09876193915245324 - acc: 0.985854189336235 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 1.249819278717041 - sq_loss: 6.236768967937678e-06 - tot_loss: 0.09399166161145445 - acc: 0.9859902067464635 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 1.2307498455047607 - sq_loss: 6.222173851710977e-06 - tot_loss: 0.09642719254454235 - acc: 0.9859902067464635 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 1.2390611171722412 - sq_loss: 6.206160378496861e-06 - tot_loss: 0.0941581597305543 - acc: 0.985854189336235 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 1.251455307006836 - sq_loss: 6.190707608766388e-06 - tot_loss: 0.10039202473900843 - acc: 0.9859902067464635 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 1.2469542026519775 - sq_loss: 6.175382623041514e-06 - tot_loss: 0.096215988295139 - acc: 0.9859902067464635 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 1.2403318881988525 - sq_loss: 6.163188572827494e-06 - tot_loss: 0.09929271167419884 - acc: 0.9859902067464635 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 1.2515530586242676 - sq_loss: 6.147718977445038e-06 - tot_loss: 0.10515348740812058 - acc: 0.9862622415669206 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 1.2278485298156738 - sq_loss: 6.132958333182614e-06 - tot_loss: 0.1020813689167781 - acc: 0.9862622415669206 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 1.2359099388122559 - sq_loss: 6.119453701103339e-06 - tot_loss: 0.1069842897463893 - acc: 0.9862622415669206 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 1.235929012298584 - sq_loss: 6.1031578297843225e-06 - tot_loss: 0.08993778921566786 - acc: 0.9863982589771491 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 1.2307453155517578 - sq_loss: 6.088989721320104e-06 - tot_loss: 0.0944970584981526 - acc: 0.9863982589771491 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 1.2346522808074951 - sq_loss: 6.07430092713912e-06 - tot_loss: 0.09936748771809079 - acc: 0.9865342763873776 - val_acc: 0.9630132337970818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 1.2137291431427002 - sq_loss: 6.058982307877159e-06 - tot_loss: 0.09328595190620703 - acc: 0.9862622415669206 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 1.2297694683074951 - sq_loss: 6.0437550928327255e-06 - tot_loss: 0.10205912958618768 - acc: 0.9863982589771491 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 1.2344403266906738 - sq_loss: 6.028583811712451e-06 - tot_loss: 0.09253274060323236 - acc: 0.9863982589771491 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 1.2305340766906738 - sq_loss: 6.014894097461365e-06 - tot_loss: 0.09737559111259131 - acc: 0.9866702937976061 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 1.2256097793579102 - sq_loss: 5.998829237796599e-06 - tot_loss: 0.09420877079149292 - acc: 0.9865342763873776 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 1.2282326221466064 - sq_loss: 5.986018095427426e-06 - tot_loss: 0.09641972373655605 - acc: 0.9866702937976061 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 1.2376582622528076 - sq_loss: 5.971942300675437e-06 - tot_loss: 0.10117138529022895 - acc: 0.9866702937976061 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 1.2244937419891357 - sq_loss: 5.9589342527033295e-06 - tot_loss: 0.09245784307965721 - acc: 0.9869423286180631 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 1.2351930141448975 - sq_loss: 5.948787929810351e-06 - tot_loss: 0.10038511475901757 - acc: 0.9869423286180631 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 1.2228705883026123 - sq_loss: 5.939718903391622e-06 - tot_loss: 0.10724485164796604 - acc: 0.9869423286180631 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 1.2363786697387695 - sq_loss: 5.9255503401800524e-06 - tot_loss: 0.09094344603897397 - acc: 0.9873503808487486 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 1.2219035625457764 - sq_loss: 5.91328853261075e-06 - tot_loss: 0.1031803716559061 - acc: 0.9873503808487486 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 1.233750343322754 - sq_loss: 5.899190000491217e-06 - tot_loss: 0.1012254133988364 - acc: 0.9873503808487486 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 1.2326006889343262 - sq_loss: 5.887739462195896e-06 - tot_loss: 0.09401671604766904 - acc: 0.9873503808487486 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 1.2247591018676758 - sq_loss: 5.8708333199319895e-06 - tot_loss: 0.09344073556402321 - acc: 0.9874863982589771 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 1.2399673461914062 - sq_loss: 5.859879365743836e-06 - tot_loss: 0.09542857513548952 - acc: 0.9874863982589771 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 1.2357254028320312 - sq_loss: 5.849532499269117e-06 - tot_loss: 0.09778980811034543 - acc: 0.9872143634385201 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 1.2610132694244385 - sq_loss: 5.837034677824704e-06 - tot_loss: 0.08971145938181024 - acc: 0.9872143634385201 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 1.232780933380127 - sq_loss: 5.8220889513904694e-06 - tot_loss: 0.09094710085651769 - acc: 0.9873503808487486 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 1.2443573474884033 - sq_loss: 5.811084065499017e-06 - tot_loss: 0.10137117541361818 - acc: 0.9873503808487486 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 1.23421049118042 - sq_loss: 5.79275638301624e-06 - tot_loss: 0.09048286704179631 - acc: 0.9878944504896626 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 1.2460801601409912 - sq_loss: 5.778868398920167e-06 - tot_loss: 0.09772296684394988 - acc: 0.9878944504896626 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 1.2430627346038818 - sq_loss: 5.766313279309543e-06 - tot_loss: 0.0959954914062493 - acc: 0.9878944504896626 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 1.2424402236938477 - sq_loss: 5.755624897574307e-06 - tot_loss: 0.09651770723661102 - acc: 0.9878944504896626 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 1.2211031913757324 - sq_loss: 5.7430679589742795e-06 - tot_loss: 0.09575976736228498 - acc: 0.9870783460282916 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 1.2352032661437988 - sq_loss: 5.733689249609597e-06 - tot_loss: 0.09504375774372065 - acc: 0.9872143634385201 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 1.2311601638793945 - sq_loss: 5.7225765885959845e-06 - tot_loss: 0.08202162620487385 - acc: 0.9876224156692056 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 1.2393875122070312 - sq_loss: 5.708669505111175e-06 - tot_loss: 0.09741978088615255 - acc: 0.9880304678998912 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 1.240929365158081 - sq_loss: 5.699210760212736e-06 - tot_loss: 0.09929755447207356 - acc: 0.9878944504896626 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 1.2367875576019287 - sq_loss: 5.687993962055771e-06 - tot_loss: 0.10232128762529769 - acc: 0.9878944504896626 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 1.2251017093658447 - sq_loss: 5.677469289366854e-06 - tot_loss: 0.09454200069271224 - acc: 0.9878944504896626 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 1.2213997840881348 - sq_loss: 5.666377091984032e-06 - tot_loss: 0.09594997328277444 - acc: 0.9880304678998912 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 1.243211030960083 - sq_loss: 5.654011147271376e-06 - tot_loss: 0.09197902747994036 - acc: 0.9877584330794341 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 1.2441823482513428 - sq_loss: 5.642832093144534e-06 - tot_loss: 0.09495807630174724 - acc: 0.9880304678998912 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 1.237480640411377 - sq_loss: 5.636062269331887e-06 - tot_loss: 0.09489914802356125 - acc: 0.9877584330794341 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 1.2397255897521973 - sq_loss: 5.62594732400612e-06 - tot_loss: 0.10221463415390986 - acc: 0.9881664853101197 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 1.221116304397583 - sq_loss: 5.6124063121387735e-06 - tot_loss: 0.10219396035200745 - acc: 0.9881664853101197 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 1.2276108264923096 - sq_loss: 5.599245469056768e-06 - tot_loss: 0.0909655282206927 - acc: 0.9881664853101197 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 1.2341511249542236 - sq_loss: 5.5896280173328705e-06 - tot_loss: 0.1021656529734365 - acc: 0.9881664853101197 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 1.2246131896972656 - sq_loss: 5.577154752245406e-06 - tot_loss: 0.10348433890040454 - acc: 0.9881664853101197 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 1.2452185153961182 - sq_loss: 5.568425422097789e-06 - tot_loss: 0.10331223110861387 - acc: 0.9881664853101197 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 1.2385904788970947 - sq_loss: 5.557209533435525e-06 - tot_loss: 0.09364449664397156 - acc: 0.9877584330794341 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 1.2272546291351318 - sq_loss: 5.5447321756219026e-06 - tot_loss: 0.08943101416602062 - acc: 0.9877584330794341 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 1.2426786422729492 - sq_loss: 5.530816451937426e-06 - tot_loss: 0.10234715308913422 - acc: 0.9877584330794341 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 1.2469608783721924 - sq_loss: 5.521833372768015e-06 - tot_loss: 0.09628252498514911 - acc: 0.9877584330794341 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 1.2443339824676514 - sq_loss: 5.512335064850049e-06 - tot_loss: 0.092823748116583 - acc: 0.9881664853101197 - val_acc: 0.9630132337970818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 1.2322168350219727 - sq_loss: 5.499925464391708e-06 - tot_loss: 0.09513189879212192 - acc: 0.9883025027203483 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 1.2291920185089111 - sq_loss: 5.490118837769842e-06 - tot_loss: 0.0976454040745729 - acc: 0.9880304678998912 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 1.2293376922607422 - sq_loss: 5.480395884660538e-06 - tot_loss: 0.09750394940238394 - acc: 0.9883025027203483 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 1.2329034805297852 - sq_loss: 5.469882580655394e-06 - tot_loss: 0.09314776426242588 - acc: 0.9884385201305768 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 1.239159345626831 - sq_loss: 5.460422471514903e-06 - tot_loss: 0.09703861353646559 - acc: 0.9883025027203483 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 1.264087438583374 - sq_loss: 5.450306616694434e-06 - tot_loss: 0.09526407191864195 - acc: 0.9888465723612623 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 1.2468361854553223 - sq_loss: 5.439010692498414e-06 - tot_loss: 0.10409512234423701 - acc: 0.9887105549510338 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 1.2364184856414795 - sq_loss: 5.423399670689832e-06 - tot_loss: 0.09013733708523475 - acc: 0.9888465723612623 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 1.2493863105773926 - sq_loss: 5.412251994130202e-06 - tot_loss: 0.09537114518870027 - acc: 0.9885745375408053 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 1.2566657066345215 - sq_loss: 5.401307134889066e-06 - tot_loss: 0.09428657159405063 - acc: 0.9889825897714908 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 1.2515594959259033 - sq_loss: 5.3915769058221485e-06 - tot_loss: 0.09795221616843719 - acc: 0.9885745375408053 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 1.2745516300201416 - sq_loss: 5.379981303121895e-06 - tot_loss: 0.10792985989913007 - acc: 0.9888465723612623 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 1.2486908435821533 - sq_loss: 5.370949111238588e-06 - tot_loss: 0.09807394911326384 - acc: 0.9889825897714908 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 1.2561070919036865 - sq_loss: 5.362762294680579e-06 - tot_loss: 0.09229175362380815 - acc: 0.9888465723612623 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 1.2407464981079102 - sq_loss: 5.353545020625461e-06 - tot_loss: 0.0942154301195437 - acc: 0.9884385201305768 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 1.240891695022583 - sq_loss: 5.344047622202197e-06 - tot_loss: 0.08995607343649326 - acc: 0.9884385201305768 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 1.2428114414215088 - sq_loss: 5.3348658184404485e-06 - tot_loss: 0.09817379085212607 - acc: 0.9881664853101197 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 1.2365567684173584 - sq_loss: 5.325906840880634e-06 - tot_loss: 0.09387887991026389 - acc: 0.9883025027203483 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 1.2281708717346191 - sq_loss: 5.315155249263626e-06 - tot_loss: 0.09181259292142485 - acc: 0.9885745375408053 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 1.2245402336120605 - sq_loss: 5.303332272887928e-06 - tot_loss: 0.09509467098007818 - acc: 0.9889825897714908 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 1.2346632480621338 - sq_loss: 5.293175036058528e-06 - tot_loss: 0.08822110685517259 - acc: 0.9888465723612623 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 1.2459828853607178 - sq_loss: 5.2850596148346085e-06 - tot_loss: 0.09732948236111127 - acc: 0.9891186071817193 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 1.2373385429382324 - sq_loss: 5.274895556794945e-06 - tot_loss: 0.09873652953311307 - acc: 0.9891186071817193 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 1.2376117706298828 - sq_loss: 5.2655695981229655e-06 - tot_loss: 0.10119847684728356 - acc: 0.9889825897714908 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 1.2227442264556885 - sq_loss: 5.254901225271169e-06 - tot_loss: 0.09496577525803218 - acc: 0.9888465723612623 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 1.2325718402862549 - sq_loss: 5.245701686362736e-06 - tot_loss: 0.10112318153968403 - acc: 0.9889825897714908 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 1.2340526580810547 - sq_loss: 5.237114237388596e-06 - tot_loss: 0.10002789744696372 - acc: 0.9889825897714908 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 1.2248811721801758 - sq_loss: 5.228225290920818e-06 - tot_loss: 0.09752715354596475 - acc: 0.9891186071817193 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 1.2400941848754883 - sq_loss: 5.221307674219133e-06 - tot_loss: 0.09718319837890022 - acc: 0.9891186071817193 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 1.235752820968628 - sq_loss: 5.211270945437718e-06 - tot_loss: 0.0960684927712201 - acc: 0.9889825897714908 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 1.228832483291626 - sq_loss: 5.1982606237288564e-06 - tot_loss: 0.0959501277578596 - acc: 0.9892546245919478 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 1.2288129329681396 - sq_loss: 5.188169780012686e-06 - tot_loss: 0.09550012007095177 - acc: 0.9891186071817193 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 1.2359857559204102 - sq_loss: 5.177367256692378e-06 - tot_loss: 0.09118359508037344 - acc: 0.9891186071817193 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 1.2361969947814941 - sq_loss: 5.167814379092306e-06 - tot_loss: 0.09292891021360816 - acc: 0.9887105549510338 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 1.2511351108551025 - sq_loss: 5.157349278306356e-06 - tot_loss: 0.10033974106909938 - acc: 0.9885745375408053 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 1.2414801120758057 - sq_loss: 5.146258899912937e-06 - tot_loss: 0.0991315257778922 - acc: 0.9891186071817193 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 1.234684705734253 - sq_loss: 5.137200332683278e-06 - tot_loss: 0.0953592314746885 - acc: 0.9892546245919478 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 1.2233710289001465 - sq_loss: 5.128452357894275e-06 - tot_loss: 0.09174793074625143 - acc: 0.9892546245919478 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 1.2489445209503174 - sq_loss: 5.1186107157263905e-06 - tot_loss: 0.08714685980249115 - acc: 0.9892546245919478 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 1.229691982269287 - sq_loss: 5.107517608848866e-06 - tot_loss: 0.09740942131140073 - acc: 0.9892546245919478 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 1.2275536060333252 - sq_loss: 5.09821893501794e-06 - tot_loss: 0.09314262773902726 - acc: 0.9888465723612623 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 1.2378361225128174 - sq_loss: 5.089822479931172e-06 - tot_loss: 0.08941620075162504 - acc: 0.9892546245919478 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 1.256213665008545 - sq_loss: 5.082815732748713e-06 - tot_loss: 0.09165827964899975 - acc: 0.9895266594124048 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 1.2376055717468262 - sq_loss: 5.075380158814369e-06 - tot_loss: 0.0946375643326256 - acc: 0.9888465723612623 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 1.2608742713928223 - sq_loss: 5.066663106845226e-06 - tot_loss: 0.09673942215256304 - acc: 0.9895266594124048 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 1.2592551708221436 - sq_loss: 5.057710495748324e-06 - tot_loss: 0.08977402770474896 - acc: 0.9895266594124048 - val_acc: 0.9647098744485918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 1.2491366863250732 - sq_loss: 5.047989361628424e-06 - tot_loss: 0.0884987821546872 - acc: 0.9895266594124048 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 1.2441489696502686 - sq_loss: 5.038256858824752e-06 - tot_loss: 0.09114577893776854 - acc: 0.9895266594124048 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 1.251774549484253 - sq_loss: 5.02888860864914e-06 - tot_loss: 0.09537475723752209 - acc: 0.9895266594124048 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 1.257833480834961 - sq_loss: 5.019191121391486e-06 - tot_loss: 0.09284385812165397 - acc: 0.9895266594124048 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 1.2553231716156006 - sq_loss: 5.010731911170296e-06 - tot_loss: 0.10345236482678644 - acc: 0.9895266594124048 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 1.268956184387207 - sq_loss: 5.002052603231277e-06 - tot_loss: 0.0902473040189733 - acc: 0.9895266594124048 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 1.2477543354034424 - sq_loss: 4.993422862753505e-06 - tot_loss: 0.09073723934772104 - acc: 0.9895266594124048 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 1.2474799156188965 - sq_loss: 4.985001851309789e-06 - tot_loss: 0.09690460006311952 - acc: 0.9897986942328618 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 1.2624931335449219 - sq_loss: 4.978236574970651e-06 - tot_loss: 0.08975918266151695 - acc: 0.9897986942328618 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 1.263047218322754 - sq_loss: 4.968657776771579e-06 - tot_loss: 0.09696598686514335 - acc: 0.9897986942328618 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 1.2560293674468994 - sq_loss: 4.961407285009045e-06 - tot_loss: 0.09270237775114154 - acc: 0.9895266594124048 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 1.258061408996582 - sq_loss: 4.953717962052906e-06 - tot_loss: 0.09866443935075964 - acc: 0.9897986942328618 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 1.242558240890503 - sq_loss: 4.94334244649508e-06 - tot_loss: 0.08636876306495722 - acc: 0.9895266594124048 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 1.2636399269104004 - sq_loss: 4.9353757276549e-06 - tot_loss: 0.09859267951225803 - acc: 0.9897986942328618 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 1.257817029953003 - sq_loss: 4.927113877783995e-06 - tot_loss: 0.09666205053589749 - acc: 0.9895266594124048 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 1.2709059715270996 - sq_loss: 4.9174836931342725e-06 - tot_loss: 0.09965492193802916 - acc: 0.9897986942328618 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 1.2511975765228271 - sq_loss: 4.909928065899294e-06 - tot_loss: 0.0918870607175073 - acc: 0.9895266594124048 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 1.246225118637085 - sq_loss: 4.902209639112698e-06 - tot_loss: 0.09273154751946322 - acc: 0.9896626768226333 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 1.242164134979248 - sq_loss: 4.893063760391669e-06 - tot_loss: 0.09147262315045523 - acc: 0.9896626768226333 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 1.2197339534759521 - sq_loss: 4.884982445219066e-06 - tot_loss: 0.08691186726559508 - acc: 0.9897986942328618 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 1.2385542392730713 - sq_loss: 4.876479579252191e-06 - tot_loss: 0.09202838316022621 - acc: 0.9895266594124048 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 1.2434942722320557 - sq_loss: 4.868305040872656e-06 - tot_loss: 0.09561091727351467 - acc: 0.9896626768226333 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 1.239964485168457 - sq_loss: 4.860068202106049e-06 - tot_loss: 0.09568013154386179 - acc: 0.9899347116430903 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 1.2231895923614502 - sq_loss: 4.851814992434811e-06 - tot_loss: 0.09089686554443688 - acc: 0.9899347116430903 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 1.2377922534942627 - sq_loss: 4.8431088544020895e-06 - tot_loss: 0.09262843029159207 - acc: 0.9899347116430903 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 1.2276370525360107 - sq_loss: 4.836625976167852e-06 - tot_loss: 0.08932855116985827 - acc: 0.9899347116430903 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 1.2320740222930908 - sq_loss: 4.829608315048972e-06 - tot_loss: 0.09324260183073108 - acc: 0.9900707290533188 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 1.223144769668579 - sq_loss: 4.823425115318969e-06 - tot_loss: 0.09678279349158814 - acc: 0.9900707290533188 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 1.225370168685913 - sq_loss: 4.815429747395683e-06 - tot_loss: 0.09546718762525508 - acc: 0.9900707290533188 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 1.2239415645599365 - sq_loss: 4.8060273911687545e-06 - tot_loss: 0.09135828733371021 - acc: 0.9900707290533188 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 1.2225215435028076 - sq_loss: 4.798058853339171e-06 - tot_loss: 0.08690604210358366 - acc: 0.9900707290533188 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 1.2290096282958984 - sq_loss: 4.791298579220893e-06 - tot_loss: 0.09008158009675071 - acc: 0.9902067464635473 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 1.2311441898345947 - sq_loss: 4.784580596606247e-06 - tot_loss: 0.08910012532963485 - acc: 0.9900707290533188 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 1.2352914810180664 - sq_loss: 4.7767248361196835e-06 - tot_loss: 0.08602736391110888 - acc: 0.9902067464635473 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 1.220644474029541 - sq_loss: 4.768842700286768e-06 - tot_loss: 0.09350830174317437 - acc: 0.9900707290533188 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 1.2550280094146729 - sq_loss: 4.760039246320957e-06 - tot_loss: 0.09512170888225313 - acc: 0.9903427638737758 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 1.2452378273010254 - sq_loss: 4.754003384732641e-06 - tot_loss: 0.09526182461357457 - acc: 0.9903427638737758 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 1.2514219284057617 - sq_loss: 4.745468231703853e-06 - tot_loss: 0.09489020762378253 - acc: 0.9902067464635473 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 1.2691864967346191 - sq_loss: 4.73815634904895e-06 - tot_loss: 0.09132826605608457 - acc: 0.9902067464635473 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 1.247856616973877 - sq_loss: 4.7309399633377325e-06 - tot_loss: 0.08351616732106137 - acc: 0.9902067464635473 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 1.2500126361846924 - sq_loss: 4.7236180762411095e-06 - tot_loss: 0.0925287200739966 - acc: 0.9903427638737758 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 1.2420337200164795 - sq_loss: 4.714360329671763e-06 - tot_loss: 0.09055859808718658 - acc: 0.9903427638737758 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 1.2335219383239746 - sq_loss: 4.706162144429982e-06 - tot_loss: 0.0985674738418858 - acc: 0.9902067464635473 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 1.2349212169647217 - sq_loss: 4.698415978054982e-06 - tot_loss: 0.09191668139762044 - acc: 0.9903427638737758 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 1.246687412261963 - sq_loss: 4.692904440162238e-06 - tot_loss: 0.09613194329501162 - acc: 0.9903427638737758 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 1.2302072048187256 - sq_loss: 4.689554771175608e-06 - tot_loss: 0.09325382995892006 - acc: 0.9903427638737758 - val_acc: 0.9657278588394977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 1.2450413703918457 - sq_loss: 4.682982307713246e-06 - tot_loss: 0.09470410016142239 - acc: 0.9903427638737758 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 1.2189934253692627 - sq_loss: 4.675995569414226e-06 - tot_loss: 0.10070217247001523 - acc: 0.9903427638737758 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 1.2209296226501465 - sq_loss: 4.669065219786717e-06 - tot_loss: 0.09079502107853266 - acc: 0.9903427638737758 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 1.2266414165496826 - sq_loss: 4.660818376578391e-06 - tot_loss: 0.09240766419779156 - acc: 0.9903427638737758 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 1.2372925281524658 - sq_loss: 4.651935341826174e-06 - tot_loss: 0.09575025693953165 - acc: 0.9903427638737758 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 1.2426824569702148 - sq_loss: 4.642789463105146e-06 - tot_loss: 0.09194797933488985 - acc: 0.9903427638737758 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 1.2442233562469482 - sq_loss: 4.6356090024346486e-06 - tot_loss: 0.08928321363173275 - acc: 0.9904787812840044 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 1.2242588996887207 - sq_loss: 4.628310762200272e-06 - tot_loss: 0.09080232275202071 - acc: 0.9907508161044614 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 1.23643159866333 - sq_loss: 4.622431333700661e-06 - tot_loss: 0.09208817718987916 - acc: 0.9906147986942329 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 1.2271718978881836 - sq_loss: 4.614750650944188e-06 - tot_loss: 0.0947327729392935 - acc: 0.9903427638737758 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 1.2382397651672363 - sq_loss: 4.606893071468221e-06 - tot_loss: 0.09032838013397537 - acc: 0.9904787812840044 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 1.2292695045471191 - sq_loss: 4.598000032274285e-06 - tot_loss: 0.09714893006139036 - acc: 0.9907508161044614 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 1.240703821182251 - sq_loss: 4.5888232307333965e-06 - tot_loss: 0.08751135509997887 - acc: 0.9906147986942329 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 1.2238438129425049 - sq_loss: 4.578871539706597e-06 - tot_loss: 0.0911853621198695 - acc: 0.9907508161044614 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 1.2460803985595703 - sq_loss: 4.5712599785474595e-06 - tot_loss: 0.08966046805959493 - acc: 0.9907508161044614 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 1.2237324714660645 - sq_loss: 4.565017661661841e-06 - tot_loss: 0.08383950012676777 - acc: 0.9904787812840044 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 1.220304012298584 - sq_loss: 4.556550720735686e-06 - tot_loss: 0.08615455455044874 - acc: 0.9906147986942329 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 1.2201905250549316 - sq_loss: 4.5499637053580955e-06 - tot_loss: 0.09027274188663093 - acc: 0.9904787812840044 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 1.2204482555389404 - sq_loss: 4.542869646684267e-06 - tot_loss: 0.08529585441291943 - acc: 0.9904787812840044 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 1.2124998569488525 - sq_loss: 4.535737389232963e-06 - tot_loss: 0.09851827476997599 - acc: 0.9904787812840044 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 1.2229530811309814 - sq_loss: 4.528372755885357e-06 - tot_loss: 0.091032296952271 - acc: 0.9904787812840044 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 1.234935998916626 - sq_loss: 4.523299594438868e-06 - tot_loss: 0.091115947502594 - acc: 0.9907508161044614 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 1.2333624362945557 - sq_loss: 4.517711658991175e-06 - tot_loss: 0.09229179457504522 - acc: 0.9907508161044614 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 1.2236518859863281 - sq_loss: 4.5087567741575185e-06 - tot_loss: 0.09870728639064019 - acc: 0.9908868335146899 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 1.234212875366211 - sq_loss: 4.499774149735458e-06 - tot_loss: 0.0927576459759667 - acc: 0.9907508161044614 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 1.242459774017334 - sq_loss: 4.493708274821984e-06 - tot_loss: 0.09422293412179172 - acc: 0.9907508161044614 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 1.246596097946167 - sq_loss: 4.487163096200675e-06 - tot_loss: 0.08571985875570043 - acc: 0.9910228509249184 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 1.2397472858428955 - sq_loss: 4.4793500819650944e-06 - tot_loss: 0.0942413489020506 - acc: 0.9907508161044614 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 1.2510876655578613 - sq_loss: 4.47279171567061e-06 - tot_loss: 0.09509571227385649 - acc: 0.9908868335146899 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 1.240577220916748 - sq_loss: 4.467153303266969e-06 - tot_loss: 0.09276397902898381 - acc: 0.9907508161044614 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 1.2372655868530273 - sq_loss: 4.460689524421468e-06 - tot_loss: 0.10075507747280277 - acc: 0.9910228509249184 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 1.2421493530273438 - sq_loss: 4.452081157069188e-06 - tot_loss: 0.08937957659038887 - acc: 0.9908868335146899 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 1.2397196292877197 - sq_loss: 4.44509532826487e-06 - tot_loss: 0.09281709804992033 - acc: 0.9908868335146899 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 1.2262907028198242 - sq_loss: 4.439266376721207e-06 - tot_loss: 0.08583261967397071 - acc: 0.9908868335146899 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 1.2461509704589844 - sq_loss: 4.433415142557351e-06 - tot_loss: 0.09316073824407667 - acc: 0.9908868335146899 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 1.247189998626709 - sq_loss: 4.428617558005499e-06 - tot_loss: 0.091642464712967 - acc: 0.9908868335146899 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 1.2328627109527588 - sq_loss: 4.422421625349671e-06 - tot_loss: 0.10240398074759938 - acc: 0.9910228509249184 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 1.240360975265503 - sq_loss: 4.414137947605923e-06 - tot_loss: 0.08509737130530937 - acc: 0.9908868335146899 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 1.240659475326538 - sq_loss: 4.407829237607075e-06 - tot_loss: 0.08599890052914638 - acc: 0.9908868335146899 - val_acc: 0.9657278588394977\n",
      "CR_1 = 0.16759738116197184   CR_2 = 0.1667972504806152\n",
      "/home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 5\n",
    "alpha = 1\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "\n",
    "#alpha1 = alpha2 = alpha3 = alpha4 = alpha5 = alpha6 = alpha7 = alpha8 = alpha9 = alpha10 = alpha\n",
    "#for rank in (35,): #(25,30,35)(100,180,220,260,300,340,380)(20,60,100,140,180,220,260,300,340,380)\n",
    "#    for tau in (400,500): #(300,400,500)(10,50,100,200,300)(10,50,100,200,300)\n",
    "#        for gamma in (0.5,0.8,2): #(0.5,0.8,2)(0.5,0.8)(0.5,1,1.5,2,3)\n",
    "            #gamma1 = gamma2 = gamma3 = gamma4 = gamma5 = gamma\n",
    "#            for rho in (0.5,0.8,2): #(0.5,0.8)(1,2)\n",
    "                #rho1 = rho2 = rho3 = rho4 = rho5= rho\n",
    "#                for alpha in (0.5,1,1.5,2):\n",
    "#                    print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "                    #print('Compression Ratio', ((1024*28*28+10*1024+(8*(rank)+32*np.square(rank))*2)/(1024*28*28+10*1024+1024*1024*2)), (8*(rank)+32*np.square(rank))*2/(1024*1024*2))\n",
    "        \n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    d0 = 561 #561 =3*11*17\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 6 \n",
    "\n",
    "    std_W1 = torch.sqrt(torch.tensor(1. / d0))\n",
    "    W1 =0.2* torch.empty(d1, d0, device=device).normal_(0, std_W1)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    std_W2 = torch.sqrt(torch.tensor(1. / d1))\n",
    "    W2 =0.2* torch.empty(d2, d1, device=device).normal_(0, std_W2)\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles ‘factors’, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    std_W3 = torch.sqrt(torch.tensor(1. / d2))\n",
    "    W3 =0.2* torch.empty(d3, d2, device=device).normal_(0, std_W3)\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    std_W4 = torch.sqrt(torch.tensor(1. / d3))\n",
    "    W4 =0.2* torch.empty(d4, d3, device=device).normal_(0, std_W4)\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "\n",
    "    std_W5 = torch.sqrt(torch.tensor(1. / d4))\n",
    "    W5 =0.2* torch.empty(d5, d4, device=device).normal_(0, std_W5)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = U5 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V5 = (y_one_hot + gamma*U5 + alpha*V5)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U5 = (gamma*V5 + rho*(torch.mm(W5,V4) + b5.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W5, b5 = updateWb_org(U5,V4,W5,b5,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b5.repeat(1, N), W5, a4_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b5.repeat(1, N_test), W5, a4_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V5,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,U5,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4\n",
    "\n",
    "    CR_1=((total_variabels)+(d4*d5))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#this postion to add new row into existing table\n",
    "    #df=pd.read_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "    #new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "    #           'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "    #           'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1], 'seed':seed} \n",
    "    #df=df.append(new_row,ignore_index=True)\n",
    "    #df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"LecunNormal_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895c825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30f34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
