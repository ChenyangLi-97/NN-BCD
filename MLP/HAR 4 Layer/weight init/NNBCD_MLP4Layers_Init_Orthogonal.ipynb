{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccc0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6113fe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 5 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 1.3331913948059082 - sq_loss: 661.6790161132812 - tot_loss: 943.2722693939868 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 1.3223369121551514 - sq_loss: 294.0794372558594 - tot_loss: 472.80204450618476 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 1.2913367748260498 - sq_loss: 161.7793426513672 - tot_loss: 258.726295045577 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 1.3005797863006592 - sq_loss: 87.77423858642578 - tot_loss: 144.54296143585816 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 1.3040597438812256 - sq_loss: 47.226661682128906 - tot_loss: 83.07219670014456 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 1.321232795715332 - sq_loss: 25.333051681518555 - tot_loss: 49.823867531493306 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 1.312023639678955 - sq_loss: 13.59334659576416 - tot_loss: 31.674762989394367 - acc: 0.20375408052230687 - val_acc: 0.19511367492365117\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 1.310920000076294 - sq_loss: 7.313499927520752 - tot_loss: 21.628846051869914 - acc: 0.2687704026115343 - val_acc: 0.2538174414658975\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 1.296051025390625 - sq_loss: 3.95339035987854 - tot_loss: 15.937033374910243 - acc: 0.338139281828074 - val_acc: 0.3203257550050899\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 1.2918593883514404 - sq_loss: 2.1517086029052734 - tot_loss: 12.602851198753342 - acc: 0.35337323177366703 - val_acc: 0.3491686460807601\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 1.282851219177246 - sq_loss: 1.1820347309112549 - tot_loss: 10.55889918084722 - acc: 0.35786180631120784 - val_acc: 0.3505259586019681\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 1.291020154953003 - sq_loss: 0.6573207974433899 - tot_loss: 9.21629844373092 - acc: 0.35840587595212187 - val_acc: 0.3505259586019681\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 1.2863547801971436 - sq_loss: 0.37132954597473145 - tot_loss: 8.27423826372251 - acc: 0.3596300326441785 - val_acc: 0.3522225992534781\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 1.2977256774902344 - sq_loss: 0.2139756679534912 - tot_loss: 7.551516959560104 - acc: 0.38139281828073995 - val_acc: 0.37563624024431624\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 1.3016610145568848 - sq_loss: 0.12637566030025482 - tot_loss: 6.955986027023755 - acc: 0.49333514689880303 - val_acc: 0.47472005429250086\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 1.292785882949829 - sq_loss: 0.07689215242862701 - tot_loss: 6.429790892812889 - acc: 0.5340043525571273 - val_acc: 0.517814726840855\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 1.2821543216705322 - sq_loss: 0.048442646861076355 - tot_loss: 5.959360154694878 - acc: 0.5421653971708379 - val_acc: 0.5266372582287071\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 1.2904455661773682 - sq_loss: 0.031741611659526825 - tot_loss: 5.526733200473245 - acc: 0.5436615886833515 - val_acc: 0.5293518832711231\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 1.2866253852844238 - sq_loss: 0.021699367091059685 - tot_loss: 5.114675722783431 - acc: 0.5444776931447225 - val_acc: 0.5300305395317272\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 1.291163682937622 - sq_loss: 0.015492163598537445 - tot_loss: 4.733600314328214 - acc: 0.544613710554951 - val_acc: 0.5303698676620292\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 1.2923502922058105 - sq_loss: 0.011536653153598309 - tot_loss: 4.382712964667007 - acc: 0.5466539717083787 - val_acc: 0.5303698676620292\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 1.2791249752044678 - sq_loss: 0.008930671028792858 - tot_loss: 4.050827993894927 - acc: 0.5578073993471164 - val_acc: 0.5330844927044452\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 1.2963488101959229 - sq_loss: 0.007150903809815645 - tot_loss: 3.752478714712197 - acc: 0.5863710554951034 - val_acc: 0.5473362741771293\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 1.2862772941589355 - sq_loss: 0.00588937709107995 - tot_loss: 3.4749044227355625 - acc: 0.6414581066376496 - val_acc: 0.5887343060739735\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 1.2909386157989502 - sq_loss: 0.0049613844603300095 - tot_loss: 3.2211927588214166 - acc: 0.6898803046789989 - val_acc: 0.6345436036647438\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 1.2977185249328613 - sq_loss: 0.004254900850355625 - tot_loss: 2.998075845578569 - acc: 0.7272850924918389 - val_acc: 0.6766202918221921\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 1.2898485660552979 - sq_loss: 0.003698853775858879 - tot_loss: 2.783814199399785 - acc: 0.7480957562568009 - val_acc: 0.7044451985069562\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 1.2912378311157227 - sq_loss: 0.0032488692086189985 - tot_loss: 2.5900948266207706 - acc: 0.7633297062023939 - val_acc: 0.7319307770614184\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 1.2799384593963623 - sq_loss: 0.002876689424738288 - tot_loss: 2.4230008959348197 - acc: 0.7736670293797606 - val_acc: 0.7482185273159145\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 1.2982568740844727 - sq_loss: 0.002563441637903452 - tot_loss: 2.261683557619108 - acc: 0.7811479869423286 - val_acc: 0.7617916525279945\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 1.288914442062378 - sq_loss: 0.002296700142323971 - tot_loss: 2.1128548286578734 - acc: 0.7902611534276387 - val_acc: 0.7753647777400746\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 1.2820279598236084 - sq_loss: 0.0020668066572397947 - tot_loss: 1.9807615518948296 - acc: 0.7996463547334058 - val_acc: 0.7872412623006447\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 1.2871654033660889 - sq_loss: 0.0018668124685063958 - tot_loss: 1.8573698927139048 - acc: 0.8099836779107725 - val_acc: 0.7984390906006108\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 1.2736058235168457 - sq_loss: 0.0016916495515033603 - tot_loss: 1.7424508109252201 - acc: 0.8188248095756256 - val_acc: 0.8096369189005769\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 1.2977299690246582 - sq_loss: 0.0015372262569144368 - tot_loss: 1.6341284762020223 - acc: 0.8294341675734495 - val_acc: 0.8187987784187309\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 1.2783212661743164 - sq_loss: 0.001400135224685073 - tot_loss: 1.5404433733820042 - acc: 0.8415397170837867 - val_acc: 0.8266033254156769\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 1.2967534065246582 - sq_loss: 0.0012782823760062456 - tot_loss: 1.4526686617027735 - acc: 0.8503808487486398 - val_acc: 0.834068544282321\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 1.2831029891967773 - sq_loss: 0.001169344293884933 - tot_loss: 1.3637826830490667 - acc: 0.8565016322089227 - val_acc: 0.843909060061079\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 1.2932460308074951 - sq_loss: 0.001071751001290977 - tot_loss: 1.2856302849286294 - acc: 0.8633025027203483 - val_acc: 0.8523922633186292\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 1.2878484725952148 - sq_loss: 0.0009840258862823248 - tot_loss: 1.218981445996178 - acc: 0.8660228509249184 - val_acc: 0.8554462164913471\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 1.2873458862304688 - sq_loss: 0.000904903223272413 - tot_loss: 1.1556707217605435 - acc: 0.8686071817192601 - val_acc: 0.8574821852731591\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 1.2997267246246338 - sq_loss: 0.0008337069302797318 - tot_loss: 1.0872722337971936 - acc: 0.8725516866158868 - val_acc: 0.8649474041398032\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 1.3000812530517578 - sq_loss: 0.0007690477068535984 - tot_loss: 1.0328721784571826 - acc: 0.8745919477693145 - val_acc: 0.8686800135731252\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 1.3058254718780518 - sq_loss: 0.0007102057570591569 - tot_loss: 0.9766946033832937 - acc: 0.875816104461371 - val_acc: 0.8707159823549372\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 1.3079957962036133 - sq_loss: 0.000656819436699152 - tot_loss: 0.9292851384198002 - acc: 0.8779923830250272 - val_acc: 0.8730912792670512\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 1.2854835987091064 - sq_loss: 0.0006081013125367463 - tot_loss: 0.881618272020205 - acc: 0.8800326441784548 - val_acc: 0.8754665761791652\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 1.2950928211212158 - sq_loss: 0.000563646899536252 - tot_loss: 0.8391480424470501 - acc: 0.8827529923830251 - val_acc: 0.8768238887003733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 1.2974371910095215 - sq_loss: 0.0005230962415225804 - tot_loss: 0.7959144891920005 - acc: 0.8841131664853101 - val_acc: 0.8788598574821853\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 1.293478012084961 - sq_loss: 0.00048597133718430996 - tot_loss: 0.7622168185862392 - acc: 0.8861534276387377 - val_acc: 0.8815744825246012\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 1.2952661514282227 - sq_loss: 0.0004520008515100926 - tot_loss: 0.7273503222295403 - acc: 0.8877856365614799 - val_acc: 0.8839497794367153\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 1.2909834384918213 - sq_loss: 0.00042081388528458774 - tot_loss: 0.6920428136490955 - acc: 0.888873775843308 - val_acc: 0.8849677638276213\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 1.2959933280944824 - sq_loss: 0.0003921631723642349 - tot_loss: 0.6588754977183271 - acc: 0.8921381936887922 - val_acc: 0.8893790295215473\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 1.294593095779419 - sq_loss: 0.00036574737168848515 - tot_loss: 0.6320052614373708 - acc: 0.8940424374319913 - val_acc: 0.8914149983033594\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 1.2918014526367188 - sq_loss: 0.0003413198282942176 - tot_loss: 0.606146362916661 - acc: 0.8956746463547334 - val_acc: 0.8917543264336614\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 1.295459270477295 - sq_loss: 0.000318760983645916 - tot_loss: 0.5850911517909481 - acc: 0.8970348204570185 - val_acc: 0.8937902952154734\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 1.294541835784912 - sq_loss: 0.00029801391065120697 - tot_loss: 0.5542276974529159 - acc: 0.8994831338411317 - val_acc: 0.8965049202578894\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 1.294036626815796 - sq_loss: 0.00027884673909284174 - tot_loss: 0.5319492550333962 - acc: 0.9005712731229597 - val_acc: 0.8982015609093994\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 1.2817230224609375 - sq_loss: 0.0002612386888358742 - tot_loss: 0.511018198293641 - acc: 0.9017954298150164 - val_acc: 0.8992195453003053\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 1.2846803665161133 - sq_loss: 0.0002449743915349245 - tot_loss: 0.4941270076642468 - acc: 0.9030195865070729 - val_acc: 0.9019341703427214\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 1.3052253723144531 - sq_loss: 0.00022999568318482488 - tot_loss: 0.47420190456796263 - acc: 0.904107725788901 - val_acc: 0.9053274516457415\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 1.2859020233154297 - sq_loss: 0.0002160696021746844 - tot_loss: 0.46324329741764814 - acc: 0.9064200217627857 - val_acc: 0.9063454360366474\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 1.2898826599121094 - sq_loss: 0.00020315469009801745 - tot_loss: 0.44134779126852663 - acc: 0.9085963003264418 - val_acc: 0.9077027485578555\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 1.3028922080993652 - sq_loss: 0.00019117840565741062 - tot_loss: 0.4230775122805426 - acc: 0.9098204570184983 - val_acc: 0.9100780454699695\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 1.2831432819366455 - sq_loss: 0.0001800545578589663 - tot_loss: 0.4062148163779966 - acc: 0.9106365614798694 - val_acc: 0.9104173736002714\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 1.2886221408843994 - sq_loss: 0.0001696983235888183 - tot_loss: 0.3948545249240851 - acc: 0.9133569096844396 - val_acc: 0.9121140142517815\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 1.2936224937438965 - sq_loss: 0.0001600316900294274 - tot_loss: 0.38514939828337447 - acc: 0.9152611534276387 - val_acc: 0.9141499830335935\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 1.2986104488372803 - sq_loss: 0.00015101948520168662 - tot_loss: 0.37064532478962064 - acc: 0.9170293797606094 - val_acc: 0.9151679674244995\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 1.2890183925628662 - sq_loss: 0.0001426061353413388 - tot_loss: 0.3611090217527817 - acc: 0.9186615886833515 - val_acc: 0.9172039362063115\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 1.2902677059173584 - sq_loss: 0.00013478986511472613 - tot_loss: 0.3422886637345073 - acc: 0.9197497279651795 - val_acc: 0.9182219205972175\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 1.2811672687530518 - sq_loss: 0.00012746798165608197 - tot_loss: 0.33563562216022547 - acc: 0.9215179542981502 - val_acc: 0.9195792331184255\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 1.276085615158081 - sq_loss: 0.00012061187590006739 - tot_loss: 0.32278842146115494 - acc: 0.9227421109902068 - val_acc: 0.9205972175093315\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 1.2912895679473877 - sq_loss: 0.00011421018280088902 - tot_loss: 0.313842919137187 - acc: 0.9245103373231773 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 1.2861557006835938 - sq_loss: 0.0001081631999113597 - tot_loss: 0.30393636931694346 - acc: 0.9255984766050055 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 1.2780535221099854 - sq_loss: 0.00010257449321215972 - tot_loss: 0.29464025147171924 - acc: 0.9270946681175191 - val_acc: 0.9250084832032576\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 1.2942655086517334 - sq_loss: 9.725353447720408e-05 - tot_loss: 0.2862770898912004 - acc: 0.9285908596300326 - val_acc: 0.9253478113335596\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 1.284775972366333 - sq_loss: 9.230161231243983e-05 - tot_loss: 0.2759623589151943 - acc: 0.9304951033732318 - val_acc: 0.9263657957244655\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 1.2794432640075684 - sq_loss: 8.764611993683502e-05 - tot_loss: 0.27148110260600333 - acc: 0.9309031556039173 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 1.2874433994293213 - sq_loss: 8.324124792125076e-05 - tot_loss: 0.26608111985092364 - acc: 0.9323993471164309 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 1.3017926216125488 - sq_loss: 7.914665184216574e-05 - tot_loss: 0.2588210377550695 - acc: 0.9349836779107725 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 1.301774263381958 - sq_loss: 7.528722926508635e-05 - tot_loss: 0.25025361528582835 - acc: 0.9367519042437432 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 1.3003911972045898 - sq_loss: 7.163706322899088e-05 - tot_loss: 0.24060902824248842 - acc: 0.9378400435255713 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 1.28456711769104 - sq_loss: 6.824304000474513e-05 - tot_loss: 0.2385965531959755 - acc: 0.9387921653971708 - val_acc: 0.9345096708517137\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 1.2924883365631104 - sq_loss: 6.500083691207692e-05 - tot_loss: 0.23734430902595705 - acc: 0.9398803046789989 - val_acc: 0.9345096708517137\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 1.2964928150177002 - sq_loss: 6.196884351084009e-05 - tot_loss: 0.22828449493749758 - acc: 0.940968443960827 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 1.2703888416290283 - sq_loss: 5.91380157857202e-05 - tot_loss: 0.2187187766983243 - acc: 0.9419205658324266 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 1.2888197898864746 - sq_loss: 5.643830809276551e-05 - tot_loss: 0.21609698250449583 - acc: 0.9430087051142546 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 1.2893459796905518 - sq_loss: 5.39034117537085e-05 - tot_loss: 0.2106938718420679 - acc: 0.9446409140369967 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 1.2793848514556885 - sq_loss: 5.151319783180952e-05 - tot_loss: 0.20581239425064268 - acc: 0.9462731229597389 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 1.2776520252227783 - sq_loss: 4.92619292344898e-05 - tot_loss: 0.19939857273686812 - acc: 0.9474972796517954 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 1.2925987243652344 - sq_loss: 4.714787792181596e-05 - tot_loss: 0.1984355165178613 - acc: 0.9480413492927094 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 1.2699923515319824 - sq_loss: 4.5138374844100326e-05 - tot_loss: 0.19076634792520508 - acc: 0.9491294885745375 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 1.3047549724578857 - sq_loss: 4.3232565076323226e-05 - tot_loss: 0.18917938546792357 - acc: 0.9498095756256801 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 1.2922084331512451 - sq_loss: 4.14412934333086e-05 - tot_loss: 0.1832539119446892 - acc: 0.9510337323177367 - val_acc: 0.9450288428910757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 1.2817730903625488 - sq_loss: 3.9764669054420665e-05 - tot_loss: 0.18314714720577285 - acc: 0.9515778019586507 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 1.3009538650512695 - sq_loss: 3.814569572568871e-05 - tot_loss: 0.1775559585485098 - acc: 0.9525299238302503 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 1.2975265979766846 - sq_loss: 3.66355488949921e-05 - tot_loss: 0.17501370633237912 - acc: 0.9526659412404788 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 1.2846431732177734 - sq_loss: 3.5188197216484696e-05 - tot_loss: 0.17607703132489405 - acc: 0.9533460282916213 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 1.2892775535583496 - sq_loss: 3.3842665288830176e-05 - tot_loss: 0.17028111716763306 - acc: 0.954570184983678 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 1.291792631149292 - sq_loss: 3.255652336520143e-05 - tot_loss: 0.16253478942633137 - acc: 0.955114254624592 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 1.2729103565216064 - sq_loss: 3.134375947411172e-05 - tot_loss: 0.16515060439940044 - acc: 0.9555223068552775 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 1.2763359546661377 - sq_loss: 3.020231997652445e-05 - tot_loss: 0.1614349077756856 - acc: 0.9560663764961915 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 1.2987678050994873 - sq_loss: 2.9127380912541412e-05 - tot_loss: 0.15570826587065767 - acc: 0.9571545157780196 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 1.2833173274993896 - sq_loss: 2.810685327858664e-05 - tot_loss: 0.15128149991096507 - acc: 0.9582426550598476 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 1.283254861831665 - sq_loss: 2.713627509365324e-05 - tot_loss: 0.14985335292504942 - acc: 0.9590587595212187 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 1.2880561351776123 - sq_loss: 2.6195863028988242e-05 - tot_loss: 0.14820760512799325 - acc: 0.9598748639825898 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 1.2834413051605225 - sq_loss: 2.531086101953406e-05 - tot_loss: 0.15000015215457552 - acc: 0.9602829162132753 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 1.279531717300415 - sq_loss: 2.4494949684594758e-05 - tot_loss: 0.1471055352070607 - acc: 0.9615070729053319 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 1.2790353298187256 - sq_loss: 2.3736791263218038e-05 - tot_loss: 0.1386174337262105 - acc: 0.9624591947769314 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 1.2876765727996826 - sq_loss: 2.3001537556410767e-05 - tot_loss: 0.1393576995290573 - acc: 0.9635473340587595 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 1.3016598224639893 - sq_loss: 2.229614619864151e-05 - tot_loss: 0.14055756179988066 - acc: 0.9647714907508161 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 1.2840030193328857 - sq_loss: 2.1619858671328984e-05 - tot_loss: 0.1355999585596237 - acc: 0.9653155603917302 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 1.2821898460388184 - sq_loss: 2.0985089577152394e-05 - tot_loss: 0.1367553763184901 - acc: 0.9662676822633297 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 1.2828288078308105 - sq_loss: 2.0384788513183594e-05 - tot_loss: 0.13530120682543156 - acc: 0.9666757344940152 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 1.2975311279296875 - sq_loss: 1.9792876628343947e-05 - tot_loss: 0.13033915888939873 - acc: 0.9666757344940152 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 1.289717197418213 - sq_loss: 1.9227396478527226e-05 - tot_loss: 0.12829019247368478 - acc: 0.9670837867247007 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 1.2659194469451904 - sq_loss: 1.8712711607804522e-05 - tot_loss: 0.1237220309374436 - acc: 0.9674918389553863 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 1.2824292182922363 - sq_loss: 1.822759077185765e-05 - tot_loss: 0.125518219273431 - acc: 0.9683079434167573 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 1.2632334232330322 - sq_loss: 1.7764856238500215e-05 - tot_loss: 0.12299399272035316 - acc: 0.9693960826985855 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 1.2875380516052246 - sq_loss: 1.733833778416738e-05 - tot_loss: 0.12571976117794748 - acc: 0.9699401523394995 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 1.2776219844818115 - sq_loss: 1.691666511760559e-05 - tot_loss: 0.12224347836567517 - acc: 0.9702121871599565 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 1.2853491306304932 - sq_loss: 1.651136699365452e-05 - tot_loss: 0.12292239525439186 - acc: 0.970348204570185 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 1.2673203945159912 - sq_loss: 1.6122708984767087e-05 - tot_loss: 0.11663215961218043 - acc: 0.9707562568008705 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 1.28745698928833 - sq_loss: 1.5752257240819745e-05 - tot_loss: 0.12039651213314073 - acc: 0.9710282916213275 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 1.2913384437561035 - sq_loss: 1.540808443678543e-05 - tot_loss: 0.11912168309928006 - acc: 0.9715723612622416 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 1.2882041931152344 - sq_loss: 1.5064337276271544e-05 - tot_loss: 0.11228455608784316 - acc: 0.9719804134929271 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 1.271205186843872 - sq_loss: 1.475183671573177e-05 - tot_loss: 0.11134372790834846 - acc: 0.9721164309031556 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 1.277759313583374 - sq_loss: 1.4460107195191085e-05 - tot_loss: 0.11273270545942182 - acc: 0.9723884657236126 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 1.2947461605072021 - sq_loss: 1.4179562640492804e-05 - tot_loss: 0.11482223241381462 - acc: 0.9726605005440696 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 1.2934544086456299 - sq_loss: 1.3913311704527587e-05 - tot_loss: 0.10998918186868423 - acc: 0.9732045701849836 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 1.2847681045532227 - sq_loss: 1.3657082490681205e-05 - tot_loss: 0.10798016738786487 - acc: 0.9737486398258978 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 1.2870588302612305 - sq_loss: 1.3409347957349382e-05 - tot_loss: 0.10856851452959404 - acc: 0.9741566920565833 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 1.2857563495635986 - sq_loss: 1.316806174145313e-05 - tot_loss: 0.10487950370617227 - acc: 0.9747007616974973 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 1.292144536972046 - sq_loss: 1.2937374776811339e-05 - tot_loss: 0.10483272206438699 - acc: 0.9749727965179543 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 1.296668291091919 - sq_loss: 1.271515338885365e-05 - tot_loss: 0.10536934705928047 - acc: 0.9751088139281828 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 1.29050612449646 - sq_loss: 1.2518814401119016e-05 - tot_loss: 0.10495399482806533 - acc: 0.9756528835690969 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 1.2959880828857422 - sq_loss: 1.2317594155319966e-05 - tot_loss: 0.10220908507255899 - acc: 0.9761969532100109 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 1.2953259944915771 - sq_loss: 1.2118855011067353e-05 - tot_loss: 0.10053323399445446 - acc: 0.9764689880304679 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 1.2974443435668945 - sq_loss: 1.19297392302542e-05 - tot_loss: 0.10203888004211592 - acc: 0.9770130576713819 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 1.3049986362457275 - sq_loss: 1.1745430128939915e-05 - tot_loss: 0.09913834161130808 - acc: 0.9772850924918389 - val_acc: 0.9548693586698337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 1.280820369720459 - sq_loss: 1.1571272807486821e-05 - tot_loss: 0.10020506069048452 - acc: 0.9776931447225244 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 1.285393476486206 - sq_loss: 1.1409703802200966e-05 - tot_loss: 0.10045466485048848 - acc: 0.977829162132753 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 1.2923226356506348 - sq_loss: 1.1252298463659827e-05 - tot_loss: 0.10173223624059347 - acc: 0.977829162132753 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 1.2882411479949951 - sq_loss: 1.1111275853181724e-05 - tot_loss: 0.09966430079020938 - acc: 0.9779651795429815 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 1.2930469512939453 - sq_loss: 1.0978259524563327e-05 - tot_loss: 0.10011600288333966 - acc: 0.9782372143634385 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 1.2838518619537354 - sq_loss: 1.0842535630217753e-05 - tot_loss: 0.09842331120810854 - acc: 0.9786452665941241 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 1.2882978916168213 - sq_loss: 1.0707121873565484e-05 - tot_loss: 0.09938376200777554 - acc: 0.9787812840043526 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 1.2836809158325195 - sq_loss: 1.056803284882335e-05 - tot_loss: 0.09218704270355715 - acc: 0.9789173014145811 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 1.2691738605499268 - sq_loss: 1.044638793246122e-05 - tot_loss: 0.09581511735990489 - acc: 0.9791893362350381 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 1.2979896068572998 - sq_loss: 1.0331162229704205e-05 - tot_loss: 0.0947489421051273 - acc: 0.9791893362350381 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 1.3069641590118408 - sq_loss: 1.0220412150374614e-05 - tot_loss: 0.09187106517001098 - acc: 0.9791893362350381 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 1.302306890487671 - sq_loss: 1.0108272363140713e-05 - tot_loss: 0.09280760319428794 - acc: 0.9794613710554951 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 1.2965481281280518 - sq_loss: 9.998633686336689e-06 - tot_loss: 0.09381199225465764 - acc: 0.9795973884657236 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 1.3046016693115234 - sq_loss: 9.897976269712672e-06 - tot_loss: 0.08964827102724371 - acc: 0.9798694232861807 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 1.3201947212219238 - sq_loss: 9.802040040085558e-06 - tot_loss: 0.09317728708471407 - acc: 0.9800054406964092 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 1.3090991973876953 - sq_loss: 9.706202945380937e-06 - tot_loss: 0.09040375720842775 - acc: 0.9802774755168662 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 1.3112373352050781 - sq_loss: 9.61447130976012e-06 - tot_loss: 0.0884923669727371 - acc: 0.9802774755168662 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 1.2981092929840088 - sq_loss: 9.523433618596755e-06 - tot_loss: 0.08785281462579775 - acc: 0.9805495103373232 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 1.3015494346618652 - sq_loss: 9.434525964024942e-06 - tot_loss: 0.08863037709141963 - acc: 0.9806855277475517 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 1.2855515480041504 - sq_loss: 9.346037586510647e-06 - tot_loss: 0.08646479991500655 - acc: 0.9806855277475517 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 1.2915165424346924 - sq_loss: 9.265547305403743e-06 - tot_loss: 0.08954713417742965 - acc: 0.9808215451577802 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 1.277106523513794 - sq_loss: 9.188021067529917e-06 - tot_loss: 0.08752833560404127 - acc: 0.9809575625680087 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 1.2760224342346191 - sq_loss: 9.106757715926506e-06 - tot_loss: 0.0828141084689662 - acc: 0.9812295973884657 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 1.2865264415740967 - sq_loss: 9.029969078255817e-06 - tot_loss: 0.08475664679367867 - acc: 0.9813656147986942 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 1.2773723602294922 - sq_loss: 8.96403616934549e-06 - tot_loss: 0.08892315038379905 - acc: 0.9816376496191512 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 1.2879765033721924 - sq_loss: 8.901950423023663e-06 - tot_loss: 0.0850762447270128 - acc: 0.9819096844396082 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 1.2803990840911865 - sq_loss: 8.842773240758106e-06 - tot_loss: 0.08710706214957042 - acc: 0.9820457018498367 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 1.2672688961029053 - sq_loss: 8.770939530222677e-06 - tot_loss: 0.0887895272520467 - acc: 0.9825897714907508 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 1.2907569408416748 - sq_loss: 8.703227649675682e-06 - tot_loss: 0.08684326451904667 - acc: 0.9828618063112078 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 1.2757253646850586 - sq_loss: 8.639336556370836e-06 - tot_loss: 0.08965062165390947 - acc: 0.9828618063112078 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 1.281381607055664 - sq_loss: 8.574862476962153e-06 - tot_loss: 0.08342607547873371 - acc: 0.9828618063112078 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 1.2867491245269775 - sq_loss: 8.516823072568513e-06 - tot_loss: 0.08016420200008412 - acc: 0.9829978237214363 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 1.2972497940063477 - sq_loss: 8.45702743390575e-06 - tot_loss: 0.08373859607158352 - acc: 0.9831338411316648 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 1.2895824909210205 - sq_loss: 8.39913082018029e-06 - tot_loss: 0.08390816715140659 - acc: 0.9832698585418934 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 1.2955212593078613 - sq_loss: 8.343419722223189e-06 - tot_loss: 0.0830691533470258 - acc: 0.9832698585418934 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 1.2903392314910889 - sq_loss: 8.292725397041067e-06 - tot_loss: 0.08533658489056961 - acc: 0.9832698585418934 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 1.2765285968780518 - sq_loss: 8.241266186814755e-06 - tot_loss: 0.08065442493335695 - acc: 0.9834058759521219 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 1.2837624549865723 - sq_loss: 8.18985699879704e-06 - tot_loss: 0.08007910737451596 - acc: 0.9836779107725789 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 1.2732415199279785 - sq_loss: 8.141376383719034e-06 - tot_loss: 0.08413825306379152 - acc: 0.9835418933623504 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 1.2819526195526123 - sq_loss: 8.093309588730335e-06 - tot_loss: 0.08262444381829681 - acc: 0.983949945593036 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 1.2963519096374512 - sq_loss: 8.043184607231524e-06 - tot_loss: 0.08285483031656327 - acc: 0.9840859630032645 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 1.3010895252227783 - sq_loss: 7.998786713869777e-06 - tot_loss: 0.0806719090373349 - acc: 0.984221980413493 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 1.2867481708526611 - sq_loss: 7.955182809382677e-06 - tot_loss: 0.07763723482043616 - acc: 0.984221980413493 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 1.2618560791015625 - sq_loss: 7.9134370025713e-06 - tot_loss: 0.0806330285914072 - acc: 0.9843579978237215 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 1.299269437789917 - sq_loss: 7.868990905990358e-06 - tot_loss: 0.08049745173374845 - acc: 0.9846300326441785 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 1.2747883796691895 - sq_loss: 7.824698514014017e-06 - tot_loss: 0.08033289957904088 - acc: 0.9846300326441785 - val_acc: 0.9599592806243638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 1.2878367900848389 - sq_loss: 7.78604135120986e-06 - tot_loss: 0.07918836919031236 - acc: 0.984766050054407 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 1.2904002666473389 - sq_loss: 7.747692507109605e-06 - tot_loss: 0.07635928426585536 - acc: 0.984766050054407 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 1.294083595275879 - sq_loss: 7.710049430897925e-06 - tot_loss: 0.08131529409485694 - acc: 0.9849020674646355 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 1.280777931213379 - sq_loss: 7.667755198781379e-06 - tot_loss: 0.0802311862949523 - acc: 0.9849020674646355 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 1.2835814952850342 - sq_loss: 7.630664185853675e-06 - tot_loss: 0.08104189621109015 - acc: 0.9849020674646355 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 1.2861683368682861 - sq_loss: 7.596946488774847e-06 - tot_loss: 0.07922868334195243 - acc: 0.985038084874864 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 1.27247953414917 - sq_loss: 7.555589036201127e-06 - tot_loss: 0.07488992425398067 - acc: 0.9851741022850925 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 1.2873845100402832 - sq_loss: 7.5161901804676745e-06 - tot_loss: 0.0802453728815351 - acc: 0.9851741022850925 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 1.281731367111206 - sq_loss: 7.477766303054523e-06 - tot_loss: 0.07838993896490365 - acc: 0.9851741022850925 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 1.2903482913970947 - sq_loss: 7.443929462169763e-06 - tot_loss: 0.07557585433912095 - acc: 0.9851741022850925 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 1.2820348739624023 - sq_loss: 7.4079225669265725e-06 - tot_loss: 0.0776818410299569 - acc: 0.985310119695321 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 1.2861642837524414 - sq_loss: 7.375573204626562e-06 - tot_loss: 0.07720265226325651 - acc: 0.985310119695321 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 1.2943856716156006 - sq_loss: 7.339700914599234e-06 - tot_loss: 0.07344940767814734 - acc: 0.9854461371055495 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 1.2819864749908447 - sq_loss: 7.307051419047639e-06 - tot_loss: 0.07662538792186524 - acc: 0.9854461371055495 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 1.2997007369995117 - sq_loss: 7.27766791897011e-06 - tot_loss: 0.07387242464207944 - acc: 0.9854461371055495 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 1.2915544509887695 - sq_loss: 7.248313067975687e-06 - tot_loss: 0.07943135144582314 - acc: 0.985582154515778 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 1.2824862003326416 - sq_loss: 7.219769941002596e-06 - tot_loss: 0.07423745365219148 - acc: 0.985582154515778 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 1.3009262084960938 - sq_loss: 7.189009011199232e-06 - tot_loss: 0.0713407445327583 - acc: 0.9857181719260065 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 1.3011431694030762 - sq_loss: 7.158290372899501e-06 - tot_loss: 0.07241692411457734 - acc: 0.9857181719260065 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 1.2873516082763672 - sq_loss: 7.125598585844273e-06 - tot_loss: 0.07320596503739907 - acc: 0.9857181719260065 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 1.291109561920166 - sq_loss: 7.089158771123039e-06 - tot_loss: 0.07751448521056048 - acc: 0.985582154515778 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 1.2881803512573242 - sq_loss: 7.055264632072067e-06 - tot_loss: 0.07251126756739623 - acc: 0.985582154515778 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 1.2819700241088867 - sq_loss: 7.030674623820232e-06 - tot_loss: 0.07518237563871466 - acc: 0.9854461371055495 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 1.294133186340332 - sq_loss: 7.00802002029377e-06 - tot_loss: 0.07671301807293673 - acc: 0.985582154515778 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 1.285630464553833 - sq_loss: 6.985714207985438e-06 - tot_loss: 0.07398148839321195 - acc: 0.985582154515778 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 1.2954695224761963 - sq_loss: 6.9574844019371085e-06 - tot_loss: 0.07450240084979143 - acc: 0.985582154515778 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 1.280944585800171 - sq_loss: 6.927193680894561e-06 - tot_loss: 0.0771622570885171 - acc: 0.9857181719260065 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 1.308530569076538 - sq_loss: 6.8978411036368925e-06 - tot_loss: 0.07672958094718396 - acc: 0.985582154515778 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 1.299992561340332 - sq_loss: 6.872784979350399e-06 - tot_loss: 0.07215979586975863 - acc: 0.985582154515778 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 1.2985115051269531 - sq_loss: 6.84462747813086e-06 - tot_loss: 0.07034910987464826 - acc: 0.985854189336235 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 1.2864727973937988 - sq_loss: 6.8190324782335665e-06 - tot_loss: 0.07327086370892388 - acc: 0.985854189336235 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 1.292884111404419 - sq_loss: 6.792591648263624e-06 - tot_loss: 0.07164432647442354 - acc: 0.985854189336235 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 1.2857954502105713 - sq_loss: 6.765295438526664e-06 - tot_loss: 0.06804143608913193 - acc: 0.9859902067464635 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 1.283862590789795 - sq_loss: 6.738775937265018e-06 - tot_loss: 0.06812633513830235 - acc: 0.9859902067464635 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 1.3069026470184326 - sq_loss: 6.713318271067692e-06 - tot_loss: 0.07026603542106358 - acc: 0.986126224156692 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 1.2992627620697021 - sq_loss: 6.688292614853708e-06 - tot_loss: 0.0727736959595795 - acc: 0.986126224156692 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 1.298435926437378 - sq_loss: 6.664802185696317e-06 - tot_loss: 0.06727175280526154 - acc: 0.9859902067464635 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 1.2977962493896484 - sq_loss: 6.642349035246298e-06 - tot_loss: 0.068172677041062 - acc: 0.9859902067464635 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 1.2771153450012207 - sq_loss: 6.619923169637332e-06 - tot_loss: 0.07326867120643499 - acc: 0.986126224156692 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 1.2898387908935547 - sq_loss: 6.5966532929451205e-06 - tot_loss: 0.07017881577375462 - acc: 0.986126224156692 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 1.2933170795440674 - sq_loss: 6.572860002052039e-06 - tot_loss: 0.0696532926060307 - acc: 0.986126224156692 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 1.2891881465911865 - sq_loss: 6.552717422891874e-06 - tot_loss: 0.07014999952853529 - acc: 0.9862622415669206 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 1.2869913578033447 - sq_loss: 6.530520749947755e-06 - tot_loss: 0.06861887344468443 - acc: 0.9863982589771491 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 1.2933988571166992 - sq_loss: 6.510023922601249e-06 - tot_loss: 0.06759548309066332 - acc: 0.9863982589771491 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 1.2794384956359863 - sq_loss: 6.490414307336323e-06 - tot_loss: 0.0692765256440886 - acc: 0.9863982589771491 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 1.2727508544921875 - sq_loss: 6.471430424426217e-06 - tot_loss: 0.0673947131896604 - acc: 0.9863982589771491 - val_acc: 0.9613165931455717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 1.3121747970581055 - sq_loss: 6.449321062973468e-06 - tot_loss: 0.07253705439996594 - acc: 0.9863982589771491 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 1.2845227718353271 - sq_loss: 6.424872026400408e-06 - tot_loss: 0.06927196445139572 - acc: 0.9863982589771491 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 1.2976715564727783 - sq_loss: 6.400956408469938e-06 - tot_loss: 0.06932839415727798 - acc: 0.9863982589771491 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 1.2909460067749023 - sq_loss: 6.381609637173824e-06 - tot_loss: 0.07135129009023444 - acc: 0.9863982589771491 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 1.2911710739135742 - sq_loss: 6.361924533848651e-06 - tot_loss: 0.0713882314630716 - acc: 0.9863982589771491 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 1.2794175148010254 - sq_loss: 6.343069799186196e-06 - tot_loss: 0.07039686119468413 - acc: 0.9863982589771491 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 1.2986066341400146 - sq_loss: 6.322979061224032e-06 - tot_loss: 0.06919225396201867 - acc: 0.9863982589771491 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 1.2777702808380127 - sq_loss: 6.30174008620088e-06 - tot_loss: 0.06810580115068632 - acc: 0.9865342763873776 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 1.2869040966033936 - sq_loss: 6.28386760581634e-06 - tot_loss: 0.06732300565530025 - acc: 0.9865342763873776 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 1.295551061630249 - sq_loss: 6.263471732381731e-06 - tot_loss: 0.06840473530915503 - acc: 0.9866702937976061 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 1.2838706970214844 - sq_loss: 6.238806690817e-06 - tot_loss: 0.06419229524327363 - acc: 0.9866702937976061 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 1.2849540710449219 - sq_loss: 6.21957451585331e-06 - tot_loss: 0.07023270632777923 - acc: 0.9866702937976061 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 1.2886626720428467 - sq_loss: 6.201910764502827e-06 - tot_loss: 0.06880604757431641 - acc: 0.9868063112078346 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 1.2783761024475098 - sq_loss: 6.184713129187003e-06 - tot_loss: 0.06597983356003212 - acc: 0.9869423286180631 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 1.2940294742584229 - sq_loss: 6.162756108096801e-06 - tot_loss: 0.0638531144962613 - acc: 0.9868063112078346 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 1.282609462738037 - sq_loss: 6.141039193607867e-06 - tot_loss: 0.0671645551809057 - acc: 0.9869423286180631 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 1.2895286083221436 - sq_loss: 6.121991646068636e-06 - tot_loss: 0.06764645588365426 - acc: 0.9869423286180631 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 1.266857385635376 - sq_loss: 6.1059213294356596e-06 - tot_loss: 0.0701083322111451 - acc: 0.9869423286180631 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 1.2746143341064453 - sq_loss: 6.0884426602569874e-06 - tot_loss: 0.06704845695941941 - acc: 0.9869423286180631 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 1.2896711826324463 - sq_loss: 6.068631591915619e-06 - tot_loss: 0.06820213776448014 - acc: 0.9869423286180631 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 1.2907764911651611 - sq_loss: 6.0512088566611055e-06 - tot_loss: 0.06622409221755632 - acc: 0.9869423286180631 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 1.289731502532959 - sq_loss: 6.032417786627775e-06 - tot_loss: 0.06713203195803175 - acc: 0.9869423286180631 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 1.2913250923156738 - sq_loss: 6.012022367940517e-06 - tot_loss: 0.06804124572513359 - acc: 0.9870783460282916 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 1.2852051258087158 - sq_loss: 5.99364329900709e-06 - tot_loss: 0.0715190910195389 - acc: 0.9870783460282916 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 1.2991626262664795 - sq_loss: 5.9781241361633874e-06 - tot_loss: 0.06837624705689649 - acc: 0.9870783460282916 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 1.3060939311981201 - sq_loss: 5.9594390222628135e-06 - tot_loss: 0.06311478537234194 - acc: 0.9872143634385201 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 1.2896313667297363 - sq_loss: 5.9441308621899225e-06 - tot_loss: 0.06717172017416573 - acc: 0.9872143634385201 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 1.2857694625854492 - sq_loss: 5.926704034209251e-06 - tot_loss: 0.06454110748316211 - acc: 0.9872143634385201 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 1.286606788635254 - sq_loss: 5.910846084589139e-06 - tot_loss: 0.06813372554708153 - acc: 0.9873503808487486 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 1.282752275466919 - sq_loss: 5.895355116081191e-06 - tot_loss: 0.06806707352824759 - acc: 0.9873503808487486 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 1.2761714458465576 - sq_loss: 5.87871818424901e-06 - tot_loss: 0.06350832766326775 - acc: 0.9873503808487486 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 1.2891144752502441 - sq_loss: 5.862227681063814e-06 - tot_loss: 0.07085255488447828 - acc: 0.9874863982589771 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 1.2670273780822754 - sq_loss: 5.8455721045902465e-06 - tot_loss: 0.06660491625945397 - acc: 0.9874863982589771 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 1.2869479656219482 - sq_loss: 5.82869643039885e-06 - tot_loss: 0.06734085242078791 - acc: 0.9874863982589771 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 1.288316249847412 - sq_loss: 5.811184109916212e-06 - tot_loss: 0.0673232822202614 - acc: 0.9874863982589771 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 1.286203145980835 - sq_loss: 5.79296147407149e-06 - tot_loss: 0.06925301629793523 - acc: 0.9874863982589771 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 1.2847278118133545 - sq_loss: 5.775570116384188e-06 - tot_loss: 0.06710470538623525 - acc: 0.9874863982589771 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 1.27903151512146 - sq_loss: 5.761128250014735e-06 - tot_loss: 0.06293203788912649 - acc: 0.9874863982589771 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 1.2871713638305664 - sq_loss: 5.748029707319802e-06 - tot_loss: 0.06670713967701047 - acc: 0.9874863982589771 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 1.2875876426696777 - sq_loss: 5.730132670578314e-06 - tot_loss: 0.06667503808064978 - acc: 0.9874863982589771 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 1.2876851558685303 - sq_loss: 5.7131442190438975e-06 - tot_loss: 0.06441183871528722 - acc: 0.9876224156692056 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 1.2913599014282227 - sq_loss: 5.695834261132404e-06 - tot_loss: 0.07000867814231526 - acc: 0.9876224156692056 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 1.2799556255340576 - sq_loss: 5.681347829522565e-06 - tot_loss: 0.06554212255962 - acc: 0.9876224156692056 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 1.2959010601043701 - sq_loss: 5.6657208915567026e-06 - tot_loss: 0.06956441543394831 - acc: 0.9876224156692056 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 1.2871055603027344 - sq_loss: 5.648735168506391e-06 - tot_loss: 0.06479658953080047 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 1.2881569862365723 - sq_loss: 5.6339467846555635e-06 - tot_loss: 0.06447150282858516 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 1.2865221500396729 - sq_loss: 5.621262971544638e-06 - tot_loss: 0.06351738006273067 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 1.2923519611358643 - sq_loss: 5.608198534901021e-06 - tot_loss: 0.06707395941782224 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 1.2828426361083984 - sq_loss: 5.595087714027613e-06 - tot_loss: 0.06325055955327485 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 1.2790799140930176 - sq_loss: 5.578395303018624e-06 - tot_loss: 0.06446597605654603 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 1.2809619903564453 - sq_loss: 5.563161266763927e-06 - tot_loss: 0.06233799701770337 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 1.2927117347717285 - sq_loss: 5.548332410398871e-06 - tot_loss: 0.06989050844432398 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 1.2835628986358643 - sq_loss: 5.5336695368168876e-06 - tot_loss: 0.06459676129897218 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 1.3033909797668457 - sq_loss: 5.520213107956806e-06 - tot_loss: 0.0683031076918148 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 1.2861354351043701 - sq_loss: 5.5062896535673644e-06 - tot_loss: 0.06324727196886926 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 1.2870862483978271 - sq_loss: 5.491888714459492e-06 - tot_loss: 0.06481043939551512 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 1.2917592525482178 - sq_loss: 5.478749244502978e-06 - tot_loss: 0.06125578653529473 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 1.2888329029083252 - sq_loss: 5.463812613015762e-06 - tot_loss: 0.06380646326604023 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 1.2830233573913574 - sq_loss: 5.44734984941897e-06 - tot_loss: 0.06408853104564471 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 1.2836997509002686 - sq_loss: 5.432115358416922e-06 - tot_loss: 0.06841137138778919 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 1.2876853942871094 - sq_loss: 5.418377440946642e-06 - tot_loss: 0.06313132887024864 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 1.2879002094268799 - sq_loss: 5.40672635906958e-06 - tot_loss: 0.060231025775770775 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 1.3074500560760498 - sq_loss: 5.3941680562275e-06 - tot_loss: 0.0641807016778202 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 1.2873220443725586 - sq_loss: 5.380919901654124e-06 - tot_loss: 0.06322902565214505 - acc: 0.9880304678998912 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 1.2869350910186768 - sq_loss: 5.368625807022909e-06 - tot_loss: 0.06425814170217947 - acc: 0.9880304678998912 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 1.2964301109313965 - sq_loss: 5.353763754101237e-06 - tot_loss: 0.0644695551622938 - acc: 0.9880304678998912 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 1.2953379154205322 - sq_loss: 5.3396283874462824e-06 - tot_loss: 0.06502921863552658 - acc: 0.9880304678998912 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 1.2984354496002197 - sq_loss: 5.330490239430219e-06 - tot_loss: 0.06802322436660901 - acc: 0.9880304678998912 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 1.2905480861663818 - sq_loss: 5.3196254157228395e-06 - tot_loss: 0.06224443161842785 - acc: 0.9880304678998912 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 1.2947900295257568 - sq_loss: 5.306334969645832e-06 - tot_loss: 0.06071785950401676 - acc: 0.9880304678998912 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 1.3005468845367432 - sq_loss: 5.292888999974821e-06 - tot_loss: 0.06132627104442179 - acc: 0.9880304678998912 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 1.290858507156372 - sq_loss: 5.279403467284283e-06 - tot_loss: 0.0628657347660102 - acc: 0.9880304678998912 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 1.2815394401550293 - sq_loss: 5.266594598651864e-06 - tot_loss: 0.06280901074624623 - acc: 0.9880304678998912 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 1.2965800762176514 - sq_loss: 5.251722996035824e-06 - tot_loss: 0.0649959662613746 - acc: 0.9880304678998912 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 1.2889764308929443 - sq_loss: 5.239569873083383e-06 - tot_loss: 0.059515255719119864 - acc: 0.9880304678998912 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 1.285616397857666 - sq_loss: 5.227106157690287e-06 - tot_loss: 0.06464661843690322 - acc: 0.9883025027203483 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 1.306699275970459 - sq_loss: 5.215211331233149e-06 - tot_loss: 0.062353429760461765 - acc: 0.9883025027203483 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 1.2959191799163818 - sq_loss: 5.2037316891073715e-06 - tot_loss: 0.06051916040962446 - acc: 0.9885745375408053 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 1.2876296043395996 - sq_loss: 5.19219884154154e-06 - tot_loss: 0.06262979835100779 - acc: 0.9885745375408053 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 1.272261619567871 - sq_loss: 5.1788147175102495e-06 - tot_loss: 0.06356520199141258 - acc: 0.9885745375408053 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 1.2826156616210938 - sq_loss: 5.166909431864042e-06 - tot_loss: 0.06604362057009716 - acc: 0.9884385201305768 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 1.2907569408416748 - sq_loss: 5.155071448825765e-06 - tot_loss: 0.06160253518382852 - acc: 0.9885745375408053 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 1.2784175872802734 - sq_loss: 5.143646831129445e-06 - tot_loss: 0.060804828661872534 - acc: 0.9885745375408053 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 1.2886581420898438 - sq_loss: 5.13035774929449e-06 - tot_loss: 0.06462186097592593 - acc: 0.9885745375408053 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 1.2871150970458984 - sq_loss: 5.119090928928927e-06 - tot_loss: 0.06080709997444167 - acc: 0.9887105549510338 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 1.2888424396514893 - sq_loss: 5.107944161863998e-06 - tot_loss: 0.0623002477963599 - acc: 0.9887105549510338 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 1.2902698516845703 - sq_loss: 5.094550033390988e-06 - tot_loss: 0.060839266557970006 - acc: 0.9884385201305768 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 1.2810742855072021 - sq_loss: 5.08423499923083e-06 - tot_loss: 0.0630563050141344 - acc: 0.9884385201305768 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 1.3053627014160156 - sq_loss: 5.070978204457788e-06 - tot_loss: 0.05884691148935062 - acc: 0.9885745375408053 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 1.2808341979980469 - sq_loss: 5.059891918790527e-06 - tot_loss: 0.06162391918247678 - acc: 0.9885745375408053 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 1.2916598320007324 - sq_loss: 5.0484936764405575e-06 - tot_loss: 0.061399432848006086 - acc: 0.9885745375408053 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 1.281653642654419 - sq_loss: 5.0386843213345855e-06 - tot_loss: 0.06065662859319687 - acc: 0.9885745375408053 - val_acc: 0.9602986087546658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 1.306692361831665 - sq_loss: 5.026561211707303e-06 - tot_loss: 0.06210401317309078 - acc: 0.9885745375408053 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 1.2863340377807617 - sq_loss: 5.014022917748662e-06 - tot_loss: 0.06266945833147552 - acc: 0.9887105549510338 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 1.2888412475585938 - sq_loss: 5.002545094612287e-06 - tot_loss: 0.06247971116766671 - acc: 0.9889825897714908 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 1.2806313037872314 - sq_loss: 4.990286925021792e-06 - tot_loss: 0.05815366445472314 - acc: 0.9889825897714908 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 1.2758073806762695 - sq_loss: 4.9783166105044074e-06 - tot_loss: 0.0600640682823137 - acc: 0.9889825897714908 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 1.28609299659729 - sq_loss: 4.9673603825795e-06 - tot_loss: 0.06239679737652537 - acc: 0.9892546245919478 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 1.2932336330413818 - sq_loss: 4.956714747095248e-06 - tot_loss: 0.061553401309154765 - acc: 0.9891186071817193 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 1.291621446609497 - sq_loss: 4.945246928400593e-06 - tot_loss: 0.06328578230927384 - acc: 0.9891186071817193 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 1.2883837223052979 - sq_loss: 4.934848220727872e-06 - tot_loss: 0.06130221425673987 - acc: 0.9888465723612623 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 1.2882781028747559 - sq_loss: 4.92537719765096e-06 - tot_loss: 0.0613683406620229 - acc: 0.9892546245919478 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 1.2884016036987305 - sq_loss: 4.915050340059679e-06 - tot_loss: 0.05916414792222291 - acc: 0.9895266594124048 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 1.2794451713562012 - sq_loss: 4.905230071017286e-06 - tot_loss: 0.0624375218046449 - acc: 0.9893906420021763 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 1.2948431968688965 - sq_loss: 4.894597623206209e-06 - tot_loss: 0.06163821649047563 - acc: 0.9895266594124048 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 1.2774479389190674 - sq_loss: 4.882827397523215e-06 - tot_loss: 0.06214559615298043 - acc: 0.9895266594124048 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 1.2748076915740967 - sq_loss: 4.8718911784817465e-06 - tot_loss: 0.056862766936834674 - acc: 0.9895266594124048 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 1.2852952480316162 - sq_loss: 4.860538410866866e-06 - tot_loss: 0.06304022357082495 - acc: 0.9895266594124048 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 1.281188726425171 - sq_loss: 4.850477580475854e-06 - tot_loss: 0.05903666388454454 - acc: 0.9895266594124048 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 1.284618616104126 - sq_loss: 4.8393280849268194e-06 - tot_loss: 0.06404331311505196 - acc: 0.9895266594124048 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 1.2758910655975342 - sq_loss: 4.828161308978451e-06 - tot_loss: 0.06318288198826671 - acc: 0.9895266594124048 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 1.2877564430236816 - sq_loss: 4.817703938897466e-06 - tot_loss: 0.061829112644169015 - acc: 0.9895266594124048 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 1.2888729572296143 - sq_loss: 4.807691311725648e-06 - tot_loss: 0.05919247216798773 - acc: 0.9895266594124048 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 1.2862615585327148 - sq_loss: 4.798247573489789e-06 - tot_loss: 0.0572903192716776 - acc: 0.9895266594124048 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 1.2869439125061035 - sq_loss: 4.788179012393812e-06 - tot_loss: 0.06435484943065184 - acc: 0.9895266594124048 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 1.303189992904663 - sq_loss: 4.779467872140231e-06 - tot_loss: 0.06556757072304364 - acc: 0.9895266594124048 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 1.2885041236877441 - sq_loss: 4.769742645294173e-06 - tot_loss: 0.057306110767427754 - acc: 0.9895266594124048 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 1.2783195972442627 - sq_loss: 4.7590974645572715e-06 - tot_loss: 0.05994521405596487 - acc: 0.9895266594124048 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 1.2891292572021484 - sq_loss: 4.74892931379145e-06 - tot_loss: 0.060514896925534245 - acc: 0.9896626768226333 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 1.2719151973724365 - sq_loss: 4.739108135254355e-06 - tot_loss: 0.061375101623060146 - acc: 0.9897986942328618 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 1.3033652305603027 - sq_loss: 4.730828550236765e-06 - tot_loss: 0.05613514467737346 - acc: 0.9897986942328618 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 1.2922611236572266 - sq_loss: 4.7206663111865055e-06 - tot_loss: 0.06342771569377348 - acc: 0.9897986942328618 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 1.286712408065796 - sq_loss: 4.709374934463995e-06 - tot_loss: 0.06349814835174072 - acc: 0.9896626768226333 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 1.2817792892456055 - sq_loss: 4.701093985204352e-06 - tot_loss: 0.06413379301728028 - acc: 0.9897986942328618 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 1.2933919429779053 - sq_loss: 4.690537025453523e-06 - tot_loss: 0.06104538567564255 - acc: 0.9897986942328618 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 1.2828657627105713 - sq_loss: 4.682591224991484e-06 - tot_loss: 0.06216924379380728 - acc: 0.9897986942328618 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 1.2904698848724365 - sq_loss: 4.673441253544297e-06 - tot_loss: 0.057876753175134965 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 1.2759060859680176 - sq_loss: 4.662498213292565e-06 - tot_loss: 0.06301922097027557 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 1.2962429523468018 - sq_loss: 4.6516784095729236e-06 - tot_loss: 0.05984817146593535 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 1.286210536956787 - sq_loss: 4.639933194994228e-06 - tot_loss: 0.05884357693622455 - acc: 0.9900707290533188 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 1.287841796875 - sq_loss: 4.628774604498176e-06 - tot_loss: 0.06355237300106076 - acc: 0.9900707290533188 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 1.295393705368042 - sq_loss: 4.61985064248438e-06 - tot_loss: 0.06424995089267682 - acc: 0.9902067464635473 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 1.3011059761047363 - sq_loss: 4.6096311052679084e-06 - tot_loss: 0.0612080976321181 - acc: 0.9900707290533188 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 1.304232120513916 - sq_loss: 4.599323347065365e-06 - tot_loss: 0.057925087625974925 - acc: 0.9899347116430903 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 1.300255298614502 - sq_loss: 4.591265678755008e-06 - tot_loss: 0.06363081055183173 - acc: 0.9900707290533188 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 1.2999579906463623 - sq_loss: 4.582620022119954e-06 - tot_loss: 0.06074866160929382 - acc: 0.9900707290533188 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 1.3092761039733887 - sq_loss: 4.5744964154437184e-06 - tot_loss: 0.05932852593347171 - acc: 0.9902067464635473 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 1.2947983741760254 - sq_loss: 4.564157279673964e-06 - tot_loss: 0.06371948220521517 - acc: 0.9902067464635473 - val_acc: 0.9619952494061758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 1.2907483577728271 - sq_loss: 4.554438874038169e-06 - tot_loss: 0.06082400628305784 - acc: 0.9902067464635473 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 1.2772095203399658 - sq_loss: 4.544896455627168e-06 - tot_loss: 0.05845234843004121 - acc: 0.9902067464635473 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 1.27708101272583 - sq_loss: 4.533220817393158e-06 - tot_loss: 0.06513665733461771 - acc: 0.9902067464635473 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 1.285243034362793 - sq_loss: 4.52443464382668e-06 - tot_loss: 0.05751363699470957 - acc: 0.9902067464635473 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 1.2842607498168945 - sq_loss: 4.515912678471068e-06 - tot_loss: 0.05829417731774278 - acc: 0.9902067464635473 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 1.2767436504364014 - sq_loss: 4.507565336098196e-06 - tot_loss: 0.06079140833442764 - acc: 0.9902067464635473 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 1.2725894451141357 - sq_loss: 4.49776416644454e-06 - tot_loss: 0.05805485816774869 - acc: 0.9902067464635473 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 1.29170823097229 - sq_loss: 4.490264927881071e-06 - tot_loss: 0.06244157900663616 - acc: 0.9902067464635473 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 1.2796320915222168 - sq_loss: 4.482012627704535e-06 - tot_loss: 0.05799874753312828 - acc: 0.9902067464635473 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 1.2673063278198242 - sq_loss: 4.473003627936123e-06 - tot_loss: 0.0584707909486184 - acc: 0.9902067464635473 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 1.30265212059021 - sq_loss: 4.466926384338876e-06 - tot_loss: 0.05573710260352982 - acc: 0.9902067464635473 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 1.2858953475952148 - sq_loss: 4.460291165742092e-06 - tot_loss: 0.05856110612772092 - acc: 0.9903427638737758 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 1.2913529872894287 - sq_loss: 4.4501352931547444e-06 - tot_loss: 0.05934608272098707 - acc: 0.9903427638737758 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 1.287663221359253 - sq_loss: 4.442544195626397e-06 - tot_loss: 0.05813053294116877 - acc: 0.9903427638737758 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 1.2856884002685547 - sq_loss: 4.434059974300908e-06 - tot_loss: 0.06250669623154081 - acc: 0.9902067464635473 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 1.2922141551971436 - sq_loss: 4.4276171138335485e-06 - tot_loss: 0.06195733519343882 - acc: 0.9902067464635473 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 1.300027847290039 - sq_loss: 4.418172920850338e-06 - tot_loss: 0.06118404747584982 - acc: 0.9902067464635473 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 1.2726898193359375 - sq_loss: 4.410241217556177e-06 - tot_loss: 0.05915135674332461 - acc: 0.9903427638737758 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 1.2869892120361328 - sq_loss: 4.40218900621403e-06 - tot_loss: 0.06494093557112635 - acc: 0.9900707290533188 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 1.2931036949157715 - sq_loss: 4.394758889247896e-06 - tot_loss: 0.05913178111859807 - acc: 0.9902067464635473 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 1.2760679721832275 - sq_loss: 4.386220098240301e-06 - tot_loss: 0.05953346823234362 - acc: 0.9902067464635473 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 1.313380241394043 - sq_loss: 4.376548076834297e-06 - tot_loss: 0.05947561353785247 - acc: 0.9903427638737758 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 1.2846572399139404 - sq_loss: 4.367612746136729e-06 - tot_loss: 0.05877698412067822 - acc: 0.9903427638737758 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 1.28446626663208 - sq_loss: 4.356381850811886e-06 - tot_loss: 0.06102656903028425 - acc: 0.9902067464635473 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 1.2881693840026855 - sq_loss: 4.347904905444011e-06 - tot_loss: 0.0625659534241052 - acc: 0.9902067464635473 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 1.284581184387207 - sq_loss: 4.34056846643216e-06 - tot_loss: 0.05775217908116126 - acc: 0.9902067464635473 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 1.2843677997589111 - sq_loss: 4.331910986365983e-06 - tot_loss: 0.054991872629702954 - acc: 0.9902067464635473 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 1.3019661903381348 - sq_loss: 4.324427209212445e-06 - tot_loss: 0.058977253014029785 - acc: 0.9903427638737758 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 1.2824039459228516 - sq_loss: 4.3174386519240215e-06 - tot_loss: 0.05965792255503999 - acc: 0.9902067464635473 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 1.289231300354004 - sq_loss: 4.307139079173794e-06 - tot_loss: 0.05685686834663706 - acc: 0.9900707290533188 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 1.2842140197753906 - sq_loss: 4.300066848372808e-06 - tot_loss: 0.05646739569425918 - acc: 0.9902067464635473 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 1.3019154071807861 - sq_loss: 4.2933866097882856e-06 - tot_loss: 0.060854140344346774 - acc: 0.9903427638737758 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 1.2835264205932617 - sq_loss: 4.285862814867869e-06 - tot_loss: 0.05404836762288667 - acc: 0.9902067464635473 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 1.2921855449676514 - sq_loss: 4.277233074390097e-06 - tot_loss: 0.057680288972770555 - acc: 0.9903427638737758 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 1.2999858856201172 - sq_loss: 4.269404143997235e-06 - tot_loss: 0.054621853526217734 - acc: 0.9904787812840044 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 1.3001983165740967 - sq_loss: 4.260858531779377e-06 - tot_loss: 0.056484537002242874 - acc: 0.9904787812840044 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 1.2992033958435059 - sq_loss: 4.253705355949933e-06 - tot_loss: 0.054870620967253814 - acc: 0.9903427638737758 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 1.3021183013916016 - sq_loss: 4.245740001351805e-06 - tot_loss: 0.05952242995476453 - acc: 0.9903427638737758 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 1.3008496761322021 - sq_loss: 4.238473593431991e-06 - tot_loss: 0.05731912358149316 - acc: 0.9904787812840044 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 1.3054707050323486 - sq_loss: 4.230243575875647e-06 - tot_loss: 0.05679507938578432 - acc: 0.9904787812840044 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 1.3052558898925781 - sq_loss: 4.2228853089909535e-06 - tot_loss: 0.05608388855876356 - acc: 0.9903427638737758 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 1.2940688133239746 - sq_loss: 4.215502485749312e-06 - tot_loss: 0.056479691529375486 - acc: 0.9902067464635473 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 1.2988824844360352 - sq_loss: 4.208789505355526e-06 - tot_loss: 0.055695177413483066 - acc: 0.9903427638737758 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 1.2942254543304443 - sq_loss: 4.1984048948506825e-06 - tot_loss: 0.06212155547948939 - acc: 0.9904787812840044 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 1.2870700359344482 - sq_loss: 4.1878224692482036e-06 - tot_loss: 0.05585514484669574 - acc: 0.9903427638737758 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 1.276709794998169 - sq_loss: 4.178878043603618e-06 - tot_loss: 0.06283510273304671 - acc: 0.9904787812840044 - val_acc: 0.9640312181879878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 1.2843372821807861 - sq_loss: 4.172089120402234e-06 - tot_loss: 0.05448649494116786 - acc: 0.9904787812840044 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 1.2908227443695068 - sq_loss: 4.1657776819192804e-06 - tot_loss: 0.061620488290444086 - acc: 0.9904787812840044 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 1.2922987937927246 - sq_loss: 4.157535840931814e-06 - tot_loss: 0.05660546280486578 - acc: 0.9904787812840044 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 1.2900912761688232 - sq_loss: 4.147246272623306e-06 - tot_loss: 0.058020849463760626 - acc: 0.9904787812840044 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 1.2756767272949219 - sq_loss: 4.139929387747543e-06 - tot_loss: 0.055881563891423625 - acc: 0.9904787812840044 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 1.2841112613677979 - sq_loss: 4.134577011427609e-06 - tot_loss: 0.05897966477912853 - acc: 0.9904787812840044 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 1.2816946506500244 - sq_loss: 4.128824912186246e-06 - tot_loss: 0.06339388115516265 - acc: 0.9904787812840044 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 1.2919604778289795 - sq_loss: 4.121357051189989e-06 - tot_loss: 0.05675045154286629 - acc: 0.9906147986942329 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 1.2751092910766602 - sq_loss: 4.115247520530829e-06 - tot_loss: 0.059220496822625535 - acc: 0.9906147986942329 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 1.2844367027282715 - sq_loss: 4.109064320800826e-06 - tot_loss: 0.05498003682695085 - acc: 0.9906147986942329 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 1.293522834777832 - sq_loss: 4.102942511963192e-06 - tot_loss: 0.060833629872671935 - acc: 0.9906147986942329 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 1.2875170707702637 - sq_loss: 4.094756604899885e-06 - tot_loss: 0.05818552015067979 - acc: 0.9906147986942329 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 1.2772626876831055 - sq_loss: 4.086830813321285e-06 - tot_loss: 0.05845151967166551 - acc: 0.9906147986942329 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 1.2760133743286133 - sq_loss: 4.079099198861513e-06 - tot_loss: 0.05611261486480501 - acc: 0.9906147986942329 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 1.2859196662902832 - sq_loss: 4.071953753737034e-06 - tot_loss: 0.05640438023909944 - acc: 0.9906147986942329 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 1.2843174934387207 - sq_loss: 4.066384462930728e-06 - tot_loss: 0.05840609794537954 - acc: 0.9907508161044614 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 1.2977657318115234 - sq_loss: 4.060226729052374e-06 - tot_loss: 0.05675145082838284 - acc: 0.9906147986942329 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 1.2665276527404785 - sq_loss: 4.052111762575805e-06 - tot_loss: 0.05942292963397833 - acc: 0.9907508161044614 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 1.27315354347229 - sq_loss: 4.043673015985405e-06 - tot_loss: 0.06425520355149139 - acc: 0.9907508161044614 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 1.2768335342407227 - sq_loss: 4.036587597511243e-06 - tot_loss: 0.055825073712698625 - acc: 0.9907508161044614 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 1.3093554973602295 - sq_loss: 4.029953743156511e-06 - tot_loss: 0.05785337714756622 - acc: 0.9907508161044614 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 1.3018834590911865 - sq_loss: 4.024358077003853e-06 - tot_loss: 0.05535748452679101 - acc: 0.9907508161044614 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 1.2900633811950684 - sq_loss: 4.016536422568606e-06 - tot_loss: 0.05582894099452851 - acc: 0.9907508161044614 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 1.2855541706085205 - sq_loss: 4.010179509350564e-06 - tot_loss: 0.05842608344934419 - acc: 0.9907508161044614 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 1.2826483249664307 - sq_loss: 4.001434717793018e-06 - tot_loss: 0.06117952007936367 - acc: 0.9907508161044614 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 1.2782983779907227 - sq_loss: 3.995446604676545e-06 - tot_loss: 0.060685857454066294 - acc: 0.9907508161044614 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 1.2805860042572021 - sq_loss: 3.987445779785048e-06 - tot_loss: 0.057473456504835596 - acc: 0.9907508161044614 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 1.290022611618042 - sq_loss: 3.9805918277124874e-06 - tot_loss: 0.057639819828620986 - acc: 0.9907508161044614 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 1.2871019840240479 - sq_loss: 3.974785613536369e-06 - tot_loss: 0.06023448905200013 - acc: 0.9907508161044614 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 1.3120074272155762 - sq_loss: 3.969930730818305e-06 - tot_loss: 0.057870531683143156 - acc: 0.9907508161044614 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 1.2912259101867676 - sq_loss: 3.965456926380284e-06 - tot_loss: 0.0530141925196812 - acc: 0.9907508161044614 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 1.2944881916046143 - sq_loss: 3.960169578931527e-06 - tot_loss: 0.05709873445943181 - acc: 0.9907508161044614 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 1.2933690547943115 - sq_loss: 3.954935436922824e-06 - tot_loss: 0.0566582411302754 - acc: 0.9907508161044614 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 1.2931702136993408 - sq_loss: 3.9493097574450076e-06 - tot_loss: 0.05798054022113419 - acc: 0.9907508161044614 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 1.2694134712219238 - sq_loss: 3.942025614378508e-06 - tot_loss: 0.056321637597317675 - acc: 0.9907508161044614 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 1.3022630214691162 - sq_loss: 3.934973847208312e-06 - tot_loss: 0.05678797395237645 - acc: 0.9907508161044614 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 1.2936863899230957 - sq_loss: 3.927631496480899e-06 - tot_loss: 0.05604913601715111 - acc: 0.9907508161044614 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 1.2888429164886475 - sq_loss: 3.9205638131534215e-06 - tot_loss: 0.057044297157347046 - acc: 0.9907508161044614 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 1.2892048358917236 - sq_loss: 3.913142336386954e-06 - tot_loss: 0.055780121383365966 - acc: 0.9907508161044614 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 1.2745046615600586 - sq_loss: 3.905274297721917e-06 - tot_loss: 0.059961862450157 - acc: 0.9907508161044614 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 1.2730836868286133 - sq_loss: 3.89889964935719e-06 - tot_loss: 0.05682761708370343 - acc: 0.9907508161044614 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 1.2838528156280518 - sq_loss: 3.891608685080428e-06 - tot_loss: 0.055788313888569974 - acc: 0.9907508161044614 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 1.2841730117797852 - sq_loss: 3.88318676414201e-06 - tot_loss: 0.05782226499884757 - acc: 0.9907508161044614 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 1.2921838760375977 - sq_loss: 3.876175469486043e-06 - tot_loss: 0.05713277906167846 - acc: 0.9907508161044614 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 1.294992208480835 - sq_loss: 3.869907232001424e-06 - tot_loss: 0.057672924062742936 - acc: 0.9907508161044614 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 1.2824089527130127 - sq_loss: 3.864457994495751e-06 - tot_loss: 0.05826718484130211 - acc: 0.9907508161044614 - val_acc: 0.9664065151001018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 1.2916502952575684 - sq_loss: 3.85966086469125e-06 - tot_loss: 0.05386531326490562 - acc: 0.9907508161044614 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 1.2775061130523682 - sq_loss: 3.853873749903869e-06 - tot_loss: 0.058550376416366845 - acc: 0.9907508161044614 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 1.2965831756591797 - sq_loss: 3.845966602966655e-06 - tot_loss: 0.05880224189412431 - acc: 0.9907508161044614 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 1.2930970191955566 - sq_loss: 3.840902991214534e-06 - tot_loss: 0.05661751615064503 - acc: 0.9907508161044614 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 1.295882225036621 - sq_loss: 3.832974471151829e-06 - tot_loss: 0.05270220627759947 - acc: 0.9907508161044614 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 1.2873046398162842 - sq_loss: 3.827164618996903e-06 - tot_loss: 0.057951233904415034 - acc: 0.9907508161044614 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 1.2783026695251465 - sq_loss: 3.819833182205912e-06 - tot_loss: 0.05497216543604999 - acc: 0.9907508161044614 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 1.2906131744384766 - sq_loss: 3.8126192976051243e-06 - tot_loss: 0.06068218265871472 - acc: 0.9907508161044614 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 1.3089745044708252 - sq_loss: 3.804622565439786e-06 - tot_loss: 0.05572526314334425 - acc: 0.9907508161044614 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 1.2890570163726807 - sq_loss: 3.79629636881873e-06 - tot_loss: 0.057049269363069754 - acc: 0.9907508161044614 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 1.3004040718078613 - sq_loss: 3.7895047171332408e-06 - tot_loss: 0.05569215780779757 - acc: 0.9907508161044614 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 1.2981250286102295 - sq_loss: 3.784426780839567e-06 - tot_loss: 0.05778156514829291 - acc: 0.9907508161044614 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 1.3031210899353027 - sq_loss: 3.7782997424073983e-06 - tot_loss: 0.06046141314086739 - acc: 0.9907508161044614 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 1.2877984046936035 - sq_loss: 3.772902346099727e-06 - tot_loss: 0.05760686047211472 - acc: 0.9907508161044614 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 1.2863068580627441 - sq_loss: 3.7676798001484713e-06 - tot_loss: 0.0553105312372022 - acc: 0.9907508161044614 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 1.2908401489257812 - sq_loss: 3.763403810808086e-06 - tot_loss: 0.05852380885348474 - acc: 0.9907508161044614 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 1.2964377403259277 - sq_loss: 3.7586221424135147e-06 - tot_loss: 0.05660406217354641 - acc: 0.9907508161044614 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 1.297231674194336 - sq_loss: 3.752151542357751e-06 - tot_loss: 0.05885854385213207 - acc: 0.9907508161044614 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 1.2928962707519531 - sq_loss: 3.7451447951752925e-06 - tot_loss: 0.057017087335967886 - acc: 0.9907508161044614 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 1.27988862991333 - sq_loss: 3.7380038975243224e-06 - tot_loss: 0.058009491145238457 - acc: 0.9907508161044614 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 1.2805705070495605 - sq_loss: 3.7314619021344697e-06 - tot_loss: 0.05485489322144943 - acc: 0.9907508161044614 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 1.2663471698760986 - sq_loss: 3.7271361179591622e-06 - tot_loss: 0.059116689304298475 - acc: 0.9907508161044614 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 1.2948286533355713 - sq_loss: 3.7221095681161387e-06 - tot_loss: 0.05460238701837561 - acc: 0.9907508161044614 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 1.2897698879241943 - sq_loss: 3.7178294860495953e-06 - tot_loss: 0.05590553749163263 - acc: 0.9907508161044614 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 1.2819929122924805 - sq_loss: 3.7134327612875495e-06 - tot_loss: 0.056210277045645185 - acc: 0.9907508161044614 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 1.2900848388671875 - sq_loss: 3.70793895854149e-06 - tot_loss: 0.05824760331659995 - acc: 0.9907508161044614 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 1.2722642421722412 - sq_loss: 3.7009333482274087e-06 - tot_loss: 0.060431115696053084 - acc: 0.9907508161044614 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 1.2892193794250488 - sq_loss: 3.6957299016648903e-06 - tot_loss: 0.05406002757113626 - acc: 0.9907508161044614 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 1.2753572463989258 - sq_loss: 3.6907226785842795e-06 - tot_loss: 0.05876848876441443 - acc: 0.9908868335146899 - val_acc: 0.9681031557516118\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 1.290771484375 - sq_loss: 3.6862536489934428e-06 - tot_loss: 0.059158740789975184 - acc: 0.9908868335146899 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 1.2835021018981934 - sq_loss: 3.679526344058104e-06 - tot_loss: 0.05707045483498874 - acc: 0.9908868335146899 - val_acc: 0.9681031557516118\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 1.289013147354126 - sq_loss: 3.674609388326644e-06 - tot_loss: 0.05612594406811766 - acc: 0.9908868335146899 - val_acc: 0.9684424838819138\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 1.2901649475097656 - sq_loss: 3.669837042252766e-06 - tot_loss: 0.06293247664757295 - acc: 0.9907508161044614 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 1.2978670597076416 - sq_loss: 3.661406481114682e-06 - tot_loss: 0.0524213004790024 - acc: 0.9908868335146899 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 1.2944347858428955 - sq_loss: 3.656323769973824e-06 - tot_loss: 0.056518180282132846 - acc: 0.9908868335146899 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 1.2866237163543701 - sq_loss: 3.6519766126730246e-06 - tot_loss: 0.05556810184072347 - acc: 0.9908868335146899 - val_acc: 0.9681031557516118\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 1.2871754169464111 - sq_loss: 3.646445748017868e-06 - tot_loss: 0.054311367834818824 - acc: 0.9908868335146899 - val_acc: 0.9684424838819138\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 1.2788894176483154 - sq_loss: 3.641695457190508e-06 - tot_loss: 0.059015140768611474 - acc: 0.9908868335146899 - val_acc: 0.9684424838819138\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 1.272902250289917 - sq_loss: 3.636936526163481e-06 - tot_loss: 0.062338534680908 - acc: 0.9908868335146899 - val_acc: 0.9681031557516118\n",
      "CR_1 = 0.16759738116197184   CR_2 = 0.1667972504806152\n",
      "/home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 5\n",
    "alpha = 1\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "\n",
    "#alpha1 = alpha2 = alpha3 = alpha4 = alpha5 = alpha6 = alpha7 = alpha8 = alpha9 = alpha10 = alpha\n",
    "#for rank in (35,): #(25,30,35)(100,180,220,260,300,340,380)(20,60,100,140,180,220,260,300,340,380)\n",
    "#    for tau in (400,500): #(300,400,500)(10,50,100,200,300)(10,50,100,200,300)\n",
    "#        for gamma in (0.5,0.8,2): #(0.5,0.8,2)(0.5,0.8)(0.5,1,1.5,2,3)\n",
    "            #gamma1 = gamma2 = gamma3 = gamma4 = gamma5 = gamma\n",
    "#            for rho in (0.5,0.8,2): #(0.5,0.8)(1,2)\n",
    "                #rho1 = rho2 = rho3 = rho4 = rho5= rho\n",
    "#                for alpha in (0.5,1,1.5,2):\n",
    "#                    print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "                    #print('Compression Ratio', ((1024*28*28+10*1024+(8*(rank)+32*np.square(rank))*2)/(1024*28*28+10*1024+1024*1024*2)), (8*(rank)+32*np.square(rank))*2/(1024*1024*2))\n",
    "        \n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    d0 = 561 #561 =3*11*17\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 6 \n",
    "\n",
    "    W1 = 0.2*init.orthogonal_(torch.empty(d1, d0, device=device), gain=1.0)\n",
    "    #W1 = 0.01*torch.randn(d1, d0, device=device)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    W2 = 0.2*init.orthogonal_(torch.empty(d2, d1, device=device), gain=1.0)\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles factors, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    W3 = 0.2*init.orthogonal_(torch.empty(d3, d2, device=device), gain=1.0)\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    W4 = 0.2*init.orthogonal_(torch.empty(d4, d3, device=device), gain=1.0)\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "\n",
    "    W5 = 0.2*init.orthogonal_(torch.empty(d5, d4, device=device), gain=1.0)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = U5 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V5 = (y_one_hot + gamma*U5 + alpha*V5)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U5 = (gamma*V5 + rho*(torch.mm(W5,V4) + b5.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W5, b5 = updateWb_org(U5,V4,W5,b5,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b5.repeat(1, N), W5, a4_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b5.repeat(1, N_test), W5, a4_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V5,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,U5,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4\n",
    "\n",
    "    CR_1=((total_variabels)+(d4*d5))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#this postion to add new row into existing table\n",
    "    #df=pd.read_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "    #new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "    #           'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "    #           'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1], 'seed':seed} \n",
    "    #df=df.append(new_row,ignore_index=True)\n",
    "    #df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"Orthogonal_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895c825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30f34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
