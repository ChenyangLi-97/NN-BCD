{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccc0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6113fe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 5 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 2.6375598907470703 - sq_loss: 661.6377563476562 - tot_loss: 1252.4216935971053 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 2.6039326190948486 - sq_loss: 294.0611877441406 - tot_loss: 515.9870989508927 - acc: 0.176550598476605 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 2.5808520317077637 - sq_loss: 157.22232055664062 - tot_loss: 292.56710113584995 - acc: 0.31120783460282914 - val_acc: 0.27315914489311166\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 2.5344326496124268 - sq_loss: 84.4797592163086 - tot_loss: 174.0689796321094 - acc: 0.3261697497279652 - val_acc: 0.2982694265354598\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 2.59975004196167 - sq_loss: 45.32595443725586 - tot_loss: 108.69854910112917 - acc: 0.3373231773667029 - val_acc: 0.3182897862232779\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 2.61633563041687 - sq_loss: 24.311105728149414 - tot_loss: 72.05248855240643 - acc: 0.3426278563656148 - val_acc: 0.32507634882931796\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 2.561370849609375 - sq_loss: 13.060256958007812 - tot_loss: 50.951427510008216 - acc: 0.352285092491839 - val_acc: 0.33016627078384797\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 2.596872091293335 - sq_loss: 7.040354251861572 - tot_loss: 38.400325768627226 - acc: 0.3691512513601741 - val_acc: 0.3498473023413641\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 2.5812668800354004 - sq_loss: 3.815492630004883 - tot_loss: 30.56348636187613 - acc: 0.4011153427638738 - val_acc: 0.37597556837461826\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 2.5890254974365234 - sq_loss: 2.083091974258423 - tot_loss: 25.396837170701474 - acc: 0.4291349292709467 - val_acc: 0.4014251781472684\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 2.577585458755493 - sq_loss: 1.148398756980896 - tot_loss: 21.78934295848012 - acc: 0.45688248095756256 - val_acc: 0.42246352222599254\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 2.5722668170928955 - sq_loss: 0.6410660743713379 - tot_loss: 19.12579862680286 - acc: 0.492791077257889 - val_acc: 0.4479131319986427\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 2.541215658187866 - sq_loss: 0.3635235130786896 - tot_loss: 17.038368748733774 - acc: 0.528835690968444 - val_acc: 0.47743467933491684\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 2.6228232383728027 - sq_loss: 0.21018095314502716 - tot_loss: 15.342760690720752 - acc: 0.5682807399347116 - val_acc: 0.5242619613165932\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 2.569901466369629 - sq_loss: 0.12441056966781616 - tot_loss: 13.922967773862183 - acc: 0.6118063112078346 - val_acc: 0.5717678995588734\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 2.6169021129608154 - sq_loss: 0.07572069019079208 - tot_loss: 12.716503452160396 - acc: 0.654107725788901 - val_acc: 0.6182558534102477\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 2.6080760955810547 - sq_loss: 0.047589581459760666 - tot_loss: 11.6676962118363 - acc: 0.6953210010881393 - val_acc: 0.664743807261622\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 2.65095853805542 - sq_loss: 0.031003449112176895 - tot_loss: 10.754253627208527 - acc: 0.7291893362350381 - val_acc: 0.6959619952494062\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 2.642634391784668 - sq_loss: 0.02099757082760334 - tot_loss: 9.921587562130298 - acc: 0.7558487486398259 - val_acc: 0.7210722768917543\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 2.590210199356079 - sq_loss: 0.014804388396441936 - tot_loss: 9.199026979738846 - acc: 0.7776115342763874 - val_acc: 0.7451645741431965\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 2.6697518825531006 - sq_loss: 0.010863112285733223 - tot_loss: 8.541587210434955 - acc: 0.7932535364526659 - val_acc: 0.7573803868340685\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 2.613337993621826 - sq_loss: 0.00827992707490921 - tot_loss: 7.957397903810488 - acc: 0.8037268770402611 - val_acc: 0.7706141839158466\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 2.5991005897521973 - sq_loss: 0.006534186191856861 - tot_loss: 7.431105553987436 - acc: 0.8091675734494015 - val_acc: 0.7770614183915847\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 2.5420403480529785 - sq_loss: 0.005315704736858606 - tot_loss: 6.935359309398336 - acc: 0.8155603917301415 - val_acc: 0.7845266372582287\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 2.583508014678955 - sq_loss: 0.004438234493136406 - tot_loss: 6.506440159631893 - acc: 0.8196409140369967 - val_acc: 0.7892772310824567\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 2.562466621398926 - sq_loss: 0.0037871638778597116 - tot_loss: 6.109814520692453 - acc: 0.8244015233949945 - val_acc: 0.7916525279945708\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 2.6092936992645264 - sq_loss: 0.0032897351775318384 - tot_loss: 5.759234884928446 - acc: 0.8267138193688792 - val_acc: 0.7950458092975907\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 2.574777126312256 - sq_loss: 0.0028989934362471104 - tot_loss: 5.42430650453025 - acc: 0.830386289445049 - val_acc: 0.7967424499491008\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 2.59032940864563 - sq_loss: 0.0025843288749456406 - tot_loss: 5.108344703592593 - acc: 0.8324265505984766 - val_acc: 0.8018323719036308\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 2.5585358142852783 - sq_loss: 0.0023256600834429264 - tot_loss: 4.821383911563316 - acc: 0.8355549510337323 - val_acc: 0.8052256532066508\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 2.6257898807525635 - sq_loss: 0.0021087047643959522 - tot_loss: 4.583902180631412 - acc: 0.8382752992383025 - val_acc: 0.8082796063793688\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 2.5996410846710205 - sq_loss: 0.0019239201210439205 - tot_loss: 4.330450873370864 - acc: 0.8416757344940152 - val_acc: 0.8113335595520869\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 2.602496385574341 - sq_loss: 0.0017639370635151863 - tot_loss: 4.097137918273802 - acc: 0.846436343852013 - val_acc: 0.8140481845945029\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 2.6342878341674805 - sq_loss: 0.0016243744175881147 - tot_loss: 3.883139593526721 - acc: 0.8486126224156693 - val_acc: 0.8167628096369189\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 2.581127405166626 - sq_loss: 0.0015009144553914666 - tot_loss: 3.6883729140099604 - acc: 0.8510609357997824 - val_acc: 0.8184594502884289\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 2.5183608531951904 - sq_loss: 0.00139081128872931 - tot_loss: 3.5221822302264627 - acc: 0.852829162132753 - val_acc: 0.8218527315914489\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 2.5956993103027344 - sq_loss: 0.0012916522100567818 - tot_loss: 3.350883947692637 - acc: 0.8545973884657236 - val_acc: 0.8245673566338649\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 2.583430290222168 - sq_loss: 0.0012022844748571515 - tot_loss: 3.1924353315043845 - acc: 0.8565016322089227 - val_acc: 0.825585341024771\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 2.5512919425964355 - sq_loss: 0.0011212428798899055 - tot_loss: 3.035446563575533 - acc: 0.859221980413493 - val_acc: 0.8262639972853749\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 2.5914011001586914 - sq_loss: 0.0010472375433892012 - tot_loss: 2.9067377022947767 - acc: 0.8612622415669206 - val_acc: 0.827960637936885\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 2.588597297668457 - sq_loss: 0.0009796455269679427 - tot_loss: 2.7586409654613817 - acc: 0.8646626768226333 - val_acc: 0.831014591109603\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 2.5860726833343506 - sq_loss: 0.0009178829495795071 - tot_loss: 2.6177258160241763 - acc: 0.8677910772578891 - val_acc: 0.833050559891415\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 2.571403980255127 - sq_loss: 0.0008611303637735546 - tot_loss: 2.526405935830553 - acc: 0.8703754080522307 - val_acc: 0.834407872412623\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 2.5997416973114014 - sq_loss: 0.0008087278110906482 - tot_loss: 2.425700979321846 - acc: 0.8732317736670294 - val_acc: 0.837122497455039\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 2.5542070865631104 - sq_loss: 0.0007604414131492376 - tot_loss: 2.3158316285807814 - acc: 0.8762241566920566 - val_acc: 0.839497794367153\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 2.595989942550659 - sq_loss: 0.0007157929358072579 - tot_loss: 2.2272174031386385 - acc: 0.8774483133841132 - val_acc: 0.8408551068883611\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 2.538318634033203 - sq_loss: 0.0006743422709405422 - tot_loss: 2.1240337348353933 - acc: 0.8801686615886833 - val_acc: 0.8432304038004751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 2.6036579608917236 - sq_loss: 0.0006358848186209798 - tot_loss: 2.034348521334323 - acc: 0.8826169749727966 - val_acc: 0.8452663725822871\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 2.578646421432495 - sq_loss: 0.0006001151632517576 - tot_loss: 1.9570185113880143 - acc: 0.8861534276387377 - val_acc: 0.8466236851034951\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 2.61466121673584 - sq_loss: 0.0005667332443408668 - tot_loss: 1.8977470086829271 - acc: 0.8868335146898803 - val_acc: 0.8489989820156091\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 2.596435308456421 - sq_loss: 0.0005356532637961209 - tot_loss: 1.8110378948549624 - acc: 0.8890097932535365 - val_acc: 0.8530709195792331\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 2.6295573711395264 - sq_loss: 0.0005068217869848013 - tot_loss: 1.753549203491275 - acc: 0.89050598476605 - val_acc: 0.8537495758398371\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 2.5843682289123535 - sq_loss: 0.00047994047054089606 - tot_loss: 1.6738920082862023 - acc: 0.8930903155603918 - val_acc: 0.8564642008822532\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 2.5296173095703125 - sq_loss: 0.0004547425778582692 - tot_loss: 1.6154455381256412 - acc: 0.8960826985854189 - val_acc: 0.8595181540549711\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 2.57658314704895 - sq_loss: 0.0004311870434321463 - tot_loss: 1.5586973248173308 - acc: 0.8977149075081611 - val_acc: 0.8622327790973872\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 2.565455436706543 - sq_loss: 0.0004092188028153032 - tot_loss: 1.4982697042360087 - acc: 0.8997551686615887 - val_acc: 0.8646080760095012\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 2.5669753551483154 - sq_loss: 0.000388689455576241 - tot_loss: 1.4608167578880966 - acc: 0.9011153427638737 - val_acc: 0.8649474041398032\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 2.6160106658935547 - sq_loss: 0.00036939652636647224 - tot_loss: 1.4082449489451392 - acc: 0.9036996735582155 - val_acc: 0.8666440447913132\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 2.629387855529785 - sq_loss: 0.0003513297706376761 - tot_loss: 1.3678659302368033 - acc: 0.9069640914036997 - val_acc: 0.8680013573125213\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 2.5213215351104736 - sq_loss: 0.00033427804009988904 - tot_loss: 1.3249638444121956 - acc: 0.9088683351468988 - val_acc: 0.8686800135731252\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 2.6145102977752686 - sq_loss: 0.0003182912478223443 - tot_loss: 1.2792448194923054 - acc: 0.9111806311207835 - val_acc: 0.8707159823549372\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 2.6289966106414795 - sq_loss: 0.0003031694213859737 - tot_loss: 1.2290437996525725 - acc: 0.9137649619151251 - val_acc: 0.8720732948761453\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 2.6400914192199707 - sq_loss: 0.00028897577431052923 - tot_loss: 1.1939596322008583 - acc: 0.9159412404787813 - val_acc: 0.8744485917882593\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 2.5795106887817383 - sq_loss: 0.0002755731693468988 - tot_loss: 1.1259595745705155 - acc: 0.9177094668117519 - val_acc: 0.8754665761791652\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 2.5283021926879883 - sq_loss: 0.0002629596274346113 - tot_loss: 1.1108929231795628 - acc: 0.920157780195865 - val_acc: 0.8781812012215813\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 2.556164026260376 - sq_loss: 0.0002510436170268804 - tot_loss: 1.082937680712348 - acc: 0.9211099020674647 - val_acc: 0.8836104513064132\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 2.6146771907806396 - sq_loss: 0.00023979009711183608 - tot_loss: 1.0494162191844225 - acc: 0.9220620239390642 - val_acc: 0.8849677638276213\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 2.6036505699157715 - sq_loss: 0.0002291960408911109 - tot_loss: 1.0031153205045484 - acc: 0.9232861806311208 - val_acc: 0.8863250763488293\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 2.591749429702759 - sq_loss: 0.00021919056598562747 - tot_loss: 0.9800259870644368 - acc: 0.9249183895538629 - val_acc: 0.8893790295215473\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 2.5484886169433594 - sq_loss: 0.0002097277611028403 - tot_loss: 0.9388927217314631 - acc: 0.9264145810663765 - val_acc: 0.8903970139124533\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 2.5887527465820312 - sq_loss: 0.00020077974477317184 - tot_loss: 0.9346268305234844 - acc: 0.9276387377584331 - val_acc: 0.8924329826942654\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 2.6055405139923096 - sq_loss: 0.0001922288938658312 - tot_loss: 0.8897684992825816 - acc: 0.9277747551686616 - val_acc: 0.8931116389548693\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 2.6144917011260986 - sq_loss: 0.0001841543853515759 - tot_loss: 0.8749775955775476 - acc: 0.9295429815016322 - val_acc: 0.8944689514760774\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 2.611013889312744 - sq_loss: 0.00017648602079134434 - tot_loss: 0.8680469989512858 - acc: 0.9306311207834603 - val_acc: 0.8954869358669834\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 2.594028949737549 - sq_loss: 0.00016926867829170078 - tot_loss: 0.8164759539658917 - acc: 0.9318552774755169 - val_acc: 0.8968442483881914\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 2.56701397895813 - sq_loss: 0.00016234027862083167 - tot_loss: 0.8036047622799742 - acc: 0.933487486398259 - val_acc: 0.8978622327790974\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 2.5631699562072754 - sq_loss: 0.00015577486192341894 - tot_loss: 0.7937507526194167 - acc: 0.9349836779107725 - val_acc: 0.8982015609093994\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 2.5647311210632324 - sq_loss: 0.00014955192455090582 - tot_loss: 0.7640895120794085 - acc: 0.9359357997823722 - val_acc: 0.8995588734306074\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 2.5883965492248535 - sq_loss: 0.00014362638466991484 - tot_loss: 0.7375316434226988 - acc: 0.9372959738846572 - val_acc: 0.9009161859518154\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 2.5945255756378174 - sq_loss: 0.0001380160974804312 - tot_loss: 0.7160604503951618 - acc: 0.9387921653971708 - val_acc: 0.9039701391245334\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 2.6236321926116943 - sq_loss: 0.00013273498916532844 - tot_loss: 0.6958695746525336 - acc: 0.9405603917301415 - val_acc: 0.9046487953851374\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 2.5813686847686768 - sq_loss: 0.00012771118781529367 - tot_loss: 0.688960180007598 - acc: 0.9420565832426551 - val_acc: 0.9066847641669494\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 2.5460689067840576 - sq_loss: 0.0001229049521498382 - tot_loss: 0.6612522428417833 - acc: 0.9430087051142546 - val_acc: 0.9087207329487614\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 2.6035654544830322 - sq_loss: 0.00011831924348371103 - tot_loss: 0.6462631166300525 - acc: 0.9440968443960827 - val_acc: 0.9110960298608755\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 2.584787368774414 - sq_loss: 0.0001139792293542996 - tot_loss: 0.6389951048536204 - acc: 0.9449129488574538 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 2.549429178237915 - sq_loss: 0.00010983974789269269 - tot_loss: 0.6257053574986458 - acc: 0.9460010881392819 - val_acc: 0.9127926705123854\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 2.63450026512146 - sq_loss: 0.00010594698687782511 - tot_loss: 0.5908073498776503 - acc: 0.9468171926006529 - val_acc: 0.9141499830335935\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 2.6111717224121094 - sq_loss: 0.00010222377750324085 - tot_loss: 0.5929073680135843 - acc: 0.9477693144722524 - val_acc: 0.9148286392941974\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 2.561258316040039 - sq_loss: 9.864327876130119e-05 - tot_loss: 0.5710918397930982 - acc: 0.9483133841131665 - val_acc: 0.9158466236851035\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 2.585916519165039 - sq_loss: 9.525710629532114e-05 - tot_loss: 0.5582142813073006 - acc: 0.9495375408052231 - val_acc: 0.9165252799457075\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 2.606023073196411 - sq_loss: 9.202144428854808e-05 - tot_loss: 0.5633949082630352 - acc: 0.9500816104461371 - val_acc: 0.9182219205972175\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 2.6082651615142822 - sq_loss: 8.894052734831348e-05 - tot_loss: 0.5400515328210531 - acc: 0.9507616974972797 - val_acc: 0.9189005768578216\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 2.5426340103149414 - sq_loss: 8.598656131653115e-05 - tot_loss: 0.5194049981428179 - acc: 0.9510337323177367 - val_acc: 0.9195792331184255\n",
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 2.5532050132751465 - sq_loss: 8.317120227729902e-05 - tot_loss: 0.5285932706156018 - acc: 0.9517138193688792 - val_acc: 0.9209365456396336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 2.5745086669921875 - sq_loss: 8.050382893998176e-05 - tot_loss: 0.5089267531166115 - acc: 0.9532100108813928 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 2.6259751319885254 - sq_loss: 7.793564145686105e-05 - tot_loss: 0.4872952892610556 - acc: 0.954842219804135 - val_acc: 0.9226331862911435\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 2.6161415576934814 - sq_loss: 7.551769522251561e-05 - tot_loss: 0.5002871584488275 - acc: 0.9552502720348205 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 2.613579034805298 - sq_loss: 7.314662798307836e-05 - tot_loss: 0.48083477474074243 - acc: 0.956474428726877 - val_acc: 0.9250084832032576\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 2.586127996444702 - sq_loss: 7.096209446899593e-05 - tot_loss: 0.46223756508811675 - acc: 0.9567464635473341 - val_acc: 0.9253478113335596\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 2.57139253616333 - sq_loss: 6.888387724757195e-05 - tot_loss: 0.46186192718482744 - acc: 0.9571545157780196 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 2.6170005798339844 - sq_loss: 6.689236033707857e-05 - tot_loss: 0.45086868782868805 - acc: 0.9578346028291621 - val_acc: 0.9263657957244655\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 2.6215085983276367 - sq_loss: 6.498042785096914e-05 - tot_loss: 0.43585402848043486 - acc: 0.9586507072905331 - val_acc: 0.9263657957244655\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 2.5390443801879883 - sq_loss: 6.315862265182659e-05 - tot_loss: 0.4376479361926613 - acc: 0.9591947769314473 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 2.58286452293396 - sq_loss: 6.1389735492412e-05 - tot_loss: 0.42970854967506966 - acc: 0.9601468988030468 - val_acc: 0.9280624363759755\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 2.544408082962036 - sq_loss: 5.971391874481924e-05 - tot_loss: 0.4245652472798156 - acc: 0.9605549510337323 - val_acc: 0.9297590770274856\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 2.5193614959716797 - sq_loss: 5.813096868223511e-05 - tot_loss: 0.43027217351277613 - acc: 0.9615070729053319 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 2.5564887523651123 - sq_loss: 5.6607372243888676e-05 - tot_loss: 0.4139554668715846 - acc: 0.9620511425462459 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 2.564284086227417 - sq_loss: 5.513295400305651e-05 - tot_loss: 0.4056287824478204 - acc: 0.9628672470076169 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 2.618587017059326 - sq_loss: 5.371185397962108e-05 - tot_loss: 0.3908029968001756 - acc: 0.9630032644178455 - val_acc: 0.9321343739395996\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 2.5746564865112305 - sq_loss: 5.236572906142101e-05 - tot_loss: 0.3990392064031312 - acc: 0.963411316648531 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 2.5613760948181152 - sq_loss: 5.107794640935026e-05 - tot_loss: 0.38721701865142677 - acc: 0.9632752992383025 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 2.584627151489258 - sq_loss: 4.983271355740726e-05 - tot_loss: 0.38272616280755756 - acc: 0.9642274211099021 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 2.546076536178589 - sq_loss: 4.86140233988408e-05 - tot_loss: 0.3621895905923793 - acc: 0.9643634385201306 - val_acc: 0.9345096708517137\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 2.54868221282959 - sq_loss: 4.746229387819767e-05 - tot_loss: 0.36352686759619246 - acc: 0.9646354733405876 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 2.5610828399658203 - sq_loss: 4.636265293811448e-05 - tot_loss: 0.35921544887787604 - acc: 0.9647714907508161 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 2.5630033016204834 - sq_loss: 4.5318232878344133e-05 - tot_loss: 0.3625856302076045 - acc: 0.9647714907508161 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 2.5145390033721924 - sq_loss: 4.432426794664934e-05 - tot_loss: 0.34068145764013025 - acc: 0.9653155603917302 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 2.6061525344848633 - sq_loss: 4.336656638770364e-05 - tot_loss: 0.34869855610531886 - acc: 0.9659956474428727 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 2.601057529449463 - sq_loss: 4.245771197020076e-05 - tot_loss: 0.3388503782285852 - acc: 0.9661316648531012 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 2.5847108364105225 - sq_loss: 4.15929825976491e-05 - tot_loss: 0.3433178568618587 - acc: 0.9664036996735582 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 2.601457357406616 - sq_loss: 4.0757109672995284e-05 - tot_loss: 0.33719408745855617 - acc: 0.9669477693144722 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 2.536830425262451 - sq_loss: 3.992953497800045e-05 - tot_loss: 0.32457462065292475 - acc: 0.9672198041349293 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 2.6013996601104736 - sq_loss: 3.914152330253273e-05 - tot_loss: 0.32954973604921634 - acc: 0.9668117519042437 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 2.5561676025390625 - sq_loss: 3.837529948214069e-05 - tot_loss: 0.3248401318138576 - acc: 0.9676278563656148 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 2.520747423171997 - sq_loss: 3.7639802030753344e-05 - tot_loss: 0.3093035109166067 - acc: 0.9676278563656148 - val_acc: 0.9382422802850356\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 2.6080055236816406 - sq_loss: 3.694110637297854e-05 - tot_loss: 0.3021823378052204 - acc: 0.9683079434167573 - val_acc: 0.9382422802850356\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 2.5883915424346924 - sq_loss: 3.6256191378924996e-05 - tot_loss: 0.31570127952761595 - acc: 0.9685799782372143 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 2.6476736068725586 - sq_loss: 3.560639379429631e-05 - tot_loss: 0.28732518888932645 - acc: 0.9687159956474428 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 2.553056001663208 - sq_loss: 3.497672878438607e-05 - tot_loss: 0.3046858924493563 - acc: 0.9693960826985855 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 2.570464611053467 - sq_loss: 3.437756095081568e-05 - tot_loss: 0.30183390439799496 - acc: 0.9691240478781284 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 2.5720529556274414 - sq_loss: 3.380476118763909e-05 - tot_loss: 0.29643824728373147 - acc: 0.969260065288357 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 2.6159982681274414 - sq_loss: 3.323716373415664e-05 - tot_loss: 0.2881713180479437 - acc: 0.9696681175190425 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 2.6148855686187744 - sq_loss: 3.269264561822638e-05 - tot_loss: 0.3072095516442914 - acc: 0.9693960826985855 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 2.5909576416015625 - sq_loss: 3.2172501960303634e-05 - tot_loss: 0.28510777369376683 - acc: 0.9702121871599565 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 2.5656485557556152 - sq_loss: 3.1675292120780796e-05 - tot_loss: 0.2839495026705663 - acc: 0.9704842219804135 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 2.5260934829711914 - sq_loss: 3.1204705010168254e-05 - tot_loss: 0.30433488527887675 - acc: 0.970892274211099 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 2.602524995803833 - sq_loss: 3.0740280635654926e-05 - tot_loss: 0.30350832611588885 - acc: 0.9713003264417845 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 2.5510966777801514 - sq_loss: 3.029276012966875e-05 - tot_loss: 0.287017865346229 - acc: 0.971436343852013 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 2.5505709648132324 - sq_loss: 2.9858732887078077e-05 - tot_loss: 0.2624594824765154 - acc: 0.9715723612622416 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 2.580312967300415 - sq_loss: 2.9444239771692082e-05 - tot_loss: 0.2705395788334499 - acc: 0.9719804134929271 - val_acc: 0.9446895147607737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 2.5629851818084717 - sq_loss: 2.903899621742312e-05 - tot_loss: 0.27966554446697955 - acc: 0.9722524483133841 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 2.546632766723633 - sq_loss: 2.8656579161179252e-05 - tot_loss: 0.2696296038656669 - acc: 0.9723884657236126 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 2.56050443649292 - sq_loss: 2.8283837309572846e-05 - tot_loss: 0.256755765406524 - acc: 0.9733405875952121 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 2.5527026653289795 - sq_loss: 2.7910540666198358e-05 - tot_loss: 0.2559852330971353 - acc: 0.9736126224156693 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 2.581336259841919 - sq_loss: 2.7553307518246584e-05 - tot_loss: 0.2540289009592698 - acc: 0.9737486398258978 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 2.526615858078003 - sq_loss: 2.7204645448364317e-05 - tot_loss: 0.2584863117434679 - acc: 0.9742927094668118 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 2.5294432640075684 - sq_loss: 2.6876858100877143e-05 - tot_loss: 0.26179971137480607 - acc: 0.9744287268770403 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 2.5896706581115723 - sq_loss: 2.6561447157291695e-05 - tot_loss: 0.252433503108648 - acc: 0.9744287268770403 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 2.581353187561035 - sq_loss: 2.6246814741170965e-05 - tot_loss: 0.2526356353598658 - acc: 0.9745647442872688 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 2.5654032230377197 - sq_loss: 2.594064972072374e-05 - tot_loss: 0.23976435382024874 - acc: 0.9744287268770403 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 2.5854358673095703 - sq_loss: 2.5645755158620887e-05 - tot_loss: 0.2527238878075764 - acc: 0.9745647442872688 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 2.574977159500122 - sq_loss: 2.5357598133268766e-05 - tot_loss: 0.2509203858676301 - acc: 0.9747007616974973 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 2.540747880935669 - sq_loss: 2.509592377464287e-05 - tot_loss: 0.24121297853082524 - acc: 0.9751088139281828 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 2.558253765106201 - sq_loss: 2.4829787435010076e-05 - tot_loss: 0.23486789460463342 - acc: 0.9752448313384113 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 2.5747368335723877 - sq_loss: 2.456542097206693e-05 - tot_loss: 0.24262981039197484 - acc: 0.9752448313384113 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 2.522303819656372 - sq_loss: 2.4313621906912886e-05 - tot_loss: 0.2335949698992863 - acc: 0.9751088139281828 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 2.561755418777466 - sq_loss: 2.406930252618622e-05 - tot_loss: 0.2551760367099405 - acc: 0.9751088139281828 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 2.5670793056488037 - sq_loss: 2.3832186343497597e-05 - tot_loss: 0.23438409620149514 - acc: 0.9752448313384113 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 2.5394420623779297 - sq_loss: 2.3595985112478957e-05 - tot_loss: 0.23905365701841674 - acc: 0.9752448313384113 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 2.5859744548797607 - sq_loss: 2.3364342268905602e-05 - tot_loss: 0.24483161298138612 - acc: 0.9752448313384113 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 2.640528917312622 - sq_loss: 2.3146183593780734e-05 - tot_loss: 0.23067325552892726 - acc: 0.9752448313384113 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 2.5912561416625977 - sq_loss: 2.294452497153543e-05 - tot_loss: 0.23516776576752818 - acc: 0.9755168661588683 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 2.5669312477111816 - sq_loss: 2.2737469407729805e-05 - tot_loss: 0.22523644752760674 - acc: 0.9759249183895539 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 2.5412509441375732 - sq_loss: 2.2536127289640717e-05 - tot_loss: 0.22998074238438448 - acc: 0.9760609357997824 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 2.562384605407715 - sq_loss: 2.2341970179695636e-05 - tot_loss: 0.21841372012897864 - acc: 0.9763329706202394 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 2.5691850185394287 - sq_loss: 2.2146037736092694e-05 - tot_loss: 0.2250196505753479 - acc: 0.9760609357997824 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 2.551990032196045 - sq_loss: 2.196523200836964e-05 - tot_loss: 0.23456812385865078 - acc: 0.9761969532100109 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 2.6023738384246826 - sq_loss: 2.1789934180560522e-05 - tot_loss: 0.22667027201936207 - acc: 0.9763329706202394 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 2.5734710693359375 - sq_loss: 2.160890471714083e-05 - tot_loss: 0.21159268358587724 - acc: 0.9761969532100109 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 2.5944485664367676 - sq_loss: 2.1435776943690144e-05 - tot_loss: 0.22013066892526467 - acc: 0.9764689880304679 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 2.568622589111328 - sq_loss: 2.1269434000714682e-05 - tot_loss: 0.22083849841010306 - acc: 0.9767410228509249 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 2.546276330947876 - sq_loss: 2.110644527419936e-05 - tot_loss: 0.22390434681977922 - acc: 0.9767410228509249 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 2.559605598449707 - sq_loss: 2.0952438717358746e-05 - tot_loss: 0.21705501285055107 - acc: 0.9766050054406964 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 2.5346407890319824 - sq_loss: 2.079549631162081e-05 - tot_loss: 0.22576615195265504 - acc: 0.9767410228509249 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 2.5260558128356934 - sq_loss: 2.064773070742376e-05 - tot_loss: 0.20203370588546932 - acc: 0.9768770402611534 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 2.5244953632354736 - sq_loss: 2.0498462617979385e-05 - tot_loss: 0.22114028632375948 - acc: 0.9772850924918389 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 2.561161518096924 - sq_loss: 2.035977377090603e-05 - tot_loss: 0.2125205634054339 - acc: 0.9776931447225244 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 2.536959648132324 - sq_loss: 2.020978536165785e-05 - tot_loss: 0.1984429664043148 - acc: 0.977829162132753 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 2.5178310871124268 - sq_loss: 2.0060168026247993e-05 - tot_loss: 0.24191208708489853 - acc: 0.977829162132753 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 2.5106914043426514 - sq_loss: 1.9919592887163162e-05 - tot_loss: 0.20085354966275304 - acc: 0.977829162132753 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 2.524674415588379 - sq_loss: 1.9780845832428895e-05 - tot_loss: 0.2059966839277081 - acc: 0.977829162132753 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 2.5710575580596924 - sq_loss: 1.96494202100439e-05 - tot_loss: 0.21376410061566276 - acc: 0.977829162132753 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 2.5684733390808105 - sq_loss: 1.9532861188054085e-05 - tot_loss: 0.21490756058665283 - acc: 0.9779651795429815 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 2.5533885955810547 - sq_loss: 1.940921720233746e-05 - tot_loss: 0.20796906497369605 - acc: 0.9782372143634385 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 2.5947389602661133 - sq_loss: 1.928398160089273e-05 - tot_loss: 0.20541143020372488 - acc: 0.97810119695321 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 2.5983693599700928 - sq_loss: 1.9161549062118866e-05 - tot_loss: 0.19870321586202522 - acc: 0.97810119695321 - val_acc: 0.9538513742789277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 2.496161699295044 - sq_loss: 1.9038865502807312e-05 - tot_loss: 0.2213034903369362 - acc: 0.9783732317736671 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 2.544497489929199 - sq_loss: 1.892045111162588e-05 - tot_loss: 0.21913481493382392 - acc: 0.97810119695321 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 2.530749797821045 - sq_loss: 1.880655690911226e-05 - tot_loss: 0.20523395332250516 - acc: 0.9783732317736671 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 2.5644490718841553 - sq_loss: 1.8695964172366075e-05 - tot_loss: 0.2078518537973082 - acc: 0.9786452665941241 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 2.5676791667938232 - sq_loss: 1.858666837506462e-05 - tot_loss: 0.1866051402002995 - acc: 0.9786452665941241 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 2.5720438957214355 - sq_loss: 1.848075226007495e-05 - tot_loss: 0.2046792098624053 - acc: 0.9787812840043526 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 2.525858163833618 - sq_loss: 1.8371265468886122e-05 - tot_loss: 0.20482423928308435 - acc: 0.9787812840043526 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 2.534342050552368 - sq_loss: 1.827141022658907e-05 - tot_loss: 0.2058880770706537 - acc: 0.9789173014145811 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 2.529773712158203 - sq_loss: 1.8169632312492467e-05 - tot_loss: 0.21995110575136323 - acc: 0.9789173014145811 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 2.573385238647461 - sq_loss: 1.8067616110784e-05 - tot_loss: 0.2024352331695809 - acc: 0.9789173014145811 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 2.5710926055908203 - sq_loss: 1.797323056962341e-05 - tot_loss: 0.198086626953085 - acc: 0.9789173014145811 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 1.4933571815490723 - sq_loss: 1.7875107005238533e-05 - tot_loss: 0.22717383838377714 - acc: 0.9791893362350381 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 1.2828691005706787 - sq_loss: 1.778354635462165e-05 - tot_loss: 0.19295862062699598 - acc: 0.9791893362350381 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 1.2917842864990234 - sq_loss: 1.7695900169201195e-05 - tot_loss: 0.20103256009645065 - acc: 0.9791893362350381 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 1.2913830280303955 - sq_loss: 1.7614007447264157e-05 - tot_loss: 0.2187521085338915 - acc: 0.9791893362350381 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 1.2844691276550293 - sq_loss: 1.7521299014333636e-05 - tot_loss: 0.20961200589712803 - acc: 0.9790533188248096 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 1.3090009689331055 - sq_loss: 1.7432135791750625e-05 - tot_loss: 0.18517676451051557 - acc: 0.9791893362350381 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 1.288564920425415 - sq_loss: 1.7348196706734598e-05 - tot_loss: 0.19944016058556713 - acc: 0.9790533188248096 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 1.2948217391967773 - sq_loss: 1.726609298202675e-05 - tot_loss: 0.20048544398474633 - acc: 0.9791893362350381 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 1.287302017211914 - sq_loss: 1.7180118447868153e-05 - tot_loss: 0.1992630455629012 - acc: 0.9791893362350381 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 1.2772297859191895 - sq_loss: 1.7100363038480282e-05 - tot_loss: 0.2141694687961717 - acc: 0.9790533188248096 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 1.2841246128082275 - sq_loss: 1.701705696177669e-05 - tot_loss: 0.19250368569041143 - acc: 0.9791893362350381 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 1.2703146934509277 - sq_loss: 1.6929698176681995e-05 - tot_loss: 0.18602939870208957 - acc: 0.9790533188248096 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 1.2882845401763916 - sq_loss: 1.6847587176016532e-05 - tot_loss: 0.2034831323958599 - acc: 0.9795973884657236 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 1.2870864868164062 - sq_loss: 1.6766551198088564e-05 - tot_loss: 0.20594254072369722 - acc: 0.9795973884657236 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 1.3030450344085693 - sq_loss: 1.6687095921952277e-05 - tot_loss: 0.18476166846042474 - acc: 0.9794613710554951 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 1.282071590423584 - sq_loss: 1.6614143532933667e-05 - tot_loss: 0.1943560858196065 - acc: 0.9797334058759521 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 1.316390037536621 - sq_loss: 1.653903746046126e-05 - tot_loss: 0.19532193461961356 - acc: 0.9798694232861807 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 1.285543441772461 - sq_loss: 1.646064265514724e-05 - tot_loss: 0.19470629006337958 - acc: 0.9798694232861807 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 1.2953755855560303 - sq_loss: 1.638840876694303e-05 - tot_loss: 0.18916315962167118 - acc: 0.9798694232861807 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 1.3119299411773682 - sq_loss: 1.631368104426656e-05 - tot_loss: 0.19261040806688356 - acc: 0.9798694232861807 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 1.2948176860809326 - sq_loss: 1.6243144273175858e-05 - tot_loss: 0.1845147077897593 - acc: 0.9798694232861807 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 1.2899274826049805 - sq_loss: 1.617649832041934e-05 - tot_loss: 0.17981682490437834 - acc: 0.9798694232861807 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 1.2808623313903809 - sq_loss: 1.6109524949570186e-05 - tot_loss: 0.1921097780823402 - acc: 0.9797334058759521 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 1.2856473922729492 - sq_loss: 1.604201679583639e-05 - tot_loss: 0.1927631174191049 - acc: 0.9798694232861807 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 1.2980082035064697 - sq_loss: 1.5975294445524924e-05 - tot_loss: 0.17923091574490968 - acc: 0.9800054406964092 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 1.2975354194641113 - sq_loss: 1.5912293747533113e-05 - tot_loss: 0.18122284036590486 - acc: 0.9802774755168662 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 1.308333158493042 - sq_loss: 1.5843928849790245e-05 - tot_loss: 0.18819519806078233 - acc: 0.9802774755168662 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 1.3170909881591797 - sq_loss: 1.5779662135173567e-05 - tot_loss: 0.20783041994599216 - acc: 0.9802774755168662 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 1.284862995147705 - sq_loss: 1.5713232642156072e-05 - tot_loss: 0.19933293953585007 - acc: 0.9805495103373232 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 1.3039424419403076 - sq_loss: 1.5649993656552397e-05 - tot_loss: 0.1925114786062636 - acc: 0.9806855277475517 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 1.302969217300415 - sq_loss: 1.5588890164508484e-05 - tot_loss: 0.19679373079588913 - acc: 0.9808215451577802 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 1.2839138507843018 - sq_loss: 1.5522375178989023e-05 - tot_loss: 0.18483613015280298 - acc: 0.9809575625680087 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 1.2827861309051514 - sq_loss: 1.546032763144467e-05 - tot_loss: 0.17822908693352701 - acc: 0.9810935799782372 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 1.2893829345703125 - sq_loss: 1.5400673873955384e-05 - tot_loss: 0.19065234790016916 - acc: 0.9810935799782372 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 1.3097317218780518 - sq_loss: 1.5341869584517553e-05 - tot_loss: 0.19828703313487495 - acc: 0.9810935799782372 - val_acc: 0.9565659993213438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 1.293497085571289 - sq_loss: 1.528272514406126e-05 - tot_loss: 0.18959593367722505 - acc: 0.9813656147986942 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 1.306196689605713 - sq_loss: 1.5219938177324366e-05 - tot_loss: 0.1876238223513269 - acc: 0.9813656147986942 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 1.299546480178833 - sq_loss: 1.5161247574724257e-05 - tot_loss: 0.17886079972060998 - acc: 0.9813656147986942 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 1.3111701011657715 - sq_loss: 1.5104043995961547e-05 - tot_loss: 0.18499397528327677 - acc: 0.9812295973884657 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 1.3102672100067139 - sq_loss: 1.505137697677128e-05 - tot_loss: 0.18929968657556628 - acc: 0.9812295973884657 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 1.3383677005767822 - sq_loss: 1.4997421203588601e-05 - tot_loss: 0.18493493640403358 - acc: 0.9813656147986942 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 1.3244061470031738 - sq_loss: 1.494288426329149e-05 - tot_loss: 0.17764397288809164 - acc: 0.9815016322089227 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 1.300220251083374 - sq_loss: 1.4885572454659268e-05 - tot_loss: 0.19212438224198536 - acc: 0.9813656147986942 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 1.3092188835144043 - sq_loss: 1.482839525124291e-05 - tot_loss: 0.17673211118489007 - acc: 0.9819096844396082 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 1.3035979270935059 - sq_loss: 1.4777016076550353e-05 - tot_loss: 0.17901812547529516 - acc: 0.9825897714907508 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 1.2804880142211914 - sq_loss: 1.4727678717463277e-05 - tot_loss: 0.19428082069362063 - acc: 0.9824537540805223 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 1.3144605159759521 - sq_loss: 1.4674915291834623e-05 - tot_loss: 0.19069829966414886 - acc: 0.9825897714907508 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 1.3088321685791016 - sq_loss: 1.4620380170526914e-05 - tot_loss: 0.18652758839235162 - acc: 0.9820457018498367 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 1.300797939300537 - sq_loss: 1.4565528545062989e-05 - tot_loss: 0.18528178481641078 - acc: 0.9825897714907508 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 1.2883830070495605 - sq_loss: 1.4514756003336515e-05 - tot_loss: 0.1869352845794907 - acc: 0.9828618063112078 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 1.28684663772583 - sq_loss: 1.446145324734971e-05 - tot_loss: 0.1825277733105537 - acc: 0.9829978237214363 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 1.2776930332183838 - sq_loss: 1.4411189113161527e-05 - tot_loss: 0.1870518617603949 - acc: 0.9829978237214363 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 1.2729933261871338 - sq_loss: 1.43593633765704e-05 - tot_loss: 0.18135287270256129 - acc: 0.9831338411316648 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 1.7346689701080322 - sq_loss: 1.4313483006844763e-05 - tot_loss: 0.1787713521306813 - acc: 0.9831338411316648 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 2.574709892272949 - sq_loss: 1.4267330698203295e-05 - tot_loss: 0.18703112719174442 - acc: 0.9831338411316648 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 2.5573439598083496 - sq_loss: 1.422178502252791e-05 - tot_loss: 0.19348949604594168 - acc: 0.9831338411316648 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 2.5432376861572266 - sq_loss: 1.4172618648444768e-05 - tot_loss: 0.17498300010902312 - acc: 0.9829978237214363 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 2.6146435737609863 - sq_loss: 1.4128416296443902e-05 - tot_loss: 0.1804651642093944 - acc: 0.9828618063112078 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 2.5448427200317383 - sq_loss: 1.408448770234827e-05 - tot_loss: 0.1971868842489357 - acc: 0.9827257889009793 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 2.645998001098633 - sq_loss: 1.4033160368853714e-05 - tot_loss: 0.16580219422496612 - acc: 0.9827257889009793 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 2.590707540512085 - sq_loss: 1.3985724763188045e-05 - tot_loss: 0.1718009198649071 - acc: 0.9828618063112078 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 2.5587663650512695 - sq_loss: 1.3938894880993757e-05 - tot_loss: 0.19028780675326118 - acc: 0.9825897714907508 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 2.558915853500366 - sq_loss: 1.3894648873247206e-05 - tot_loss: 0.17276258328659821 - acc: 0.9823177366702938 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 2.601208209991455 - sq_loss: 1.3848904018232133e-05 - tot_loss: 0.1821928439653533 - acc: 0.9823177366702938 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 2.626610279083252 - sq_loss: 1.3801213754049968e-05 - tot_loss: 0.19533156514934547 - acc: 0.9828618063112078 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 2.521007537841797 - sq_loss: 1.3759942703472916e-05 - tot_loss: 0.18618667028361813 - acc: 0.9829978237214363 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 2.547118663787842 - sq_loss: 1.3720438801101409e-05 - tot_loss: 0.18347870317973047 - acc: 0.9825897714907508 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 2.579469680786133 - sq_loss: 1.3678932191396598e-05 - tot_loss: 0.19047246781603633 - acc: 0.9829978237214363 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 2.603619337081909 - sq_loss: 1.3637316442327574e-05 - tot_loss: 0.19900569694003423 - acc: 0.9828618063112078 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 2.5447375774383545 - sq_loss: 1.3596420103567652e-05 - tot_loss: 0.18470494289339 - acc: 0.9829978237214363 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 2.5759503841400146 - sq_loss: 1.3551858501159586e-05 - tot_loss: 0.18176171638478422 - acc: 0.9829978237214363 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 2.577017307281494 - sq_loss: 1.3502901310857851e-05 - tot_loss: 0.19214214666003215 - acc: 0.9832698585418934 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 2.5534162521362305 - sq_loss: 1.3459531146509107e-05 - tot_loss: 0.17780612633568182 - acc: 0.9829978237214363 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 2.535557270050049 - sq_loss: 1.3421592484519351e-05 - tot_loss: 0.18777191099395907 - acc: 0.9828618063112078 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 2.5455820560455322 - sq_loss: 1.338225592917297e-05 - tot_loss: 0.1629931490415828 - acc: 0.9831338411316648 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 2.61445951461792 - sq_loss: 1.3341353223950136e-05 - tot_loss: 0.1821513798942931 - acc: 0.9829978237214363 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 2.524508476257324 - sq_loss: 1.3300446880748495e-05 - tot_loss: 0.18263966292042255 - acc: 0.9832698585418934 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 2.531275510787964 - sq_loss: 1.3257997125037946e-05 - tot_loss: 0.18842774478969204 - acc: 0.9835418933623504 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 2.55665922164917 - sq_loss: 1.3220374057709705e-05 - tot_loss: 0.1794247230802597 - acc: 0.9831338411316648 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 2.5723187923431396 - sq_loss: 1.3183619557821658e-05 - tot_loss: 0.1792214627702009 - acc: 0.9831338411316648 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 2.602261781692505 - sq_loss: 1.3146541277819779e-05 - tot_loss: 0.17629740470397337 - acc: 0.9835418933623504 - val_acc: 0.9592806243637597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 2.5258429050445557 - sq_loss: 1.311063806497259e-05 - tot_loss: 0.1763833865602038 - acc: 0.9834058759521219 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 2.543368339538574 - sq_loss: 1.307168622588506e-05 - tot_loss: 0.16536730741007943 - acc: 0.9835418933623504 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 2.5044772624969482 - sq_loss: 1.3031415619479958e-05 - tot_loss: 0.18074201403848633 - acc: 0.9834058759521219 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 2.5382721424102783 - sq_loss: 1.2990982213523239e-05 - tot_loss: 0.1695560083702503 - acc: 0.9838139281828074 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 2.536607503890991 - sq_loss: 1.2954565136169549e-05 - tot_loss: 0.17630867662707317 - acc: 0.9835418933623504 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 2.518209457397461 - sq_loss: 1.2915124898427166e-05 - tot_loss: 0.1805678262986561 - acc: 0.9836779107725789 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 2.5343575477600098 - sq_loss: 1.2876746950496454e-05 - tot_loss: 0.18270303394874077 - acc: 0.9834058759521219 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 2.5710580348968506 - sq_loss: 1.2841343050240539e-05 - tot_loss: 0.18653872185690545 - acc: 0.9838139281828074 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 2.5479660034179688 - sq_loss: 1.280572632822441e-05 - tot_loss: 0.18938407686741243 - acc: 0.9838139281828074 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 2.5459327697753906 - sq_loss: 1.2773184607794974e-05 - tot_loss: 0.19178559373099802 - acc: 0.9838139281828074 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 2.502366542816162 - sq_loss: 1.2734431948047131e-05 - tot_loss: 0.1704322474739257 - acc: 0.9835418933623504 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 2.5485031604766846 - sq_loss: 1.269848053198075e-05 - tot_loss: 0.16161127766936545 - acc: 0.9838139281828074 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 2.617896318435669 - sq_loss: 1.2664093446801417e-05 - tot_loss: 0.16946863593835815 - acc: 0.9836779107725789 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 2.51851224899292 - sq_loss: 1.2628815966309048e-05 - tot_loss: 0.17371724792825205 - acc: 0.9838139281828074 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 2.5614137649536133 - sq_loss: 1.2594568033819087e-05 - tot_loss: 0.16683842066311172 - acc: 0.9836779107725789 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 2.5427985191345215 - sq_loss: 1.2556530236906838e-05 - tot_loss: 0.17277507268974546 - acc: 0.9836779107725789 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 2.535057544708252 - sq_loss: 1.2521451935754158e-05 - tot_loss: 0.18015306044785007 - acc: 0.9835418933623504 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 2.6157543659210205 - sq_loss: 1.2486738341976888e-05 - tot_loss: 0.19088220584200144 - acc: 0.983949945593036 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 2.5808751583099365 - sq_loss: 1.2451292604964692e-05 - tot_loss: 0.1714323356436438 - acc: 0.9840859630032645 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 2.5633139610290527 - sq_loss: 1.2417199286574032e-05 - tot_loss: 0.16480340792692516 - acc: 0.9835418933623504 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 2.546112537384033 - sq_loss: 1.2382894055917859e-05 - tot_loss: 0.16866266573505584 - acc: 0.9836779107725789 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 2.561450481414795 - sq_loss: 1.2351533769106027e-05 - tot_loss: 0.1772236803323466 - acc: 0.9836779107725789 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 2.571147918701172 - sq_loss: 1.2322134352871217e-05 - tot_loss: 0.1746333662873525 - acc: 0.9838139281828074 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 2.6258456707000732 - sq_loss: 1.2292963219806552e-05 - tot_loss: 0.16463165010453906 - acc: 0.9836779107725789 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 2.5759189128875732 - sq_loss: 1.2260236871952657e-05 - tot_loss: 0.17111762378813467 - acc: 0.9836779107725789 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 2.5483314990997314 - sq_loss: 1.2225246791786049e-05 - tot_loss: 0.1719505095364866 - acc: 0.9840859630032645 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 2.579216241836548 - sq_loss: 1.219237492477987e-05 - tot_loss: 0.18874265092503606 - acc: 0.9840859630032645 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 2.5420351028442383 - sq_loss: 1.2161424820078537e-05 - tot_loss: 0.16423087430379724 - acc: 0.9840859630032645 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 2.493457078933716 - sq_loss: 1.2131627954659052e-05 - tot_loss: 0.17143847703191284 - acc: 0.9840859630032645 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 2.581254482269287 - sq_loss: 1.2100523235858418e-05 - tot_loss: 0.1717876762261028 - acc: 0.9840859630032645 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 2.5444066524505615 - sq_loss: 1.2070877346559428e-05 - tot_loss: 0.18643828101362203 - acc: 0.984221980413493 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 2.5259928703308105 - sq_loss: 1.2039866305713076e-05 - tot_loss: 0.17220538446365197 - acc: 0.984221980413493 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 2.5303502082824707 - sq_loss: 1.2005853022856172e-05 - tot_loss: 0.17104801921817625 - acc: 0.984221980413493 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 2.558396100997925 - sq_loss: 1.197157416754635e-05 - tot_loss: 0.18286447144004114 - acc: 0.98449401523395 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 2.5171775817871094 - sq_loss: 1.1940247532038484e-05 - tot_loss: 0.17456324300059123 - acc: 0.9843579978237215 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 2.5770204067230225 - sq_loss: 1.1910130524483975e-05 - tot_loss: 0.1671548390343105 - acc: 0.98449401523395 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 2.5875205993652344 - sq_loss: 1.1881011232617311e-05 - tot_loss: 0.1661694225086876 - acc: 0.98449401523395 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 2.5569863319396973 - sq_loss: 1.1853392607008573e-05 - tot_loss: 0.16844292712424647 - acc: 0.98449401523395 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 2.546018123626709 - sq_loss: 1.1824508874269668e-05 - tot_loss: 0.17127311391446653 - acc: 0.98449401523395 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 2.5809874534606934 - sq_loss: 1.1793541489169002e-05 - tot_loss: 0.17753866512478567 - acc: 0.98449401523395 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 2.5997064113616943 - sq_loss: 1.1763608199544251e-05 - tot_loss: 0.15347336817008284 - acc: 0.9846300326441785 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 2.559723138809204 - sq_loss: 1.1733080100384541e-05 - tot_loss: 0.1764222561593698 - acc: 0.9846300326441785 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 2.5368974208831787 - sq_loss: 1.1706715667969547e-05 - tot_loss: 0.1687251282073703 - acc: 0.984766050054407 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 2.5745303630828857 - sq_loss: 1.1677677321131341e-05 - tot_loss: 0.1671646639033213 - acc: 0.984766050054407 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 2.5783519744873047 - sq_loss: 1.1646529856079724e-05 - tot_loss: 0.17037938997656 - acc: 0.9846300326441785 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 2.5345234870910645 - sq_loss: 1.1616180017881561e-05 - tot_loss: 0.17335219773595156 - acc: 0.9849020674646355 - val_acc: 0.9606379368849678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 2.6256003379821777 - sq_loss: 1.1587598237383645e-05 - tot_loss: 0.16759071316016616 - acc: 0.9849020674646355 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 2.6399340629577637 - sq_loss: 1.1559928680071607e-05 - tot_loss: 0.1710993659636415 - acc: 0.9849020674646355 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 2.569925308227539 - sq_loss: 1.153070024884073e-05 - tot_loss: 0.18062174516337848 - acc: 0.9849020674646355 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 2.548815965652466 - sq_loss: 1.1501771041366737e-05 - tot_loss: 0.15692839881396026 - acc: 0.9849020674646355 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 2.639240026473999 - sq_loss: 1.1471426660136785e-05 - tot_loss: 0.18202931672286127 - acc: 0.985038084874864 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 2.5581326484680176 - sq_loss: 1.144250654760981e-05 - tot_loss: 0.16903947889349524 - acc: 0.9849020674646355 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 2.541255235671997 - sq_loss: 1.141771917900769e-05 - tot_loss: 0.1658210190604592 - acc: 0.9849020674646355 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 2.5243005752563477 - sq_loss: 1.1390864528948441e-05 - tot_loss: 0.16866344262855648 - acc: 0.985038084874864 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 2.5396955013275146 - sq_loss: 1.1365345017111395e-05 - tot_loss: 0.15953907369068077 - acc: 0.9851741022850925 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 2.502113103866577 - sq_loss: 1.1339609955030028e-05 - tot_loss: 0.16348841843925754 - acc: 0.9851741022850925 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 2.588685989379883 - sq_loss: 1.131572662416147e-05 - tot_loss: 0.17386328497813963 - acc: 0.9851741022850925 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 2.6244685649871826 - sq_loss: 1.128931216953788e-05 - tot_loss: 0.16310628607691058 - acc: 0.9851741022850925 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 2.5861916542053223 - sq_loss: 1.1261766303505283e-05 - tot_loss: 0.1700286971410918 - acc: 0.9851741022850925 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 2.5771172046661377 - sq_loss: 1.1234557860007044e-05 - tot_loss: 0.17021750053156381 - acc: 0.985038084874864 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 2.5685842037200928 - sq_loss: 1.1206437193322927e-05 - tot_loss: 0.16662454100850255 - acc: 0.9851741022850925 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 2.592538833618164 - sq_loss: 1.1180597539350856e-05 - tot_loss: 0.18208042290127935 - acc: 0.9851741022850925 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 2.5642623901367188 - sq_loss: 1.1153973900945857e-05 - tot_loss: 0.16359099555171497 - acc: 0.9851741022850925 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 2.5584940910339355 - sq_loss: 1.113028065446997e-05 - tot_loss: 0.17924975412363153 - acc: 0.9851741022850925 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 2.572556495666504 - sq_loss: 1.1105796147603542e-05 - tot_loss: 0.1608037248163754 - acc: 0.9851741022850925 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 2.590635299682617 - sq_loss: 1.1082430319220293e-05 - tot_loss: 0.17769323891423028 - acc: 0.985310119695321 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 2.578989028930664 - sq_loss: 1.1058244126616046e-05 - tot_loss: 0.16195478416217668 - acc: 0.985310119695321 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 2.5614638328552246 - sq_loss: 1.1033757800760213e-05 - tot_loss: 0.16055437746159384 - acc: 0.985310119695321 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 2.5632479190826416 - sq_loss: 1.1008387446054257e-05 - tot_loss: 0.17505801236933394 - acc: 0.985310119695321 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 2.5625112056732178 - sq_loss: 1.0983182619384024e-05 - tot_loss: 0.180379562695407 - acc: 0.985310119695321 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 2.59159779548645 - sq_loss: 1.0958292477880605e-05 - tot_loss: 0.18137739703260536 - acc: 0.985310119695321 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 2.5443129539489746 - sq_loss: 1.0931938959402032e-05 - tot_loss: 0.18294558197436572 - acc: 0.985310119695321 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 2.541977882385254 - sq_loss: 1.0907748219324276e-05 - tot_loss: 0.1610992355408598 - acc: 0.9851741022850925 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 2.542306900024414 - sq_loss: 1.0881826710829046e-05 - tot_loss: 0.176446110187797 - acc: 0.9851741022850925 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 2.55965518951416 - sq_loss: 1.0856496373889968e-05 - tot_loss: 0.16146288692756627 - acc: 0.985310119695321 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 2.572493314743042 - sq_loss: 1.082951439457247e-05 - tot_loss: 0.1606816720997557 - acc: 0.985310119695321 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 2.5559771060943604 - sq_loss: 1.080529091268545e-05 - tot_loss: 0.15448103810400937 - acc: 0.985310119695321 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 2.617760181427002 - sq_loss: 1.0779863259813283e-05 - tot_loss: 0.18091587837739098 - acc: 0.9862622415669206 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 2.5538411140441895 - sq_loss: 1.0756232768471818e-05 - tot_loss: 0.17411716086510864 - acc: 0.9854461371055495 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 2.5956227779388428 - sq_loss: 1.0734336683526635e-05 - tot_loss: 0.17832632128794046 - acc: 0.9854461371055495 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 2.59372878074646 - sq_loss: 1.0714903510233853e-05 - tot_loss: 0.17910766117209675 - acc: 0.9862622415669206 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 2.588538408279419 - sq_loss: 1.0693242074921727e-05 - tot_loss: 0.18576513268622818 - acc: 0.986126224156692 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 2.5894229412078857 - sq_loss: 1.0675290468498133e-05 - tot_loss: 0.1714525503709723 - acc: 0.986126224156692 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 2.587185859680176 - sq_loss: 1.0653097888280172e-05 - tot_loss: 0.15930982774224844 - acc: 0.9865342763873776 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 2.5717289447784424 - sq_loss: 1.0632194971549325e-05 - tot_loss: 0.1576898393332442 - acc: 0.9865342763873776 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 2.5785412788391113 - sq_loss: 1.060942577169044e-05 - tot_loss: 0.1757689832823388 - acc: 0.986126224156692 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 2.5559298992156982 - sq_loss: 1.0587938049866352e-05 - tot_loss: 0.16944438034218479 - acc: 0.985854189336235 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 2.548419713973999 - sq_loss: 1.0562367606326006e-05 - tot_loss: 0.16653555531553366 - acc: 0.9859902067464635 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 2.5706684589385986 - sq_loss: 1.0538925380387809e-05 - tot_loss: 0.16021822321231127 - acc: 0.9857181719260065 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 2.5597739219665527 - sq_loss: 1.0518824637983926e-05 - tot_loss: 0.161384879974932 - acc: 0.9859902067464635 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 2.597505807876587 - sq_loss: 1.0493215995666105e-05 - tot_loss: 0.1660584661176756 - acc: 0.9859902067464635 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 2.5144248008728027 - sq_loss: 1.0468816071806941e-05 - tot_loss: 0.18714722922518945 - acc: 0.9863982589771491 - val_acc: 0.9619952494061758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 2.545010805130005 - sq_loss: 1.0446728083479684e-05 - tot_loss: 0.17516255293480754 - acc: 0.9863982589771491 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 2.569648027420044 - sq_loss: 1.0422820196254179e-05 - tot_loss: 0.17231780838746147 - acc: 0.9863982589771491 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 2.5541746616363525 - sq_loss: 1.0401165127404965e-05 - tot_loss: 0.1773869645171402 - acc: 0.9862622415669206 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 2.5586299896240234 - sq_loss: 1.037540550896665e-05 - tot_loss: 0.16138160310613614 - acc: 0.9862622415669206 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 2.562387704849243 - sq_loss: 1.0352353456255514e-05 - tot_loss: 0.16990714352152736 - acc: 0.9863982589771491 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 2.5686166286468506 - sq_loss: 1.0330408258596435e-05 - tot_loss: 0.1802440453585774 - acc: 0.9863982589771491 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 2.5513243675231934 - sq_loss: 1.0309181561751757e-05 - tot_loss: 0.17565903260680216 - acc: 0.9865342763873776 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 2.5484635829925537 - sq_loss: 1.0286660653946456e-05 - tot_loss: 0.1716223440475062 - acc: 0.9865342763873776 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 2.535512685775757 - sq_loss: 1.0266413482895587e-05 - tot_loss: 0.16966343944463347 - acc: 0.9863982589771491 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 2.586151361465454 - sq_loss: 1.0249833394482266e-05 - tot_loss: 0.16134650132674722 - acc: 0.9865342763873776 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 2.6194255352020264 - sq_loss: 1.0230609404970892e-05 - tot_loss: 0.16336289090895662 - acc: 0.9865342763873776 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 2.584883213043213 - sq_loss: 1.0208775165665429e-05 - tot_loss: 0.16827145017852274 - acc: 0.9865342763873776 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 2.5330307483673096 - sq_loss: 1.0188191481574904e-05 - tot_loss: 0.16479583120926122 - acc: 0.9865342763873776 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 2.5710434913635254 - sq_loss: 1.0166118954657577e-05 - tot_loss: 0.17022754072473845 - acc: 0.9863982589771491 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 2.5668582916259766 - sq_loss: 1.0144397492695134e-05 - tot_loss: 0.18361854906383712 - acc: 0.9862622415669206 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 2.5459415912628174 - sq_loss: 1.0123408173967618e-05 - tot_loss: 0.17031704699026307 - acc: 0.9863982589771491 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 2.561601400375366 - sq_loss: 1.0101344741997309e-05 - tot_loss: 0.16502774528100872 - acc: 0.9863982589771491 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 2.5044918060302734 - sq_loss: 1.008118942991132e-05 - tot_loss: 0.16940831799922762 - acc: 0.9865342763873776 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 2.5336151123046875 - sq_loss: 1.0059350643132348e-05 - tot_loss: 0.168405244471856 - acc: 0.9865342763873776 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 2.495882749557495 - sq_loss: 1.0037791980721522e-05 - tot_loss: 0.16402742824887184 - acc: 0.9863982589771491 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 2.5285730361938477 - sq_loss: 1.0019424735219218e-05 - tot_loss: 0.16338136746183807 - acc: 0.9863982589771491 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 2.492354393005371 - sq_loss: 9.999743269872852e-06 - tot_loss: 0.17011772996025343 - acc: 0.9865342763873776 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 2.538511276245117 - sq_loss: 9.98138239083346e-06 - tot_loss: 0.16753598654099733 - acc: 0.9863982589771491 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 2.595510244369507 - sq_loss: 9.961181604012381e-06 - tot_loss: 0.17078254578500207 - acc: 0.9866702937976061 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 2.530019521713257 - sq_loss: 9.937806680682115e-06 - tot_loss: 0.16829011813238282 - acc: 0.9865342763873776 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 2.5295968055725098 - sq_loss: 9.920704542309977e-06 - tot_loss: 0.17059682374301843 - acc: 0.9865342763873776 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 2.5675034523010254 - sq_loss: 9.903057616611477e-06 - tot_loss: 0.1682412311226571 - acc: 0.9866702937976061 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 2.5261223316192627 - sq_loss: 9.886290172289591e-06 - tot_loss: 0.1757607895307487 - acc: 0.9868063112078346 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 2.5708224773406982 - sq_loss: 9.868087545328308e-06 - tot_loss: 0.17207316764750402 - acc: 0.9870783460282916 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 2.5434529781341553 - sq_loss: 9.850179594650399e-06 - tot_loss: 0.17145200736209887 - acc: 0.9870783460282916 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 2.5427775382995605 - sq_loss: 9.830118870013393e-06 - tot_loss: 0.16900365243400728 - acc: 0.9870783460282916 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 2.521026372909546 - sq_loss: 9.811590643948875e-06 - tot_loss: 0.1799869110752823 - acc: 0.9869423286180631 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 2.5260510444641113 - sq_loss: 9.79568540060427e-06 - tot_loss: 0.19293005310768052 - acc: 0.9873503808487486 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 2.538193464279175 - sq_loss: 9.776536899153143e-06 - tot_loss: 0.1820843101697136 - acc: 0.9870783460282916 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 2.5811376571655273 - sq_loss: 9.758029591466766e-06 - tot_loss: 0.1707520787614314 - acc: 0.9874863982589771 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 2.5626869201660156 - sq_loss: 9.741124813444912e-06 - tot_loss: 0.15780405893228533 - acc: 0.9874863982589771 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 2.5767440795898438 - sq_loss: 9.71867484622635e-06 - tot_loss: 0.15663543342473218 - acc: 0.9874863982589771 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 2.527045965194702 - sq_loss: 9.699052498035599e-06 - tot_loss: 0.1700972574526034 - acc: 0.9874863982589771 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 2.5579710006713867 - sq_loss: 9.679254617367405e-06 - tot_loss: 0.16197306488598429 - acc: 0.9872143634385201 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 2.5490570068359375 - sq_loss: 9.660550858825445e-06 - tot_loss: 0.16826103114104995 - acc: 0.9870783460282916 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 2.6264259815216064 - sq_loss: 9.643368684919551e-06 - tot_loss: 0.15770155160304 - acc: 0.9872143634385201 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 2.5985450744628906 - sq_loss: 9.627479812479578e-06 - tot_loss: 0.17579014187742814 - acc: 0.9870783460282916 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 2.556058883666992 - sq_loss: 9.610241249902174e-06 - tot_loss: 0.175995774138336 - acc: 0.9872143634385201 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 2.642920970916748 - sq_loss: 9.591369234840386e-06 - tot_loss: 0.16207074521489062 - acc: 0.9872143634385201 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 2.608912467956543 - sq_loss: 9.57267820922425e-06 - tot_loss: 0.17308911957550066 - acc: 0.9870783460282916 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 2.573871612548828 - sq_loss: 9.552329174766783e-06 - tot_loss: 0.1801754395228059 - acc: 0.9870783460282916 - val_acc: 0.9630132337970818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 2.621614933013916 - sq_loss: 9.534846867609303e-06 - tot_loss: 0.1760902989734987 - acc: 0.9870783460282916 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 2.573643207550049 - sq_loss: 9.515342753729783e-06 - tot_loss: 0.1904046115948006 - acc: 0.9872143634385201 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 2.595935344696045 - sq_loss: 9.497400242253207e-06 - tot_loss: 0.1627280603328316 - acc: 0.9874863982589771 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 2.6362740993499756 - sq_loss: 9.477842468186282e-06 - tot_loss: 0.17882537340327787 - acc: 0.9870783460282916 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 2.6132609844207764 - sq_loss: 9.459787179366685e-06 - tot_loss: 0.1733666700152554 - acc: 0.9873503808487486 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 2.602483034133911 - sq_loss: 9.442498594580684e-06 - tot_loss: 0.1750734588202576 - acc: 0.9874863982589771 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 2.5903148651123047 - sq_loss: 9.426523320144042e-06 - tot_loss: 0.18216190262328524 - acc: 0.9872143634385201 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 2.603367328643799 - sq_loss: 9.409737685928121e-06 - tot_loss: 0.18156987712341532 - acc: 0.9874863982589771 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 2.6384382247924805 - sq_loss: 9.39418805501191e-06 - tot_loss: 0.1831965146922414 - acc: 0.9874863982589771 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 2.5897583961486816 - sq_loss: 9.37598269956652e-06 - tot_loss: 0.1686001400732806 - acc: 0.9872143634385201 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 2.5475358963012695 - sq_loss: 9.357595445180777e-06 - tot_loss: 0.1780790339218612 - acc: 0.9873503808487486 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 2.5767266750335693 - sq_loss: 9.340722499473486e-06 - tot_loss: 0.17794067894396903 - acc: 0.9870783460282916 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 2.5815579891204834 - sq_loss: 9.321645848103799e-06 - tot_loss: 0.17886376001436588 - acc: 0.9873503808487486 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 2.5851550102233887 - sq_loss: 9.3027683760738e-06 - tot_loss: 0.173233119686941 - acc: 0.9876224156692056 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 2.590644121170044 - sq_loss: 9.286091881222092e-06 - tot_loss: 0.17265817370827108 - acc: 0.9877584330794341 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 2.537945508956909 - sq_loss: 9.271410817746073e-06 - tot_loss: 0.18289452533559825 - acc: 0.9877584330794341 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 2.5825836658477783 - sq_loss: 9.255254553863779e-06 - tot_loss: 0.16896218337175384 - acc: 0.9876224156692056 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 2.6327879428863525 - sq_loss: 9.23977859201841e-06 - tot_loss: 0.16813802903823216 - acc: 0.9878944504896626 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 2.644099235534668 - sq_loss: 9.224318091582973e-06 - tot_loss: 0.1653510901873716 - acc: 0.9878944504896626 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 2.590013027191162 - sq_loss: 9.208476512867492e-06 - tot_loss: 0.16824763988115876 - acc: 0.9876224156692056 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 2.611469268798828 - sq_loss: 9.191849130729679e-06 - tot_loss: 0.1654874211244035 - acc: 0.9873503808487486 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 2.602069854736328 - sq_loss: 9.17627039598301e-06 - tot_loss: 0.17727284823895673 - acc: 0.9876224156692056 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 2.6381170749664307 - sq_loss: 9.160816262010485e-06 - tot_loss: 0.1657045525190881 - acc: 0.9877584330794341 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 2.5867128372192383 - sq_loss: 9.14249994821148e-06 - tot_loss: 0.15485151193914248 - acc: 0.9873503808487486 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 2.5984363555908203 - sq_loss: 9.124250937020406e-06 - tot_loss: 0.16501040326350136 - acc: 0.9876224156692056 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 2.5678274631500244 - sq_loss: 9.10673406906426e-06 - tot_loss: 0.19859287822920635 - acc: 0.9878944504896626 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 2.6172640323638916 - sq_loss: 9.093447260966059e-06 - tot_loss: 0.19020795323043416 - acc: 0.9880304678998912 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 2.633840322494507 - sq_loss: 9.077977665583603e-06 - tot_loss: 0.16350343216199548 - acc: 0.9877584330794341 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 2.5534915924072266 - sq_loss: 9.061069249582943e-06 - tot_loss: 0.154799204922071 - acc: 0.9878944504896626 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 2.52223801612854 - sq_loss: 9.04557600733824e-06 - tot_loss: 0.1675045730277276 - acc: 0.9880304678998912 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 2.5682451725006104 - sq_loss: 9.02729789231671e-06 - tot_loss: 0.16006502954929402 - acc: 0.9877584330794341 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 2.56156063079834 - sq_loss: 9.008694178191945e-06 - tot_loss: 0.17011900395946356 - acc: 0.9877584330794341 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 2.569587469100952 - sq_loss: 8.99220958672231e-06 - tot_loss: 0.16898906781104017 - acc: 0.9878944504896626 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 2.558631658554077 - sq_loss: 8.976418939710129e-06 - tot_loss: 0.17733594476924708 - acc: 0.9880304678998912 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 2.5882365703582764 - sq_loss: 8.963463187683374e-06 - tot_loss: 0.17206192429259914 - acc: 0.9877584330794341 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 2.545543909072876 - sq_loss: 8.949304174166173e-06 - tot_loss: 0.1764228574325557 - acc: 0.9877584330794341 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 2.5789060592651367 - sq_loss: 8.933437129599042e-06 - tot_loss: 0.19130480419492812 - acc: 0.9881664853101197 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 2.535762310028076 - sq_loss: 8.916073056752793e-06 - tot_loss: 0.1588287284078831 - acc: 0.9881664853101197 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 2.5714797973632812 - sq_loss: 8.900037755665835e-06 - tot_loss: 0.15924811334736688 - acc: 0.9877584330794341 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 2.58845591545105 - sq_loss: 8.883055670594331e-06 - tot_loss: 0.16556555944556095 - acc: 0.9878944504896626 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 2.5559561252593994 - sq_loss: 8.867869837558828e-06 - tot_loss: 0.16079517871243354 - acc: 0.9880304678998912 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 2.5619144439697266 - sq_loss: 8.85300960362656e-06 - tot_loss: 0.1766587005107496 - acc: 0.9878944504896626 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 2.626934051513672 - sq_loss: 8.83848679222865e-06 - tot_loss: 0.1843879263513415 - acc: 0.9880304678998912 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 2.5418710708618164 - sq_loss: 8.823731150187086e-06 - tot_loss: 0.17418819252105067 - acc: 0.9880304678998912 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 2.5086071491241455 - sq_loss: 8.808417078398634e-06 - tot_loss: 0.15690224472205472 - acc: 0.9881664853101197 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 2.5412933826446533 - sq_loss: 8.791756954451557e-06 - tot_loss: 0.17141866099231606 - acc: 0.9881664853101197 - val_acc: 0.9633525619273838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 2.5516610145568848 - sq_loss: 8.777322364039719e-06 - tot_loss: 0.17893656226785737 - acc: 0.9881664853101197 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 2.5722155570983887 - sq_loss: 8.762988727539778e-06 - tot_loss: 0.1655837557889086 - acc: 0.9881664853101197 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 2.6039388179779053 - sq_loss: 8.748920663492754e-06 - tot_loss: 0.16275120566189827 - acc: 0.9881664853101197 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 2.573087215423584 - sq_loss: 8.734981747693382e-06 - tot_loss: 0.17598205195572092 - acc: 0.9881664853101197 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 2.5588810443878174 - sq_loss: 8.71986776473932e-06 - tot_loss: 0.18040250776085998 - acc: 0.9880304678998912 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 2.558901786804199 - sq_loss: 8.706784683454316e-06 - tot_loss: 0.15151466122034662 - acc: 0.9880304678998912 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 2.5633537769317627 - sq_loss: 8.693137715454213e-06 - tot_loss: 0.16802197620410908 - acc: 0.9881664853101197 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 2.5972039699554443 - sq_loss: 8.679123311594594e-06 - tot_loss: 0.14382770970193803 - acc: 0.9881664853101197 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 2.5217995643615723 - sq_loss: 8.663619155413471e-06 - tot_loss: 0.16099438922886122 - acc: 0.9881664853101197 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 2.5213351249694824 - sq_loss: 8.647488357382827e-06 - tot_loss: 0.1727216078679774 - acc: 0.9881664853101197 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 2.496706485748291 - sq_loss: 8.633689503767528e-06 - tot_loss: 0.17221704357545065 - acc: 0.9880304678998912 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 2.5719618797302246 - sq_loss: 8.619447726232465e-06 - tot_loss: 0.17982993927024893 - acc: 0.9881664853101197 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 2.6076502799987793 - sq_loss: 8.606450137449428e-06 - tot_loss: 0.18131945745262357 - acc: 0.9880304678998912 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 2.5944342613220215 - sq_loss: 8.592581252742093e-06 - tot_loss: 0.18015709776754107 - acc: 0.9881664853101197 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 2.5788934230804443 - sq_loss: 8.578661436331458e-06 - tot_loss: 0.16610890879043438 - acc: 0.9881664853101197 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 2.568575382232666 - sq_loss: 8.565522875869647e-06 - tot_loss: 0.16218710859067187 - acc: 0.9881664853101197 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 2.565838575363159 - sq_loss: 8.55313101055799e-06 - tot_loss: 0.19586576322018345 - acc: 0.9881664853101197 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 2.5622246265411377 - sq_loss: 8.540559974790085e-06 - tot_loss: 0.17233625810783337 - acc: 0.9881664853101197 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 2.5822575092315674 - sq_loss: 8.52729135658592e-06 - tot_loss: 0.1766256288386714 - acc: 0.9881664853101197 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 2.596727132797241 - sq_loss: 8.51525692269206e-06 - tot_loss: 0.16529116116620912 - acc: 0.9881664853101197 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 2.5844931602478027 - sq_loss: 8.502352102368604e-06 - tot_loss: 0.18383195279495368 - acc: 0.9883025027203483 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 2.6037397384643555 - sq_loss: 8.48885338200489e-06 - tot_loss: 0.19654839922922207 - acc: 0.9883025027203483 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 2.53183650970459 - sq_loss: 8.476256880385336e-06 - tot_loss: 0.16215254137078006 - acc: 0.9883025027203483 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 2.5812275409698486 - sq_loss: 8.461985999019817e-06 - tot_loss: 0.1678107153577315 - acc: 0.9883025027203483 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 2.5413076877593994 - sq_loss: 8.447452273685485e-06 - tot_loss: 0.17314858867292315 - acc: 0.9881664853101197 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 2.532621145248413 - sq_loss: 8.433471521129832e-06 - tot_loss: 0.1737515867276187 - acc: 0.9881664853101197 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 2.5448038578033447 - sq_loss: 8.418582183367107e-06 - tot_loss: 0.19087355561779873 - acc: 0.9883025027203483 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 2.556070566177368 - sq_loss: 8.40348639030708e-06 - tot_loss: 0.17107964100033968 - acc: 0.9883025027203483 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 2.5679068565368652 - sq_loss: 8.389428330701776e-06 - tot_loss: 0.16505403117621142 - acc: 0.9884385201305768 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 2.5305869579315186 - sq_loss: 8.375787729164585e-06 - tot_loss: 0.18078364664290092 - acc: 0.9883025027203483 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 2.5824129581451416 - sq_loss: 8.362583685084246e-06 - tot_loss: 0.17146701959357813 - acc: 0.9883025027203483 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 2.558504819869995 - sq_loss: 8.349642484972719e-06 - tot_loss: 0.17628878215358412 - acc: 0.9883025027203483 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 2.502305269241333 - sq_loss: 8.336757673532702e-06 - tot_loss: 0.18431159326765112 - acc: 0.9887105549510338 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 2.5311989784240723 - sq_loss: 8.324258487846237e-06 - tot_loss: 0.168413471909183 - acc: 0.9884385201305768 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 2.537055492401123 - sq_loss: 8.314260412589647e-06 - tot_loss: 0.16995171987893087 - acc: 0.9884385201305768 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 2.5256974697113037 - sq_loss: 8.301133675558958e-06 - tot_loss: 0.1793242629981293 - acc: 0.9883025027203483 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 2.580000400543213 - sq_loss: 8.288418939628173e-06 - tot_loss: 0.1813326144975349 - acc: 0.9885745375408053 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 2.563339948654175 - sq_loss: 8.274544597952627e-06 - tot_loss: 0.1938125579048986 - acc: 0.9883025027203483 - val_acc: 0.9640312181879878\n",
      "CR_1 = 0.16759738116197184   CR_2 = 0.1667972504806152\n",
      "/home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 5\n",
    "alpha = 1\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "\n",
    "#alpha1 = alpha2 = alpha3 = alpha4 = alpha5 = alpha6 = alpha7 = alpha8 = alpha9 = alpha10 = alpha\n",
    "#for rank in (35,): #(25,30,35)(100,180,220,260,300,340,380)(20,60,100,140,180,220,260,300,340,380)\n",
    "#    for tau in (400,500): #(300,400,500)(10,50,100,200,300)(10,50,100,200,300)\n",
    "#        for gamma in (0.5,0.8,2): #(0.5,0.8,2)(0.5,0.8)(0.5,1,1.5,2,3)\n",
    "            #gamma1 = gamma2 = gamma3 = gamma4 = gamma5 = gamma\n",
    "#            for rho in (0.5,0.8,2): #(0.5,0.8)(1,2)\n",
    "                #rho1 = rho2 = rho3 = rho4 = rho5= rho\n",
    "#                for alpha in (0.5,1,1.5,2):\n",
    "#                    print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "                    #print('Compression Ratio', ((1024*28*28+10*1024+(8*(rank)+32*np.square(rank))*2)/(1024*28*28+10*1024+1024*1024*2)), (8*(rank)+32*np.square(rank))*2/(1024*1024*2))\n",
    "        \n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    d0 = 561 #561 =3*11*17\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 6 \n",
    "\n",
    "    W1 = 0.2*init.kaiming_normal_(torch.empty(d1, d0, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    #W1 = 0.01*torch.randn(d1, d0, device=device)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    W2 = 0.2*init.kaiming_normal_(torch.empty(d2, d1, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles factors, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    W3 = 0.2*init.kaiming_normal_(torch.empty(d3, d2, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    W4 = 0.2*init.kaiming_normal_(torch.empty(d4, d3, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "\n",
    "    W5 = 0.2*init.kaiming_normal_(torch.empty(d5, d4, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = U5 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V5 = (y_one_hot + gamma*U5 + alpha*V5)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U5 = (gamma*V5 + rho*(torch.mm(W5,V4) + b5.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W5, b5 = updateWb_org(U5,V4,W5,b5,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b5.repeat(1, N), W5, a4_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b5.repeat(1, N_test), W5, a4_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V5,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,U5,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4\n",
    "\n",
    "    CR_1=((total_variabels)+(d4*d5))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#this postion to add new row into existing table\n",
    "    #df=pd.read_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "    #new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "    #           'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "    #           'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1], 'seed':seed} \n",
    "    #df=df.append(new_row,ignore_index=True)\n",
    "    #df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"KaimingNormal_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895c825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30f34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
