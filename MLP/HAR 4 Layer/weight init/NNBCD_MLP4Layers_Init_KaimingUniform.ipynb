{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccc0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6113fe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 5 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 2.6187729835510254 - sq_loss: 661.7448120117188 - tot_loss: 1252.5230238315999 - acc: 0.19423286180631122 - val_acc: 0.19511367492365117\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 2.6186187267303467 - sq_loss: 294.10882568359375 - tot_loss: 515.7608848810196 - acc: 0.25571273122959737 - val_acc: 0.23922633186291142\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 2.5946764945983887 - sq_loss: 157.2239227294922 - tot_loss: 292.48887702450156 - acc: 0.47429270946681173 - val_acc: 0.45877163216830674\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 2.5693840980529785 - sq_loss: 84.50540924072266 - tot_loss: 173.97780356928706 - acc: 0.5410772578890098 - val_acc: 0.5300305395317272\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 2.616443395614624 - sq_loss: 45.35883331298828 - tot_loss: 108.56599060632288 - acc: 0.5877312295973884 - val_acc: 0.5744825246012895\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 2.5346052646636963 - sq_loss: 24.340164184570312 - tot_loss: 71.88112540729344 - acc: 0.6007889009793254 - val_acc: 0.5894129623345775\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 2.551706075668335 - sq_loss: 13.082507133483887 - tot_loss: 50.78650149144232 - acc: 0.6141186071817193 - val_acc: 0.6043434000678656\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 2.5239408016204834 - sq_loss: 7.056237697601318 - tot_loss: 38.22356078866869 - acc: 0.6211915125136017 - val_acc: 0.6141839158466237\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 2.5559542179107666 - sq_loss: 3.8263566493988037 - tot_loss: 30.415289843454957 - acc: 0.6263601741022851 - val_acc: 0.6199524940617577\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 2.5315754413604736 - sq_loss: 2.0903208255767822 - tot_loss: 25.29197103762999 - acc: 0.6303046789989118 - val_acc: 0.6243637597556837\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 2.554105758666992 - sq_loss: 1.1531155109405518 - tot_loss: 21.697915334720165 - acc: 0.6335690968443961 - val_acc: 0.6257210722768918\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 2.57145357131958 - sq_loss: 0.6441144943237305 - tot_loss: 19.05821171635762 - acc: 0.6411860718171926 - val_acc: 0.6308109942314218\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 2.5095081329345703 - sq_loss: 0.3655059337615967 - tot_loss: 16.989612450357527 - acc: 0.6539717083786725 - val_acc: 0.6386155412283678\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 2.554262399673462 - sq_loss: 0.21149484813213348 - tot_loss: 15.311694379895926 - acc: 0.6660772578890098 - val_acc: 0.6443841194435018\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 2.5538437366485596 - sq_loss: 0.1253168284893036 - tot_loss: 13.918667331337929 - acc: 0.6753264417845484 - val_acc: 0.6491347132677299\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 2.5597856044769287 - sq_loss: 0.07637747377157211 - tot_loss: 12.724969569011591 - acc: 0.6825353645266594 - val_acc: 0.6603325415676959\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 2.5892789363861084 - sq_loss: 0.048093583434820175 - tot_loss: 11.68300296831876 - acc: 0.6920565832426551 - val_acc: 0.6725483542585681\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 2.5814690589904785 - sq_loss: 0.03141026571393013 - tot_loss: 10.787413641053718 - acc: 0.7007616974972797 - val_acc: 0.6827281981676281\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 2.5568089485168457 - sq_loss: 0.02133893594145775 - tot_loss: 9.955938240513206 - acc: 0.7116430903155604 - val_acc: 0.6946046827281982\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 2.54309344291687 - sq_loss: 0.015102000907063484 - tot_loss: 9.248864368186332 - acc: 0.7221164309031556 - val_acc: 0.7047845266372582\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 2.5341475009918213 - sq_loss: 0.011128699406981468 - tot_loss: 8.604716895497404 - acc: 0.734221980413493 - val_acc: 0.7136070580251103\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 2.4942469596862793 - sq_loss: 0.008520574308931828 - tot_loss: 8.016175092110643 - acc: 0.7448313384113167 - val_acc: 0.7200542925008483\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 2.534579038619995 - sq_loss: 0.006754452828317881 - tot_loss: 7.497490808804287 - acc: 0.7557127312295974 - val_acc: 0.7278588394977944\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 2.544177293777466 - sq_loss: 0.00551971048116684 - tot_loss: 7.011888801353052 - acc: 0.7659140369967355 - val_acc: 0.7366813708856464\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 2.5945708751678467 - sq_loss: 0.00462860893458128 - tot_loss: 6.562752591475146 - acc: 0.7780195865070729 - val_acc: 0.7451645741431965\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 2.562436819076538 - sq_loss: 0.003965811803936958 - tot_loss: 6.1753045174409635 - acc: 0.7908052230685527 - val_acc: 0.7543264336613505\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 2.5739855766296387 - sq_loss: 0.0034583681263029575 - tot_loss: 5.82283505970554 - acc: 0.8005984766050055 - val_acc: 0.7614523243976926\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 2.547755718231201 - sq_loss: 0.0030591634567826986 - tot_loss: 5.486122130852891 - acc: 0.8101196953210011 - val_acc: 0.7685782151340346\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 2.4959871768951416 - sq_loss: 0.0027381391264498234 - tot_loss: 5.181754328325042 - acc: 0.8185527747551686 - val_acc: 0.7757041058703766\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 2.548339605331421 - sq_loss: 0.002474057488143444 - tot_loss: 4.88376173695724 - acc: 0.8265778019586507 - val_acc: 0.7828299966067187\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 2.522071599960327 - sq_loss: 0.0022526425309479237 - tot_loss: 4.616796468471875 - acc: 0.8321545157780196 - val_acc: 0.7885985748218527\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 2.553696393966675 - sq_loss: 0.002063906053081155 - tot_loss: 4.378425632516155 - acc: 0.838411316648531 - val_acc: 0.7933491686460807\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 2.5580408573150635 - sq_loss: 0.0019003769848495722 - tot_loss: 4.1502768123173155 - acc: 0.8438520130576714 - val_acc: 0.7964031218187988\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 2.5786983966827393 - sq_loss: 0.0017571494681760669 - tot_loss: 3.9316608229855774 - acc: 0.8491566920565833 - val_acc: 0.8014930437733289\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 2.569777011871338 - sq_loss: 0.0016305261524394155 - tot_loss: 3.740218961138453 - acc: 0.8537812840043526 - val_acc: 0.8045469969460468\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 2.55072021484375 - sq_loss: 0.0015172348357737064 - tot_loss: 3.5618811940439628 - acc: 0.8581338411316648 - val_acc: 0.8079402782490669\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 2.61848783493042 - sq_loss: 0.0014151186915114522 - tot_loss: 3.3867671367843286 - acc: 0.8634385201305768 - val_acc: 0.8099762470308789\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 2.584251880645752 - sq_loss: 0.0013226957526057959 - tot_loss: 3.2248031633498613 - acc: 0.8673830250272034 - val_acc: 0.8126908720732948\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 2.6040735244750977 - sq_loss: 0.0012385480804368854 - tot_loss: 3.0956468040894833 - acc: 0.8707834602829162 - val_acc: 0.8167628096369189\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 2.561337947845459 - sq_loss: 0.001161342253908515 - tot_loss: 2.929638072841044 - acc: 0.8722796517954298 - val_acc: 0.819138106549033\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 2.5267434120178223 - sq_loss: 0.001090541365556419 - tot_loss: 2.803014466611785 - acc: 0.8766322089227421 - val_acc: 0.8204954190702409\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 2.5084238052368164 - sq_loss: 0.0010253055952489376 - tot_loss: 2.6733614822660456 - acc: 0.8796245919477693 - val_acc: 0.822870715982355\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 2.5510263442993164 - sq_loss: 0.0009649486164562404 - tot_loss: 2.5632598391821375 - acc: 0.8819368879216539 - val_acc: 0.8238887003732609\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 2.6397483348846436 - sq_loss: 0.0009091697284020483 - tot_loss: 2.462207377393497 - acc: 0.8839771490750816 - val_acc: 0.825585341024771\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 2.6206867694854736 - sq_loss: 0.000857416947837919 - tot_loss: 2.347562059378106 - acc: 0.8856093579978237 - val_acc: 0.825924669155073\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 2.5559017658233643 - sq_loss: 0.0008093932410702109 - tot_loss: 2.2529928789263067 - acc: 0.8873775843307944 - val_acc: 0.8262639972853749\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 2.486102342605591 - sq_loss: 0.000764664146117866 - tot_loss: 2.1576845722665894 - acc: 0.8890097932535365 - val_acc: 0.827621309806583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 2.5994873046875 - sq_loss: 0.000723005214240402 - tot_loss: 2.079909611140465 - acc: 0.8903699673558215 - val_acc: 0.8306752629793009\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 2.544754981994629 - sq_loss: 0.0006841194117441773 - tot_loss: 1.9824618332895625 - acc: 0.8928182807399347 - val_acc: 0.832371903630811\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 2.5071349143981934 - sq_loss: 0.0006476641283370554 - tot_loss: 1.9072562521905638 - acc: 0.8936343852013058 - val_acc: 0.832371903630811\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 2.5887444019317627 - sq_loss: 0.0006137029267847538 - tot_loss: 1.8195157664267754 - acc: 0.8948585418933623 - val_acc: 0.832371903630811\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 2.58123779296875 - sq_loss: 0.0005819800426252186 - tot_loss: 1.7568441487528617 - acc: 0.8956746463547334 - val_acc: 0.833050559891415\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 2.50972318649292 - sq_loss: 0.0005522909923456609 - tot_loss: 1.7074046515444934 - acc: 0.8973068552774756 - val_acc: 0.833729216152019\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 2.541299343109131 - sq_loss: 0.0005243968917056918 - tot_loss: 1.6366846884411643 - acc: 0.8978509249183896 - val_acc: 0.835425856803529\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 2.556936264038086 - sq_loss: 0.0004980749217793345 - tot_loss: 1.5856872655203915 - acc: 0.8998911860718172 - val_acc: 0.8367831693247371\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 2.508436918258667 - sq_loss: 0.00047344062477350235 - tot_loss: 1.5044402794555936 - acc: 0.9008433079434167 - val_acc: 0.8388191381065491\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 2.5188310146331787 - sq_loss: 0.00045010788016952574 - tot_loss: 1.4753362598385138 - acc: 0.9020674646354734 - val_acc: 0.839837122497455\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 2.5943145751953125 - sq_loss: 0.0004282108275219798 - tot_loss: 1.4082255140292546 - acc: 0.9027475516866159 - val_acc: 0.841873091279267\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 2.5165627002716064 - sq_loss: 0.0004075128526892513 - tot_loss: 1.3568996676531242 - acc: 0.904107725788901 - val_acc: 0.8445877163216831\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 2.552961826324463 - sq_loss: 0.0003879260038957 - tot_loss: 1.3143386742503935 - acc: 0.9042437431991295 - val_acc: 0.845945028842891\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 2.581176519393921 - sq_loss: 0.0003695476916618645 - tot_loss: 1.2753368824087374 - acc: 0.9053318824809575 - val_acc: 0.8479809976247031\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 2.5420076847076416 - sq_loss: 0.0003521620819810778 - tot_loss: 1.2193341727288498 - acc: 0.9064200217627857 - val_acc: 0.8489989820156091\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 2.490046262741089 - sq_loss: 0.000335733377141878 - tot_loss: 1.1825560748548014 - acc: 0.9072361262241567 - val_acc: 0.8500169664065151\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 2.512637138366699 - sq_loss: 0.0003202244406566024 - tot_loss: 1.147087955409006 - acc: 0.9085963003264418 - val_acc: 0.8517136070580251\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 2.558612108230591 - sq_loss: 0.00030570023227483034 - tot_loss: 1.0980203750132205 - acc: 0.9091403699673558 - val_acc: 0.8527315914489311\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 2.578486919403076 - sq_loss: 0.00029197338153608143 - tot_loss: 1.0841438857059984 - acc: 0.9098204570184983 - val_acc: 0.8527315914489311\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 2.5511858463287354 - sq_loss: 0.00027908282936550677 - tot_loss: 1.0371544692461612 - acc: 0.9111806311207835 - val_acc: 0.8568035290125552\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 2.5670509338378906 - sq_loss: 0.00026683846954256296 - tot_loss: 1.0100946786478744 - acc: 0.911588683351469 - val_acc: 0.8578215134034611\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 2.5528547763824463 - sq_loss: 0.00025533788721077144 - tot_loss: 0.9893707172022914 - acc: 0.9129488574537541 - val_acc: 0.8585001696640652\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 2.558189868927002 - sq_loss: 0.00024437817046418786 - tot_loss: 0.9442251369437145 - acc: 0.9137649619151251 - val_acc: 0.8598574821852731\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 2.536829948425293 - sq_loss: 0.00023395835887640715 - tot_loss: 0.9197690417086051 - acc: 0.9147170837867247 - val_acc: 0.8612147947064812\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 2.6011056900024414 - sq_loss: 0.0002241407783003524 - tot_loss: 0.8847957835951092 - acc: 0.9152611534276387 - val_acc: 0.8608754665761792\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 2.5602176189422607 - sq_loss: 0.00021483087039086968 - tot_loss: 0.8646785421706227 - acc: 0.9160772578890098 - val_acc: 0.8608754665761792\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 2.586022138595581 - sq_loss: 0.00020606242469511926 - tot_loss: 0.8509327116671557 - acc: 0.9167573449401524 - val_acc: 0.8612147947064812\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 2.5251429080963135 - sq_loss: 0.00019773592066485435 - tot_loss: 0.8222990373615175 - acc: 0.9175734494015234 - val_acc: 0.8629114353579912\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 2.6242918968200684 - sq_loss: 0.0001897709589684382 - tot_loss: 0.8000170524956047 - acc: 0.9186615886833515 - val_acc: 0.8639294197488971\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 2.5417377948760986 - sq_loss: 0.00018217257456853986 - tot_loss: 0.777267143975223 - acc: 0.919613710554951 - val_acc: 0.8659653885307091\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 2.5214295387268066 - sq_loss: 0.0001749114744598046 - tot_loss: 0.7463802566044251 - acc: 0.9207018498367792 - val_acc: 0.8673227010519172\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 2.5692522525787354 - sq_loss: 0.0001680390996625647 - tot_loss: 0.7272516511275171 - acc: 0.9216539717083787 - val_acc: 0.8690193417034272\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 2.5527775287628174 - sq_loss: 0.0001615615765331313 - tot_loss: 0.7318711660636836 - acc: 0.9227421109902068 - val_acc: 0.8707159823549372\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 2.542384624481201 - sq_loss: 0.000155332701979205 - tot_loss: 0.6950725084980149 - acc: 0.9243743199129488 - val_acc: 0.8710553104852392\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 2.565960168838501 - sq_loss: 0.00014939851826056838 - tot_loss: 0.6795793925693943 - acc: 0.9251904243743199 - val_acc: 0.8710553104852392\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 2.576385021209717 - sq_loss: 0.00014373673184309155 - tot_loss: 0.6616454519944455 - acc: 0.926006528835691 - val_acc: 0.8724126230064473\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 2.5471789836883545 - sq_loss: 0.0001383790950058028 - tot_loss: 0.6531048947808813 - acc: 0.9277747551686616 - val_acc: 0.8741092636579573\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 2.5943148136138916 - sq_loss: 0.00013328665227163583 - tot_loss: 0.6236577862928243 - acc: 0.9288628944504896 - val_acc: 0.8758059043094673\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 2.560978412628174 - sq_loss: 0.0001284181489609182 - tot_loss: 0.6121383043846436 - acc: 0.9302230685527747 - val_acc: 0.8758059043094673\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 2.518376111984253 - sq_loss: 0.00012375398364383727 - tot_loss: 0.613784143527937 - acc: 0.9310391730141458 - val_acc: 0.8768238887003733\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 2.601285696029663 - sq_loss: 0.0001193436692119576 - tot_loss: 0.5877255473214973 - acc: 0.9314472252448314 - val_acc: 0.8788598574821853\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 2.5613038539886475 - sq_loss: 0.00011512437049532309 - tot_loss: 0.5728298062090289 - acc: 0.9321273122959739 - val_acc: 0.8795385137427892\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 2.582839250564575 - sq_loss: 0.00011106042802566662 - tot_loss: 0.5581026425625168 - acc: 0.9328073993471164 - val_acc: 0.8798778418730913\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 2.568171262741089 - sq_loss: 0.00010719041165430099 - tot_loss: 0.5335863444729512 - acc: 0.9333514689880305 - val_acc: 0.8815744825246012\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 2.5244762897491455 - sq_loss: 0.00010351466335123405 - tot_loss: 0.5408060674458284 - acc: 0.9341675734494015 - val_acc: 0.8825924669155073\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 2.5260279178619385 - sq_loss: 0.00010002165799960494 - tot_loss: 0.520582334404935 - acc: 0.9351196953210011 - val_acc: 0.8836104513064132\n",
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 2.6003196239471436 - sq_loss: 9.666213009040803e-05 - tot_loss: 0.5045664442704947 - acc: 0.9355277475516867 - val_acc: 0.8836104513064132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 2.551281452178955 - sq_loss: 9.348502499051392e-05 - tot_loss: 0.4982248112855814 - acc: 0.9362078346028292 - val_acc: 0.8849677638276213\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 2.556293249130249 - sq_loss: 9.043748286785558e-05 - tot_loss: 0.4869306413738741 - acc: 0.9368879216539717 - val_acc: 0.8859857482185273\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 2.576005458831787 - sq_loss: 8.749637345317751e-05 - tot_loss: 0.48866199233589214 - acc: 0.9379760609357998 - val_acc: 0.8859857482185273\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 2.5220754146575928 - sq_loss: 8.469400927424431e-05 - tot_loss: 0.4775728924651048 - acc: 0.9389281828073993 - val_acc: 0.8876823888700374\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 2.5323872566223145 - sq_loss: 8.199943113140762e-05 - tot_loss: 0.4712616969713963 - acc: 0.9392002176278563 - val_acc: 0.8890397013912453\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 2.5023891925811768 - sq_loss: 7.946552796056494e-05 - tot_loss: 0.4753012462974766 - acc: 0.9397442872687704 - val_acc: 0.8890397013912453\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 2.568626642227173 - sq_loss: 7.703554729232565e-05 - tot_loss: 0.4483313240050393 - acc: 0.9405603917301415 - val_acc: 0.8893790295215473\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 2.5415873527526855 - sq_loss: 7.468406693078578e-05 - tot_loss: 0.4352909536419247 - acc: 0.941512513601741 - val_acc: 0.8903970139124533\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 2.505185842514038 - sq_loss: 7.246690074680373e-05 - tot_loss: 0.42197217623333927 - acc: 0.9427366702937976 - val_acc: 0.8920936545639634\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 2.542114019393921 - sq_loss: 7.03378245816566e-05 - tot_loss: 0.4171919799457555 - acc: 0.9431447225244831 - val_acc: 0.8937902952154734\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 2.634366035461426 - sq_loss: 6.829325866419822e-05 - tot_loss: 0.4061711833330719 - acc: 0.9434167573449401 - val_acc: 0.8958262639972854\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 2.5608325004577637 - sq_loss: 6.632624717894942e-05 - tot_loss: 0.4061414913448971 - acc: 0.9442328618063112 - val_acc: 0.8968442483881914\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 2.6042466163635254 - sq_loss: 6.442696030717343e-05 - tot_loss: 0.40134536495543216 - acc: 0.9451849836779108 - val_acc: 0.8978622327790974\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 2.5982513427734375 - sq_loss: 6.261601083679125e-05 - tot_loss: 0.3899088631249015 - acc: 0.9465451577801959 - val_acc: 0.8978622327790974\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 2.5802738666534424 - sq_loss: 6.090907845646143e-05 - tot_loss: 0.36831097671824864 - acc: 0.9474972796517954 - val_acc: 0.8988802171700034\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 2.554456949234009 - sq_loss: 5.925839286646806e-05 - tot_loss: 0.3718038086283286 - acc: 0.9488574537540805 - val_acc: 0.8988802171700034\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 2.582157850265503 - sq_loss: 5.771629002992995e-05 - tot_loss: 0.3648253888372892 - acc: 0.9495375408052231 - val_acc: 0.9002375296912114\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 2.5419418811798096 - sq_loss: 5.621952732326463e-05 - tot_loss: 0.3776143338827751 - acc: 0.9504896626768227 - val_acc: 0.9005768578215134\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 2.536031484603882 - sq_loss: 5.474856880027801e-05 - tot_loss: 0.35772869138850183 - acc: 0.9511697497279652 - val_acc: 0.9012555140821175\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 2.572129249572754 - sq_loss: 5.33527709194459e-05 - tot_loss: 0.3459251796787157 - acc: 0.9519858541893362 - val_acc: 0.9015948422124194\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 2.5459647178649902 - sq_loss: 5.2023333410033956e-05 - tot_loss: 0.34223899014659764 - acc: 0.9522578890097932 - val_acc: 0.9015948422124194\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 2.5131123065948486 - sq_loss: 5.073507418273948e-05 - tot_loss: 0.34892165917312923 - acc: 0.9529379760609358 - val_acc: 0.9022734984730234\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 2.5683557987213135 - sq_loss: 4.951871233060956e-05 - tot_loss: 0.3327169879205485 - acc: 0.9534820457018498 - val_acc: 0.9026128266033254\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 2.5596303939819336 - sq_loss: 4.83400872326456e-05 - tot_loss: 0.3308564004253185 - acc: 0.9536180631120783 - val_acc: 0.9026128266033254\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 2.539065361022949 - sq_loss: 4.723394158645533e-05 - tot_loss: 0.3216824148419164 - acc: 0.9538900979325353 - val_acc: 0.9039701391245334\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 2.5468389987945557 - sq_loss: 4.6150704292813316e-05 - tot_loss: 0.32370229705156817 - acc: 0.9544341675734495 - val_acc: 0.9049881235154394\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 2.5723180770874023 - sq_loss: 4.510088911047205e-05 - tot_loss: 0.3312763874939719 - acc: 0.954842219804135 - val_acc: 0.9063454360366474\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 2.5220868587493896 - sq_loss: 4.411175905261189e-05 - tot_loss: 0.30844482153258923 - acc: 0.955386289445049 - val_acc: 0.9066847641669494\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 2.488574981689453 - sq_loss: 4.315502883400768e-05 - tot_loss: 0.3084583510938046 - acc: 0.955658324265506 - val_acc: 0.9070240922972514\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 2.5670087337493896 - sq_loss: 4.224194344715215e-05 - tot_loss: 0.30344652900612346 - acc: 0.9566104461371056 - val_acc: 0.9073634204275535\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 2.531322956085205 - sq_loss: 4.1361992771271616e-05 - tot_loss: 0.29850306914045177 - acc: 0.9578346028291621 - val_acc: 0.9083814048184594\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 2.547070264816284 - sq_loss: 4.0502724004909396e-05 - tot_loss: 0.3003884199939648 - acc: 0.9581066376496191 - val_acc: 0.9087207329487614\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 2.5760111808776855 - sq_loss: 3.967049269704148e-05 - tot_loss: 0.2867946282858611 - acc: 0.9586507072905331 - val_acc: 0.9090600610790635\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 2.518531560897827 - sq_loss: 3.886034755851142e-05 - tot_loss: 0.2940002881249484 - acc: 0.9586507072905331 - val_acc: 0.9083814048184594\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 2.55352783203125 - sq_loss: 3.8110014429548755e-05 - tot_loss: 0.28128028665628335 - acc: 0.9590587595212187 - val_acc: 0.9090600610790635\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 2.5608699321746826 - sq_loss: 3.736427242984064e-05 - tot_loss: 0.2870635727425679 - acc: 0.9597388465723613 - val_acc: 0.9090600610790635\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 2.552987575531006 - sq_loss: 3.666036718641408e-05 - tot_loss: 0.2860973827990847 - acc: 0.9598748639825898 - val_acc: 0.9104173736002714\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 2.5522282123565674 - sq_loss: 3.598727926146239e-05 - tot_loss: 0.26521292282711784 - acc: 0.9606909684439608 - val_acc: 0.9114353579911775\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 2.5115742683410645 - sq_loss: 3.533668859745376e-05 - tot_loss: 0.28880452306520965 - acc: 0.9606909684439608 - val_acc: 0.9114353579911775\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 2.5781216621398926 - sq_loss: 3.472443495411426e-05 - tot_loss: 0.2763678237234899 - acc: 0.9620511425462459 - val_acc: 0.9121140142517815\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 2.5521960258483887 - sq_loss: 3.4131324355257675e-05 - tot_loss: 0.2665497049258647 - acc: 0.9627312295973884 - val_acc: 0.9117746861214795\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 2.5025999546051025 - sq_loss: 3.3547730708960444e-05 - tot_loss: 0.2703743916119947 - acc: 0.963411316648531 - val_acc: 0.9127926705123854\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 2.558824062347412 - sq_loss: 3.298934825579636e-05 - tot_loss: 0.26161857852730463 - acc: 0.9638193688792165 - val_acc: 0.9134713267729895\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 2.5313525199890137 - sq_loss: 3.243151513743214e-05 - tot_loss: 0.26530648831999315 - acc: 0.9643634385201306 - val_acc: 0.9148286392941974\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 2.5140771865844727 - sq_loss: 3.1899780879030004e-05 - tot_loss: 0.2612436747672291 - acc: 0.9644994559303591 - val_acc: 0.9151679674244995\n",
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 2.502939224243164 - sq_loss: 3.1378542189486325e-05 - tot_loss: 0.25243530249747437 - acc: 0.9643634385201306 - val_acc: 0.9148286392941974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 2.5142879486083984 - sq_loss: 3.089355959673412e-05 - tot_loss: 0.25617382788311716 - acc: 0.9644994559303591 - val_acc: 0.9158466236851035\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 2.477722644805908 - sq_loss: 3.0444347430602647e-05 - tot_loss: 0.2660640091816049 - acc: 0.9650435255712732 - val_acc: 0.9158466236851035\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 2.501218318939209 - sq_loss: 2.9991622795932926e-05 - tot_loss: 0.2472197022783007 - acc: 0.9657236126224157 - val_acc: 0.9168646080760094\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 2.482121229171753 - sq_loss: 2.9554601496784016e-05 - tot_loss: 0.2620868950334625 - acc: 0.9658596300326442 - val_acc: 0.9175432643366135\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 2.5501441955566406 - sq_loss: 2.913915886892937e-05 - tot_loss: 0.25384419879105735 - acc: 0.9658596300326442 - val_acc: 0.9178825924669155\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 2.488529920578003 - sq_loss: 2.87296024907846e-05 - tot_loss: 0.24588240529317318 - acc: 0.9662676822633297 - val_acc: 0.9182219205972175\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 2.558356761932373 - sq_loss: 2.8325497623882256e-05 - tot_loss: 0.2416551587736535 - acc: 0.9668117519042437 - val_acc: 0.9199185612487275\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 2.5656471252441406 - sq_loss: 2.7937820050283335e-05 - tot_loss: 0.2475574558786775 - acc: 0.9669477693144722 - val_acc: 0.9202578893790295\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 2.5346295833587646 - sq_loss: 2.7571384634939022e-05 - tot_loss: 0.24282305220276612 - acc: 0.9676278563656148 - val_acc: 0.9212758737699356\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 2.526003360748291 - sq_loss: 2.7206502636545338e-05 - tot_loss: 0.23261482370611475 - acc: 0.9674918389553863 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 2.479401111602783 - sq_loss: 2.6865460313274525e-05 - tot_loss: 0.24137347024174005 - acc: 0.9677638737758433 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 2.554140567779541 - sq_loss: 2.6531575713306665e-05 - tot_loss: 0.23986518349346397 - acc: 0.9681719260065288 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 2.521273136138916 - sq_loss: 2.6221418011118658e-05 - tot_loss: 0.2219018288504344 - acc: 0.9687159956474428 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 2.5185329914093018 - sq_loss: 2.590711483207997e-05 - tot_loss: 0.2178843783924549 - acc: 0.9689880304678999 - val_acc: 0.9222938581608415\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 2.5093843936920166 - sq_loss: 2.5610239390516654e-05 - tot_loss: 0.22720004718422615 - acc: 0.9691240478781284 - val_acc: 0.9229725144214456\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 2.5485854148864746 - sq_loss: 2.5304845621576533e-05 - tot_loss: 0.23577285131727876 - acc: 0.9693960826985855 - val_acc: 0.9236511706820495\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 2.56429386138916 - sq_loss: 2.501884773664642e-05 - tot_loss: 0.2394107641384835 - acc: 0.9693960826985855 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 2.5647010803222656 - sq_loss: 2.4747307179495692e-05 - tot_loss: 0.2280727316903608 - acc: 0.969804134929271 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 2.5477230548858643 - sq_loss: 2.448051964165643e-05 - tot_loss: 0.2205747639050628 - acc: 0.9696681175190425 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 2.5960729122161865 - sq_loss: 2.4215911253122613e-05 - tot_loss: 0.21316158434575527 - acc: 0.9699401523394995 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 2.559438705444336 - sq_loss: 2.3962376872077584e-05 - tot_loss: 0.22218444025855888 - acc: 0.9699401523394995 - val_acc: 0.9246691550729556\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 2.541910409927368 - sq_loss: 2.371983828197699e-05 - tot_loss: 0.22266301330245142 - acc: 0.970076169749728 - val_acc: 0.9256871394638616\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 2.602318525314331 - sq_loss: 2.3479822630179115e-05 - tot_loss: 0.22354369975795407 - acc: 0.9704842219804135 - val_acc: 0.9256871394638616\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 2.610828161239624 - sq_loss: 2.3242473616846837e-05 - tot_loss: 0.22641857668060084 - acc: 0.9704842219804135 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 2.6473264694213867 - sq_loss: 2.3017115381662734e-05 - tot_loss: 0.21160032172804222 - acc: 0.970620239390642 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 2.563070297241211 - sq_loss: 2.2787367925047874e-05 - tot_loss: 0.2185350243065045 - acc: 0.9707562568008705 - val_acc: 0.9263657957244655\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 2.6113224029541016 - sq_loss: 2.25730545935221e-05 - tot_loss: 0.21265266064449406 - acc: 0.970892274211099 - val_acc: 0.9263657957244655\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 2.5598161220550537 - sq_loss: 2.2361688024830073e-05 - tot_loss: 0.21303873363547154 - acc: 0.971164309031556 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 2.628422260284424 - sq_loss: 2.2164102119859308e-05 - tot_loss: 0.22145218311192139 - acc: 0.9710282916213275 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 2.6279211044311523 - sq_loss: 2.196353852923494e-05 - tot_loss: 0.2126815166571987 - acc: 0.971436343852013 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 2.622922420501709 - sq_loss: 2.1774947526864707e-05 - tot_loss: 0.19931670628443499 - acc: 0.9715723612622416 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 2.5470943450927734 - sq_loss: 2.1589599782601e-05 - tot_loss: 0.20493089799924746 - acc: 0.9715723612622416 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 2.6226627826690674 - sq_loss: 2.1399970137281343e-05 - tot_loss: 0.23479844505556002 - acc: 0.9722524483133841 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 2.5604450702667236 - sq_loss: 2.1221281713224016e-05 - tot_loss: 0.21137934565143723 - acc: 0.9723884657236126 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 2.624046564102173 - sq_loss: 2.1052948795841075e-05 - tot_loss: 0.2030375417402297 - acc: 0.9727965179542981 - val_acc: 0.9267051238547676\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 2.581650733947754 - sq_loss: 2.0883655452053063e-05 - tot_loss: 0.2237505656249823 - acc: 0.9730685527747551 - val_acc: 0.9267051238547676\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 2.5580594539642334 - sq_loss: 2.0710265744128264e-05 - tot_loss: 0.201849521502794 - acc: 0.9732045701849836 - val_acc: 0.9267051238547676\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 2.568176031112671 - sq_loss: 2.054718424915336e-05 - tot_loss: 0.20440577707944385 - acc: 0.9732045701849836 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 2.5758955478668213 - sq_loss: 2.040126310021151e-05 - tot_loss: 0.2032660665630317 - acc: 0.9734766050054406 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 2.5812368392944336 - sq_loss: 2.0234298062860034e-05 - tot_loss: 0.20551829259812848 - acc: 0.9736126224156693 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 2.558579444885254 - sq_loss: 2.007923467317596e-05 - tot_loss: 0.19195104830950527 - acc: 0.9738846572361263 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 2.616072177886963 - sq_loss: 1.99314617930213e-05 - tot_loss: 0.19098102328950972 - acc: 0.9744287268770403 - val_acc: 0.9277231082456736\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 2.6401875019073486 - sq_loss: 1.9788401914411224e-05 - tot_loss: 0.21283881790620285 - acc: 0.9742927094668118 - val_acc: 0.9277231082456736\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 2.6389970779418945 - sq_loss: 1.964552757272031e-05 - tot_loss: 0.19517090732705356 - acc: 0.9744287268770403 - val_acc: 0.9277231082456736\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 2.570068597793579 - sq_loss: 1.951217564055696e-05 - tot_loss: 0.19793798778704286 - acc: 0.9748367791077258 - val_acc: 0.9287410926365796\n",
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 2.638843536376953 - sq_loss: 1.938151581271086e-05 - tot_loss: 0.18900879021609285 - acc: 0.9749727965179543 - val_acc: 0.9287410926365796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 2.595858097076416 - sq_loss: 1.9247278032707982e-05 - tot_loss: 0.2131174661114983 - acc: 0.9752448313384113 - val_acc: 0.9290804207668816\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 2.545872688293457 - sq_loss: 1.9124863683828153e-05 - tot_loss: 0.19724904207009786 - acc: 0.9753808487486398 - val_acc: 0.9297590770274856\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 2.5785019397735596 - sq_loss: 1.9007826267625205e-05 - tot_loss: 0.19539326023675585 - acc: 0.9760609357997824 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 2.6041977405548096 - sq_loss: 1.8879856725106947e-05 - tot_loss: 0.18838444090340545 - acc: 0.9761969532100109 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 2.6249401569366455 - sq_loss: 1.8755548808258027e-05 - tot_loss: 0.1894080545804968 - acc: 0.9764689880304679 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 2.556164264678955 - sq_loss: 1.8635717424331233e-05 - tot_loss: 0.20106139171602422 - acc: 0.9764689880304679 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 2.5297083854675293 - sq_loss: 1.851974411692936e-05 - tot_loss: 0.18947624654913398 - acc: 0.9766050054406964 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 2.5417983531951904 - sq_loss: 1.8409371477901004e-05 - tot_loss: 0.18450900848955598 - acc: 0.9767410228509249 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 2.4846079349517822 - sq_loss: 1.83019492396852e-05 - tot_loss: 0.18265280973270137 - acc: 0.9770130576713819 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 2.5834314823150635 - sq_loss: 1.8186989109381102e-05 - tot_loss: 0.1971734744429341 - acc: 0.9770130576713819 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 2.564789295196533 - sq_loss: 1.808887282095384e-05 - tot_loss: 0.19878511480024486 - acc: 0.9775571273122959 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 2.5607311725616455 - sq_loss: 1.7984768419410102e-05 - tot_loss: 0.19794469080730437 - acc: 0.9779651795429815 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 2.529041290283203 - sq_loss: 1.7886917703435756e-05 - tot_loss: 0.1976010340876826 - acc: 0.9779651795429815 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 2.5667924880981445 - sq_loss: 1.7795055100577883e-05 - tot_loss: 0.1772890537014291 - acc: 0.9779651795429815 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 2.5626602172851562 - sq_loss: 1.769163463904988e-05 - tot_loss: 0.18153558636100797 - acc: 0.9783732317736671 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 2.5452046394348145 - sq_loss: 1.759636143106036e-05 - tot_loss: 0.18702807834304735 - acc: 0.9785092491838956 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 2.5338635444641113 - sq_loss: 1.7502343325759284e-05 - tot_loss: 0.18519652422821764 - acc: 0.9783732317736671 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 2.4939815998077393 - sq_loss: 1.7414611647836864e-05 - tot_loss: 0.20360692279913906 - acc: 0.9785092491838956 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 2.5735254287719727 - sq_loss: 1.7327722162008286e-05 - tot_loss: 0.18175141296751463 - acc: 0.9783732317736671 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 2.5784804821014404 - sq_loss: 1.7237123756785877e-05 - tot_loss: 0.18900467182274383 - acc: 0.9783732317736671 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 2.5707626342773438 - sq_loss: 1.7135607777163386e-05 - tot_loss: 0.18247317684534892 - acc: 0.9785092491838956 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 2.531656265258789 - sq_loss: 1.7043485058820806e-05 - tot_loss: 0.18881629547351508 - acc: 0.9785092491838956 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 2.520378351211548 - sq_loss: 1.696113577054348e-05 - tot_loss: 0.18040834469618972 - acc: 0.9783732317736671 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 2.4897422790527344 - sq_loss: 1.6883765056263655e-05 - tot_loss: 0.1690807333278883 - acc: 0.9785092491838956 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 2.5358641147613525 - sq_loss: 1.6803704056655988e-05 - tot_loss: 0.1872297349417522 - acc: 0.9786452665941241 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 2.535916805267334 - sq_loss: 1.672068356128875e-05 - tot_loss: 0.1899586607457877 - acc: 0.9786452665941241 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 2.5819339752197266 - sq_loss: 1.6642808986944146e-05 - tot_loss: 0.1852814697279257 - acc: 0.9787812840043526 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 2.5459561347961426 - sq_loss: 1.6563837561989203e-05 - tot_loss: 0.18097385196637106 - acc: 0.9790533188248096 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 2.5836615562438965 - sq_loss: 1.6481299098813906e-05 - tot_loss: 0.19593418846235977 - acc: 0.9790533188248096 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 2.539808511734009 - sq_loss: 1.6397620129282586e-05 - tot_loss: 0.17317004718498197 - acc: 0.9793253536452666 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 2.5284483432769775 - sq_loss: 1.632052044442389e-05 - tot_loss: 0.1786914689206185 - acc: 0.9794613710554951 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 2.522334575653076 - sq_loss: 1.624833203095477e-05 - tot_loss: 0.1888377394396059 - acc: 0.9797334058759521 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 2.5772593021392822 - sq_loss: 1.61748357641045e-05 - tot_loss: 0.19686284956046052 - acc: 0.9802774755168662 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 2.509897470474243 - sq_loss: 1.6100941138574854e-05 - tot_loss: 0.1808694739194152 - acc: 0.9800054406964092 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 2.514286518096924 - sq_loss: 1.6028609024942853e-05 - tot_loss: 0.18606975394706637 - acc: 0.9801414581066377 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 2.531000852584839 - sq_loss: 1.5955329217831604e-05 - tot_loss: 0.17618183896405526 - acc: 0.9801414581066377 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 2.5594770908355713 - sq_loss: 1.588462146173697e-05 - tot_loss: 0.18497353012600115 - acc: 0.9801414581066377 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 2.5369603633880615 - sq_loss: 1.5820409316802397e-05 - tot_loss: 0.17437526694905614 - acc: 0.9802774755168662 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 2.508543014526367 - sq_loss: 1.5760142559884116e-05 - tot_loss: 0.18261838360851357 - acc: 0.9802774755168662 - val_acc: 0.9382422802850356\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 2.565671920776367 - sq_loss: 1.569746200402733e-05 - tot_loss: 0.1831448820154833 - acc: 0.9805495103373232 - val_acc: 0.9382422802850356\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 2.513796091079712 - sq_loss: 1.5620620615663938e-05 - tot_loss: 0.1814111587176228 - acc: 0.9805495103373232 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 2.5159554481506348 - sq_loss: 1.5562111002509482e-05 - tot_loss: 0.17571241235663138 - acc: 0.9806855277475517 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 2.5547807216644287 - sq_loss: 1.5489502402488142e-05 - tot_loss: 0.1877875205049122 - acc: 0.9806855277475517 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 2.5899336338043213 - sq_loss: 1.5425457604578696e-05 - tot_loss: 0.17611529105411705 - acc: 0.9806855277475517 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 2.5202579498291016 - sq_loss: 1.5359297321992926e-05 - tot_loss: 0.188998189242227 - acc: 0.9809575625680087 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 2.529712677001953 - sq_loss: 1.530497866042424e-05 - tot_loss: 0.1803955142876532 - acc: 0.9813656147986942 - val_acc: 0.9399389209365456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 2.547436475753784 - sq_loss: 1.5256784536177292e-05 - tot_loss: 0.16980102115388718 - acc: 0.9813656147986942 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 2.5563595294952393 - sq_loss: 1.5205245290417224e-05 - tot_loss: 0.16697669232794965 - acc: 0.9815016322089227 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 2.5514867305755615 - sq_loss: 1.5148072634474374e-05 - tot_loss: 0.19519077360421022 - acc: 0.9815016322089227 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 2.546884775161743 - sq_loss: 1.5088427971932106e-05 - tot_loss: 0.18248528927756524 - acc: 0.9815016322089227 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 2.5584263801574707 - sq_loss: 1.5028414964035619e-05 - tot_loss: 0.16831621516477924 - acc: 0.9817736670293797 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 2.549684524536133 - sq_loss: 1.4968345567467622e-05 - tot_loss: 0.17674973961501905 - acc: 0.9821817192600653 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 2.558318614959717 - sq_loss: 1.4909174751664978e-05 - tot_loss: 0.17032832736626347 - acc: 0.9824537540805223 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 2.5444846153259277 - sq_loss: 1.484678614360746e-05 - tot_loss: 0.18352564514708547 - acc: 0.9824537540805223 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 2.546304702758789 - sq_loss: 1.47969440149609e-05 - tot_loss: 0.17351669875414188 - acc: 0.9823177366702938 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 2.549117088317871 - sq_loss: 1.4745597582077608e-05 - tot_loss: 0.1689198357653794 - acc: 0.9824537540805223 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 2.5370657444000244 - sq_loss: 1.4690599527966697e-05 - tot_loss: 0.17179305686617852 - acc: 0.9828618063112078 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 2.5011508464813232 - sq_loss: 1.4639077562605962e-05 - tot_loss: 0.17909589467640785 - acc: 0.9829978237214363 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 2.5796139240264893 - sq_loss: 1.4589892089134082e-05 - tot_loss: 0.179455886410139 - acc: 0.9829978237214363 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 2.5198709964752197 - sq_loss: 1.4537105926137883e-05 - tot_loss: 0.1743481408303751 - acc: 0.9831338411316648 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 2.6069746017456055 - sq_loss: 1.448768762202235e-05 - tot_loss: 0.18349278530463664 - acc: 0.9831338411316648 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 2.588469982147217 - sq_loss: 1.4437705431191716e-05 - tot_loss: 0.1803670362387635 - acc: 0.9835418933623504 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 1.7542448043823242 - sq_loss: 1.4388228919415269e-05 - tot_loss: 0.16839367193287558 - acc: 0.9834058759521219 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 1.2657651901245117 - sq_loss: 1.4343140719574876e-05 - tot_loss: 0.17268973461578696 - acc: 0.9836779107725789 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 1.2761180400848389 - sq_loss: 1.4301385817816481e-05 - tot_loss: 0.1809085503931982 - acc: 0.9840859630032645 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 1.288834810256958 - sq_loss: 1.4253296285460237e-05 - tot_loss: 0.188831463917154 - acc: 0.983949945593036 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 1.2943956851959229 - sq_loss: 1.4208096217771526e-05 - tot_loss: 0.18005259894151493 - acc: 0.9840859630032645 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 1.3092858791351318 - sq_loss: 1.4161865692585707e-05 - tot_loss: 0.18269249420379197 - acc: 0.9840859630032645 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 1.3152341842651367 - sq_loss: 1.4113449651631527e-05 - tot_loss: 0.16122528576694606 - acc: 0.984221980413493 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 1.2916574478149414 - sq_loss: 1.40678821480833e-05 - tot_loss: 0.18387341377102473 - acc: 0.984221980413493 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 1.282355546951294 - sq_loss: 1.401848658133531e-05 - tot_loss: 0.1865408807588551 - acc: 0.984221980413493 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 1.2737035751342773 - sq_loss: 1.3973078239359893e-05 - tot_loss: 0.1608821169293435 - acc: 0.984221980413493 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 1.276782512664795 - sq_loss: 1.3930423847341444e-05 - tot_loss: 0.17710381909147088 - acc: 0.9843579978237215 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 1.2755985260009766 - sq_loss: 1.3881909580959473e-05 - tot_loss: 0.18060113224275653 - acc: 0.98449401523395 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 1.2762658596038818 - sq_loss: 1.383650305797346e-05 - tot_loss: 0.18677506621806117 - acc: 0.98449401523395 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 1.2736177444458008 - sq_loss: 1.3791036508337129e-05 - tot_loss: 0.18393705090156232 - acc: 0.98449401523395 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 1.2899906635284424 - sq_loss: 1.3747522643825505e-05 - tot_loss: 0.1699897712121441 - acc: 0.984766050054407 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 1.279921293258667 - sq_loss: 1.3708505321119446e-05 - tot_loss: 0.1674410987194932 - acc: 0.984766050054407 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 1.278611421585083 - sq_loss: 1.365814205200877e-05 - tot_loss: 0.17295620460947703 - acc: 0.984766050054407 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 1.2925081253051758 - sq_loss: 1.3614044291898608e-05 - tot_loss: 0.16956633861990156 - acc: 0.984766050054407 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 1.2944555282592773 - sq_loss: 1.3573095202445984e-05 - tot_loss: 0.17217938890949824 - acc: 0.984766050054407 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 1.2817018032073975 - sq_loss: 1.3536387996282429e-05 - tot_loss: 0.16251237435324128 - acc: 0.9846300326441785 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 1.2957797050476074 - sq_loss: 1.3500775821739808e-05 - tot_loss: 0.17422902440858934 - acc: 0.9846300326441785 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 1.2721331119537354 - sq_loss: 1.3458974535751622e-05 - tot_loss: 0.1607037138989682 - acc: 0.9846300326441785 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 1.286496639251709 - sq_loss: 1.3415296962193679e-05 - tot_loss: 0.17343080294831736 - acc: 0.9846300326441785 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 1.2917850017547607 - sq_loss: 1.33712928800378e-05 - tot_loss: 0.16811011409568266 - acc: 0.984766050054407 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 1.2899320125579834 - sq_loss: 1.3332150956557598e-05 - tot_loss: 0.1692951660762958 - acc: 0.985038084874864 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 1.2927019596099854 - sq_loss: 1.3292250514496118e-05 - tot_loss: 0.1547193775455611 - acc: 0.984766050054407 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 1.292771577835083 - sq_loss: 1.3254173609311692e-05 - tot_loss: 0.15987103223493193 - acc: 0.985038084874864 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 1.2796058654785156 - sq_loss: 1.3217050764069427e-05 - tot_loss: 0.18400581494763912 - acc: 0.985038084874864 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 1.286667823791504 - sq_loss: 1.3181761460145935e-05 - tot_loss: 0.1638826899801984 - acc: 0.985038084874864 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 1.2862272262573242 - sq_loss: 1.3143100659362972e-05 - tot_loss: 0.17263751840800978 - acc: 0.9851741022850925 - val_acc: 0.9463861554122837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 1.2816615104675293 - sq_loss: 1.3102246157359332e-05 - tot_loss: 0.17374557844661354 - acc: 0.985038084874864 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 1.273874282836914 - sq_loss: 1.306357626162935e-05 - tot_loss: 0.18366220123303378 - acc: 0.9851741022850925 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 1.2999005317687988 - sq_loss: 1.3021602171647828e-05 - tot_loss: 0.17374881558829713 - acc: 0.9854461371055495 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 1.297987699508667 - sq_loss: 1.2982389307580888e-05 - tot_loss: 0.18220971712911194 - acc: 0.9854461371055495 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 1.2826886177062988 - sq_loss: 1.2951184544363059e-05 - tot_loss: 0.1657788876509585 - acc: 0.985582154515778 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 1.3011033535003662 - sq_loss: 1.2919590517412871e-05 - tot_loss: 0.17316022351150195 - acc: 0.985854189336235 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 1.307208776473999 - sq_loss: 1.2884109310107306e-05 - tot_loss: 0.15526248737245396 - acc: 0.985854189336235 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 1.2915623188018799 - sq_loss: 1.284705285797827e-05 - tot_loss: 0.16241707054243193 - acc: 0.985854189336235 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 1.2971179485321045 - sq_loss: 1.2810295629606117e-05 - tot_loss: 0.16696549025013496 - acc: 0.985854189336235 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 1.2908804416656494 - sq_loss: 1.2774469723808579e-05 - tot_loss: 0.1662911159188667 - acc: 0.9859902067464635 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 1.2876808643341064 - sq_loss: 1.2742700164380949e-05 - tot_loss: 0.16095162414532638 - acc: 0.985854189336235 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 1.3113751411437988 - sq_loss: 1.2707715541182552e-05 - tot_loss: 0.16155494157015937 - acc: 0.9859902067464635 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 1.2858037948608398 - sq_loss: 1.2672375305555761e-05 - tot_loss: 0.1724145884135453 - acc: 0.986126224156692 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 1.2950496673583984 - sq_loss: 1.2639301530725788e-05 - tot_loss: 0.1553500935578711 - acc: 0.9859902067464635 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 1.3022360801696777 - sq_loss: 1.2605806659848895e-05 - tot_loss: 0.16858626443878677 - acc: 0.986126224156692 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 1.2961618900299072 - sq_loss: 1.257295207324205e-05 - tot_loss: 0.17013074215925883 - acc: 0.986126224156692 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 1.3030517101287842 - sq_loss: 1.2541653632069938e-05 - tot_loss: 0.16854580127919405 - acc: 0.9862622415669206 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 1.293879508972168 - sq_loss: 1.2513874025898986e-05 - tot_loss: 0.17303628924166503 - acc: 0.9862622415669206 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 1.3271565437316895 - sq_loss: 1.2482866623031441e-05 - tot_loss: 0.17409609492271727 - acc: 0.986126224156692 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 1.3108327388763428 - sq_loss: 1.2452913324523252e-05 - tot_loss: 0.1617948214484528 - acc: 0.9862622415669206 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 1.297084093093872 - sq_loss: 1.2413772310537752e-05 - tot_loss: 0.16991231123871842 - acc: 0.986126224156692 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 1.3061647415161133 - sq_loss: 1.2383063221932389e-05 - tot_loss: 0.16683002310023198 - acc: 0.9859902067464635 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 1.3291034698486328 - sq_loss: 1.2351533769106027e-05 - tot_loss: 0.18659514189035065 - acc: 0.986126224156692 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 1.320751428604126 - sq_loss: 1.2317826076468918e-05 - tot_loss: 0.18382373703066435 - acc: 0.9862622415669206 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 1.3211336135864258 - sq_loss: 1.2285468073969241e-05 - tot_loss: 0.1670779934581219 - acc: 0.9862622415669206 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 1.3053417205810547 - sq_loss: 1.2259804861969315e-05 - tot_loss: 0.17097910777569325 - acc: 0.986126224156692 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 1.2879717350006104 - sq_loss: 1.222649370902218e-05 - tot_loss: 0.16927603027775717 - acc: 0.9862622415669206 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 1.3160912990570068 - sq_loss: 1.2194294868095312e-05 - tot_loss: 0.18131904289619172 - acc: 0.9862622415669206 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 1.3052465915679932 - sq_loss: 1.2166423402959481e-05 - tot_loss: 0.16143580189306306 - acc: 0.9862622415669206 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 1.3058514595031738 - sq_loss: 1.2134265489294194e-05 - tot_loss: 0.17606372753810717 - acc: 0.9863982589771491 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 1.2800695896148682 - sq_loss: 1.2097191756765824e-05 - tot_loss: 0.17840821532936957 - acc: 0.9862622415669206 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 1.294255018234253 - sq_loss: 1.2063054782629479e-05 - tot_loss: 0.17693686040756518 - acc: 0.9862622415669206 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 1.279723882675171 - sq_loss: 1.2033685379719827e-05 - tot_loss: 0.16060933517191245 - acc: 0.9863982589771491 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 1.2785675525665283 - sq_loss: 1.1999512935290113e-05 - tot_loss: 0.15687957383200057 - acc: 0.9862622415669206 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 1.273319959640503 - sq_loss: 1.19701635412639e-05 - tot_loss: 0.17483457189567275 - acc: 0.9862622415669206 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 1.2989463806152344 - sq_loss: 1.194303604279412e-05 - tot_loss: 0.1675045391849892 - acc: 0.9863982589771491 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 1.2939043045043945 - sq_loss: 1.1917999472643714e-05 - tot_loss: 0.16166491185528287 - acc: 0.9865342763873776 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 1.2747256755828857 - sq_loss: 1.1888758308487013e-05 - tot_loss: 0.1644765039057603 - acc: 0.9866702937976061 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 1.2994372844696045 - sq_loss: 1.1859334335895255e-05 - tot_loss: 0.1785432673441676 - acc: 0.9866702937976061 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 1.2790379524230957 - sq_loss: 1.1829607501567807e-05 - tot_loss: 0.17714238004684546 - acc: 0.9865342763873776 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 1.2842271327972412 - sq_loss: 1.1801644177467097e-05 - tot_loss: 0.17484265239603758 - acc: 0.9863982589771491 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 1.2848701477050781 - sq_loss: 1.1776721294154413e-05 - tot_loss: 0.16999233271832281 - acc: 0.9863982589771491 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 1.3065941333770752 - sq_loss: 1.1753010767279193e-05 - tot_loss: 0.1672409194991502 - acc: 0.9863982589771491 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 1.3095600605010986 - sq_loss: 1.1726343473128509e-05 - tot_loss: 0.17371013877585995 - acc: 0.9863982589771491 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 1.2800824642181396 - sq_loss: 1.1701478797476739e-05 - tot_loss: 0.1861271249538703 - acc: 0.9863982589771491 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 1.2993032932281494 - sq_loss: 1.1673074368445668e-05 - tot_loss: 0.1667577162899363 - acc: 0.9865342763873776 - val_acc: 0.9504580929759077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 1.2930433750152588 - sq_loss: 1.1643323887255974e-05 - tot_loss: 0.16286070109336492 - acc: 0.9863982589771491 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 1.300661563873291 - sq_loss: 1.1612994967435952e-05 - tot_loss: 0.16434597051565447 - acc: 0.9863982589771491 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 1.2887482643127441 - sq_loss: 1.1582174920476973e-05 - tot_loss: 0.1647199819516203 - acc: 0.9865342763873776 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 1.2687122821807861 - sq_loss: 1.1551743227755651e-05 - tot_loss: 0.1717875868669978 - acc: 0.9868063112078346 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 1.2995283603668213 - sq_loss: 1.1524231922521722e-05 - tot_loss: 0.17611622674931482 - acc: 0.9866702937976061 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 1.283977746963501 - sq_loss: 1.1495561921037734e-05 - tot_loss: 0.1692715023069269 - acc: 0.9870783460282916 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 1.2974915504455566 - sq_loss: 1.146590966527583e-05 - tot_loss: 0.1795598072135931 - acc: 0.9870783460282916 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 1.3038783073425293 - sq_loss: 1.1439421541581396e-05 - tot_loss: 0.15998863831036658 - acc: 0.9868063112078346 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 1.3140101432800293 - sq_loss: 1.1412798812671099e-05 - tot_loss: 0.1551601905113671 - acc: 0.9872143634385201 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 1.3031337261199951 - sq_loss: 1.1388181519578211e-05 - tot_loss: 0.17777807479924945 - acc: 0.9870783460282916 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 1.3100247383117676 - sq_loss: 1.1364627425791696e-05 - tot_loss: 0.17013833043607463 - acc: 0.9872143634385201 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 1.3245081901550293 - sq_loss: 1.133816476794891e-05 - tot_loss: 0.16064243005230594 - acc: 0.9872143634385201 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 1.3374583721160889 - sq_loss: 1.1312405149510596e-05 - tot_loss: 0.16176300086397077 - acc: 0.9870783460282916 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 1.2861716747283936 - sq_loss: 1.1286081644357182e-05 - tot_loss: 0.16882454206398734 - acc: 0.9873503808487486 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 1.305732250213623 - sq_loss: 1.1257530786679126e-05 - tot_loss: 0.16413577840494042 - acc: 0.9874863982589771 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 1.292405605316162 - sq_loss: 1.1237127182539552e-05 - tot_loss: 0.16292515130568574 - acc: 0.9873503808487486 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 1.286400556564331 - sq_loss: 1.1216328857699409e-05 - tot_loss: 0.15889880823667113 - acc: 0.9873503808487486 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 1.2881786823272705 - sq_loss: 1.1192975762241986e-05 - tot_loss: 0.1619161875050139 - acc: 0.9873503808487486 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 1.2824196815490723 - sq_loss: 1.11712324724067e-05 - tot_loss: 0.16190690237479544 - acc: 0.9873503808487486 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 1.297607421875 - sq_loss: 1.1146728866151534e-05 - tot_loss: 0.14832085927974958 - acc: 0.9873503808487486 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 1.296583890914917 - sq_loss: 1.1116779205622151e-05 - tot_loss: 0.1704785619196798 - acc: 0.9873503808487486 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 1.3137016296386719 - sq_loss: 1.1091760825365782e-05 - tot_loss: 0.1576633398598375 - acc: 0.9873503808487486 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 1.323350191116333 - sq_loss: 1.1067477316828445e-05 - tot_loss: 0.17270385210190398 - acc: 0.9874863982589771 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 1.3047640323638916 - sq_loss: 1.104511375160655e-05 - tot_loss: 0.1649399782462666 - acc: 0.9874863982589771 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 1.2925729751586914 - sq_loss: 1.1023869774362538e-05 - tot_loss: 0.1644015704810755 - acc: 0.9874863982589771 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 1.2822701930999756 - sq_loss: 1.0999737241945695e-05 - tot_loss: 0.1483327637466232 - acc: 0.9873503808487486 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 1.2919178009033203 - sq_loss: 1.0975878467434086e-05 - tot_loss: 0.1718025335959794 - acc: 0.9874863982589771 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 1.2839553356170654 - sq_loss: 1.0951878721243702e-05 - tot_loss: 0.15648243119331795 - acc: 0.9876224156692056 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 1.2945146560668945 - sq_loss: 1.0928055417025462e-05 - tot_loss: 0.17105798580344356 - acc: 0.9874863982589771 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 1.3062233924865723 - sq_loss: 1.090542173187714e-05 - tot_loss: 0.1680688499318208 - acc: 0.9874863982589771 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 1.279801845550537 - sq_loss: 1.088225963030709e-05 - tot_loss: 0.15538649671760396 - acc: 0.9876224156692056 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 1.2984654903411865 - sq_loss: 1.0862685485335533e-05 - tot_loss: 0.16975198673016223 - acc: 0.9874863982589771 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 1.3031656742095947 - sq_loss: 1.0836565706995316e-05 - tot_loss: 0.17258278080650058 - acc: 0.9876224156692056 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 1.2963943481445312 - sq_loss: 1.081301616068231e-05 - tot_loss: 0.17207290219216276 - acc: 0.9877584330794341 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 1.308109998703003 - sq_loss: 1.078605328075355e-05 - tot_loss: 0.16313242035930386 - acc: 0.9877584330794341 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 1.300854206085205 - sq_loss: 1.0764397302409634e-05 - tot_loss: 0.16258575919723484 - acc: 0.9877584330794341 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 1.302363395690918 - sq_loss: 1.0738738637883216e-05 - tot_loss: 0.1640769440925638 - acc: 0.9877584330794341 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 1.3057279586791992 - sq_loss: 1.0717006261984352e-05 - tot_loss: 0.14882244701764336 - acc: 0.9876224156692056 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 1.2829430103302002 - sq_loss: 1.0695057426346466e-05 - tot_loss: 0.16865325834037748 - acc: 0.9876224156692056 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 1.2963840961456299 - sq_loss: 1.0671920790628064e-05 - tot_loss: 0.16539300622989117 - acc: 0.9876224156692056 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 1.2895479202270508 - sq_loss: 1.0652580385794863e-05 - tot_loss: 0.17433544435271386 - acc: 0.9876224156692056 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 1.2786791324615479 - sq_loss: 1.0631461918819696e-05 - tot_loss: 0.17910972356698096 - acc: 0.9876224156692056 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 1.2769381999969482 - sq_loss: 1.0608075172058307e-05 - tot_loss: 0.17921587007462136 - acc: 0.9876224156692056 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 1.3052353858947754 - sq_loss: 1.0584086339804344e-05 - tot_loss: 0.1543618039056227 - acc: 0.9876224156692056 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 1.2971205711364746 - sq_loss: 1.0562408533587586e-05 - tot_loss: 0.16854647835945968 - acc: 0.9877584330794341 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 1.304117202758789 - sq_loss: 1.054057793226093e-05 - tot_loss: 0.1544286337199665 - acc: 0.9877584330794341 - val_acc: 0.9541907024092298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 1.304398775100708 - sq_loss: 1.0516596375964582e-05 - tot_loss: 0.15099881582037966 - acc: 0.9877584330794341 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 1.288930892944336 - sq_loss: 1.049567072186619e-05 - tot_loss: 0.14858608250090555 - acc: 0.9876224156692056 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 1.2982566356658936 - sq_loss: 1.0472665962879546e-05 - tot_loss: 0.1619532894226836 - acc: 0.9877584330794341 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 1.2764670848846436 - sq_loss: 1.045116368914023e-05 - tot_loss: 0.14066788620206694 - acc: 0.9878944504896626 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 1.2843780517578125 - sq_loss: 1.0431339433125686e-05 - tot_loss: 0.16599018629719353 - acc: 0.9876224156692056 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 1.2639386653900146 - sq_loss: 1.0412255505798385e-05 - tot_loss: 0.16113153990117723 - acc: 0.9877584330794341 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 1.270735502243042 - sq_loss: 1.0395428944320884e-05 - tot_loss: 0.15709031799780604 - acc: 0.9877584330794341 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 1.2733755111694336 - sq_loss: 1.0375714737165254e-05 - tot_loss: 0.15243238134578263 - acc: 0.9878944504896626 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 1.2808284759521484 - sq_loss: 1.0351754099247046e-05 - tot_loss: 0.14835072258809845 - acc: 0.9877584330794341 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 1.2762653827667236 - sq_loss: 1.0328637472412083e-05 - tot_loss: 0.1535855732265432 - acc: 0.9877584330794341 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 1.277336597442627 - sq_loss: 1.030893145070877e-05 - tot_loss: 0.15804098982766135 - acc: 0.9877584330794341 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 1.2492895126342773 - sq_loss: 1.0287654731655493e-05 - tot_loss: 0.1548448119127599 - acc: 0.9878944504896626 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 1.3010990619659424 - sq_loss: 1.0270113307342399e-05 - tot_loss: 0.17354396620375212 - acc: 0.9877584330794341 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 1.2845885753631592 - sq_loss: 1.0251722414977849e-05 - tot_loss: 0.155870638371006 - acc: 0.9880304678998912 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 1.2642054557800293 - sq_loss: 1.0231396117887925e-05 - tot_loss: 0.15473679037398114 - acc: 0.9880304678998912 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 1.285407304763794 - sq_loss: 1.0210063919657841e-05 - tot_loss: 0.15821380068290836 - acc: 0.9877584330794341 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 1.2866122722625732 - sq_loss: 1.0191489309363533e-05 - tot_loss: 0.17040126575948733 - acc: 0.9877584330794341 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 1.2814061641693115 - sq_loss: 1.0174177077715285e-05 - tot_loss: 0.16199581616803727 - acc: 0.9878944504896626 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 1.2807350158691406 - sq_loss: 1.0156072676181793e-05 - tot_loss: 0.15131230203517276 - acc: 0.9878944504896626 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 1.26566743850708 - sq_loss: 1.0137720892089419e-05 - tot_loss: 0.15877284895701393 - acc: 0.9880304678998912 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 1.2722656726837158 - sq_loss: 1.011686799756717e-05 - tot_loss: 0.1447541321239214 - acc: 0.9880304678998912 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 1.2696857452392578 - sq_loss: 1.0096989171870518e-05 - tot_loss: 0.14715618988456214 - acc: 0.9881664853101197 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 1.287764072418213 - sq_loss: 1.007970240607392e-05 - tot_loss: 0.17319874884928055 - acc: 0.9880304678998912 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 1.30440354347229 - sq_loss: 1.006161437544506e-05 - tot_loss: 0.17246058656390773 - acc: 0.9883025027203483 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 1.279402494430542 - sq_loss: 1.004229488899e-05 - tot_loss: 0.15755288204968565 - acc: 0.9883025027203483 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 1.2890088558197021 - sq_loss: 1.0022027709055692e-05 - tot_loss: 0.15983699569925136 - acc: 0.9884385201305768 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 1.2846519947052002 - sq_loss: 1.0002083399740513e-05 - tot_loss: 0.1491513391020831 - acc: 0.9883025027203483 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 1.2879722118377686 - sq_loss: 9.981017683458049e-06 - tot_loss: 0.16233673658782521 - acc: 0.9883025027203483 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 1.2904903888702393 - sq_loss: 9.962041076505557e-06 - tot_loss: 0.16703214376160247 - acc: 0.9883025027203483 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 1.2716484069824219 - sq_loss: 9.94382116914494e-06 - tot_loss: 0.15622533598970278 - acc: 0.9883025027203483 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 1.286412239074707 - sq_loss: 9.927147402777337e-06 - tot_loss: 0.16046244268346754 - acc: 0.9884385201305768 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 1.2847514152526855 - sq_loss: 9.907215826387983e-06 - tot_loss: 0.17348001241654742 - acc: 0.9884385201305768 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 1.28725266456604 - sq_loss: 9.888452041195706e-06 - tot_loss: 0.1646262668179972 - acc: 0.9884385201305768 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 1.288217544555664 - sq_loss: 9.87035127764102e-06 - tot_loss: 0.16364284437641885 - acc: 0.9884385201305768 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 1.2738842964172363 - sq_loss: 9.853614756138995e-06 - tot_loss: 0.15137584407830929 - acc: 0.9884385201305768 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 1.3042402267456055 - sq_loss: 9.834371667238884e-06 - tot_loss: 0.1535475979962797 - acc: 0.9887105549510338 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 1.3041601181030273 - sq_loss: 9.81478933681501e-06 - tot_loss: 0.16989847973152905 - acc: 0.9888465723612623 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 1.2863960266113281 - sq_loss: 9.796735866984818e-06 - tot_loss: 0.16364822520196043 - acc: 0.9885745375408053 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 1.3041601181030273 - sq_loss: 9.775461876415648e-06 - tot_loss: 0.15176220874283075 - acc: 0.9888465723612623 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 1.3059217929840088 - sq_loss: 9.760600732988678e-06 - tot_loss: 0.16424153338103054 - acc: 0.9889825897714908 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 1.3283047676086426 - sq_loss: 9.741860594658647e-06 - tot_loss: 0.17668323479031756 - acc: 0.9889825897714908 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 1.308121919631958 - sq_loss: 9.726293683343101e-06 - tot_loss: 0.15895920997527213 - acc: 0.9889825897714908 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 1.2864923477172852 - sq_loss: 9.708855031931307e-06 - tot_loss: 0.15577278748911283 - acc: 0.9889825897714908 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 1.2755358219146729 - sq_loss: 9.68876793194795e-06 - tot_loss: 0.16126759984433647 - acc: 0.9888465723612623 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 1.2958571910858154 - sq_loss: 9.673266504250932e-06 - tot_loss: 0.15420850975828415 - acc: 0.9889825897714908 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 1.3103563785552979 - sq_loss: 9.658806447987445e-06 - tot_loss: 0.17606260512328475 - acc: 0.9889825897714908 - val_acc: 0.9575839837122497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 1.2837440967559814 - sq_loss: 9.63877209869679e-06 - tot_loss: 0.16816268955456337 - acc: 0.9889825897714908 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 1.3040742874145508 - sq_loss: 9.622707693779375e-06 - tot_loss: 0.16979439677967179 - acc: 0.9889825897714908 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 1.2852671146392822 - sq_loss: 9.608618711354211e-06 - tot_loss: 0.1586435266544015 - acc: 0.9892546245919478 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 1.3003015518188477 - sq_loss: 9.593235517968424e-06 - tot_loss: 0.1450319126630646 - acc: 0.9891186071817193 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 1.3070805072784424 - sq_loss: 9.573559509590268e-06 - tot_loss: 0.15648986651807206 - acc: 0.9891186071817193 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 1.3059697151184082 - sq_loss: 9.553603376843967e-06 - tot_loss: 0.15866806560842406 - acc: 0.9891186071817193 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 1.2800891399383545 - sq_loss: 9.538002814224456e-06 - tot_loss: 0.17139256201486575 - acc: 0.9891186071817193 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 1.2826824188232422 - sq_loss: 9.523142580292188e-06 - tot_loss: 0.14847196613868618 - acc: 0.9891186071817193 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 1.2708945274353027 - sq_loss: 9.50854882830754e-06 - tot_loss: 0.16036096831546587 - acc: 0.9892546245919478 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 1.2664904594421387 - sq_loss: 9.492235221841838e-06 - tot_loss: 0.1533880494688873 - acc: 0.9893906420021763 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 1.2781288623809814 - sq_loss: 9.475121260038577e-06 - tot_loss: 0.16606512067058077 - acc: 0.9892546245919478 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 1.3026056289672852 - sq_loss: 9.453452548768837e-06 - tot_loss: 0.1587792812655593 - acc: 0.9895266594124048 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 1.2856357097625732 - sq_loss: 9.436360414838418e-06 - tot_loss: 0.16544445528597862 - acc: 0.9893906420021763 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 1.2825608253479004 - sq_loss: 9.417588444193825e-06 - tot_loss: 0.18637003580504086 - acc: 0.9893906420021763 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 1.2746918201446533 - sq_loss: 9.39954406931065e-06 - tot_loss: 0.16333742328847478 - acc: 0.9895266594124048 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 1.2798078060150146 - sq_loss: 9.382465577800758e-06 - tot_loss: 0.16562413651611507 - acc: 0.9895266594124048 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 1.296065092086792 - sq_loss: 9.366945050715003e-06 - tot_loss: 0.1692408372033185 - acc: 0.9893906420021763 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 1.3039183616638184 - sq_loss: 9.349839274364058e-06 - tot_loss: 0.16114453622379443 - acc: 0.9895266594124048 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 1.2966840267181396 - sq_loss: 9.335166396340355e-06 - tot_loss: 0.1624490428903087 - acc: 0.9895266594124048 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 1.2822773456573486 - sq_loss: 9.322193363914266e-06 - tot_loss: 0.18381712676912798 - acc: 0.9895266594124048 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 1.2878239154815674 - sq_loss: 9.305487765232101e-06 - tot_loss: 0.15896199200503247 - acc: 0.9895266594124048 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 1.2947285175323486 - sq_loss: 9.287961802328937e-06 - tot_loss: 0.1719111785980374 - acc: 0.9892546245919478 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 1.2969496250152588 - sq_loss: 9.274260264646728e-06 - tot_loss: 0.1652459376773905 - acc: 0.9893906420021763 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 1.2989230155944824 - sq_loss: 9.257471901946701e-06 - tot_loss: 0.1469673766355939 - acc: 0.9895266594124048 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 1.306898832321167 - sq_loss: 9.242475243809167e-06 - tot_loss: 0.1594980050329795 - acc: 0.9895266594124048 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 1.2819902896881104 - sq_loss: 9.22867184272036e-06 - tot_loss: 0.1632148591229452 - acc: 0.9895266594124048 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 1.303790807723999 - sq_loss: 9.213341400027275e-06 - tot_loss: 0.16093854433540145 - acc: 0.9893906420021763 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 1.2840492725372314 - sq_loss: 9.19958074518945e-06 - tot_loss: 0.1557902418441799 - acc: 0.9893906420021763 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 1.2976818084716797 - sq_loss: 9.18374462344218e-06 - tot_loss: 0.1511976179336827 - acc: 0.9893906420021763 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 1.2845759391784668 - sq_loss: 9.168104043055791e-06 - tot_loss: 0.16873510020433002 - acc: 0.9895266594124048 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 1.2985949516296387 - sq_loss: 9.149058314505965e-06 - tot_loss: 0.1584028396836814 - acc: 0.9895266594124048 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 1.2790272235870361 - sq_loss: 9.134456377069e-06 - tot_loss: 0.18369604520790261 - acc: 0.9895266594124048 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 1.2787744998931885 - sq_loss: 9.122885785473045e-06 - tot_loss: 0.17468580979975457 - acc: 0.9895266594124048 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 1.2879393100738525 - sq_loss: 9.109809070650954e-06 - tot_loss: 0.1696932556580535 - acc: 0.9895266594124048 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 1.2662250995635986 - sq_loss: 9.096173016587272e-06 - tot_loss: 0.16415335116478502 - acc: 0.9895266594124048 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 1.2776339054107666 - sq_loss: 9.082082215172704e-06 - tot_loss: 0.16647221977349602 - acc: 0.9895266594124048 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 1.2975871562957764 - sq_loss: 9.066796337720007e-06 - tot_loss: 0.1623416915829452 - acc: 0.9895266594124048 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 1.2924060821533203 - sq_loss: 9.049060281540733e-06 - tot_loss: 0.16112585105918242 - acc: 0.9895266594124048 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 1.2917678356170654 - sq_loss: 9.030402907228563e-06 - tot_loss: 0.17540726130101092 - acc: 0.9896626768226333 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 1.2935481071472168 - sq_loss: 9.01558087207377e-06 - tot_loss: 0.16152523738717406 - acc: 0.9895266594124048 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 1.2770023345947266 - sq_loss: 8.99893984751543e-06 - tot_loss: 0.1506051803667674 - acc: 0.9895266594124048 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 1.3010900020599365 - sq_loss: 8.9823033704306e-06 - tot_loss: 0.15278097309544592 - acc: 0.9897986942328618 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 1.3013689517974854 - sq_loss: 8.965898814494722e-06 - tot_loss: 0.16668364428375781 - acc: 0.9896626768226333 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 1.287858009338379 - sq_loss: 8.94972345122369e-06 - tot_loss: 0.16880859870659748 - acc: 0.9896626768226333 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 1.2990636825561523 - sq_loss: 8.93093238119036e-06 - tot_loss: 0.14726108088715506 - acc: 0.9896626768226333 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 1.284285068511963 - sq_loss: 8.916674232750665e-06 - tot_loss: 0.17002471640843453 - acc: 0.9897986942328618 - val_acc: 0.9592806243637597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 1.29811429977417 - sq_loss: 8.903413799998816e-06 - tot_loss: 0.1533646807023672 - acc: 0.9897986942328618 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 1.2982990741729736 - sq_loss: 8.891728612070438e-06 - tot_loss: 0.17389367136237865 - acc: 0.9897986942328618 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 1.3047261238098145 - sq_loss: 8.877788786776364e-06 - tot_loss: 0.17878630926004746 - acc: 0.9896626768226333 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 1.2989721298217773 - sq_loss: 8.865770723787136e-06 - tot_loss: 0.16221111285408085 - acc: 0.9896626768226333 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 1.298570156097412 - sq_loss: 8.849533514876384e-06 - tot_loss: 0.167150726659834 - acc: 0.9896626768226333 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 1.280057430267334 - sq_loss: 8.833619176584762e-06 - tot_loss: 0.16902679489597716 - acc: 0.9897986942328618 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 1.298882007598877 - sq_loss: 8.820326002023648e-06 - tot_loss: 0.16824053699336616 - acc: 0.9896626768226333 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 1.3063571453094482 - sq_loss: 8.808434358797967e-06 - tot_loss: 0.1556075781765287 - acc: 0.9897986942328618 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 1.285531759262085 - sq_loss: 8.79668823472457e-06 - tot_loss: 0.1818932511340492 - acc: 0.9897986942328618 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 1.289527416229248 - sq_loss: 8.784608326095622e-06 - tot_loss: 0.17282277888610054 - acc: 0.9897986942328618 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 1.281553030014038 - sq_loss: 8.767362487560604e-06 - tot_loss: 0.14809905843578974 - acc: 0.9897986942328618 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 1.2848942279815674 - sq_loss: 8.75347359396983e-06 - tot_loss: 0.16026847757127882 - acc: 0.9899347116430903 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 1.2858507633209229 - sq_loss: 8.739263648749329e-06 - tot_loss: 0.17119739109534748 - acc: 0.9899347116430903 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 1.3021631240844727 - sq_loss: 8.722674465388991e-06 - tot_loss: 0.1591694510260595 - acc: 0.9899347116430903 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 1.287010908126831 - sq_loss: 8.708506356924772e-06 - tot_loss: 0.1598673713390184 - acc: 0.9899347116430903 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 1.3027396202087402 - sq_loss: 8.694019015820231e-06 - tot_loss: 0.1584376177975244 - acc: 0.9899347116430903 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 1.297954797744751 - sq_loss: 8.67803828441538e-06 - tot_loss: 0.14466490743780724 - acc: 0.9902067464635473 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 1.3008818626403809 - sq_loss: 8.662662366987206e-06 - tot_loss: 0.1653844884045199 - acc: 0.9902067464635473 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 1.3044500350952148 - sq_loss: 8.653200893604662e-06 - tot_loss: 0.1615310981083269 - acc: 0.9902067464635473 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 1.3139686584472656 - sq_loss: 8.640586202091072e-06 - tot_loss: 0.1601932419544312 - acc: 0.9902067464635473 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 1.310509204864502 - sq_loss: 8.62763226905372e-06 - tot_loss: 0.15866152273200385 - acc: 0.9900707290533188 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 1.3015172481536865 - sq_loss: 8.611532393842936e-06 - tot_loss: 0.1658643381350231 - acc: 0.9902067464635473 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 1.300631046295166 - sq_loss: 8.597289706813172e-06 - tot_loss: 0.16208337240134085 - acc: 0.9899347116430903 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 1.3094370365142822 - sq_loss: 8.585032446717378e-06 - tot_loss: 0.15056131286598884 - acc: 0.9902067464635473 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 1.287672996520996 - sq_loss: 8.570755198888946e-06 - tot_loss: 0.1599979644402012 - acc: 0.9900707290533188 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 1.2761461734771729 - sq_loss: 8.554725354770198e-06 - tot_loss: 0.16024796459289092 - acc: 0.9902067464635473 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 1.2965843677520752 - sq_loss: 8.541897841496393e-06 - tot_loss: 0.16091015586726343 - acc: 0.9902067464635473 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 1.2984542846679688 - sq_loss: 8.530730156053323e-06 - tot_loss: 0.16011505854315544 - acc: 0.9902067464635473 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 1.2788639068603516 - sq_loss: 8.51870936457999e-06 - tot_loss: 0.17757234051174464 - acc: 0.9902067464635473 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 1.304018259048462 - sq_loss: 8.504851393809076e-06 - tot_loss: 0.16444857011634184 - acc: 0.9903427638737758 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 1.2811765670776367 - sq_loss: 8.493452696711756e-06 - tot_loss: 0.16264366935173058 - acc: 0.9902067464635473 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 1.2907307147979736 - sq_loss: 8.48296895128442e-06 - tot_loss: 0.1737114531077708 - acc: 0.9903427638737758 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 1.3039090633392334 - sq_loss: 8.471455657854676e-06 - tot_loss: 0.16060172623246416 - acc: 0.9903427638737758 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 1.2933135032653809 - sq_loss: 8.459356649836991e-06 - tot_loss: 0.17100711965689896 - acc: 0.9903427638737758 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 1.279487133026123 - sq_loss: 8.446355423075147e-06 - tot_loss: 0.14691487468819275 - acc: 0.9903427638737758 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 1.2893102169036865 - sq_loss: 8.436694770352915e-06 - tot_loss: 0.1525255402420811 - acc: 0.9903427638737758 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 1.2854459285736084 - sq_loss: 8.425646228715777e-06 - tot_loss: 0.15640519135915554 - acc: 0.9903427638737758 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 1.289538860321045 - sq_loss: 8.413510840910021e-06 - tot_loss: 0.16599923693381413 - acc: 0.9903427638737758 - val_acc: 0.9596199524940617\n",
      "CR_1 = 0.16759738116197184   CR_2 = 0.1667972504806152\n",
      "/home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 5\n",
    "alpha = 1\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "\n",
    "#alpha1 = alpha2 = alpha3 = alpha4 = alpha5 = alpha6 = alpha7 = alpha8 = alpha9 = alpha10 = alpha\n",
    "#for rank in (35,): #(25,30,35)(100,180,220,260,300,340,380)(20,60,100,140,180,220,260,300,340,380)\n",
    "#    for tau in (400,500): #(300,400,500)(10,50,100,200,300)(10,50,100,200,300)\n",
    "#        for gamma in (0.5,0.8,2): #(0.5,0.8,2)(0.5,0.8)(0.5,1,1.5,2,3)\n",
    "            #gamma1 = gamma2 = gamma3 = gamma4 = gamma5 = gamma\n",
    "#            for rho in (0.5,0.8,2): #(0.5,0.8)(1,2)\n",
    "                #rho1 = rho2 = rho3 = rho4 = rho5= rho\n",
    "#                for alpha in (0.5,1,1.5,2):\n",
    "#                    print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "                    #print('Compression Ratio', ((1024*28*28+10*1024+(8*(rank)+32*np.square(rank))*2)/(1024*28*28+10*1024+1024*1024*2)), (8*(rank)+32*np.square(rank))*2/(1024*1024*2))\n",
    "        \n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    d0 = 561 #561 =3*11*17\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 6 \n",
    "\n",
    "    W1 = 0.2*init.kaiming_uniform_(torch.empty(d1, d0, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    #W1 = 0.01*torch.randn(d1, d0, device=device)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    W2 = 0.2*init.kaiming_uniform_(torch.empty(d2, d1, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles ‘factors’, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    W3 = 0.2*init.kaiming_uniform_(torch.empty(d3, d2, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    W4 = 0.2*init.kaiming_uniform_(torch.empty(d4, d3, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "\n",
    "    W5 = 0.2*init.kaiming_uniform_(torch.empty(d5, d4, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = U5 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V5 = (y_one_hot + gamma*U5 + alpha*V5)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U5 = (gamma*V5 + rho*(torch.mm(W5,V4) + b5.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W5, b5 = updateWb_org(U5,V4,W5,b5,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b5.repeat(1, N), W5, a4_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b5.repeat(1, N_test), W5, a4_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V5,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,U5,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4\n",
    "\n",
    "    CR_1=((total_variabels)+(d4*d5))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#this postion to add new row into existing table\n",
    "    #df=pd.read_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "    #new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "    #           'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "    #           'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1], 'seed':seed} \n",
    "    #df=df.append(new_row,ignore_index=True)\n",
    "    #df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"KaimingUniform_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895c825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30f34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
