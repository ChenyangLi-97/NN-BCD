{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccc0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6113fe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 5 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 1.2714040279388428 - sq_loss: 661.6912231445312 - tot_loss: 1029.325135433326 - acc: 0.1838955386289445 - val_acc: 0.1818798778418731\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 1.236530065536499 - sq_loss: 294.0849914550781 - tot_loss: 486.38769765850157 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 1.2426419258117676 - sq_loss: 161.3899383544922 - tot_loss: 268.4336228463799 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 1.2341430187225342 - sq_loss: 87.46602630615234 - tot_loss: 152.6410679658875 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 1.238257884979248 - sq_loss: 47.03624725341797 - tot_loss: 89.95820982242003 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 1.239062786102295 - sq_loss: 25.224702835083008 - tot_loss: 55.7445611092262 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 1.2621359825134277 - sq_loss: 13.533771514892578 - tot_loss: 36.8007849608548 - acc: 0.18756800870511425 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 1.249645709991455 - sq_loss: 7.281209468841553 - tot_loss: 26.1037784924265 - acc: 0.2044341675734494 - val_acc: 0.1964709874448592\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 1.2388908863067627 - sq_loss: 3.9359285831451416 - tot_loss: 19.861316688824445 - acc: 0.3736398258977149 - val_acc: 0.332541567695962\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 1.231809377670288 - sq_loss: 2.142181873321533 - tot_loss: 16.070630008820444 - acc: 0.4766050054406964 - val_acc: 0.43501866304716663\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 1.2304527759552002 - sq_loss: 1.1767263412475586 - tot_loss: 13.61888839607127 - acc: 0.5195865070729053 - val_acc: 0.49541907024092297\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 1.2415602207183838 - sq_loss: 0.6542668342590332 - tot_loss: 11.933519912185147 - acc: 0.5330522306855278 - val_acc: 0.5215473362741772\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 1.2312190532684326 - sq_loss: 0.369475781917572 - tot_loss: 10.679639983456582 - acc: 0.5406692056583242 - val_acc: 0.5300305395317272\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 1.2251780033111572 - sq_loss: 0.21277278661727905 - tot_loss: 9.695444172946736 - acc: 0.544613710554951 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 1.2281389236450195 - sq_loss: 0.12552614510059357 - tot_loss: 8.867295379866846 - acc: 0.5486942328618063 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 1.216379165649414 - sq_loss: 0.07623524963855743 - tot_loss: 8.140331599395722 - acc: 0.5609357997823722 - val_acc: 0.5347811333559552\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 1.214656114578247 - sq_loss: 0.047894567251205444 - tot_loss: 7.5102954501635395 - acc: 0.5856909684439608 - val_acc: 0.5564981336952833\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 1.2201991081237793 - sq_loss: 0.03125778213143349 - tot_loss: 6.921493435278535 - acc: 0.610310119695321 - val_acc: 0.5850016966406515\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 1.2314841747283936 - sq_loss: 0.021253645420074463 - tot_loss: 6.387321699410677 - acc: 0.6352013057671382 - val_acc: 0.6023074312860536\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 1.2554309368133545 - sq_loss: 0.015071562491357327 - tot_loss: 5.903623754624277 - acc: 0.6536996735582155 - val_acc: 0.6155412283678316\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 1.2369425296783447 - sq_loss: 0.011135009117424488 - tot_loss: 5.469901958829723 - acc: 0.6739662676822633 - val_acc: 0.6250424160162877\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 1.2444610595703125 - sq_loss: 0.008544613607227802 - tot_loss: 5.07593027909752 - acc: 0.6867519042437432 - val_acc: 0.6321683067526298\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 1.2195732593536377 - sq_loss: 0.006780413445085287 - tot_loss: 4.712569270428503 - acc: 0.6943688792165397 - val_acc: 0.6406515100101798\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 1.252032995223999 - sq_loss: 0.005535101518034935 - tot_loss: 4.381032278339262 - acc: 0.7007616974972797 - val_acc: 0.6532066508313539\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 1.2322676181793213 - sq_loss: 0.00462490925565362 - tot_loss: 4.071270830274443 - acc: 0.7089227421109902 - val_acc: 0.66440447913132\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 1.248795986175537 - sq_loss: 0.003936662804335356 - tot_loss: 3.803547006275039 - acc: 0.7155875952121872 - val_acc: 0.677638276213098\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 1.2458391189575195 - sq_loss: 0.003400601679459214 - tot_loss: 3.550204495055368 - acc: 0.7213003264417845 - val_acc: 0.6861214794706482\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 1.2357473373413086 - sq_loss: 0.002972307614982128 - tot_loss: 3.3329991652426543 - acc: 0.7287812840043526 - val_acc: 0.6922293858160842\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 1.2450063228607178 - sq_loss: 0.00262165954336524 - tot_loss: 3.1150225235833204 - acc: 0.7370783460282916 - val_acc: 0.7000339328130302\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 1.2379062175750732 - sq_loss: 0.00232967478223145 - tot_loss: 2.92186856893386 - acc: 0.7452393906420022 - val_acc: 0.7061418391584663\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 1.2277805805206299 - sq_loss: 0.0020831956062465906 - tot_loss: 2.744475934836373 - acc: 0.7558487486398259 - val_acc: 0.7159823549372243\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 1.2405681610107422 - sq_loss: 0.001871966291218996 - tot_loss: 2.58663923007407 - acc: 0.7645538628944505 - val_acc: 0.7227689175432643\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 1.2381775379180908 - sq_loss: 0.001689455471932888 - tot_loss: 2.4351125284811133 - acc: 0.77189880304679 - val_acc: 0.7336274177129284\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 1.2282261848449707 - sq_loss: 0.001530672307126224 - tot_loss: 2.2934113206429174 - acc: 0.7810119695321001 - val_acc: 0.7421106209704784\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 1.2500488758087158 - sq_loss: 0.0013913896400481462 - tot_loss: 2.1707670044343104 - acc: 0.7917573449401524 - val_acc: 0.7522904648795385\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 1.2339229583740234 - sq_loss: 0.0012685771798714995 - tot_loss: 2.050347840617178 - acc: 0.8004624591947769 - val_acc: 0.7614523243976926\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 1.231081247329712 - sq_loss: 0.0011594716925173998 - tot_loss: 1.9451083826970716 - acc: 0.8103917301414582 - val_acc: 0.7726501526976587\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 1.248232126235962 - sq_loss: 0.0010622626869007945 - tot_loss: 1.8320936497584626 - acc: 0.8210010881392819 - val_acc: 0.7814726840855107\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 1.2267909049987793 - sq_loss: 0.0009755252976901829 - tot_loss: 1.7323855145405105 - acc: 0.8284820457018498 - val_acc: 0.7902952154733628\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 1.2203419208526611 - sq_loss: 0.0008975855889730155 - tot_loss: 1.65195656526339 - acc: 0.8370511425462459 - val_acc: 0.7964031218187988\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 1.2442448139190674 - sq_loss: 0.000827225623652339 - tot_loss: 1.571058567820728 - acc: 0.8457562568008705 - val_acc: 0.8045469969460468\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 1.248659372329712 - sq_loss: 0.0007637050002813339 - tot_loss: 1.4926552477918449 - acc: 0.8517410228509249 - val_acc: 0.8140481845945029\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 1.2371861934661865 - sq_loss: 0.0007062462391331792 - tot_loss: 1.417656569639803 - acc: 0.8569096844396082 - val_acc: 0.8215134034611469\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 1.23433518409729 - sq_loss: 0.0006542003247886896 - tot_loss: 1.3512847302299633 - acc: 0.8628944504896626 - val_acc: 0.8266033254156769\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 1.2450742721557617 - sq_loss: 0.0006069366354495287 - tot_loss: 1.2892171674957353 - acc: 0.8684711643090316 - val_acc: 0.832032575500509\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 1.2368347644805908 - sq_loss: 0.0005637638969346881 - tot_loss: 1.2345143549082422 - acc: 0.874183895538629 - val_acc: 0.835765184933831\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 1.2335762977600098 - sq_loss: 0.0005245342035777867 - tot_loss: 1.1770312575463322 - acc: 0.8778563656147987 - val_acc: 0.840176450627757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 1.2174012660980225 - sq_loss: 0.0004885353264398873 - tot_loss: 1.124499349425605 - acc: 0.8813928182807399 - val_acc: 0.8445877163216831\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 1.2388477325439453 - sq_loss: 0.0004554734914563596 - tot_loss: 1.0722286274885846 - acc: 0.8853373231773667 - val_acc: 0.8479809976247031\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 1.226099967956543 - sq_loss: 0.00042506863246671855 - tot_loss: 1.0269144911217154 - acc: 0.8881936887921654 - val_acc: 0.8537495758398371\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 1.241323471069336 - sq_loss: 0.0003970947000198066 - tot_loss: 0.9805205897991982 - acc: 0.8915941240478781 - val_acc: 0.8557855446216491\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 1.2379484176635742 - sq_loss: 0.00037121635978110135 - tot_loss: 0.9377796541903081 - acc: 0.8943144722524483 - val_acc: 0.8601968103155752\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 1.2249748706817627 - sq_loss: 0.0003473201359156519 - tot_loss: 0.895828049910051 - acc: 0.89689880304679 - val_acc: 0.8618934509670851\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 1.2396271228790283 - sq_loss: 0.0003251740999985486 - tot_loss: 0.8590812563725194 - acc: 0.8992110990206746 - val_acc: 0.8646080760095012\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 1.2469794750213623 - sq_loss: 0.00030460767447948456 - tot_loss: 0.8337885730970811 - acc: 0.9007072905331882 - val_acc: 0.8669833729216152\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 1.2280328273773193 - sq_loss: 0.0002855687343981117 - tot_loss: 0.7955515419262156 - acc: 0.9019314472252449 - val_acc: 0.8686800135731252\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 1.2327830791473389 - sq_loss: 0.00026784063084051013 - tot_loss: 0.7717396194520916 - acc: 0.9027475516866159 - val_acc: 0.8737699355276553\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 1.2257664203643799 - sq_loss: 0.0002514240040909499 - tot_loss: 0.7389343937138619 - acc: 0.904107725788901 - val_acc: 0.8771632168306752\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 1.2189912796020508 - sq_loss: 0.00023619865532964468 - tot_loss: 0.7147400231497159 - acc: 0.9065560391730142 - val_acc: 0.8812351543942993\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 1.326495885848999 - sq_loss: 0.00022206723224371672 - tot_loss: 0.6860571859033371 - acc: 0.9090043525571273 - val_acc: 0.8829317950458093\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 1.243631362915039 - sq_loss: 0.00020895310444757342 - tot_loss: 0.6642342222849038 - acc: 0.9105005440696409 - val_acc: 0.8856464200882254\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 1.2493717670440674 - sq_loss: 0.00019684720609802753 - tot_loss: 0.6372053121522185 - acc: 0.911860718171926 - val_acc: 0.8870037326094333\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 1.2591602802276611 - sq_loss: 0.000185487893759273 - tot_loss: 0.6176799935665258 - acc: 0.9140369967355821 - val_acc: 0.8883610451306413\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 1.2409961223602295 - sq_loss: 0.00017493381164968014 - tot_loss: 0.5940010112244636 - acc: 0.9159412404787813 - val_acc: 0.8917543264336614\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 1.2420804500579834 - sq_loss: 0.0001650489284656942 - tot_loss: 0.57698759541654 - acc: 0.9177094668117519 - val_acc: 0.8927723108245673\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 1.2386481761932373 - sq_loss: 0.00015584827633574605 - tot_loss: 0.5628850605571643 - acc: 0.9194776931447225 - val_acc: 0.8948082796063793\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 1.609961748123169 - sq_loss: 0.00014726324297953397 - tot_loss: 0.5418727991782362 - acc: 0.9202937976060935 - val_acc: 0.8961655921275874\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 1.9934234619140625 - sq_loss: 0.0001392531266901642 - tot_loss: 0.5234254088463786 - acc: 0.9213819368879217 - val_acc: 0.8982015609093994\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 1.2354846000671387 - sq_loss: 0.000131747976411134 - tot_loss: 0.5052972122730353 - acc: 0.9227421109902068 - val_acc: 0.8985408890397014\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 1.2309563159942627 - sq_loss: 0.0001247019972652197 - tot_loss: 0.4890098044129445 - acc: 0.9238302502720348 - val_acc: 0.8992195453003053\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 1.2303664684295654 - sq_loss: 0.00011806607653852552 - tot_loss: 0.4736635689991999 - acc: 0.9250544069640914 - val_acc: 0.9012555140821175\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 1.232429027557373 - sq_loss: 0.00011184150207554922 - tot_loss: 0.45944466765786274 - acc: 0.9255984766050055 - val_acc: 0.9039701391245334\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 1.2383594512939453 - sq_loss: 0.00010598911467241123 - tot_loss: 0.44915724687507463 - acc: 0.9275027203482046 - val_acc: 0.9077027485578555\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 1.2306690216064453 - sq_loss: 0.00010052821016870439 - tot_loss: 0.4335730547481944 - acc: 0.9283188248095756 - val_acc: 0.9093993892093655\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 1.2312917709350586 - sq_loss: 9.543369378661737e-05 - tot_loss: 0.42111644116812386 - acc: 0.9291349292709467 - val_acc: 0.9097387173396675\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 1.2411398887634277 - sq_loss: 9.067815699381754e-05 - tot_loss: 0.4060534249997545 - acc: 0.9303590859630033 - val_acc: 0.9100780454699695\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 1.2226614952087402 - sq_loss: 8.618718857178465e-05 - tot_loss: 0.39631747002567863 - acc: 0.9317192600652884 - val_acc: 0.9107567017305734\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 1.239269495010376 - sq_loss: 8.196001726901159e-05 - tot_loss: 0.384855194247848 - acc: 0.933487486398259 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 1.2342607975006104 - sq_loss: 7.797277794452384e-05 - tot_loss: 0.3797829639565862 - acc: 0.9349836779107725 - val_acc: 0.9134713267729895\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 1.260493516921997 - sq_loss: 7.419972826028243e-05 - tot_loss: 0.36764419699670725 - acc: 0.9356637649619152 - val_acc: 0.9144893111638955\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 1.2401652336120605 - sq_loss: 7.065922545734793e-05 - tot_loss: 0.36195449883689435 - acc: 0.9367519042437432 - val_acc: 0.9158466236851035\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 1.2419965267181396 - sq_loss: 6.733116606483236e-05 - tot_loss: 0.3455048025909946 - acc: 0.9375680087051143 - val_acc: 0.9161859518154055\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 1.2543418407440186 - sq_loss: 6.423475133487955e-05 - tot_loss: 0.3379644677197575 - acc: 0.9385201305767138 - val_acc: 0.9172039362063115\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 1.252335786819458 - sq_loss: 6.131137342890725e-05 - tot_loss: 0.3357717560670608 - acc: 0.9398803046789989 - val_acc: 0.9178825924669155\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 1.240210771560669 - sq_loss: 5.85604393563699e-05 - tot_loss: 0.32196073671684644 - acc: 0.9413764961915125 - val_acc: 0.9185612487275195\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 1.2506558895111084 - sq_loss: 5.598018105956726e-05 - tot_loss: 0.3170882604815688 - acc: 0.9423286180631121 - val_acc: 0.9202578893790295\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 1.237854242324829 - sq_loss: 5.352767766453326e-05 - tot_loss: 0.3007976006165336 - acc: 0.9430087051142546 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 1.2257912158966064 - sq_loss: 5.120856440044008e-05 - tot_loss: 0.30150372188086294 - acc: 0.9440968443960827 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 1.2235827445983887 - sq_loss: 4.9030968511942774e-05 - tot_loss: 0.29008779162950304 - acc: 0.9451849836779108 - val_acc: 0.9222938581608415\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 1.2246978282928467 - sq_loss: 4.697554322774522e-05 - tot_loss: 0.28677415321044464 - acc: 0.9460010881392819 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 1.231825828552246 - sq_loss: 4.501120565691963e-05 - tot_loss: 0.27576344318435986 - acc: 0.9465451577801959 - val_acc: 0.9236511706820495\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 1.2422642707824707 - sq_loss: 4.317334605730139e-05 - tot_loss: 0.27900556694339684 - acc: 0.9473612622415669 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 1.233917474746704 - sq_loss: 4.143180922255851e-05 - tot_loss: 0.2658306290240944 - acc: 0.948449401523395 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 1.2382440567016602 - sq_loss: 3.98109077650588e-05 - tot_loss: 0.2682418201013661 - acc: 0.948993471164309 - val_acc: 0.9273837801153716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 1.2397406101226807 - sq_loss: 3.826139072771184e-05 - tot_loss: 0.26666555748624887 - acc: 0.9491294885745375 - val_acc: 0.9277231082456736\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 1.2470693588256836 - sq_loss: 3.6813704355154186e-05 - tot_loss: 0.25665707800203563 - acc: 0.9500816104461371 - val_acc: 0.9277231082456736\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 1.2353193759918213 - sq_loss: 3.5444321838440374e-05 - tot_loss: 0.24612129483853096 - acc: 0.9511697497279652 - val_acc: 0.9284017645062775\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 1.2609765529632568 - sq_loss: 3.41423146892339e-05 - tot_loss: 0.24187668465742718 - acc: 0.9528019586507073 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 1.224395513534546 - sq_loss: 3.290054155513644e-05 - tot_loss: 0.24468824722453064 - acc: 0.9536180631120783 - val_acc: 0.9297590770274856\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 1.2345430850982666 - sq_loss: 3.1730145565234125e-05 - tot_loss: 0.2339729843895384 - acc: 0.9540261153427638 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 1.2232909202575684 - sq_loss: 3.0633265851065516e-05 - tot_loss: 0.22504771665603585 - acc: 0.9547062023939065 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 1.2381279468536377 - sq_loss: 2.9593245926662348e-05 - tot_loss: 0.22861283239603836 - acc: 0.955386289445049 - val_acc: 0.9321343739395996\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 1.224243402481079 - sq_loss: 2.8619533622986637e-05 - tot_loss: 0.21862953130903406 - acc: 0.95620239390642 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 1.248117208480835 - sq_loss: 2.7699514248524792e-05 - tot_loss: 0.2193506639001157 - acc: 0.9567464635473341 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 1.2232997417449951 - sq_loss: 2.6814970624400303e-05 - tot_loss: 0.21424260745783386 - acc: 0.9571545157780196 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 1.2241871356964111 - sq_loss: 2.5986671971622854e-05 - tot_loss: 0.21392690871829245 - acc: 0.9576985854189336 - val_acc: 0.9345096708517137\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 1.2453830242156982 - sq_loss: 2.5203864424838684e-05 - tot_loss: 0.2123395145864606 - acc: 0.9582426550598476 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 1.2237739562988281 - sq_loss: 2.445502468617633e-05 - tot_loss: 0.20496608480897294 - acc: 0.9585146898803046 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 1.2389862537384033 - sq_loss: 2.3761209376971237e-05 - tot_loss: 0.2020943979247818 - acc: 0.9589227421109902 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 1.2215330600738525 - sq_loss: 2.31003559747478e-05 - tot_loss: 0.19101558577563083 - acc: 0.9597388465723613 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 1.2375314235687256 - sq_loss: 2.2461872504209168e-05 - tot_loss: 0.19129812958084358 - acc: 0.9606909684439608 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 1.2289657592773438 - sq_loss: 2.186992969654966e-05 - tot_loss: 0.19369647877397256 - acc: 0.9612350380848749 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 1.243804931640625 - sq_loss: 2.128801861545071e-05 - tot_loss: 0.1886363609972932 - acc: 0.9619151251360174 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 1.24171781539917 - sq_loss: 2.0743558707181364e-05 - tot_loss: 0.19291167339133608 - acc: 0.9621871599564744 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 1.2184054851531982 - sq_loss: 2.0212008166708983e-05 - tot_loss: 0.18745294384922317 - acc: 0.9628672470076169 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 1.226259708404541 - sq_loss: 1.9724631783901714e-05 - tot_loss: 0.18773008464171426 - acc: 0.9632752992383025 - val_acc: 0.9382422802850356\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 1.2295024394989014 - sq_loss: 1.9251461708336137e-05 - tot_loss: 0.1798881188591963 - acc: 0.9639553862894451 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 1.2289831638336182 - sq_loss: 1.8805701984092593e-05 - tot_loss: 0.17484482853086547 - acc: 0.9640914036996736 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 1.2344138622283936 - sq_loss: 1.837175659602508e-05 - tot_loss: 0.17581002722025119 - acc: 0.9644994559303591 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 1.2255980968475342 - sq_loss: 1.7958485841518268e-05 - tot_loss: 0.17085947608731544 - acc: 0.9655875952121872 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 1.2667689323425293 - sq_loss: 1.756435631250497e-05 - tot_loss: 0.1757175328502001 - acc: 0.9658596300326442 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 1.262911319732666 - sq_loss: 1.7199634385178797e-05 - tot_loss: 0.16894134259487714 - acc: 0.9659956474428727 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 1.263230323791504 - sq_loss: 1.6833086192491464e-05 - tot_loss: 0.16482469440293812 - acc: 0.9668117519042437 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 1.2613577842712402 - sq_loss: 1.6494179362780415e-05 - tot_loss: 0.16194878053568118 - acc: 0.9670837867247007 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 1.2571125030517578 - sq_loss: 1.61755542649189e-05 - tot_loss: 0.1601947051645709 - acc: 0.9670837867247007 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 1.2396278381347656 - sq_loss: 1.5864878150750883e-05 - tot_loss: 0.16002214986130525 - acc: 0.9676278563656148 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 1.2353711128234863 - sq_loss: 1.557252835482359e-05 - tot_loss: 0.16314719068793693 - acc: 0.9676278563656148 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 1.2549858093261719 - sq_loss: 1.5288074791897088e-05 - tot_loss: 0.1545532167377246 - acc: 0.9681719260065288 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 1.2565343379974365 - sq_loss: 1.502192117186496e-05 - tot_loss: 0.16013768405861128 - acc: 0.9689880304678999 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 1.2403602600097656 - sq_loss: 1.4758959878236055e-05 - tot_loss: 0.15707653513618425 - acc: 0.969260065288357 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 1.2532517910003662 - sq_loss: 1.4511155313812196e-05 - tot_loss: 0.15539297342567693 - acc: 0.970076169749728 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 1.2422471046447754 - sq_loss: 1.4279471542977262e-05 - tot_loss: 0.146898341920064 - acc: 0.9704842219804135 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 1.2485253810882568 - sq_loss: 1.4061543879506644e-05 - tot_loss: 0.15373489635859983 - acc: 0.9707562568008705 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 1.2276029586791992 - sq_loss: 1.3843779925082345e-05 - tot_loss: 0.15397970616339762 - acc: 0.9707562568008705 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 1.2314484119415283 - sq_loss: 1.3630842659040354e-05 - tot_loss: 0.157146593468525 - acc: 0.971436343852013 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 1.238691806793213 - sq_loss: 1.3439384929370135e-05 - tot_loss: 0.14765497775829317 - acc: 0.9721164309031556 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 1.2444593906402588 - sq_loss: 1.3250866686576046e-05 - tot_loss: 0.1467522703674149 - acc: 0.9722524483133841 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 1.2457127571105957 - sq_loss: 1.3064423001196701e-05 - tot_loss: 0.15050181459896805 - acc: 0.9725244831338411 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 1.2316179275512695 - sq_loss: 1.2892999620817136e-05 - tot_loss: 0.14767632761832772 - acc: 0.9726605005440696 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 1.2231230735778809 - sq_loss: 1.2718915968434885e-05 - tot_loss: 0.13776810130208617 - acc: 0.9727965179542981 - val_acc: 0.9440108585001696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 1.2342028617858887 - sq_loss: 1.2558539310703054e-05 - tot_loss: 0.13852332742287388 - acc: 0.9730685527747551 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 1.233992099761963 - sq_loss: 1.2402019820001442e-05 - tot_loss: 0.14389325682957121 - acc: 0.9729325353645266 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 1.2416298389434814 - sq_loss: 1.225904816237744e-05 - tot_loss: 0.1386993458895205 - acc: 0.9733405875952121 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 1.255936861038208 - sq_loss: 1.2108343071304262e-05 - tot_loss: 0.13756050957100285 - acc: 0.9737486398258978 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 1.2409954071044922 - sq_loss: 1.1958059076278005e-05 - tot_loss: 0.13160734503807703 - acc: 0.9742927094668118 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 1.2400860786437988 - sq_loss: 1.1817162885563448e-05 - tot_loss: 0.13601924178898628 - acc: 0.9742927094668118 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 1.2299470901489258 - sq_loss: 1.1686940524668898e-05 - tot_loss: 0.14456554356785034 - acc: 0.9744287268770403 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 1.2432746887207031 - sq_loss: 1.1555387573025655e-05 - tot_loss: 0.135327493678858 - acc: 0.9751088139281828 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 1.2263410091400146 - sq_loss: 1.1432114661147352e-05 - tot_loss: 0.1258950995590027 - acc: 0.9752448313384113 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 1.2248210906982422 - sq_loss: 1.1315140909573529e-05 - tot_loss: 0.13369230808889654 - acc: 0.9752448313384113 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 1.2560193538665771 - sq_loss: 1.1205832379346248e-05 - tot_loss: 0.13025810650145786 - acc: 0.9752448313384113 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 1.2213799953460693 - sq_loss: 1.1099024959548842e-05 - tot_loss: 0.13363142435981956 - acc: 0.9753808487486398 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 1.2218029499053955 - sq_loss: 1.0991411727445666e-05 - tot_loss: 0.1289167659563617 - acc: 0.9756528835690969 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 1.2273454666137695 - sq_loss: 1.088918543246109e-05 - tot_loss: 0.1268319794993289 - acc: 0.9759249183895539 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 1.2253272533416748 - sq_loss: 1.0789513908093795e-05 - tot_loss: 0.1223235840129746 - acc: 0.9759249183895539 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 1.2404301166534424 - sq_loss: 1.0696750905481167e-05 - tot_loss: 0.12560726593473248 - acc: 0.9759249183895539 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 1.2305662631988525 - sq_loss: 1.0609037417452782e-05 - tot_loss: 0.12428682549078474 - acc: 0.9760609357997824 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 1.2392857074737549 - sq_loss: 1.0516979273234028e-05 - tot_loss: 0.1321188656016119 - acc: 0.9760609357997824 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 1.2461984157562256 - sq_loss: 1.0429001122247428e-05 - tot_loss: 0.12101498593837334 - acc: 0.9764689880304679 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 1.2267084121704102 - sq_loss: 1.0342161658627447e-05 - tot_loss: 0.12848154487235774 - acc: 0.9770130576713819 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 1.2387111186981201 - sq_loss: 1.0262509931635577e-05 - tot_loss: 0.12417954580345736 - acc: 0.9770130576713819 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 1.2347455024719238 - sq_loss: 1.0182373443967663e-05 - tot_loss: 0.1319645876841662 - acc: 0.9770130576713819 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 1.2266201972961426 - sq_loss: 1.0093494893226307e-05 - tot_loss: 0.12159462591093018 - acc: 0.9771490750816104 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 1.2317068576812744 - sq_loss: 1.0013568498834502e-05 - tot_loss: 0.11453533439345875 - acc: 0.9772850924918389 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 1.2398576736450195 - sq_loss: 9.933981345966458e-06 - tot_loss: 0.121808346733836 - acc: 0.9776931447225244 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 1.2192375659942627 - sq_loss: 9.860697900876403e-06 - tot_loss: 0.11425282533387815 - acc: 0.9775571273122959 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 1.2476441860198975 - sq_loss: 9.788736861082725e-06 - tot_loss: 0.11725760874865898 - acc: 0.9776931447225244 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 1.2434406280517578 - sq_loss: 9.721187780087348e-06 - tot_loss: 0.121126381179117 - acc: 0.9779651795429815 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 1.2358522415161133 - sq_loss: 9.653042070567608e-06 - tot_loss: 0.11924136644816485 - acc: 0.9783732317736671 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 1.2306890487670898 - sq_loss: 9.587229214957915e-06 - tot_loss: 0.11786413209335933 - acc: 0.9785092491838956 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 1.226306676864624 - sq_loss: 9.52205118665006e-06 - tot_loss: 0.12150076495059636 - acc: 0.9786452665941241 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 1.218855857849121 - sq_loss: 9.46076397667639e-06 - tot_loss: 0.12771899409808185 - acc: 0.9786452665941241 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 1.2539033889770508 - sq_loss: 9.395171218784526e-06 - tot_loss: 0.11788937612222838 - acc: 0.9789173014145811 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 1.2202262878417969 - sq_loss: 9.33449700823985e-06 - tot_loss: 0.11685739323169742 - acc: 0.9791893362350381 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 1.2302231788635254 - sq_loss: 9.27625205804361e-06 - tot_loss: 0.11042851192090808 - acc: 0.9793253536452666 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 1.228525161743164 - sq_loss: 9.218895684171002e-06 - tot_loss: 0.1189215522377367 - acc: 0.9798694232861807 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 1.2395482063293457 - sq_loss: 9.16166027309373e-06 - tot_loss: 0.116636326859485 - acc: 0.9797334058759521 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 1.2305984497070312 - sq_loss: 9.108700396609493e-06 - tot_loss: 0.11256120494202548 - acc: 0.9795973884657236 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 1.2300846576690674 - sq_loss: 9.058118848770391e-06 - tot_loss: 0.11442641047838009 - acc: 0.9795973884657236 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 1.2268290519714355 - sq_loss: 9.00819395610597e-06 - tot_loss: 0.11154736057078907 - acc: 0.9797334058759521 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 1.2311832904815674 - sq_loss: 8.958708349382505e-06 - tot_loss: 0.11708640974131157 - acc: 0.9797334058759521 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 1.222456932067871 - sq_loss: 8.909258212952409e-06 - tot_loss: 0.10934179076190986 - acc: 0.9800054406964092 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 1.2198171615600586 - sq_loss: 8.857654393068515e-06 - tot_loss: 0.11935394605367833 - acc: 0.9800054406964092 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 1.23726224899292 - sq_loss: 8.802217053016648e-06 - tot_loss: 0.11598352925698663 - acc: 0.9801414581066377 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 1.217517614364624 - sq_loss: 8.758886906434782e-06 - tot_loss: 0.11320681482315109 - acc: 0.9801414581066377 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 1.2341828346252441 - sq_loss: 8.714270734344609e-06 - tot_loss: 0.11193452586999797 - acc: 0.9804134929270947 - val_acc: 0.9518154054971157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 1.2587344646453857 - sq_loss: 8.668454029248096e-06 - tot_loss: 0.10873190661378374 - acc: 0.9804134929270947 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 1.2267069816589355 - sq_loss: 8.624885595054366e-06 - tot_loss: 0.11155291012283897 - acc: 0.9804134929270947 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 1.2380762100219727 - sq_loss: 8.580527719459496e-06 - tot_loss: 0.11714074353147907 - acc: 0.9804134929270947 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 1.236562728881836 - sq_loss: 8.540847375115845e-06 - tot_loss: 0.11046919929213317 - acc: 0.9806855277475517 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 1.2335045337677002 - sq_loss: 8.501283446094021e-06 - tot_loss: 0.1118434271267219 - acc: 0.9808215451577802 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 1.2338666915893555 - sq_loss: 8.459328455501236e-06 - tot_loss: 0.10935341570868928 - acc: 0.9809575625680087 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 1.2407066822052002 - sq_loss: 8.420888661930803e-06 - tot_loss: 0.10620938770651378 - acc: 0.9809575625680087 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 1.2639174461364746 - sq_loss: 8.378297934541479e-06 - tot_loss: 0.10837201847176914 - acc: 0.9809575625680087 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 1.254589557647705 - sq_loss: 8.336291102750693e-06 - tot_loss: 0.10918179629758384 - acc: 0.9809575625680087 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 1.2359957695007324 - sq_loss: 8.299726687255315e-06 - tot_loss: 0.1000444205778308 - acc: 0.9809575625680087 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 1.2357685565948486 - sq_loss: 8.261804396170191e-06 - tot_loss: 0.11600803154937722 - acc: 0.9810935799782372 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 1.234947919845581 - sq_loss: 8.22435504232999e-06 - tot_loss: 0.1101248350602475 - acc: 0.9812295973884657 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 1.2242143154144287 - sq_loss: 8.185112164937891e-06 - tot_loss: 0.10683847361855214 - acc: 0.9812295973884657 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 1.2289578914642334 - sq_loss: 8.147208973241504e-06 - tot_loss: 0.10589758675262573 - acc: 0.9812295973884657 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 1.2304871082305908 - sq_loss: 8.108918336802162e-06 - tot_loss: 0.10554406670595284 - acc: 0.9815016322089227 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 1.2321007251739502 - sq_loss: 8.073922799667343e-06 - tot_loss: 0.10539733529499529 - acc: 0.9816376496191512 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 1.2350561618804932 - sq_loss: 8.039462045417167e-06 - tot_loss: 0.11020991093930377 - acc: 0.9817736670293797 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 1.2164366245269775 - sq_loss: 8.005705240066163e-06 - tot_loss: 0.10758197586667251 - acc: 0.9819096844396082 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 1.235685110092163 - sq_loss: 7.967250894580502e-06 - tot_loss: 0.11727557506168296 - acc: 0.9817736670293797 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 1.230320930480957 - sq_loss: 7.932005246402696e-06 - tot_loss: 0.10566807294675584 - acc: 0.9819096844396082 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 1.2328789234161377 - sq_loss: 7.901559001766145e-06 - tot_loss: 0.10555330504065807 - acc: 0.9819096844396082 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 1.240588665008545 - sq_loss: 7.868814464018214e-06 - tot_loss: 0.10445365133349327 - acc: 0.9819096844396082 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 1.2424941062927246 - sq_loss: 7.839342288207263e-06 - tot_loss: 0.09981979870670443 - acc: 0.9819096844396082 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 1.2249135971069336 - sq_loss: 7.809524504409637e-06 - tot_loss: 0.1059626563319398 - acc: 0.9823177366702938 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 1.2373547554016113 - sq_loss: 7.777973223710433e-06 - tot_loss: 0.10587058820080841 - acc: 0.9820457018498367 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 1.218095302581787 - sq_loss: 7.747311428829562e-06 - tot_loss: 0.1052810948277525 - acc: 0.9821817192600653 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 1.2383050918579102 - sq_loss: 7.718306733295321e-06 - tot_loss: 0.10525829077680982 - acc: 0.9824537540805223 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 1.2184362411499023 - sq_loss: 7.688541700190399e-06 - tot_loss: 0.09996691393919832 - acc: 0.9827257889009793 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 1.2306020259857178 - sq_loss: 7.6573523983825e-06 - tot_loss: 0.09992784978559399 - acc: 0.9829978237214363 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 1.2223644256591797 - sq_loss: 7.625927082699491e-06 - tot_loss: 0.09923860503180748 - acc: 0.9831338411316648 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 1.2380175590515137 - sq_loss: 7.595754141220823e-06 - tot_loss: 0.09546861244272975 - acc: 0.9832698585418934 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 1.2302756309509277 - sq_loss: 7.563592134829378e-06 - tot_loss: 0.10498604280502377 - acc: 0.9831338411316648 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 1.222928762435913 - sq_loss: 7.533822099503595e-06 - tot_loss: 0.10134729771211326 - acc: 0.9832698585418934 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 1.226945161819458 - sq_loss: 7.504592304030666e-06 - tot_loss: 0.10403874454205209 - acc: 0.9832698585418934 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 1.216505765914917 - sq_loss: 7.481790817109868e-06 - tot_loss: 0.1103602755626909 - acc: 0.9835418933623504 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 1.2212035655975342 - sq_loss: 7.457206720573595e-06 - tot_loss: 0.10628218374768394 - acc: 0.9836779107725789 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 1.2241106033325195 - sq_loss: 7.430039204336936e-06 - tot_loss: 0.0980175686694551 - acc: 0.9836779107725789 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 1.2134132385253906 - sq_loss: 7.402756637020502e-06 - tot_loss: 0.10533014437602262 - acc: 0.9836779107725789 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 1.233889102935791 - sq_loss: 7.378105237876298e-06 - tot_loss: 0.10621606710428111 - acc: 0.984221980413493 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 1.2617082595825195 - sq_loss: 7.35222101866384e-06 - tot_loss: 0.09946477157900091 - acc: 0.984221980413493 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 1.2503337860107422 - sq_loss: 7.323617410293082e-06 - tot_loss: 0.09527657265486411 - acc: 0.9843579978237215 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 1.2300770282745361 - sq_loss: 7.2969069151440635e-06 - tot_loss: 0.10619456353316536 - acc: 0.984221980413493 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 1.2490553855895996 - sq_loss: 7.272481980180601e-06 - tot_loss: 0.11112153426222093 - acc: 0.98449401523395 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 1.2519733905792236 - sq_loss: 7.249210739246337e-06 - tot_loss: 0.10628544678839091 - acc: 0.98449401523395 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 1.2568011283874512 - sq_loss: 7.224997261801036e-06 - tot_loss: 0.10095339399077119 - acc: 0.98449401523395 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 1.2476580142974854 - sq_loss: 7.201737389550544e-06 - tot_loss: 0.10359626205079664 - acc: 0.98449401523395 - val_acc: 0.9552086868001357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 1.2373802661895752 - sq_loss: 7.1757981459086295e-06 - tot_loss: 0.0949800014631137 - acc: 0.98449401523395 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 1.2581446170806885 - sq_loss: 7.152135822252603e-06 - tot_loss: 0.10434454598444631 - acc: 0.98449401523395 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 1.2397966384887695 - sq_loss: 7.127689514163649e-06 - tot_loss: 0.10323551251425656 - acc: 0.984766050054407 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 1.2419793605804443 - sq_loss: 7.102987183316145e-06 - tot_loss: 0.09829455930303155 - acc: 0.984766050054407 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 1.2185547351837158 - sq_loss: 7.077137070155004e-06 - tot_loss: 0.1019899823576722 - acc: 0.9849020674646355 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 1.243269920349121 - sq_loss: 7.0563555709668435e-06 - tot_loss: 0.09920765536788423 - acc: 0.9849020674646355 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 1.2321317195892334 - sq_loss: 7.031136647128733e-06 - tot_loss: 0.10030158527646549 - acc: 0.985038084874864 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 1.242833137512207 - sq_loss: 7.008412922004936e-06 - tot_loss: 0.09801905932210886 - acc: 0.9851741022850925 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 1.2272870540618896 - sq_loss: 6.984862466197228e-06 - tot_loss: 0.10265584698268526 - acc: 0.9851741022850925 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 1.2397480010986328 - sq_loss: 6.963443865970476e-06 - tot_loss: 0.10268075797347365 - acc: 0.9851741022850925 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 1.2148921489715576 - sq_loss: 6.944717370060971e-06 - tot_loss: 0.09972689018076508 - acc: 0.985310119695321 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 1.246103048324585 - sq_loss: 6.922695320099592e-06 - tot_loss: 0.09061275275869107 - acc: 0.985310119695321 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 1.22698974609375 - sq_loss: 6.900556400069036e-06 - tot_loss: 0.10066084602484437 - acc: 0.985310119695321 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 1.230381727218628 - sq_loss: 6.877485702716513e-06 - tot_loss: 0.09594148218591059 - acc: 0.985582154515778 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 1.2544286251068115 - sq_loss: 6.85728264215868e-06 - tot_loss: 0.09761831556580702 - acc: 0.985582154515778 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 1.2510368824005127 - sq_loss: 6.83731741446536e-06 - tot_loss: 0.09909916330635937 - acc: 0.985582154515778 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 1.2417247295379639 - sq_loss: 6.813927484472515e-06 - tot_loss: 0.09715366955110127 - acc: 0.985582154515778 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 1.2206275463104248 - sq_loss: 6.792286058043828e-06 - tot_loss: 0.09872849045817489 - acc: 0.9857181719260065 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 1.247063159942627 - sq_loss: 6.770791969756829e-06 - tot_loss: 0.09917650962653468 - acc: 0.9857181719260065 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 1.226874828338623 - sq_loss: 6.751295131834922e-06 - tot_loss: 0.09992635577982512 - acc: 0.9857181719260065 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 1.2150733470916748 - sq_loss: 6.732276233378798e-06 - tot_loss: 0.0972755332470463 - acc: 0.985854189336235 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 1.2403652667999268 - sq_loss: 6.714762548654107e-06 - tot_loss: 0.09437443657076372 - acc: 0.9859902067464635 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 1.24342679977417 - sq_loss: 6.694927378703142e-06 - tot_loss: 0.0971539658437166 - acc: 0.986126224156692 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 1.219376802444458 - sq_loss: 6.676544217043556e-06 - tot_loss: 0.0952274774115196 - acc: 0.986126224156692 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 1.2326910495758057 - sq_loss: 6.65396419208264e-06 - tot_loss: 0.10588074559192506 - acc: 0.986126224156692 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 1.2372379302978516 - sq_loss: 6.632266831729794e-06 - tot_loss: 0.10147753642926105 - acc: 0.986126224156692 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 1.2396824359893799 - sq_loss: 6.61606463836506e-06 - tot_loss: 0.09127441075533227 - acc: 0.9862622415669206 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 1.2379207611083984 - sq_loss: 6.597130777663551e-06 - tot_loss: 0.09691989119743027 - acc: 0.9863982589771491 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 1.2308845520019531 - sq_loss: 6.5811527747428045e-06 - tot_loss: 0.10494453646316515 - acc: 0.9862622415669206 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 1.2232143878936768 - sq_loss: 6.56516567687504e-06 - tot_loss: 0.10170341226481128 - acc: 0.9863982589771491 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 1.2183678150177002 - sq_loss: 6.544987172674155e-06 - tot_loss: 0.09602779605813438 - acc: 0.9863982589771491 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 1.2330865859985352 - sq_loss: 6.524071523017483e-06 - tot_loss: 0.10545623109672064 - acc: 0.9863982589771491 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 1.2256464958190918 - sq_loss: 6.504732027678983e-06 - tot_loss: 0.10152947897593023 - acc: 0.9863982589771491 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 1.2380728721618652 - sq_loss: 6.4842197389225475e-06 - tot_loss: 0.09889803092371352 - acc: 0.9865342763873776 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 1.2319066524505615 - sq_loss: 6.467057573900092e-06 - tot_loss: 0.1040400076416681 - acc: 0.9863982589771491 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 1.2401788234710693 - sq_loss: 6.447965915867826e-06 - tot_loss: 0.09314932857500224 - acc: 0.9865342763873776 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 1.2391951084136963 - sq_loss: 6.429681889130734e-06 - tot_loss: 0.08866426863108856 - acc: 0.9865342763873776 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 1.2733726501464844 - sq_loss: 6.4153764469665475e-06 - tot_loss: 0.0944721331335252 - acc: 0.9865342763873776 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 1.238593339920044 - sq_loss: 6.40156304143602e-06 - tot_loss: 0.09232173217325013 - acc: 0.9865342763873776 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 1.240471601486206 - sq_loss: 6.382832907547709e-06 - tot_loss: 0.09856334742222828 - acc: 0.9865342763873776 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 1.2380712032318115 - sq_loss: 6.362577551044524e-06 - tot_loss: 0.09637284698213477 - acc: 0.9865342763873776 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 1.2587895393371582 - sq_loss: 6.343861059576739e-06 - tot_loss: 0.10038925589236314 - acc: 0.9865342763873776 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 1.2326433658599854 - sq_loss: 6.326128186628921e-06 - tot_loss: 0.09806317913498575 - acc: 0.9865342763873776 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 1.249694585800171 - sq_loss: 6.309909167612204e-06 - tot_loss: 0.0905024969575372 - acc: 0.9865342763873776 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 1.2516956329345703 - sq_loss: 6.296317224041559e-06 - tot_loss: 0.09442072331438567 - acc: 0.9866702937976061 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 1.2407493591308594 - sq_loss: 6.279024091782048e-06 - tot_loss: 0.08650718067258722 - acc: 0.9866702937976061 - val_acc: 0.9579233118425518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 1.2534747123718262 - sq_loss: 6.2609474298369605e-06 - tot_loss: 0.08888278587353682 - acc: 0.9868063112078346 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 1.236687183380127 - sq_loss: 6.243325060495408e-06 - tot_loss: 0.09555315125663455 - acc: 0.9866702937976061 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 1.2305853366851807 - sq_loss: 6.227133326319745e-06 - tot_loss: 0.0938935235365399 - acc: 0.9866702937976061 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 1.2468557357788086 - sq_loss: 6.2104522839945275e-06 - tot_loss: 0.09665709804590605 - acc: 0.9868063112078346 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 1.2175498008728027 - sq_loss: 6.189643954712665e-06 - tot_loss: 0.0910527321144663 - acc: 0.9868063112078346 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 1.247359275817871 - sq_loss: 6.17216392129194e-06 - tot_loss: 0.09579935150624408 - acc: 0.9866702937976061 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 1.2412762641906738 - sq_loss: 6.153366030048346e-06 - tot_loss: 0.0994872927737056 - acc: 0.9868063112078346 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 1.2341666221618652 - sq_loss: 6.138189291959861e-06 - tot_loss: 0.09459442350150837 - acc: 0.9866702937976061 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 1.2503893375396729 - sq_loss: 6.1223431657708716e-06 - tot_loss: 0.0901851674542975 - acc: 0.9866702937976061 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 1.2381904125213623 - sq_loss: 6.10877896178863e-06 - tot_loss: 0.0921709894568501 - acc: 0.9868063112078346 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 1.2323884963989258 - sq_loss: 6.093913270888152e-06 - tot_loss: 0.09249253949839087 - acc: 0.9869423286180631 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 1.2285213470458984 - sq_loss: 6.079260856495239e-06 - tot_loss: 0.10320036914313135 - acc: 0.9869423286180631 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 1.2304847240447998 - sq_loss: 6.065706656954717e-06 - tot_loss: 0.09330625265289072 - acc: 0.9870783460282916 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 1.2204768657684326 - sq_loss: 6.049686362530338e-06 - tot_loss: 0.10233201935598757 - acc: 0.9872143634385201 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 1.2318365573883057 - sq_loss: 6.035835667717038e-06 - tot_loss: 0.09500741021244963 - acc: 0.9872143634385201 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 1.2184419631958008 - sq_loss: 6.0237766774662305e-06 - tot_loss: 0.09840635479151416 - acc: 0.9872143634385201 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 1.2307591438293457 - sq_loss: 6.007105639582733e-06 - tot_loss: 0.10525599749893644 - acc: 0.9873503808487486 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 1.2230589389801025 - sq_loss: 5.992149908706779e-06 - tot_loss: 0.09886945150453741 - acc: 0.9873503808487486 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 1.2326717376708984 - sq_loss: 5.975875410513254e-06 - tot_loss: 0.08823910309707017 - acc: 0.9873503808487486 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 1.2346553802490234 - sq_loss: 5.960091584711336e-06 - tot_loss: 0.09492473227134468 - acc: 0.9873503808487486 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 1.2466461658477783 - sq_loss: 5.944297754467698e-06 - tot_loss: 0.0980108326580158 - acc: 0.9874863982589771 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 1.2142362594604492 - sq_loss: 5.9301760302332696e-06 - tot_loss: 0.10879710080982008 - acc: 0.9874863982589771 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 1.2445793151855469 - sq_loss: 5.916303052799776e-06 - tot_loss: 0.09141437302331212 - acc: 0.9874863982589771 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 1.2419452667236328 - sq_loss: 5.901291387999663e-06 - tot_loss: 0.0926405728087154 - acc: 0.9874863982589771 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 1.2319495677947998 - sq_loss: 5.88792136113625e-06 - tot_loss: 0.09842959403232499 - acc: 0.9876224156692056 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 1.2522869110107422 - sq_loss: 5.875283022760414e-06 - tot_loss: 0.09338163149456236 - acc: 0.9876224156692056 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 1.2436680793762207 - sq_loss: 5.861752924829489e-06 - tot_loss: 0.09416992726422535 - acc: 0.9876224156692056 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 1.2290544509887695 - sq_loss: 5.845109626534395e-06 - tot_loss: 0.09036782164199053 - acc: 0.9876224156692056 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 1.235443353652954 - sq_loss: 5.83265682507772e-06 - tot_loss: 0.09732110304736707 - acc: 0.9876224156692056 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 1.2272114753723145 - sq_loss: 5.8193368204229046e-06 - tot_loss: 0.09311240453182634 - acc: 0.9877584330794341 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 1.2351064682006836 - sq_loss: 5.807995421491796e-06 - tot_loss: 0.09917203306111233 - acc: 0.9877584330794341 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 1.2197644710540771 - sq_loss: 5.795855940959882e-06 - tot_loss: 0.0878012402634063 - acc: 0.9876224156692056 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 1.2312700748443604 - sq_loss: 5.782567768619629e-06 - tot_loss: 0.087793535613784 - acc: 0.9876224156692056 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 1.2334537506103516 - sq_loss: 5.767672064393992e-06 - tot_loss: 0.09508743439779721 - acc: 0.9876224156692056 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 1.230048656463623 - sq_loss: 5.7503375501255505e-06 - tot_loss: 0.08930632198064359 - acc: 0.9876224156692056 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 1.2201347351074219 - sq_loss: 5.737526407756377e-06 - tot_loss: 0.09187731333436133 - acc: 0.9876224156692056 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 1.2315864562988281 - sq_loss: 5.726320978283184e-06 - tot_loss: 0.09286677750260708 - acc: 0.9876224156692056 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 1.2242977619171143 - sq_loss: 5.715898169000866e-06 - tot_loss: 0.10080766117285833 - acc: 0.9876224156692056 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 1.2422566413879395 - sq_loss: 5.704800514649833e-06 - tot_loss: 0.08687628014285309 - acc: 0.9876224156692056 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 1.2231521606445312 - sq_loss: 5.690144462278113e-06 - tot_loss: 0.08825091592650836 - acc: 0.9878944504896626 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 1.2426166534423828 - sq_loss: 5.676049113390036e-06 - tot_loss: 0.09472466484806219 - acc: 0.9880304678998912 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 1.2340495586395264 - sq_loss: 5.661801424139412e-06 - tot_loss: 0.09478415640390025 - acc: 0.9880304678998912 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 1.2382168769836426 - sq_loss: 5.646822046401212e-06 - tot_loss: 0.09341321755507082 - acc: 0.9878944504896626 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 1.2284085750579834 - sq_loss: 5.637491995003074e-06 - tot_loss: 0.09835798831077369 - acc: 0.9881664853101197 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 1.2565953731536865 - sq_loss: 5.624068762699608e-06 - tot_loss: 0.09716442706506356 - acc: 0.9881664853101197 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 1.2435603141784668 - sq_loss: 5.610437256109435e-06 - tot_loss: 0.09511578303967028 - acc: 0.9880304678998912 - val_acc: 0.9589412962334578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 1.2339537143707275 - sq_loss: 5.598942607321078e-06 - tot_loss: 0.10038453533907088 - acc: 0.9883025027203483 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 1.246248483657837 - sq_loss: 5.584806785918772e-06 - tot_loss: 0.08935485770434326 - acc: 0.9883025027203483 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 1.23966383934021 - sq_loss: 5.574353053816594e-06 - tot_loss: 0.09533509195371082 - acc: 0.9883025027203483 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 1.260188102722168 - sq_loss: 5.56059785594698e-06 - tot_loss: 0.08794344862558745 - acc: 0.9883025027203483 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 1.253178358078003 - sq_loss: 5.54662392460159e-06 - tot_loss: 0.09214123323705437 - acc: 0.9883025027203483 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 1.2482500076293945 - sq_loss: 5.533604962693062e-06 - tot_loss: 0.08771352604322047 - acc: 0.9884385201305768 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 1.2626056671142578 - sq_loss: 5.518342277355259e-06 - tot_loss: 0.09777007725352505 - acc: 0.9883025027203483 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 1.2463798522949219 - sq_loss: 5.50665163245867e-06 - tot_loss: 0.0879593455709049 - acc: 0.9884385201305768 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 1.22566819190979 - sq_loss: 5.493875050888164e-06 - tot_loss: 0.09408439568657201 - acc: 0.9884385201305768 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 1.232142686843872 - sq_loss: 5.481769676407566e-06 - tot_loss: 0.09918340315243057 - acc: 0.9884385201305768 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 1.2361485958099365 - sq_loss: 5.470194992085453e-06 - tot_loss: 0.08542947085929598 - acc: 0.9884385201305768 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 1.2305450439453125 - sq_loss: 5.458642590383533e-06 - tot_loss: 0.08804862330516627 - acc: 0.9884385201305768 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 1.2434475421905518 - sq_loss: 5.447413059300743e-06 - tot_loss: 0.09114042074859441 - acc: 0.9884385201305768 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 1.2314743995666504 - sq_loss: 5.434872491605347e-06 - tot_loss: 0.09463877079640781 - acc: 0.9884385201305768 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 1.2328274250030518 - sq_loss: 5.423918082669843e-06 - tot_loss: 0.09387254378090759 - acc: 0.9884385201305768 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 1.23455810546875 - sq_loss: 5.41179451829521e-06 - tot_loss: 0.0953130097972057 - acc: 0.9887105549510338 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 1.2323417663574219 - sq_loss: 5.4007346079743e-06 - tot_loss: 0.09335860136768659 - acc: 0.9885745375408053 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 1.2314491271972656 - sq_loss: 5.389488251239527e-06 - tot_loss: 0.09234928957499022 - acc: 0.9884385201305768 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 1.2379734516143799 - sq_loss: 5.376236003939994e-06 - tot_loss: 0.08917790424722227 - acc: 0.9885745375408053 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 1.2510433197021484 - sq_loss: 5.3647336244466715e-06 - tot_loss: 0.08704871844025774 - acc: 0.9884385201305768 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 1.2531187534332275 - sq_loss: 5.354866971174488e-06 - tot_loss: 0.0819835548970218 - acc: 0.9887105549510338 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 1.2529957294464111 - sq_loss: 5.345256340660853e-06 - tot_loss: 0.0908965666779622 - acc: 0.9887105549510338 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 1.2553250789642334 - sq_loss: 5.331856755219633e-06 - tot_loss: 0.08851416222352526 - acc: 0.9888465723612623 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 1.2461137771606445 - sq_loss: 5.3186404329608195e-06 - tot_loss: 0.09135859030020654 - acc: 0.9887105549510338 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 1.260051965713501 - sq_loss: 5.3068447414261755e-06 - tot_loss: 0.09005755613997479 - acc: 0.9887105549510338 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 1.2316014766693115 - sq_loss: 5.297039024299011e-06 - tot_loss: 0.09191569295421687 - acc: 0.9887105549510338 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 1.2147657871246338 - sq_loss: 5.289459295454435e-06 - tot_loss: 0.0905133785997343 - acc: 0.9885745375408053 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 1.2238292694091797 - sq_loss: 5.280252025841037e-06 - tot_loss: 0.09944702928527605 - acc: 0.9887105549510338 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 1.2238950729370117 - sq_loss: 5.271284862828907e-06 - tot_loss: 0.0959795545947344 - acc: 0.9887105549510338 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 1.2332792282104492 - sq_loss: 5.259256340650609e-06 - tot_loss: 0.09189218144205213 - acc: 0.9888465723612623 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 1.2227630615234375 - sq_loss: 5.246442015049979e-06 - tot_loss: 0.0920389002907065 - acc: 0.9887105549510338 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 1.2229020595550537 - sq_loss: 5.235925073066028e-06 - tot_loss: 0.08878942758081187 - acc: 0.9887105549510338 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 1.2327327728271484 - sq_loss: 5.22822620041552e-06 - tot_loss: 0.08518223399614477 - acc: 0.9887105549510338 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 1.2230429649353027 - sq_loss: 5.217897069087485e-06 - tot_loss: 0.09078254363764593 - acc: 0.9887105549510338 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 1.2488150596618652 - sq_loss: 5.206754394748714e-06 - tot_loss: 0.09013137747631639 - acc: 0.9887105549510338 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 1.2314119338989258 - sq_loss: 5.198174676479539e-06 - tot_loss: 0.08844277608023354 - acc: 0.9887105549510338 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 1.2381572723388672 - sq_loss: 5.186603175388882e-06 - tot_loss: 0.08374868001260793 - acc: 0.9887105549510338 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 1.2341461181640625 - sq_loss: 5.175695150683168e-06 - tot_loss: 0.08750806767002217 - acc: 0.9887105549510338 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 1.2208995819091797 - sq_loss: 5.165197762835305e-06 - tot_loss: 0.08818545994031624 - acc: 0.9885745375408053 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 1.2336688041687012 - sq_loss: 5.1570254981925245e-06 - tot_loss: 0.09185792113348157 - acc: 0.9887105549510338 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 1.225771188735962 - sq_loss: 5.1451579565764405e-06 - tot_loss: 0.09435672849520671 - acc: 0.9889825897714908 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 1.2314598560333252 - sq_loss: 5.1331257964193355e-06 - tot_loss: 0.09992856559697749 - acc: 0.9889825897714908 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 1.223714828491211 - sq_loss: 5.12287851961446e-06 - tot_loss: 0.09215402475079593 - acc: 0.9889825897714908 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 1.2452468872070312 - sq_loss: 5.111838618176989e-06 - tot_loss: 0.09302165102048399 - acc: 0.9889825897714908 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 1.2196505069732666 - sq_loss: 5.101258011563914e-06 - tot_loss: 0.09035957417212792 - acc: 0.9889825897714908 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 1.2492785453796387 - sq_loss: 5.09359688294353e-06 - tot_loss: 0.08522556343113585 - acc: 0.9889825897714908 - val_acc: 0.9596199524940617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 1.220482587814331 - sq_loss: 5.083182259113528e-06 - tot_loss: 0.09033361655448147 - acc: 0.9888465723612623 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 1.2245738506317139 - sq_loss: 5.072346993983956e-06 - tot_loss: 0.09057524605503176 - acc: 0.9889825897714908 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 1.2200098037719727 - sq_loss: 5.05837533637532e-06 - tot_loss: 0.09224728410968375 - acc: 0.9889825897714908 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 1.2215631008148193 - sq_loss: 5.047205831942847e-06 - tot_loss: 0.08740881990585514 - acc: 0.9888465723612623 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 1.2345025539398193 - sq_loss: 5.037221853854135e-06 - tot_loss: 0.09151928418997102 - acc: 0.9889825897714908 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 1.2281067371368408 - sq_loss: 5.026991402701242e-06 - tot_loss: 0.0961532376176315 - acc: 0.9889825897714908 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 1.2201132774353027 - sq_loss: 5.016773229726823e-06 - tot_loss: 0.0902727298696977 - acc: 0.9889825897714908 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 1.2425224781036377 - sq_loss: 5.0077792366209906e-06 - tot_loss: 0.09231368622431191 - acc: 0.9891186071817193 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 1.233943223953247 - sq_loss: 5.000639703212073e-06 - tot_loss: 0.08765574192622694 - acc: 0.9888465723612623 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 1.2235243320465088 - sq_loss: 4.9917985052161384e-06 - tot_loss: 0.08752195442293775 - acc: 0.9888465723612623 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 1.2355601787567139 - sq_loss: 4.9827021939563565e-06 - tot_loss: 0.10005872455515252 - acc: 0.9888465723612623 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 1.2287213802337646 - sq_loss: 4.97457813253277e-06 - tot_loss: 0.0890577598002551 - acc: 0.9888465723612623 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 1.2164173126220703 - sq_loss: 4.965097105014138e-06 - tot_loss: 0.08616908881310081 - acc: 0.9888465723612623 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 1.2629916667938232 - sq_loss: 4.954245468979934e-06 - tot_loss: 0.09281570278800189 - acc: 0.9888465723612623 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 1.2308003902435303 - sq_loss: 4.9465184019936714e-06 - tot_loss: 0.08540155341712818 - acc: 0.9891186071817193 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 1.2360293865203857 - sq_loss: 4.937131507176673e-06 - tot_loss: 0.09303575933988206 - acc: 0.9889825897714908 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 1.2514426708221436 - sq_loss: 4.928072939947015e-06 - tot_loss: 0.08967505947757637 - acc: 0.9891186071817193 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 1.228064775466919 - sq_loss: 4.919210368825588e-06 - tot_loss: 0.09231047189419428 - acc: 0.9889825897714908 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 1.225921630859375 - sq_loss: 4.911750238534296e-06 - tot_loss: 0.0898179368278278 - acc: 0.9889825897714908 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 1.222245693206787 - sq_loss: 4.902770797343692e-06 - tot_loss: 0.08879250444859288 - acc: 0.9889825897714908 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 1.2216598987579346 - sq_loss: 4.893635377811734e-06 - tot_loss: 0.09171826018240203 - acc: 0.9888465723612623 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 1.2688348293304443 - sq_loss: 4.884896952717099e-06 - tot_loss: 0.08666509491655106 - acc: 0.9889825897714908 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 1.2276582717895508 - sq_loss: 4.875072136201197e-06 - tot_loss: 0.08986574488063681 - acc: 0.9889825897714908 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 1.2367579936981201 - sq_loss: 4.865184109803522e-06 - tot_loss: 0.09046375405190332 - acc: 0.9889825897714908 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 1.2619051933288574 - sq_loss: 4.856637133343611e-06 - tot_loss: 0.08855653614532955 - acc: 0.9891186071817193 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 1.2479591369628906 - sq_loss: 4.851262019656133e-06 - tot_loss: 0.08993271398963465 - acc: 0.9889825897714908 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 1.2665867805480957 - sq_loss: 4.842434464080725e-06 - tot_loss: 0.09295276336328584 - acc: 0.9891186071817193 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 1.2571935653686523 - sq_loss: 4.8346414587285835e-06 - tot_loss: 0.0906950385491001 - acc: 0.9889825897714908 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 1.252500295639038 - sq_loss: 4.826429176318925e-06 - tot_loss: 0.09198334603942193 - acc: 0.9891186071817193 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 1.251945972442627 - sq_loss: 4.816458840650739e-06 - tot_loss: 0.09904375496378037 - acc: 0.9889825897714908 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 1.2448806762695312 - sq_loss: 4.805769094673451e-06 - tot_loss: 0.08782350008097417 - acc: 0.9891186071817193 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 1.2532739639282227 - sq_loss: 4.796524990524631e-06 - tot_loss: 0.09394457815990087 - acc: 0.9891186071817193 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 1.2387049198150635 - sq_loss: 4.78876290799235e-06 - tot_loss: 0.08518930472775033 - acc: 0.9891186071817193 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 1.2341325283050537 - sq_loss: 4.780422841577092e-06 - tot_loss: 0.09159369455754529 - acc: 0.9892546245919478 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 1.2628757953643799 - sq_loss: 4.770164650835795e-06 - tot_loss: 0.09024618441528709 - acc: 0.9891186071817193 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 1.2703957557678223 - sq_loss: 4.759705007018056e-06 - tot_loss: 0.09265430409999986 - acc: 0.9891186071817193 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 1.259842872619629 - sq_loss: 4.7492681005678605e-06 - tot_loss: 0.08937543386807079 - acc: 0.9891186071817193 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 1.2407639026641846 - sq_loss: 4.737519702757709e-06 - tot_loss: 0.09210663637709793 - acc: 0.9891186071817193 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 1.2292091846466064 - sq_loss: 4.7279436330427416e-06 - tot_loss: 0.08956391858359503 - acc: 0.9892546245919478 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 1.2343339920043945 - sq_loss: 4.720343440567376e-06 - tot_loss: 0.09034093487172434 - acc: 0.9891186071817193 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 1.2226722240447998 - sq_loss: 4.711789188149851e-06 - tot_loss: 0.08314869171412909 - acc: 0.9892546245919478 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 1.232245922088623 - sq_loss: 4.703804279415635e-06 - tot_loss: 0.08976858549952027 - acc: 0.9893906420021763 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 1.229888677597046 - sq_loss: 4.6957534323155414e-06 - tot_loss: 0.08996803979113999 - acc: 0.9895266594124048 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 1.2486484050750732 - sq_loss: 4.687800355895888e-06 - tot_loss: 0.08681416324148472 - acc: 0.9893906420021763 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 1.2382545471191406 - sq_loss: 4.67974723505904e-06 - tot_loss: 0.08748045205546084 - acc: 0.9895266594124048 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 1.2537100315093994 - sq_loss: 4.672108389058849e-06 - tot_loss: 0.09151278808381491 - acc: 0.9895266594124048 - val_acc: 0.9630132337970818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 1.2483255863189697 - sq_loss: 4.664160314860055e-06 - tot_loss: 0.087587759158966 - acc: 0.9892546245919478 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 1.2485108375549316 - sq_loss: 4.65683206130052e-06 - tot_loss: 0.08969962311567592 - acc: 0.9893906420021763 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 1.250889778137207 - sq_loss: 4.64841377834091e-06 - tot_loss: 0.0946375720100825 - acc: 0.9892546245919478 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 1.2450919151306152 - sq_loss: 4.640006409317721e-06 - tot_loss: 0.09268996571526245 - acc: 0.9893906420021763 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 1.2522318363189697 - sq_loss: 4.632493528333725e-06 - tot_loss: 0.08558440248058297 - acc: 0.9893906420021763 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 1.2492949962615967 - sq_loss: 4.625277142622508e-06 - tot_loss: 0.07778001453270633 - acc: 0.9893906420021763 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 1.249995231628418 - sq_loss: 4.617515969584929e-06 - tot_loss: 0.08232108336008359 - acc: 0.9893906420021763 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 1.2487094402313232 - sq_loss: 4.610253199643921e-06 - tot_loss: 0.08091371816966131 - acc: 0.9893906420021763 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 1.2471871376037598 - sq_loss: 4.6022287278901786e-06 - tot_loss: 0.09130550394218062 - acc: 0.9896626768226333 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 1.274916648864746 - sq_loss: 4.593884114001412e-06 - tot_loss: 0.09107354877913387 - acc: 0.9893906420021763 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 1.2616055011749268 - sq_loss: 4.585564965964295e-06 - tot_loss: 0.08897001118376835 - acc: 0.9895266594124048 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 1.260730504989624 - sq_loss: 4.579017058858881e-06 - tot_loss: 0.08797260705835974 - acc: 0.9895266594124048 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 1.2772095203399658 - sq_loss: 4.571156296151457e-06 - tot_loss: 0.09171942676542422 - acc: 0.9895266594124048 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 1.24623703956604 - sq_loss: 4.561814421322197e-06 - tot_loss: 0.08722152470534539 - acc: 0.9895266594124048 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 1.2482035160064697 - sq_loss: 4.55168446933385e-06 - tot_loss: 0.09160162881857836 - acc: 0.9895266594124048 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 1.2614574432373047 - sq_loss: 4.543292561720591e-06 - tot_loss: 0.09392493291410631 - acc: 0.9895266594124048 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 1.2737846374511719 - sq_loss: 4.534749677986838e-06 - tot_loss: 0.09347354273118746 - acc: 0.9895266594124048 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 1.2363190650939941 - sq_loss: 4.527118107944261e-06 - tot_loss: 0.08754624914854858 - acc: 0.9895266594124048 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 1.2465617656707764 - sq_loss: 4.518298737821169e-06 - tot_loss: 0.09644259669250488 - acc: 0.9895266594124048 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 1.2389767169952393 - sq_loss: 4.509891823545331e-06 - tot_loss: 0.08135306240537865 - acc: 0.9895266594124048 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 1.2455251216888428 - sq_loss: 4.502613592194393e-06 - tot_loss: 0.08270326642148618 - acc: 0.9895266594124048 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 1.2271738052368164 - sq_loss: 4.496128894970752e-06 - tot_loss: 0.08857052377621422 - acc: 0.9895266594124048 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 1.241145133972168 - sq_loss: 4.488359536480857e-06 - tot_loss: 0.07875793046464175 - acc: 0.9895266594124048 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 1.2351882457733154 - sq_loss: 4.4799949137086514e-06 - tot_loss: 0.09073425671715185 - acc: 0.9897986942328618 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 1.240379810333252 - sq_loss: 4.471650299819885e-06 - tot_loss: 0.08981794644641639 - acc: 0.9897986942328618 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 1.2395668029785156 - sq_loss: 4.4646558308159e-06 - tot_loss: 0.0956852813615825 - acc: 0.9897986942328618 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 1.2343776226043701 - sq_loss: 4.457434897631174e-06 - tot_loss: 0.08337203121068448 - acc: 0.9897986942328618 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 1.2339582443237305 - sq_loss: 4.453342171473196e-06 - tot_loss: 0.0858662502123071 - acc: 0.9895266594124048 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 1.2396292686462402 - sq_loss: 4.448419986147201e-06 - tot_loss: 0.08564645586126574 - acc: 0.9895266594124048 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 1.2376055717468262 - sq_loss: 4.442208137334092e-06 - tot_loss: 0.08209641148539504 - acc: 0.9893906420021763 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 1.2391583919525146 - sq_loss: 4.436906237970106e-06 - tot_loss: 0.08804439971014943 - acc: 0.9896626768226333 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 1.2602167129516602 - sq_loss: 4.430617991602048e-06 - tot_loss: 0.09028625391770895 - acc: 0.9896626768226333 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 1.237933874130249 - sq_loss: 4.423493010108359e-06 - tot_loss: 0.09019465974221497 - acc: 0.9895266594124048 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 1.2395918369293213 - sq_loss: 4.41557267549797e-06 - tot_loss: 0.08532941853057352 - acc: 0.9896626768226333 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 1.2399523258209229 - sq_loss: 4.4056519072910305e-06 - tot_loss: 0.0951924355461724 - acc: 0.9896626768226333 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 1.2828576564788818 - sq_loss: 4.397983957460383e-06 - tot_loss: 0.08675194515418383 - acc: 0.9897986942328618 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 1.2699100971221924 - sq_loss: 4.391919446788961e-06 - tot_loss: 0.08346836110304956 - acc: 0.9895266594124048 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 1.2328064441680908 - sq_loss: 4.3873396862181835e-06 - tot_loss: 0.09794388053816583 - acc: 0.9896626768226333 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 1.2798376083374023 - sq_loss: 4.380461177788675e-06 - tot_loss: 0.10095627382617955 - acc: 0.9896626768226333 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 1.2764694690704346 - sq_loss: 4.3737859414250124e-06 - tot_loss: 0.10948072021103172 - acc: 0.9897986942328618 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 1.2475345134735107 - sq_loss: 4.36735672337818e-06 - tot_loss: 0.08647907698630775 - acc: 0.9897986942328618 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 1.229001522064209 - sq_loss: 4.360916136647575e-06 - tot_loss: 0.09059660451730878 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 1.2308189868927002 - sq_loss: 4.352466930868104e-06 - tot_loss: 0.09776096451145655 - acc: 0.9896626768226333 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 1.264789342880249 - sq_loss: 4.34632420365233e-06 - tot_loss: 0.09030932384779788 - acc: 0.9897986942328618 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 1.2691280841827393 - sq_loss: 4.339753559179371e-06 - tot_loss: 0.08200292320416835 - acc: 0.9897986942328618 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 1.2731704711914062 - sq_loss: 4.334606728662038e-06 - tot_loss: 0.09306076001180408 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 1.2803986072540283 - sq_loss: 4.32874412581441e-06 - tot_loss: 0.08926396515854051 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 1.2794914245605469 - sq_loss: 4.318967512517702e-06 - tot_loss: 0.08852120544122855 - acc: 0.9897986942328618 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 1.2456233501434326 - sq_loss: 4.313462795835221e-06 - tot_loss: 0.08763441902404168 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 1.2475261688232422 - sq_loss: 4.304815320210764e-06 - tot_loss: 0.08893460211664106 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 1.2583916187286377 - sq_loss: 4.296471615816699e-06 - tot_loss: 0.09073902316829141 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 1.2544090747833252 - sq_loss: 4.289507614885224e-06 - tot_loss: 0.09330658925465407 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 1.2527155876159668 - sq_loss: 4.283459929865785e-06 - tot_loss: 0.08621426530263498 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 1.2511799335479736 - sq_loss: 4.275734681868926e-06 - tot_loss: 0.08494691085801875 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 1.3021702766418457 - sq_loss: 4.269329110684339e-06 - tot_loss: 0.08659204426514933 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 1.2664828300476074 - sq_loss: 4.263116807123879e-06 - tot_loss: 0.08726478837709983 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 1.2421619892120361 - sq_loss: 4.258219632902183e-06 - tot_loss: 0.09584496655251051 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 1.249377965927124 - sq_loss: 4.250668098393362e-06 - tot_loss: 0.08055717440123011 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 1.2625725269317627 - sq_loss: 4.245187938067829e-06 - tot_loss: 0.08953027620302301 - acc: 0.9899347116430903 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 1.2653305530548096 - sq_loss: 4.2388505789858755e-06 - tot_loss: 0.09200796456880944 - acc: 0.9897986942328618 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 1.26246976852417 - sq_loss: 4.231784714647802e-06 - tot_loss: 0.08501095337297038 - acc: 0.9896626768226333 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 1.261108636856079 - sq_loss: 4.223144060233608e-06 - tot_loss: 0.09442734557020138 - acc: 0.9896626768226333 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 1.2543039321899414 - sq_loss: 4.2173219299002085e-06 - tot_loss: 0.09083263823329624 - acc: 0.9899347116430903 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 1.2512285709381104 - sq_loss: 4.211003215459641e-06 - tot_loss: 0.0785132082420752 - acc: 0.9899347116430903 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 1.2560462951660156 - sq_loss: 4.204521246720105e-06 - tot_loss: 0.08326089759168731 - acc: 0.9899347116430903 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 1.2653298377990723 - sq_loss: 4.196711415715981e-06 - tot_loss: 0.07969663296697505 - acc: 0.9899347116430903 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 1.2469110488891602 - sq_loss: 4.189146238786634e-06 - tot_loss: 0.09138201732269913 - acc: 0.9899347116430903 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 1.2579748630523682 - sq_loss: 4.183110377198318e-06 - tot_loss: 0.08445329082405095 - acc: 0.9899347116430903 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 1.2424123287200928 - sq_loss: 4.176762558927294e-06 - tot_loss: 0.09618435009729431 - acc: 0.9899347116430903 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 1.2332837581634521 - sq_loss: 4.170636657363502e-06 - tot_loss: 0.08044314478644665 - acc: 0.9899347116430903 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 1.256669521331787 - sq_loss: 4.166364306001924e-06 - tot_loss: 0.08784427342798828 - acc: 0.9899347116430903 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 1.257399320602417 - sq_loss: 4.160756361670792e-06 - tot_loss: 0.0834459683809623 - acc: 0.9899347116430903 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 1.2340655326843262 - sq_loss: 4.15472231907188e-06 - tot_loss: 0.08438297705409248 - acc: 0.9899347116430903 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 1.2486824989318848 - sq_loss: 4.1503772081341594e-06 - tot_loss: 0.08516776583229557 - acc: 0.9897986942328618 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 1.2665905952453613 - sq_loss: 4.1459393287368584e-06 - tot_loss: 0.08797528024509305 - acc: 0.9899347116430903 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 1.2537376880645752 - sq_loss: 4.139018983551068e-06 - tot_loss: 0.09004009454410067 - acc: 0.9899347116430903 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 1.2495036125183105 - sq_loss: 4.132440153625794e-06 - tot_loss: 0.08872541901832243 - acc: 0.9899347116430903 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 1.2705674171447754 - sq_loss: 4.1255279938923195e-06 - tot_loss: 0.08791600570422275 - acc: 0.9900707290533188 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 1.2613425254821777 - sq_loss: 4.1182142922480125e-06 - tot_loss: 0.08318088663743417 - acc: 0.9900707290533188 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 1.26729154586792 - sq_loss: 4.110098871024093e-06 - tot_loss: 0.09590373245800698 - acc: 0.9899347116430903 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 1.2711350917816162 - sq_loss: 4.103000719624106e-06 - tot_loss: 0.08808268017428844 - acc: 0.9899347116430903 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 1.2386548519134521 - sq_loss: 4.0952641029434744e-06 - tot_loss: 0.08801020741946708 - acc: 0.9899347116430903 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 1.2397689819335938 - sq_loss: 4.090876245754771e-06 - tot_loss: 0.09267960953809862 - acc: 0.9899347116430903 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 1.2460708618164062 - sq_loss: 4.085163709532935e-06 - tot_loss: 0.08177265700323488 - acc: 0.9899347116430903 - val_acc: 0.9626739056667798\n",
      "CR_1 = 0.16759738116197184   CR_2 = 0.1667972504806152\n",
      "/home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 5\n",
    "alpha = 1\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "\n",
    "#alpha1 = alpha2 = alpha3 = alpha4 = alpha5 = alpha6 = alpha7 = alpha8 = alpha9 = alpha10 = alpha\n",
    "#for rank in (35,): #(25,30,35)(100,180,220,260,300,340,380)(20,60,100,140,180,220,260,300,340,380)\n",
    "#    for tau in (400,500): #(300,400,500)(10,50,100,200,300)(10,50,100,200,300)\n",
    "#        for gamma in (0.5,0.8,2): #(0.5,0.8,2)(0.5,0.8)(0.5,1,1.5,2,3)\n",
    "            #gamma1 = gamma2 = gamma3 = gamma4 = gamma5 = gamma\n",
    "#            for rho in (0.5,0.8,2): #(0.5,0.8)(1,2)\n",
    "                #rho1 = rho2 = rho3 = rho4 = rho5= rho\n",
    "#                for alpha in (0.5,1,1.5,2):\n",
    "#                    print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "                    #print('Compression Ratio', ((1024*28*28+10*1024+(8*(rank)+32*np.square(rank))*2)/(1024*28*28+10*1024+1024*1024*2)), (8*(rank)+32*np.square(rank))*2/(1024*1024*2))\n",
    "        \n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    d0 = 561 #561 =3*11*17\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 6 \n",
    "\n",
    "    limit = torch.sqrt(torch.tensor(3. / d0))\n",
    "    W1 = 0.2* torch.empty(d1, d0, device=device).uniform_(-limit, limit)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    limit = torch.sqrt(torch.tensor(3. / d1))\n",
    "    W2 = 0.2* torch.empty(d2, d1, device=device).uniform_(-limit, limit)\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles ‘factors’, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    limit = torch.sqrt(torch.tensor(3. / d2))\n",
    "    W3 = 0.2* torch.empty(d3, d2, device=device).uniform_(-limit, limit)\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    limit = torch.sqrt(torch.tensor(3. / d3))\n",
    "    W4 = 0.2* torch.empty(d4, d3, device=device).uniform_(-limit, limit)\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "\n",
    "    limit = torch.sqrt(torch.tensor(3. / d4))\n",
    "    W5 = 0.2* torch.empty(d5, d4, device=device).uniform_(-limit, limit)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = U5 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V5 = (y_one_hot + gamma*U5 + alpha*V5)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U5 = (gamma*V5 + rho*(torch.mm(W5,V4) + b5.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W5, b5 = updateWb_org(U5,V4,W5,b5,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b5.repeat(1, N), W5, a4_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b5.repeat(1, N_test), W5, a4_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V5,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,U5,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4\n",
    "\n",
    "    CR_1=((total_variabels)+(d4*d5))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#this postion to add new row into existing table\n",
    "    #df=pd.read_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "    #new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "    #           'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "    #           'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1], 'seed':seed} \n",
    "    #df=df.append(new_row,ignore_index=True)\n",
    "    #df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"LecunUniform_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895c825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30f34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
