{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccc0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6113fe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 5 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 1.7425446510314941 - sq_loss: 661.6697387695312 - tot_loss: 1023.5006638470877 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 1.3214137554168701 - sq_loss: 294.075439453125 - tot_loss: 475.39059319347143 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 1.315943717956543 - sq_loss: 160.69215393066406 - tot_loss: 261.01051138341427 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 1.3142530918121338 - sq_loss: 86.99430847167969 - tot_loss: 147.26321842707694 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 1.3319859504699707 - sq_loss: 46.784786224365234 - tot_loss: 85.8411285309121 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 1.3096609115600586 - sq_loss: 25.103256225585938 - tot_loss: 52.45884685823694 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 1.3090920448303223 - sq_loss: 13.479974746704102 - tot_loss: 34.10828976565972 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 1.3036363124847412 - sq_loss: 7.260493278503418 - tot_loss: 23.82494920026511 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 1.3157551288604736 - sq_loss: 3.930534839630127 - tot_loss: 17.902285010088235 - acc: 0.18784004352557127 - val_acc: 0.1845945028842891\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 1.3190081119537354 - sq_loss: 2.143371105194092 - tot_loss: 14.360546093201265 - acc: 0.3532372143634385 - val_acc: 0.33389888021717\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 1.3163506984710693 - sq_loss: 1.180345058441162 - tot_loss: 12.10570209682919 - acc: 0.43375952121871597 - val_acc: 0.4190702409229725\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 1.2952232360839844 - sq_loss: 0.6584257483482361 - tot_loss: 10.587294878670946 - acc: 0.45375408052230687 - val_acc: 0.44757380386834067\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 1.3113751411437988 - sq_loss: 0.3733893930912018 - tot_loss: 9.47915945877321 - acc: 0.4557943416757345 - val_acc: 0.47472005429250086\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 1.3097238540649414 - sq_loss: 0.21617242693901062 - tot_loss: 8.614261364331469 - acc: 0.46694776931447224 - val_acc: 0.48489989820156093\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 1.2935447692871094 - sq_loss: 0.1283694952726364 - tot_loss: 7.890781706315465 - acc: 0.4851741022850925 - val_acc: 0.495758398371225\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 1.295224905014038 - sq_loss: 0.07857495546340942 - tot_loss: 7.261559529462829 - acc: 0.5118335146898803 - val_acc: 0.5140821174075331\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 1.2943379878997803 - sq_loss: 0.0498119592666626 - tot_loss: 6.696332612074912 - acc: 0.5315560391730142 - val_acc: 0.5232439769256871\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 1.2953588962554932 - sq_loss: 0.03283403441309929 - tot_loss: 6.195529947523028 - acc: 0.5398531011969532 - val_acc: 0.5273159144893111\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 1.282219409942627 - sq_loss: 0.02256178855895996 - tot_loss: 5.720838920446113 - acc: 0.5433895538628944 - val_acc: 0.5300305395317272\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 1.2941207885742188 - sq_loss: 0.01617111638188362 - tot_loss: 5.291806178807747 - acc: 0.5442056583242655 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 1.2980875968933105 - sq_loss: 0.012072470039129257 - tot_loss: 4.909091886715032 - acc: 0.5444776931447225 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 1.284975528717041 - sq_loss: 0.009355304762721062 - tot_loss: 4.547078020113986 - acc: 0.5458378672470077 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 1.2832553386688232 - sq_loss: 0.0074910386465489864 - tot_loss: 4.224813032196835 - acc: 0.5529107725788901 - val_acc: 0.5334238208347472\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 1.2932217121124268 - sq_loss: 0.006166554521769285 - tot_loss: 3.9359020496776793 - acc: 0.5673286180631121 - val_acc: 0.5408890397013912\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 1.2898120880126953 - sq_loss: 0.005192036274820566 - tot_loss: 3.6558691225363873 - acc: 0.5907236126224157 - val_acc: 0.5588734306073974\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 1.2890889644622803 - sq_loss: 0.004452000837773085 - tot_loss: 3.409008631540928 - acc: 0.6304406964091404 - val_acc: 0.5822870715982355\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 1.2802197933197021 - sq_loss: 0.0038723761681467295 - tot_loss: 3.185557792239706 - acc: 0.6675734494015234 - val_acc: 0.6152019002375297\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 1.2910351753234863 - sq_loss: 0.0034072089474648237 - tot_loss: 2.9795410779188387 - acc: 0.7041621327529923 - val_acc: 0.6481167288768239\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 1.2978451251983643 - sq_loss: 0.0030247820541262627 - tot_loss: 2.792706780397566 - acc: 0.7331338411316648 - val_acc: 0.66949440108585\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 1.2778522968292236 - sq_loss: 0.0027045863680541515 - tot_loss: 2.622569599887356 - acc: 0.7593852013057671 - val_acc: 0.6949440108585002\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 1.292529582977295 - sq_loss: 0.002432325156405568 - tot_loss: 2.455943032487994 - acc: 0.7747551686615887 - val_acc: 0.7203936206311503\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 1.282808780670166 - sq_loss: 0.00219808891415596 - tot_loss: 2.315171508671483 - acc: 0.7903971708378672 - val_acc: 0.7400746521886664\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 1.2927498817443848 - sq_loss: 0.001994617283344269 - tot_loss: 2.1754639494174626 - acc: 0.8054951033732318 - val_acc: 0.7573803868340685\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 1.2776877880096436 - sq_loss: 0.0018164180219173431 - tot_loss: 2.0520676411906607 - acc: 0.8174646354733406 - val_acc: 0.7712928401764506\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 1.2859046459197998 - sq_loss: 0.001658932538703084 - tot_loss: 1.9296927956893342 - acc: 0.8279379760609358 - val_acc: 0.7852052935188327\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 1.274397373199463 - sq_loss: 0.0015195300802588463 - tot_loss: 1.8260711598341004 - acc: 0.8362350380848749 - val_acc: 0.7967424499491008\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 1.2956454753875732 - sq_loss: 0.0013951314613223076 - tot_loss: 1.7228598412038991 - acc: 0.8443960826985855 - val_acc: 0.8076009501187649\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 1.2770473957061768 - sq_loss: 0.0012838678667321801 - tot_loss: 1.6284746842939057 - acc: 0.8502448313384113 - val_acc: 0.8184594502884289\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 1.2866733074188232 - sq_loss: 0.0011840362567454576 - tot_loss: 1.543507674599823 - acc: 0.8560935799782372 - val_acc: 0.8262639972853749\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 1.2880744934082031 - sq_loss: 0.0010939700296148658 - tot_loss: 1.4622151093717548 - acc: 0.860854189336235 - val_acc: 0.8347472005429251\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 1.3206875324249268 - sq_loss: 0.001012304681353271 - tot_loss: 1.3895125897033722 - acc: 0.8628944504896626 - val_acc: 0.841873091279267\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 1.281489610671997 - sq_loss: 0.0009384368895553052 - tot_loss: 1.319962946290616 - acc: 0.8669749727965179 - val_acc: 0.8486596538853071\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 1.2857639789581299 - sq_loss: 0.0008712796261534095 - tot_loss: 1.2497548187238863 - acc: 0.8694232861806311 - val_acc: 0.8520529351883271\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 1.3232216835021973 - sq_loss: 0.0008100685081444681 - tot_loss: 1.1829512265321682 - acc: 0.8736398258977149 - val_acc: 0.8568035290125552\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 1.3037047386169434 - sq_loss: 0.0007541679660789669 - tot_loss: 1.122790272547718 - acc: 0.8759521218715995 - val_acc: 0.8591788259246692\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 1.2996091842651367 - sq_loss: 0.0007029107655398548 - tot_loss: 1.0768727005015535 - acc: 0.8808487486398259 - val_acc: 0.8618934509670851\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 1.2913131713867188 - sq_loss: 0.0006557925371453166 - tot_loss: 1.0260293669743987 - acc: 0.8831610446137106 - val_acc: 0.8629114353579912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 1.2911641597747803 - sq_loss: 0.000612259260378778 - tot_loss: 0.9720702514241566 - acc: 0.8857453754080522 - val_acc: 0.8686800135731252\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 1.309067726135254 - sq_loss: 0.000572146091144532 - tot_loss: 0.9318796098377788 - acc: 0.8875136017410229 - val_acc: 0.8730912792670512\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 1.302140235900879 - sq_loss: 0.0005350055289454758 - tot_loss: 0.8857553449379338 - acc: 0.8887377584330794 - val_acc: 0.8724126230064473\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 1.3069775104522705 - sq_loss: 0.0005007779691368341 - tot_loss: 0.8501487037501647 - acc: 0.891050054406964 - val_acc: 0.8754665761791652\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 1.3039112091064453 - sq_loss: 0.0004690583737101406 - tot_loss: 0.8113640344690793 - acc: 0.8932263329706203 - val_acc: 0.8788598574821853\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 1.2928962707519531 - sq_loss: 0.00043954490683972836 - tot_loss: 0.778876299456897 - acc: 0.8952665941240479 - val_acc: 0.8815744825246012\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 1.2754197120666504 - sq_loss: 0.000412075431086123 - tot_loss: 0.7424040910300391 - acc: 0.89689880304679 - val_acc: 0.8822531387852053\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 1.325162649154663 - sq_loss: 0.0003865892649628222 - tot_loss: 0.717538115055504 - acc: 0.8983949945593036 - val_acc: 0.8849677638276213\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 1.2916066646575928 - sq_loss: 0.0003627107944339514 - tot_loss: 0.6770796424716536 - acc: 0.9002992383025027 - val_acc: 0.8849677638276213\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 1.2979965209960938 - sq_loss: 0.0003406348405405879 - tot_loss: 0.6560346063633915 - acc: 0.9017954298150164 - val_acc: 0.8880217170003394\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 1.2802448272705078 - sq_loss: 0.0003200196661055088 - tot_loss: 0.6323206461347581 - acc: 0.903563656147987 - val_acc: 0.8917543264336614\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 1.280637264251709 - sq_loss: 0.0003007908817380667 - tot_loss: 0.6031341947746114 - acc: 0.9053318824809575 - val_acc: 0.8937902952154734\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 1.2970430850982666 - sq_loss: 0.00028287808527238667 - tot_loss: 0.5836146362253203 - acc: 0.9071001088139282 - val_acc: 0.8954869358669834\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 1.3007838726043701 - sq_loss: 0.00026612519286572933 - tot_loss: 0.560023087728041 - acc: 0.9081882480957563 - val_acc: 0.8978622327790974\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 1.2933568954467773 - sq_loss: 0.00025042437482625246 - tot_loss: 0.5391720303141483 - acc: 0.9105005440696409 - val_acc: 0.8978622327790974\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 1.2791252136230469 - sq_loss: 0.00023579168191645294 - tot_loss: 0.5188178536900523 - acc: 0.9114526659412405 - val_acc: 0.8998982015609094\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 1.2791612148284912 - sq_loss: 0.00022204148990567774 - tot_loss: 0.4988318220266592 - acc: 0.9130848748639826 - val_acc: 0.9015948422124194\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 1.312720537185669 - sq_loss: 0.00020929204765707254 - tot_loss: 0.4855429365970849 - acc: 0.9147170837867247 - val_acc: 0.9036308109942314\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 1.2928564548492432 - sq_loss: 0.00019736916874535382 - tot_loss: 0.47076313353500154 - acc: 0.9163492927094669 - val_acc: 0.9056667797760435\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 1.2828519344329834 - sq_loss: 0.0001861661730799824 - tot_loss: 0.4518885288416641 - acc: 0.9182535364526659 - val_acc: 0.9056667797760435\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 1.2815954685211182 - sq_loss: 0.00017568678595125675 - tot_loss: 0.4368473546228415 - acc: 0.919341675734494 - val_acc: 0.9093993892093655\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 1.2806029319763184 - sq_loss: 0.00016587965365033597 - tot_loss: 0.4184059593571874 - acc: 0.920429815016322 - val_acc: 0.9104173736002714\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 1.282827377319336 - sq_loss: 0.00015670809079892933 - tot_loss: 0.40707954252320633 - acc: 0.9220620239390642 - val_acc: 0.9121140142517815\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 1.2926621437072754 - sq_loss: 0.00014814989117439836 - tot_loss: 0.3965416418377572 - acc: 0.9234221980413493 - val_acc: 0.9134713267729895\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 1.2710442543029785 - sq_loss: 0.00014010613085702062 - tot_loss: 0.3799907492721104 - acc: 0.9249183895538629 - val_acc: 0.9158466236851035\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 1.296156406402588 - sq_loss: 0.00013257903628982604 - tot_loss: 0.37295221459226013 - acc: 0.9258705114254625 - val_acc: 0.9178825924669155\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 1.2773842811584473 - sq_loss: 0.0001255602401215583 - tot_loss: 0.3591642335195502 - acc: 0.9276387377584331 - val_acc: 0.9185612487275195\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 1.2890839576721191 - sq_loss: 0.00011899795936187729 - tot_loss: 0.35234422009261834 - acc: 0.9285908596300326 - val_acc: 0.9209365456396336\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 1.2809126377105713 - sq_loss: 0.00011278152669547126 - tot_loss: 0.3432836865686113 - acc: 0.9300870511425462 - val_acc: 0.9226331862911435\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 1.2690966129302979 - sq_loss: 0.00010701597784645855 - tot_loss: 0.3273702844799118 - acc: 0.9321273122959739 - val_acc: 0.9253478113335596\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 1.2948036193847656 - sq_loss: 0.00010160933743463829 - tot_loss: 0.32179202633415116 - acc: 0.9321273122959739 - val_acc: 0.9267051238547676\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 1.280447006225586 - sq_loss: 9.646765829529613e-05 - tot_loss: 0.3126831972263062 - acc: 0.9330794341675734 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 1.296067476272583 - sq_loss: 9.172582213068381e-05 - tot_loss: 0.3060331133615364 - acc: 0.9338955386289445 - val_acc: 0.9280624363759755\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 1.2837929725646973 - sq_loss: 8.724581857677549e-05 - tot_loss: 0.2969680188880375 - acc: 0.9357997823721437 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 1.2948014736175537 - sq_loss: 8.302476635435596e-05 - tot_loss: 0.288290364194836 - acc: 0.9364798694232862 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 1.3092255592346191 - sq_loss: 7.908617408247665e-05 - tot_loss: 0.28410458591588394 - acc: 0.9374319912948857 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 1.284663200378418 - sq_loss: 7.538117642980069e-05 - tot_loss: 0.27591630917186194 - acc: 0.9379760609357998 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 1.2721951007843018 - sq_loss: 7.187719165813178e-05 - tot_loss: 0.266268869076157 - acc: 0.9394722524483133 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 1.308377742767334 - sq_loss: 6.855350511614233e-05 - tot_loss: 0.2592469692394843 - acc: 0.940424374319913 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 1.7519986629486084 - sq_loss: 6.54211689834483e-05 - tot_loss: 0.25374014795443145 - acc: 0.941784548422198 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 2.1926774978637695 - sq_loss: 6.248128192964941e-05 - tot_loss: 0.25099255146710675 - acc: 0.9426006528835691 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 2.2520909309387207 - sq_loss: 5.974177474854514e-05 - tot_loss: 0.24235001966212621 - acc: 0.9434167573449401 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 2.226259708404541 - sq_loss: 5.710129698854871e-05 - tot_loss: 0.24350690086953364 - acc: 0.9443688792165397 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 2.455214262008667 - sq_loss: 5.464348214445636e-05 - tot_loss: 0.2370283129382642 - acc: 0.9455930359085963 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 2.431884288787842 - sq_loss: 5.231889372225851e-05 - tot_loss: 0.23035252884801594 - acc: 0.9461371055495104 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 2.878539562225342 - sq_loss: 5.0123129767598584e-05 - tot_loss: 0.2221828489696236 - acc: 0.9465451577801959 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 3.25055193901062 - sq_loss: 4.805866410606541e-05 - tot_loss: 0.2175347276888715 - acc: 0.9470892274211099 - val_acc: 0.9372242958941296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 3.086397171020508 - sq_loss: 4.6111854317132384e-05 - tot_loss: 0.2141261361616671 - acc: 0.9477693144722524 - val_acc: 0.9382422802850356\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 2.734746217727661 - sq_loss: 4.4274827814660966e-05 - tot_loss: 0.20995044855771994 - acc: 0.948177366702938 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 2.613633394241333 - sq_loss: 4.2510422645136714e-05 - tot_loss: 0.2041906743227173 - acc: 0.9488574537540805 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 2.60365891456604 - sq_loss: 4.0843046008376405e-05 - tot_loss: 0.203348161302074 - acc: 0.9494015233949945 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 2.6483705043792725 - sq_loss: 3.927775105694309e-05 - tot_loss: 0.1933927623258569 - acc: 0.9494015233949945 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 2.6690783500671387 - sq_loss: 3.778962854994461e-05 - tot_loss: 0.19655109584448383 - acc: 0.9500816104461371 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 2.659672975540161 - sq_loss: 3.6410678148968145e-05 - tot_loss: 0.1946221057864932 - acc: 0.9508977149075082 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 2.616438865661621 - sq_loss: 3.5118533560307696e-05 - tot_loss: 0.18841007254627584 - acc: 0.9513057671381937 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 2.6300368309020996 - sq_loss: 3.383289367775433e-05 - tot_loss: 0.18712706031692505 - acc: 0.9521218715995647 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 2.6646060943603516 - sq_loss: 3.262234531575814e-05 - tot_loss: 0.1769293867197348 - acc: 0.9529379760609358 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 2.639843225479126 - sq_loss: 3.148903851979412e-05 - tot_loss: 0.17664302467119342 - acc: 0.9536180631120783 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 2.6578452587127686 - sq_loss: 3.041293348360341e-05 - tot_loss: 0.17026701163831603 - acc: 0.9542981501632208 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 2.6136891841888428 - sq_loss: 2.938830220955424e-05 - tot_loss: 0.1740954634085483 - acc: 0.9555223068552775 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 2.628100872039795 - sq_loss: 2.8441529138945043e-05 - tot_loss: 0.16886386611508897 - acc: 0.9557943416757345 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 2.655087947845459 - sq_loss: 2.7532812964636832e-05 - tot_loss: 0.17329134609542507 - acc: 0.9567464635473341 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 2.6334352493286133 - sq_loss: 2.6680563678382896e-05 - tot_loss: 0.16635849269994196 - acc: 0.9576985854189336 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 2.6431117057800293 - sq_loss: 2.5865401767077856e-05 - tot_loss: 0.1623542952356729 - acc: 0.9583786724700761 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 1.6757276058197021 - sq_loss: 2.5080404157051817e-05 - tot_loss: 0.1584426816600626 - acc: 0.9589227421109902 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 1.2709126472473145 - sq_loss: 2.4347024009330198e-05 - tot_loss: 0.15456575881853496 - acc: 0.9596028291621328 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 1.2920198440551758 - sq_loss: 2.3643773602088913e-05 - tot_loss: 0.15759518079045165 - acc: 0.9602829162132753 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 1.3154630661010742 - sq_loss: 2.29851393669378e-05 - tot_loss: 0.15750235480226138 - acc: 0.9608269858541894 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 1.2980751991271973 - sq_loss: 2.234869316453114e-05 - tot_loss: 0.15843531825890977 - acc: 0.9613710554951034 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 1.3046019077301025 - sq_loss: 2.173853135900572e-05 - tot_loss: 0.1525712593191315 - acc: 0.9615070729053319 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 1.2869455814361572 - sq_loss: 2.115044480888173e-05 - tot_loss: 0.15054105762442305 - acc: 0.9623231773667029 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 1.9309539794921875 - sq_loss: 2.0587938706739806e-05 - tot_loss: 0.14545914734304688 - acc: 0.9627312295973884 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 2.620267152786255 - sq_loss: 2.0066816432517953e-05 - tot_loss: 0.14403688303411855 - acc: 0.9630032644178455 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 2.6193902492523193 - sq_loss: 1.9586761482059956e-05 - tot_loss: 0.14259932682404042 - acc: 0.9630032644178455 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 2.650009870529175 - sq_loss: 1.911778235808015e-05 - tot_loss: 0.14814836626931083 - acc: 0.9635473340587595 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 2.6360740661621094 - sq_loss: 1.866723869170528e-05 - tot_loss: 0.13847596020065112 - acc: 0.9643634385201306 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 2.6138439178466797 - sq_loss: 1.8237926269648597e-05 - tot_loss: 0.14156473671135927 - acc: 0.9643634385201306 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 3.035486936569214 - sq_loss: 1.783676452760119e-05 - tot_loss: 0.13759863821746876 - acc: 0.9646354733405876 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 3.1802597045898438 - sq_loss: 1.7437265341868624e-05 - tot_loss: 0.1387831743048764 - acc: 0.9651795429815017 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 3.1800360679626465 - sq_loss: 1.7050775568350218e-05 - tot_loss: 0.13624894916983976 - acc: 0.9658596300326442 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 3.345465660095215 - sq_loss: 1.668444565439131e-05 - tot_loss: 0.1320957013005568 - acc: 0.9661316648531012 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 3.197859525680542 - sq_loss: 1.6337113265763037e-05 - tot_loss: 0.13386425655460243 - acc: 0.9669477693144722 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 3.2358293533325195 - sq_loss: 1.6012230844353326e-05 - tot_loss: 0.12819939048679885 - acc: 0.9676278563656148 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 3.214646816253662 - sq_loss: 1.5700579751865007e-05 - tot_loss: 0.1299444687417406 - acc: 0.9676278563656148 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 2.445296287536621 - sq_loss: 1.5397728930111043e-05 - tot_loss: 0.12340550221509261 - acc: 0.9677638737758433 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 1.3162903785705566 - sq_loss: 1.5109867490536999e-05 - tot_loss: 0.12729607609264804 - acc: 0.9680359085963003 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 1.2962698936462402 - sq_loss: 1.4833780369372107e-05 - tot_loss: 0.1249558538867177 - acc: 0.9683079434167573 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 1.2981796264648438 - sq_loss: 1.4566086974809878e-05 - tot_loss: 0.12297292686099581 - acc: 0.9683079434167573 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 1.2968041896820068 - sq_loss: 1.4325682059279643e-05 - tot_loss: 0.1239193953832114 - acc: 0.9684439608269858 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 1.2793877124786377 - sq_loss: 1.408569369232282e-05 - tot_loss: 0.11952885622181952 - acc: 0.9691240478781284 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 1.294264316558838 - sq_loss: 1.3863235835742671e-05 - tot_loss: 0.1184243787101309 - acc: 0.9693960826985855 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 1.7525670528411865 - sq_loss: 1.3646382285514846e-05 - tot_loss: 0.11892703949385464 - acc: 0.9699401523394995 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 1.682023286819458 - sq_loss: 1.3424774806480855e-05 - tot_loss: 0.11788411330579152 - acc: 0.9702121871599565 - val_acc: 0.9569053274516457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 1.3088734149932861 - sq_loss: 1.320965475315461e-05 - tot_loss: 0.12386782274063535 - acc: 0.9707562568008705 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 1.2869815826416016 - sq_loss: 1.3006097105972003e-05 - tot_loss: 0.11304152338851736 - acc: 0.970620239390642 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 1.2888257503509521 - sq_loss: 1.2814859474019613e-05 - tot_loss: 0.11507115269046153 - acc: 0.970892274211099 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 1.2799363136291504 - sq_loss: 1.2641952707781456e-05 - tot_loss: 0.12327089720523077 - acc: 0.9710282916213275 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 1.2875683307647705 - sq_loss: 1.2467762644519098e-05 - tot_loss: 0.11444607965393061 - acc: 0.9715723612622416 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 1.2793478965759277 - sq_loss: 1.2303407856961712e-05 - tot_loss: 0.11673879828552458 - acc: 0.9721164309031556 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 1.2848782539367676 - sq_loss: 1.2145213986514136e-05 - tot_loss: 0.11270904272811322 - acc: 0.9722524483133841 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 1.2686073780059814 - sq_loss: 1.1994257874903269e-05 - tot_loss: 0.11148992068956431 - acc: 0.9726605005440696 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 1.3012375831604004 - sq_loss: 1.1845499102491885e-05 - tot_loss: 0.11184416863144975 - acc: 0.9727965179542981 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 1.2743284702301025 - sq_loss: 1.1699748938553967e-05 - tot_loss: 0.11260726685870281 - acc: 0.9730685527747551 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 1.2841699123382568 - sq_loss: 1.1562881809368264e-05 - tot_loss: 0.11169062036141497 - acc: 0.9732045701849836 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 1.2808103561401367 - sq_loss: 1.1427287972765043e-05 - tot_loss: 0.10454844637030192 - acc: 0.9737486398258978 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 1.2861642837524414 - sq_loss: 1.1293804163869936e-05 - tot_loss: 0.11099388542753275 - acc: 0.9741566920565833 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 1.2754578590393066 - sq_loss: 1.1155472748214379e-05 - tot_loss: 0.10624375850993317 - acc: 0.9745647442872688 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 1.294344425201416 - sq_loss: 1.102950864151353e-05 - tot_loss: 0.10712052178894282 - acc: 0.9747007616974973 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 1.2756717205047607 - sq_loss: 1.091515787265962e-05 - tot_loss: 0.10716934975017978 - acc: 0.9748367791077258 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 1.2867043018341064 - sq_loss: 1.0801264579640701e-05 - tot_loss: 0.11142177267254283 - acc: 0.9748367791077258 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 1.2985303401947021 - sq_loss: 1.0693995136534795e-05 - tot_loss: 0.1056455423217244 - acc: 0.9749727965179543 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 1.2879712581634521 - sq_loss: 1.0589553312456701e-05 - tot_loss: 0.10658399779265437 - acc: 0.9749727965179543 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 1.284226894378662 - sq_loss: 1.0487176041351631e-05 - tot_loss: 0.10743948959162708 - acc: 0.9752448313384113 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 1.2829036712646484 - sq_loss: 1.0388273040007334e-05 - tot_loss: 0.10338885997470015 - acc: 0.9755168661588683 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 1.270272970199585 - sq_loss: 1.0290672435075976e-05 - tot_loss: 0.10050344639827813 - acc: 0.9756528835690969 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 1.2891366481781006 - sq_loss: 1.0187298357777763e-05 - tot_loss: 0.10001925034787007 - acc: 0.9756528835690969 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 1.2779731750488281 - sq_loss: 1.009801053442061e-05 - tot_loss: 0.09911781884883908 - acc: 0.9757889009793254 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 1.2929110527038574 - sq_loss: 1.0009360266849399e-05 - tot_loss: 0.10754603474980229 - acc: 0.9759249183895539 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 1.2712178230285645 - sq_loss: 9.927188330038916e-06 - tot_loss: 0.10306789709183306 - acc: 0.9760609357997824 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 1.281830072402954 - sq_loss: 9.83975587587338e-06 - tot_loss: 0.09571375213344879 - acc: 0.9763329706202394 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 1.288238763809204 - sq_loss: 9.755924111232162e-06 - tot_loss: 0.1032950247694231 - acc: 0.9763329706202394 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 1.3049254417419434 - sq_loss: 9.677472917246632e-06 - tot_loss: 0.09935500072596426 - acc: 0.9764689880304679 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 1.3007326126098633 - sq_loss: 9.606461389921606e-06 - tot_loss: 0.10105617382714627 - acc: 0.9766050054406964 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 1.2816712856292725 - sq_loss: 9.536225661577191e-06 - tot_loss: 0.09991229174970329 - acc: 0.9771490750816104 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 1.300999402999878 - sq_loss: 9.46716590988217e-06 - tot_loss: 0.09836741959043138 - acc: 0.9768770402611534 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 1.28507399559021 - sq_loss: 9.395618690177798e-06 - tot_loss: 0.09922538532212855 - acc: 0.9772850924918389 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 1.2784063816070557 - sq_loss: 9.325559403805528e-06 - tot_loss: 0.09470231867457812 - acc: 0.9774211099020674 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 1.298743724822998 - sq_loss: 9.257269994122908e-06 - tot_loss: 0.09673466559591759 - acc: 0.9774211099020674 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 1.2921416759490967 - sq_loss: 9.193795449391473e-06 - tot_loss: 0.09829526831593682 - acc: 0.97810119695321 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 1.2813024520874023 - sq_loss: 9.134317224379629e-06 - tot_loss: 0.09345108209122088 - acc: 0.9782372143634385 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 1.2667236328125 - sq_loss: 9.076075002667494e-06 - tot_loss: 0.09769460108088879 - acc: 0.9783732317736671 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 1.2802603244781494 - sq_loss: 9.012885129777715e-06 - tot_loss: 0.09704342218780937 - acc: 0.9785092491838956 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 1.2732856273651123 - sq_loss: 8.95452467375435e-06 - tot_loss: 0.09964484063978318 - acc: 0.9791893362350381 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 1.2845022678375244 - sq_loss: 8.895306564227212e-06 - tot_loss: 0.09445502901900227 - acc: 0.9793253536452666 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 1.2981107234954834 - sq_loss: 8.839999281917699e-06 - tot_loss: 0.10168631049533161 - acc: 0.9794613710554951 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 1.2804632186889648 - sq_loss: 8.78211449162336e-06 - tot_loss: 0.09800080713424109 - acc: 0.9794613710554951 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 1.2793893814086914 - sq_loss: 8.727966815058608e-06 - tot_loss: 0.09851315449672882 - acc: 0.9793253536452666 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 1.2907166481018066 - sq_loss: 8.678010090079624e-06 - tot_loss: 0.09505118579833294 - acc: 0.9794613710554951 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 1.2806904315948486 - sq_loss: 8.62456454342464e-06 - tot_loss: 0.10127892102528335 - acc: 0.9791893362350381 - val_acc: 0.9592806243637597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 1.272984266281128 - sq_loss: 8.577537300880067e-06 - tot_loss: 0.09301329265596081 - acc: 0.9794613710554951 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 1.2850959300994873 - sq_loss: 8.52281300467439e-06 - tot_loss: 0.09547662969649906 - acc: 0.9795973884657236 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 1.2803444862365723 - sq_loss: 8.470853572362103e-06 - tot_loss: 0.0886829924820347 - acc: 0.9800054406964092 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 1.2849688529968262 - sq_loss: 8.425413398072124e-06 - tot_loss: 0.09503645191963983 - acc: 0.9801414581066377 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 1.2819106578826904 - sq_loss: 8.382793566852342e-06 - tot_loss: 0.08638911198921306 - acc: 0.9804134929270947 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 1.283376693725586 - sq_loss: 8.334859558090102e-06 - tot_loss: 0.08891739001135335 - acc: 0.9805495103373232 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 1.2811284065246582 - sq_loss: 8.290908226626925e-06 - tot_loss: 0.0918559115182731 - acc: 0.9806855277475517 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 1.299713134765625 - sq_loss: 8.245478966273367e-06 - tot_loss: 0.09360969223637028 - acc: 0.9808215451577802 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 1.2751469612121582 - sq_loss: 8.197204806492664e-06 - tot_loss: 0.09573876501259093 - acc: 0.9808215451577802 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 1.278369426727295 - sq_loss: 8.151937436196022e-06 - tot_loss: 0.0906414798841979 - acc: 0.9808215451577802 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 1.2814624309539795 - sq_loss: 8.114477168419398e-06 - tot_loss: 0.09248012776799897 - acc: 0.9812295973884657 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 1.282832145690918 - sq_loss: 8.076261110545602e-06 - tot_loss: 0.0910584124238909 - acc: 0.9812295973884657 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 1.2920420169830322 - sq_loss: 8.04145929578226e-06 - tot_loss: 0.08728640556037703 - acc: 0.9813656147986942 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 1.2841854095458984 - sq_loss: 8.003895345609635e-06 - tot_loss: 0.08821437965620049 - acc: 0.9812295973884657 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 1.2724707126617432 - sq_loss: 7.967684723553248e-06 - tot_loss: 0.08851604941864366 - acc: 0.9813656147986942 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 1.2830734252929688 - sq_loss: 7.93158687883988e-06 - tot_loss: 0.09231682711876488 - acc: 0.9812295973884657 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 1.296074628829956 - sq_loss: 7.891586392361205e-06 - tot_loss: 0.08744782999804812 - acc: 0.9813656147986942 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 1.2817940711975098 - sq_loss: 7.853243914723862e-06 - tot_loss: 0.08622959837666144 - acc: 0.9815016322089227 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 1.2836089134216309 - sq_loss: 7.816386641934514e-06 - tot_loss: 0.09028807621875501 - acc: 0.9815016322089227 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 1.2992534637451172 - sq_loss: 7.783439286868088e-06 - tot_loss: 0.08730068241357003 - acc: 0.9816376496191512 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 1.2906856536865234 - sq_loss: 7.750544682494365e-06 - tot_loss: 0.08825593395411602 - acc: 0.9815016322089227 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 1.2849130630493164 - sq_loss: 7.71681334299501e-06 - tot_loss: 0.0885000531052853 - acc: 0.9816376496191512 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 1.285114049911499 - sq_loss: 7.682165232836269e-06 - tot_loss: 0.08715155910461903 - acc: 0.9816376496191512 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 1.2943384647369385 - sq_loss: 7.654110959265381e-06 - tot_loss: 0.08701141715621219 - acc: 0.9817736670293797 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 1.282674789428711 - sq_loss: 7.624949830642436e-06 - tot_loss: 0.0879932972500157 - acc: 0.9817736670293797 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 1.2776098251342773 - sq_loss: 7.59661952542956e-06 - tot_loss: 0.08648742851305968 - acc: 0.9819096844396082 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 1.2763876914978027 - sq_loss: 7.5672901402867865e-06 - tot_loss: 0.09202516413376571 - acc: 0.9819096844396082 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 1.2775719165802002 - sq_loss: 7.537913916166872e-06 - tot_loss: 0.08405493645022943 - acc: 0.9820457018498367 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 1.2927882671356201 - sq_loss: 7.505122084694449e-06 - tot_loss: 0.08373814596295404 - acc: 0.9820457018498367 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 1.2832024097442627 - sq_loss: 7.473335699614836e-06 - tot_loss: 0.0880666665862293 - acc: 0.9821817192600653 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 1.2790307998657227 - sq_loss: 7.442482456099242e-06 - tot_loss: 0.08539646544175383 - acc: 0.9820457018498367 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 1.3005986213684082 - sq_loss: 7.4162658165732864e-06 - tot_loss: 0.08767665906761124 - acc: 0.9823177366702938 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 1.288602590560913 - sq_loss: 7.390285645669792e-06 - tot_loss: 0.08696901978909466 - acc: 0.9823177366702938 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 1.2878766059875488 - sq_loss: 7.361896223301301e-06 - tot_loss: 0.08799307361526587 - acc: 0.9823177366702938 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 1.289050579071045 - sq_loss: 7.333523171837442e-06 - tot_loss: 0.09031281052145346 - acc: 0.9823177366702938 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 1.2909328937530518 - sq_loss: 7.3058067755482625e-06 - tot_loss: 0.08795611419461125 - acc: 0.9823177366702938 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 1.2731478214263916 - sq_loss: 7.2817711043171585e-06 - tot_loss: 0.07983282898054256 - acc: 0.9823177366702938 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 1.2900793552398682 - sq_loss: 7.259366157086333e-06 - tot_loss: 0.08894827879955614 - acc: 0.9824537540805223 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 1.2890467643737793 - sq_loss: 7.231790277728578e-06 - tot_loss: 0.08838551840160846 - acc: 0.9827257889009793 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 1.272186517715454 - sq_loss: 7.204143003036734e-06 - tot_loss: 0.0877644462967524 - acc: 0.9829978237214363 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 1.2842769622802734 - sq_loss: 7.178785836003954e-06 - tot_loss: 0.08574906464775722 - acc: 0.9823177366702938 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 1.2770376205444336 - sq_loss: 7.150739747885382e-06 - tot_loss: 0.0843050706295898 - acc: 0.9831338411316648 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 1.2921233177185059 - sq_loss: 7.121233466023114e-06 - tot_loss: 0.08455945185288982 - acc: 0.9829978237214363 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 1.2782177925109863 - sq_loss: 7.094389275152935e-06 - tot_loss: 0.08915482619894988 - acc: 0.9829978237214363 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 1.2927098274230957 - sq_loss: 7.069018010952277e-06 - tot_loss: 0.08214662337611855 - acc: 0.9831338411316648 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 1.2745654582977295 - sq_loss: 7.044434823910706e-06 - tot_loss: 0.08207099622858038 - acc: 0.9829978237214363 - val_acc: 0.9609772650152698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 1.2632577419281006 - sq_loss: 7.0215014602581505e-06 - tot_loss: 0.082370062663081 - acc: 0.9831338411316648 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 1.279627799987793 - sq_loss: 6.998309345362941e-06 - tot_loss: 0.08216481733236947 - acc: 0.9831338411316648 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 1.296933650970459 - sq_loss: 6.97955920259119e-06 - tot_loss: 0.08420307715540787 - acc: 0.9831338411316648 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 1.280381441116333 - sq_loss: 6.956268407520838e-06 - tot_loss: 0.08577187720494805 - acc: 0.9831338411316648 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 1.2675364017486572 - sq_loss: 6.932219548616558e-06 - tot_loss: 0.08345445247424266 - acc: 0.9835418933623504 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 1.2899677753448486 - sq_loss: 6.910239335411461e-06 - tot_loss: 0.08079661890818102 - acc: 0.9836779107725789 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 1.2919762134552002 - sq_loss: 6.885143648105441e-06 - tot_loss: 0.07868468408887708 - acc: 0.9836779107725789 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 1.3014650344848633 - sq_loss: 6.865489012852777e-06 - tot_loss: 0.08777902570507479 - acc: 0.9836779107725789 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 1.2976653575897217 - sq_loss: 6.846033556939801e-06 - tot_loss: 0.08260312567090011 - acc: 0.9838139281828074 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 1.3164799213409424 - sq_loss: 6.821008355473168e-06 - tot_loss: 0.08750689855859406 - acc: 0.9840859630032645 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 1.317039966583252 - sq_loss: 6.797853984608082e-06 - tot_loss: 0.08269615023509402 - acc: 0.984221980413493 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 1.2894086837768555 - sq_loss: 6.779867817385821e-06 - tot_loss: 0.07875720368029704 - acc: 0.984221980413493 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 1.2892107963562012 - sq_loss: 6.761535132682184e-06 - tot_loss: 0.08065864692774483 - acc: 0.984221980413493 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 1.3186278343200684 - sq_loss: 6.741919150954345e-06 - tot_loss: 0.08475696717093228 - acc: 0.9846300326441785 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 1.3004610538482666 - sq_loss: 6.71891893944121e-06 - tot_loss: 0.08004362934393328 - acc: 0.9846300326441785 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 1.2809033393859863 - sq_loss: 6.696119271509815e-06 - tot_loss: 0.08331588550575475 - acc: 0.9846300326441785 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 1.2772667407989502 - sq_loss: 6.675963959423825e-06 - tot_loss: 0.08147131915340111 - acc: 0.9846300326441785 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 1.269604206085205 - sq_loss: 6.656060577370226e-06 - tot_loss: 0.08101035980623195 - acc: 0.9846300326441785 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 1.2753143310546875 - sq_loss: 6.635940735577606e-06 - tot_loss: 0.08016173192892495 - acc: 0.9846300326441785 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 1.2831053733825684 - sq_loss: 6.614054655074142e-06 - tot_loss: 0.08044304092060273 - acc: 0.9846300326441785 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 1.2774584293365479 - sq_loss: 6.595302238565637e-06 - tot_loss: 0.08227480362871376 - acc: 0.9846300326441785 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 1.263526439666748 - sq_loss: 6.578325610462343e-06 - tot_loss: 0.07829197880642269 - acc: 0.9846300326441785 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 1.3128821849822998 - sq_loss: 6.560740985150915e-06 - tot_loss: 0.07797327855159253 - acc: 0.9846300326441785 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 1.277543306350708 - sq_loss: 6.542959908983903e-06 - tot_loss: 0.08379373318418004 - acc: 0.9849020674646355 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 1.2945616245269775 - sq_loss: 6.525381195388036e-06 - tot_loss: 0.07976001720439996 - acc: 0.985038084874864 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 1.2681505680084229 - sq_loss: 6.503773420263315e-06 - tot_loss: 0.08247500293772703 - acc: 0.985038084874864 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 1.2906832695007324 - sq_loss: 6.4840396589715965e-06 - tot_loss: 0.0806302410095654 - acc: 0.985038084874864 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 1.2872800827026367 - sq_loss: 6.463621502916794e-06 - tot_loss: 0.08314038120208167 - acc: 0.9851741022850925 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 1.2882404327392578 - sq_loss: 6.445528924814425e-06 - tot_loss: 0.07918872582097691 - acc: 0.9851741022850925 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 1.2787983417510986 - sq_loss: 6.427936568798032e-06 - tot_loss: 0.07931787462819884 - acc: 0.9851741022850925 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 1.2860920429229736 - sq_loss: 6.4099131122929975e-06 - tot_loss: 0.07915530685582439 - acc: 0.9851741022850925 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 1.2900776863098145 - sq_loss: 6.392869636329124e-06 - tot_loss: 0.08235253158274602 - acc: 0.9851741022850925 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 1.290689468383789 - sq_loss: 6.375244538503466e-06 - tot_loss: 0.08385295333314602 - acc: 0.985310119695321 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 1.286269187927246 - sq_loss: 6.358076007018099e-06 - tot_loss: 0.07949807376921214 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 1.289226770401001 - sq_loss: 6.33972194918897e-06 - tot_loss: 0.08251666804911295 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 1.276881456375122 - sq_loss: 6.324688911263365e-06 - tot_loss: 0.07629450409447003 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 1.2742538452148438 - sq_loss: 6.304754151642555e-06 - tot_loss: 0.07980616191457557 - acc: 0.985582154515778 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 1.2835216522216797 - sq_loss: 6.2867966335034e-06 - tot_loss: 0.0814589426480623 - acc: 0.985582154515778 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 1.2828998565673828 - sq_loss: 6.2685057855560444e-06 - tot_loss: 0.08011091773777324 - acc: 0.985582154515778 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 1.2760224342346191 - sq_loss: 6.252616913116071e-06 - tot_loss: 0.0781538518750331 - acc: 0.985582154515778 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 1.2833235263824463 - sq_loss: 6.236179615370929e-06 - tot_loss: 0.07573383470467476 - acc: 0.985582154515778 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 1.29046630859375 - sq_loss: 6.2200692809710745e-06 - tot_loss: 0.07623156938415576 - acc: 0.985582154515778 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 1.2941679954528809 - sq_loss: 6.204309102031402e-06 - tot_loss: 0.07609648251083101 - acc: 0.985582154515778 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 1.3044352531433105 - sq_loss: 6.187000508361962e-06 - tot_loss: 0.07644031223652092 - acc: 0.985582154515778 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 1.3051304817199707 - sq_loss: 6.1704472500423435e-06 - tot_loss: 0.07908672560076724 - acc: 0.9857181719260065 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 1.2787597179412842 - sq_loss: 6.155031769594643e-06 - tot_loss: 0.0760580452845474 - acc: 0.9857181719260065 - val_acc: 0.9630132337970818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 1.2883009910583496 - sq_loss: 6.139029210316949e-06 - tot_loss: 0.08268839694096641 - acc: 0.9857181719260065 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 1.2770273685455322 - sq_loss: 6.126205789769301e-06 - tot_loss: 0.0782918478259873 - acc: 0.985582154515778 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 1.293074131011963 - sq_loss: 6.110470621933928e-06 - tot_loss: 0.07302382903705507 - acc: 0.9857181719260065 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 1.2870244979858398 - sq_loss: 6.091905106586637e-06 - tot_loss: 0.07617686856190886 - acc: 0.9857181719260065 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 1.278618574142456 - sq_loss: 6.076143108657561e-06 - tot_loss: 0.08414178253428162 - acc: 0.9857181719260065 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 1.2774534225463867 - sq_loss: 6.06061439611949e-06 - tot_loss: 0.07316004287502409 - acc: 0.9857181719260065 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 1.2840890884399414 - sq_loss: 6.0469756135717034e-06 - tot_loss: 0.076784715924056 - acc: 0.9857181719260065 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 1.2914369106292725 - sq_loss: 6.030393706168979e-06 - tot_loss: 0.0805208872331562 - acc: 0.9857181719260065 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 1.2757046222686768 - sq_loss: 6.017206942487974e-06 - tot_loss: 0.08322979412502818 - acc: 0.9857181719260065 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 1.288254737854004 - sq_loss: 6.005177056067623e-06 - tot_loss: 0.07473973918020249 - acc: 0.9857181719260065 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 1.2840454578399658 - sq_loss: 5.993261311232345e-06 - tot_loss: 0.07850044758484387 - acc: 0.985854189336235 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 1.2853212356567383 - sq_loss: 5.977486580377445e-06 - tot_loss: 0.07864314166194575 - acc: 0.9857181719260065 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 1.2731990814208984 - sq_loss: 5.9649582908605225e-06 - tot_loss: 0.0791442572023584 - acc: 0.985854189336235 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 1.267770528793335 - sq_loss: 5.947981208009878e-06 - tot_loss: 0.07662255638722115 - acc: 0.985854189336235 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 1.2973082065582275 - sq_loss: 5.932609838055214e-06 - tot_loss: 0.07514916546604766 - acc: 0.985854189336235 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 1.2829396724700928 - sq_loss: 5.919491741224192e-06 - tot_loss: 0.07373974772022862 - acc: 0.985854189336235 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 1.2706444263458252 - sq_loss: 5.904715180804487e-06 - tot_loss: 0.07905593882153639 - acc: 0.9859902067464635 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 1.2803540229797363 - sq_loss: 5.891423370485427e-06 - tot_loss: 0.071187830335397 - acc: 0.9859902067464635 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 1.2960319519042969 - sq_loss: 5.878779120394029e-06 - tot_loss: 0.07022686701429137 - acc: 0.9859902067464635 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 1.2948129177093506 - sq_loss: 5.861355020897463e-06 - tot_loss: 0.07691398981329556 - acc: 0.9859902067464635 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 1.2891879081726074 - sq_loss: 5.843568487762241e-06 - tot_loss: 0.07571828500455524 - acc: 0.986126224156692 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 1.2861180305480957 - sq_loss: 5.829729616380064e-06 - tot_loss: 0.08233161720911397 - acc: 0.986126224156692 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 1.2829155921936035 - sq_loss: 5.816421889903722e-06 - tot_loss: 0.07834454823587222 - acc: 0.9863982589771491 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 1.26969575881958 - sq_loss: 5.800845428893808e-06 - tot_loss: 0.07913023272150355 - acc: 0.9865342763873776 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 1.289818286895752 - sq_loss: 5.786258043372072e-06 - tot_loss: 0.07724918889220689 - acc: 0.9866702937976061 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 1.296996831893921 - sq_loss: 5.7746860875340644e-06 - tot_loss: 0.07588226998948144 - acc: 0.9866702937976061 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 1.287996768951416 - sq_loss: 5.760025032941485e-06 - tot_loss: 0.07975465987108166 - acc: 0.9866702937976061 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 1.2947020530700684 - sq_loss: 5.746327133238083e-06 - tot_loss: 0.08120966330040247 - acc: 0.9865342763873776 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 1.2704594135284424 - sq_loss: 5.734764272347093e-06 - tot_loss: 0.07654186750107783 - acc: 0.9866702937976061 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 1.2836310863494873 - sq_loss: 5.722068635805044e-06 - tot_loss: 0.07424895213591398 - acc: 0.9868063112078346 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 1.2982244491577148 - sq_loss: 5.70984684600262e-06 - tot_loss: 0.07676186973783672 - acc: 0.9868063112078346 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 1.2923023700714111 - sq_loss: 5.697866981790867e-06 - tot_loss: 0.07671562535982801 - acc: 0.9868063112078346 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 1.284966230392456 - sq_loss: 5.684580628440017e-06 - tot_loss: 0.0710497868004758 - acc: 0.9868063112078346 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 1.3094902038574219 - sq_loss: 5.674207841366297e-06 - tot_loss: 0.07354517694087903 - acc: 0.9868063112078346 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 1.2965056896209717 - sq_loss: 5.662916919391137e-06 - tot_loss: 0.08029819594790766 - acc: 0.9868063112078346 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 1.282470941543579 - sq_loss: 5.6500402934034355e-06 - tot_loss: 0.08284516517236185 - acc: 0.9866702937976061 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 1.3040714263916016 - sq_loss: 5.637066351482645e-06 - tot_loss: 0.07914892222575531 - acc: 0.9869423286180631 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 1.2959117889404297 - sq_loss: 5.6223152569145896e-06 - tot_loss: 0.08242526596132294 - acc: 0.9866702937976061 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 1.2954018115997314 - sq_loss: 5.608122592093423e-06 - tot_loss: 0.07346527532313019 - acc: 0.9869423286180631 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 1.296067476272583 - sq_loss: 5.594812591880327e-06 - tot_loss: 0.07516464034734227 - acc: 0.9868063112078346 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 1.2753913402557373 - sq_loss: 5.582407084148144e-06 - tot_loss: 0.0776716399356907 - acc: 0.9870783460282916 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 1.3144607543945312 - sq_loss: 5.569948370975908e-06 - tot_loss: 0.07512816875645356 - acc: 0.9868063112078346 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 1.271787166595459 - sq_loss: 5.556229552894365e-06 - tot_loss: 0.07357448299872615 - acc: 0.9870783460282916 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 1.2916903495788574 - sq_loss: 5.54526968699065e-06 - tot_loss: 0.07838503366676974 - acc: 0.9869423286180631 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 1.279798984527588 - sq_loss: 5.532650902750902e-06 - tot_loss: 0.07474640816365863 - acc: 0.9872143634385201 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 1.2972500324249268 - sq_loss: 5.521719685930293e-06 - tot_loss: 0.07532644044376724 - acc: 0.9870783460282916 - val_acc: 0.9647098744485918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 1.2891991138458252 - sq_loss: 5.510049504664494e-06 - tot_loss: 0.07550053940800083 - acc: 0.9873503808487486 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 1.2861781120300293 - sq_loss: 5.499305189005099e-06 - tot_loss: 0.07553989753908397 - acc: 0.9872143634385201 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 1.2988052368164062 - sq_loss: 5.487101134349359e-06 - tot_loss: 0.08543215162237416 - acc: 0.9872143634385201 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 1.2837865352630615 - sq_loss: 5.4768265727034304e-06 - tot_loss: 0.0769850088412376 - acc: 0.9873503808487486 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 1.286067008972168 - sq_loss: 5.462943136080867e-06 - tot_loss: 0.077602266876859 - acc: 0.9873503808487486 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 1.2782351970672607 - sq_loss: 5.451637207443127e-06 - tot_loss: 0.07634585900846602 - acc: 0.9873503808487486 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 1.3077962398529053 - sq_loss: 5.443696409201948e-06 - tot_loss: 0.07348456295794392 - acc: 0.9877584330794341 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 1.2594714164733887 - sq_loss: 5.433553724287776e-06 - tot_loss: 0.07569624054628576 - acc: 0.9874863982589771 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 1.2738473415374756 - sq_loss: 5.4217730394157115e-06 - tot_loss: 0.08197814681636828 - acc: 0.9877584330794341 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 1.2769787311553955 - sq_loss: 5.410477569967043e-06 - tot_loss: 0.07686428080688756 - acc: 0.9874863982589771 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 1.2827529907226562 - sq_loss: 5.398544544732431e-06 - tot_loss: 0.07080344593305199 - acc: 0.9876224156692056 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 1.2862305641174316 - sq_loss: 5.386703833210049e-06 - tot_loss: 0.07670381813416327 - acc: 0.9876224156692056 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 1.2742903232574463 - sq_loss: 5.376162789616501e-06 - tot_loss: 0.08271569429179948 - acc: 0.9876224156692056 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 1.2741880416870117 - sq_loss: 5.36360448677442e-06 - tot_loss: 0.07601335197552572 - acc: 0.9877584330794341 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 1.2837707996368408 - sq_loss: 5.350613719201647e-06 - tot_loss: 0.07251388402957915 - acc: 0.9880304678998912 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 1.2737395763397217 - sq_loss: 5.337832590157632e-06 - tot_loss: 0.07482682098320481 - acc: 0.9878944504896626 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 1.2749855518341064 - sq_loss: 5.327075086825062e-06 - tot_loss: 0.07563411904223116 - acc: 0.9877584330794341 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 1.2698566913604736 - sq_loss: 5.316183887771331e-06 - tot_loss: 0.07606312623284595 - acc: 0.9877584330794341 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 1.2914009094238281 - sq_loss: 5.306731964083156e-06 - tot_loss: 0.07305373203634957 - acc: 0.9878944504896626 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 1.2827119827270508 - sq_loss: 5.298421910993056e-06 - tot_loss: 0.07735613115052686 - acc: 0.9881664853101197 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 1.2835819721221924 - sq_loss: 5.2880395742249675e-06 - tot_loss: 0.07722934548388949 - acc: 0.9883025027203483 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 1.2834978103637695 - sq_loss: 5.2788032007811125e-06 - tot_loss: 0.07146499009265739 - acc: 0.9883025027203483 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 1.2903735637664795 - sq_loss: 5.267452706902986e-06 - tot_loss: 0.06842150166737682 - acc: 0.9878944504896626 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 1.2639050483703613 - sq_loss: 5.25772293258342e-06 - tot_loss: 0.07370793810874332 - acc: 0.9880304678998912 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 1.2904202938079834 - sq_loss: 5.247328317636857e-06 - tot_loss: 0.07486632728054232 - acc: 0.9883025027203483 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 1.2660105228424072 - sq_loss: 5.235575827100547e-06 - tot_loss: 0.07283971638935682 - acc: 0.9883025027203483 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 1.2874464988708496 - sq_loss: 5.224041615292663e-06 - tot_loss: 0.07997084809216304 - acc: 0.9880304678998912 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 1.2677907943725586 - sq_loss: 5.212270480114967e-06 - tot_loss: 0.07394233723399779 - acc: 0.9880304678998912 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 1.2944977283477783 - sq_loss: 5.1983242883579805e-06 - tot_loss: 0.07372464247803023 - acc: 0.9877584330794341 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 1.290583610534668 - sq_loss: 5.188126124267001e-06 - tot_loss: 0.07384652636130795 - acc: 0.9881664853101197 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 1.2897589206695557 - sq_loss: 5.181146207178244e-06 - tot_loss: 0.0784693847395026 - acc: 0.9880304678998912 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 1.2891273498535156 - sq_loss: 5.172776127437828e-06 - tot_loss: 0.07217881882170119 - acc: 0.9880304678998912 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 1.2850196361541748 - sq_loss: 5.159025477041723e-06 - tot_loss: 0.07676048424211501 - acc: 0.9880304678998912 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 1.2884166240692139 - sq_loss: 5.145530849404167e-06 - tot_loss: 0.07611117735476114 - acc: 0.9880304678998912 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 1.2992751598358154 - sq_loss: 5.136387699167244e-06 - tot_loss: 0.06827651546144509 - acc: 0.9880304678998912 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 1.2888305187225342 - sq_loss: 5.126266387378564e-06 - tot_loss: 0.06781201609086551 - acc: 0.9880304678998912 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 1.302605390548706 - sq_loss: 5.1162837735319044e-06 - tot_loss: 0.07397822311072133 - acc: 0.9880304678998912 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 1.2860486507415771 - sq_loss: 5.1053689276159275e-06 - tot_loss: 0.07374663686961114 - acc: 0.9881664853101197 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 1.2656397819519043 - sq_loss: 5.09428946315893e-06 - tot_loss: 0.07100941528088711 - acc: 0.9881664853101197 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 1.289921760559082 - sq_loss: 5.086665169073967e-06 - tot_loss: 0.07379078444531828 - acc: 0.9881664853101197 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 1.2798330783843994 - sq_loss: 5.076242814539e-06 - tot_loss: 0.08249193482075867 - acc: 0.9881664853101197 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 1.2715508937835693 - sq_loss: 5.065724053565646e-06 - tot_loss: 0.08508187297900349 - acc: 0.9881664853101197 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 1.273822546005249 - sq_loss: 5.055622295913054e-06 - tot_loss: 0.07186688185311496 - acc: 0.9880304678998912 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 1.2724318504333496 - sq_loss: 5.0446806199033745e-06 - tot_loss: 0.07134417444430952 - acc: 0.9881664853101197 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 1.2901864051818848 - sq_loss: 5.032565240981057e-06 - tot_loss: 0.07172619162840377 - acc: 0.9881664853101197 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 1.2793593406677246 - sq_loss: 5.021212928113528e-06 - tot_loss: 0.07460393639723506 - acc: 0.9881664853101197 - val_acc: 0.9650492025788938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 1.2865467071533203 - sq_loss: 5.014281668991316e-06 - tot_loss: 0.07788025033798007 - acc: 0.9881664853101197 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 1.2720415592193604 - sq_loss: 5.006072569813114e-06 - tot_loss: 0.07639558342260244 - acc: 0.9880304678998912 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 1.2914531230926514 - sq_loss: 4.998195890948409e-06 - tot_loss: 0.07782583007674759 - acc: 0.9880304678998912 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 1.3087260723114014 - sq_loss: 4.989533863408724e-06 - tot_loss: 0.07375554346627666 - acc: 0.9884385201305768 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 1.2804338932037354 - sq_loss: 4.98081089972402e-06 - tot_loss: 0.07120873097780134 - acc: 0.9884385201305768 - val_acc: 0.9653885307091958\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 1.3006582260131836 - sq_loss: 4.971609087078832e-06 - tot_loss: 0.06914813858655577 - acc: 0.9884385201305768 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 1.2809505462646484 - sq_loss: 4.964857453160221e-06 - tot_loss: 0.07058951778295253 - acc: 0.9884385201305768 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 1.2744429111480713 - sq_loss: 4.955264557793271e-06 - tot_loss: 0.06783866125442373 - acc: 0.9884385201305768 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 1.2851817607879639 - sq_loss: 4.9473710532765836e-06 - tot_loss: 0.07280611810592674 - acc: 0.9884385201305768 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 1.3216919898986816 - sq_loss: 4.939541668136371e-06 - tot_loss: 0.07342421332127458 - acc: 0.9884385201305768 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 1.310744047164917 - sq_loss: 4.93032257509185e-06 - tot_loss: 0.07488156538336099 - acc: 0.9884385201305768 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 1.3105192184448242 - sq_loss: 4.921317668049596e-06 - tot_loss: 0.07903060291006625 - acc: 0.9885745375408053 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 1.2908151149749756 - sq_loss: 4.912816621072125e-06 - tot_loss: 0.07604265348176753 - acc: 0.9885745375408053 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 1.2703444957733154 - sq_loss: 4.9029963520297315e-06 - tot_loss: 0.07395282102625345 - acc: 0.9885745375408053 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 1.2887744903564453 - sq_loss: 4.894938683719374e-06 - tot_loss: 0.07087539774576612 - acc: 0.9885745375408053 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 1.2652592658996582 - sq_loss: 4.888177500106394e-06 - tot_loss: 0.07185985714415466 - acc: 0.9885745375408053 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 1.2856576442718506 - sq_loss: 4.879711923422292e-06 - tot_loss: 0.07341059065708322 - acc: 0.9887105549510338 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 1.2662453651428223 - sq_loss: 4.869885287916986e-06 - tot_loss: 0.07736873959919777 - acc: 0.9885745375408053 - val_acc: 0.9650492025788938\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 1.2745327949523926 - sq_loss: 4.858176453126362e-06 - tot_loss: 0.08295237306045067 - acc: 0.9887105549510338 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 1.2971041202545166 - sq_loss: 4.849219294555951e-06 - tot_loss: 0.07919060338093686 - acc: 0.9887105549510338 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 1.2687671184539795 - sq_loss: 4.838427685172064e-06 - tot_loss: 0.076184577393974 - acc: 0.9887105549510338 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 1.2758028507232666 - sq_loss: 4.82744735563756e-06 - tot_loss: 0.07853647680911635 - acc: 0.9887105549510338 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 1.2832889556884766 - sq_loss: 4.820702088181861e-06 - tot_loss: 0.069140967344822 - acc: 0.9888465723612623 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 1.2726361751556396 - sq_loss: 4.812009592569666e-06 - tot_loss: 0.07502967114362136 - acc: 0.9888465723612623 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 1.310166597366333 - sq_loss: 4.804247055290034e-06 - tot_loss: 0.07623903535812815 - acc: 0.9888465723612623 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 1.264638900756836 - sq_loss: 4.796168013854185e-06 - tot_loss: 0.07382840966025128 - acc: 0.9888465723612623 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 1.273165225982666 - sq_loss: 4.788081241713371e-06 - tot_loss: 0.07464312117206617 - acc: 0.9888465723612623 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 1.2872309684753418 - sq_loss: 4.780727067554835e-06 - tot_loss: 0.07440265546499703 - acc: 0.9888465723612623 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 1.2657184600830078 - sq_loss: 4.770424766320502e-06 - tot_loss: 0.07319246920715372 - acc: 0.9889825897714908 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 1.2994179725646973 - sq_loss: 4.7617027121305e-06 - tot_loss: 0.07432797430390536 - acc: 0.9888465723612623 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 1.287442922592163 - sq_loss: 4.752507720695576e-06 - tot_loss: 0.07481478438034017 - acc: 0.9888465723612623 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 1.267845630645752 - sq_loss: 4.746265858557308e-06 - tot_loss: 0.06850114879026492 - acc: 0.9887105549510338 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 1.283128261566162 - sq_loss: 4.7389144128828775e-06 - tot_loss: 0.07245277616097923 - acc: 0.9888465723612623 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 1.2701795101165771 - sq_loss: 4.730626187665621e-06 - tot_loss: 0.0762662073393674 - acc: 0.9888465723612623 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 1.2735331058502197 - sq_loss: 4.723020992969396e-06 - tot_loss: 0.08101602958614862 - acc: 0.9888465723612623 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 1.2901935577392578 - sq_loss: 4.716275270766346e-06 - tot_loss: 0.07575130335598601 - acc: 0.9888465723612623 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 1.288832426071167 - sq_loss: 4.707772404799471e-06 - tot_loss: 0.0718937473589083 - acc: 0.9888465723612623 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 1.2835042476654053 - sq_loss: 4.698852080764482e-06 - tot_loss: 0.07264084944765159 - acc: 0.9889825897714908 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 1.272731065750122 - sq_loss: 4.68781672680052e-06 - tot_loss: 0.08004690579552154 - acc: 0.9891186071817193 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 1.2909140586853027 - sq_loss: 4.680481652030721e-06 - tot_loss: 0.0706864131728242 - acc: 0.9891186071817193 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 1.2866380214691162 - sq_loss: 4.670941962103825e-06 - tot_loss: 0.07119068433438791 - acc: 0.9891186071817193 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 1.2797036170959473 - sq_loss: 4.662554601964075e-06 - tot_loss: 0.07243402243497421 - acc: 0.9893906420021763 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 1.2866132259368896 - sq_loss: 4.654315034713363e-06 - tot_loss: 0.07523093211984566 - acc: 0.9893906420021763 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 1.2813403606414795 - sq_loss: 4.6468840082525276e-06 - tot_loss: 0.07319855436767853 - acc: 0.9892546245919478 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 1.2829358577728271 - sq_loss: 4.639456619770499e-06 - tot_loss: 0.06915678854454654 - acc: 0.9896626768226333 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 1.2777361869812012 - sq_loss: 4.631553110812092e-06 - tot_loss: 0.07028904128769575 - acc: 0.9896626768226333 - val_acc: 0.9664065151001018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 1.2827303409576416 - sq_loss: 4.622263986675534e-06 - tot_loss: 0.06925009054339526 - acc: 0.9896626768226333 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 1.295292854309082 - sq_loss: 4.614563295035623e-06 - tot_loss: 0.07828225780497533 - acc: 0.9897986942328618 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 1.287093162536621 - sq_loss: 4.6059899432293605e-06 - tot_loss: 0.07154171207887394 - acc: 0.9897986942328618 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 1.290116310119629 - sq_loss: 4.598641226039035e-06 - tot_loss: 0.074808887046661 - acc: 0.9897986942328618 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 1.2615001201629639 - sq_loss: 4.591425295075169e-06 - tot_loss: 0.07466984073068872 - acc: 0.9897986942328618 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 1.2751505374908447 - sq_loss: 4.583942882163683e-06 - tot_loss: 0.0718108195933862 - acc: 0.9900707290533188 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 1.2815299034118652 - sq_loss: 4.575262209982611e-06 - tot_loss: 0.0746254768555481 - acc: 0.9897986942328618 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 1.2928967475891113 - sq_loss: 4.568670647131512e-06 - tot_loss: 0.07236498837704097 - acc: 0.9899347116430903 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 1.2660510540008545 - sq_loss: 4.561097284749849e-06 - tot_loss: 0.07658119184328349 - acc: 0.9897986942328618 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 1.2976257801055908 - sq_loss: 4.555376108328346e-06 - tot_loss: 0.08497048037861354 - acc: 0.9899347116430903 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 1.2816047668457031 - sq_loss: 4.54785231340793e-06 - tot_loss: 0.06977520847729757 - acc: 0.9897986942328618 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 1.2787666320800781 - sq_loss: 4.538969733403064e-06 - tot_loss: 0.07234230086332083 - acc: 0.9896626768226333 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 1.2766330242156982 - sq_loss: 4.530699698079843e-06 - tot_loss: 0.07582983142502364 - acc: 0.9896626768226333 - val_acc: 0.9657278588394977\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 1.294863224029541 - sq_loss: 4.521718892647186e-06 - tot_loss: 0.07862128249820621 - acc: 0.9897986942328618 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 1.2886974811553955 - sq_loss: 4.513794010563288e-06 - tot_loss: 0.07178214098765956 - acc: 0.9897986942328618 - val_acc: 0.9660671869697998\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 1.28177809715271 - sq_loss: 4.503842774283839e-06 - tot_loss: 0.06930409717233665 - acc: 0.9899347116430903 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 1.2789342403411865 - sq_loss: 4.497855115914717e-06 - tot_loss: 0.07627785062117987 - acc: 0.9902067464635473 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 1.281254529953003 - sq_loss: 4.491298113862285e-06 - tot_loss: 0.06903059856540494 - acc: 0.9900707290533188 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 1.2752134799957275 - sq_loss: 4.484333658183459e-06 - tot_loss: 0.071918284712293 - acc: 0.9899347116430903 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 1.2672429084777832 - sq_loss: 4.4789690036850516e-06 - tot_loss: 0.07149154408001479 - acc: 0.9900707290533188 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 1.2963662147521973 - sq_loss: 4.473900844459422e-06 - tot_loss: 0.06980976987649434 - acc: 0.9899347116430903 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 1.2791595458984375 - sq_loss: 4.466831796889892e-06 - tot_loss: 0.07228725745808973 - acc: 0.9896626768226333 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 1.2900359630584717 - sq_loss: 4.4595112740353215e-06 - tot_loss: 0.07198014686800747 - acc: 0.9899347116430903 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 1.279099702835083 - sq_loss: 4.454061581782298e-06 - tot_loss: 0.07732676181789877 - acc: 0.9897986942328618 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 1.2956833839416504 - sq_loss: 4.447027549758786e-06 - tot_loss: 0.0674677013314966 - acc: 0.9900707290533188 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 1.2905046939849854 - sq_loss: 4.439509666553931e-06 - tot_loss: 0.07488993947471378 - acc: 0.9900707290533188 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 1.286651849746704 - sq_loss: 4.431907200341811e-06 - tot_loss: 0.06556384372095003 - acc: 0.9900707290533188 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 1.2966198921203613 - sq_loss: 4.424841790751088e-06 - tot_loss: 0.07023342033004276 - acc: 0.9900707290533188 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 1.283174753189087 - sq_loss: 4.419058768689865e-06 - tot_loss: 0.06877923323785495 - acc: 0.9900707290533188 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 1.2697374820709229 - sq_loss: 4.410451310832286e-06 - tot_loss: 0.07088712120151541 - acc: 0.9900707290533188 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 1.2695157527923584 - sq_loss: 4.403236289363122e-06 - tot_loss: 0.07304421603545919 - acc: 0.9900707290533188 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 1.2753612995147705 - sq_loss: 4.396855729282834e-06 - tot_loss: 0.0693962431209112 - acc: 0.9900707290533188 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 1.2961225509643555 - sq_loss: 4.3887589527003e-06 - tot_loss: 0.07236917669043486 - acc: 0.9900707290533188 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 1.2812023162841797 - sq_loss: 4.381572580314241e-06 - tot_loss: 0.07216915027255943 - acc: 0.9900707290533188 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 1.2829797267913818 - sq_loss: 4.37559538113419e-06 - tot_loss: 0.07290238757924783 - acc: 0.9900707290533188 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 1.296766996383667 - sq_loss: 4.367880592326401e-06 - tot_loss: 0.07871937015714892 - acc: 0.9900707290533188 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 1.285754919052124 - sq_loss: 4.362138497526757e-06 - tot_loss: 0.07557619299626595 - acc: 0.9900707290533188 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 1.2833435535430908 - sq_loss: 4.353519670985406e-06 - tot_loss: 0.07690288130888945 - acc: 0.9900707290533188 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 1.3056674003601074 - sq_loss: 4.34657567893737e-06 - tot_loss: 0.07210073914492021 - acc: 0.9900707290533188 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 1.2873139381408691 - sq_loss: 4.339531187724788e-06 - tot_loss: 0.07166501393555968 - acc: 0.9900707290533188 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 1.3014678955078125 - sq_loss: 4.332800017436966e-06 - tot_loss: 0.06935241492650235 - acc: 0.9900707290533188 - val_acc: 0.9681031557516118\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 1.315675973892212 - sq_loss: 4.324754627305083e-06 - tot_loss: 0.07169477599190799 - acc: 0.9900707290533188 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 1.2909598350524902 - sq_loss: 4.318286300986074e-06 - tot_loss: 0.07112733191041265 - acc: 0.9900707290533188 - val_acc: 0.9681031557516118\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 1.2878212928771973 - sq_loss: 4.312545115681132e-06 - tot_loss: 0.06837002824671501 - acc: 0.9900707290533188 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 1.2762482166290283 - sq_loss: 4.304703907109797e-06 - tot_loss: 0.07180724814480577 - acc: 0.9900707290533188 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 1.2863500118255615 - sq_loss: 4.2987062442989554e-06 - tot_loss: 0.06973458672008803 - acc: 0.9900707290533188 - val_acc: 0.9674244994910078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 1.275484323501587 - sq_loss: 4.292160156182945e-06 - tot_loss: 0.06541956596296572 - acc: 0.9900707290533188 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 1.2812838554382324 - sq_loss: 4.285197519493522e-06 - tot_loss: 0.06919444047136203 - acc: 0.9900707290533188 - val_acc: 0.9681031557516118\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 1.2908968925476074 - sq_loss: 4.276742856745841e-06 - tot_loss: 0.07121937693888292 - acc: 0.9902067464635473 - val_acc: 0.9681031557516118\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 1.2898802757263184 - sq_loss: 4.270318186172517e-06 - tot_loss: 0.06924153370751007 - acc: 0.9902067464635473 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 1.2868432998657227 - sq_loss: 4.2632045733626e-06 - tot_loss: 0.07145273140045738 - acc: 0.9902067464635473 - val_acc: 0.9681031557516118\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 1.2767341136932373 - sq_loss: 4.257227828929899e-06 - tot_loss: 0.06629947965726402 - acc: 0.9903427638737758 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 1.2707939147949219 - sq_loss: 4.2504857447056565e-06 - tot_loss: 0.07107460358070306 - acc: 0.9900707290533188 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 1.2817683219909668 - sq_loss: 4.242441718815826e-06 - tot_loss: 0.0693454875158448 - acc: 0.9902067464635473 - val_acc: 0.9681031557516118\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 1.286531925201416 - sq_loss: 4.237014763930347e-06 - tot_loss: 0.07027188996487332 - acc: 0.9902067464635473 - val_acc: 0.9677638276213099\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 1.2719800472259521 - sq_loss: 4.230059857945889e-06 - tot_loss: 0.06810710216577931 - acc: 0.9903427638737758 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 1.276930809020996 - sq_loss: 4.22225775764673e-06 - tot_loss: 0.07410290883619552 - acc: 0.9904787812840044 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 1.302720069885254 - sq_loss: 4.215346507407958e-06 - tot_loss: 0.06732687609141585 - acc: 0.9903427638737758 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 1.2726719379425049 - sq_loss: 4.20926880906336e-06 - tot_loss: 0.06459620008120304 - acc: 0.9904787812840044 - val_acc: 0.9664065151001018\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 1.272369384765625 - sq_loss: 4.202491254545748e-06 - tot_loss: 0.07377106326568672 - acc: 0.9904787812840044 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 1.279308795928955 - sq_loss: 4.199043360131327e-06 - tot_loss: 0.06892887630092481 - acc: 0.9904787812840044 - val_acc: 0.9667458432304038\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 1.260467767715454 - sq_loss: 4.1925568439182825e-06 - tot_loss: 0.07683228454262014 - acc: 0.9904787812840044 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 1.299710750579834 - sq_loss: 4.188041657471331e-06 - tot_loss: 0.07245091743006782 - acc: 0.9903427638737758 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 1.2832658290863037 - sq_loss: 4.1844423321890645e-06 - tot_loss: 0.07098374377362049 - acc: 0.9904787812840044 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 1.2790133953094482 - sq_loss: 4.17787896367372e-06 - tot_loss: 0.07573871911717767 - acc: 0.9906147986942329 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 1.2651891708374023 - sq_loss: 4.171886303083738e-06 - tot_loss: 0.06812884463789359 - acc: 0.9906147986942329 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 1.2942442893981934 - sq_loss: 4.1663861338747665e-06 - tot_loss: 0.07528083874924363 - acc: 0.9906147986942329 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 1.2839829921722412 - sq_loss: 4.160580374445999e-06 - tot_loss: 0.072149889258311 - acc: 0.9906147986942329 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 1.2818207740783691 - sq_loss: 4.153097506787162e-06 - tot_loss: 0.07567806732815718 - acc: 0.9908868335146899 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 1.2654058933258057 - sq_loss: 4.146574610786047e-06 - tot_loss: 0.07323760644476174 - acc: 0.9907508161044614 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 1.2848789691925049 - sq_loss: 4.140135843044845e-06 - tot_loss: 0.07016217325263874 - acc: 0.9907508161044614 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 1.2931110858917236 - sq_loss: 4.1333742046845146e-06 - tot_loss: 0.07256482428520172 - acc: 0.9908868335146899 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 1.27009916305542 - sq_loss: 4.1267576307291165e-06 - tot_loss: 0.0679089787254803 - acc: 0.9907508161044614 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 1.2912421226501465 - sq_loss: 4.1194316509063356e-06 - tot_loss: 0.07358690419605907 - acc: 0.9907508161044614 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 1.2774989604949951 - sq_loss: 4.112383976462297e-06 - tot_loss: 0.07141795913121385 - acc: 0.9908868335146899 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 1.2882282733917236 - sq_loss: 4.1062785385292955e-06 - tot_loss: 0.07553842245263276 - acc: 0.9910228509249184 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 1.2717926502227783 - sq_loss: 4.100060323253274e-06 - tot_loss: 0.0692794137805155 - acc: 0.9908868335146899 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 1.2726612091064453 - sq_loss: 4.095214535482228e-06 - tot_loss: 0.0741377450875369 - acc: 0.9910228509249184 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 1.2719151973724365 - sq_loss: 4.090822585567366e-06 - tot_loss: 0.07265864666543465 - acc: 0.9907508161044614 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 1.2744731903076172 - sq_loss: 4.085446107637836e-06 - tot_loss: 0.06886520635408111 - acc: 0.9907508161044614 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 1.278618335723877 - sq_loss: 4.0812692532199435e-06 - tot_loss: 0.06838607313478384 - acc: 0.9907508161044614 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 1.2771544456481934 - sq_loss: 4.0754857764113694e-06 - tot_loss: 0.06567072964911347 - acc: 0.9907508161044614 - val_acc: 0.9674244994910078\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 1.3163611888885498 - sq_loss: 4.069313945365138e-06 - tot_loss: 0.07251415212566314 - acc: 0.9910228509249184 - val_acc: 0.9670851713607058\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 1.291461706161499 - sq_loss: 4.06215349357808e-06 - tot_loss: 0.06902592912783945 - acc: 0.9910228509249184 - val_acc: 0.9670851713607058\n",
      "CR_1 = 0.16759738116197184   CR_2 = 0.1667972504806152\n",
      "/home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 5\n",
    "alpha = 1\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "\n",
    "#alpha1 = alpha2 = alpha3 = alpha4 = alpha5 = alpha6 = alpha7 = alpha8 = alpha9 = alpha10 = alpha\n",
    "#for rank in (35,): #(25,30,35)(100,180,220,260,300,340,380)(20,60,100,140,180,220,260,300,340,380)\n",
    "#    for tau in (400,500): #(300,400,500)(10,50,100,200,300)(10,50,100,200,300)\n",
    "#        for gamma in (0.5,0.8,2): #(0.5,0.8,2)(0.5,0.8)(0.5,1,1.5,2,3)\n",
    "            #gamma1 = gamma2 = gamma3 = gamma4 = gamma5 = gamma\n",
    "#            for rho in (0.5,0.8,2): #(0.5,0.8)(1,2)\n",
    "                #rho1 = rho2 = rho3 = rho4 = rho5= rho\n",
    "#                for alpha in (0.5,1,1.5,2):\n",
    "#                    print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "                    #print('Compression Ratio', ((1024*28*28+10*1024+(8*(rank)+32*np.square(rank))*2)/(1024*28*28+10*1024+1024*1024*2)), (8*(rank)+32*np.square(rank))*2/(1024*1024*2))\n",
    "        \n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    d0 = 561 #561 =3*11*17\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 6 \n",
    "\n",
    "    W1 = 0.2*init.xavier_normal_(torch.empty(d1, d0, device=device), gain=1.0)\n",
    "    #W1 = 0.01*torch.randn(d1, d0, device=device)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    W2 = 0.2*init.xavier_normal_(torch.empty(d2, d1, device=device), gain=1.0)\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles ‘factors’, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    W3 = 0.2*init.xavier_normal_(torch.empty(d3, d2, device=device), gain=1.0)\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    W4 = 0.2*init.xavier_normal_(torch.empty(d4, d3, device=device), gain=1.0)\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "\n",
    "    W5 = 0.2*init.xavier_normal_(torch.empty(d5, d4, device=device), gain=1.0)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = U5 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V5 = (y_one_hot + gamma*U5 + alpha*V5)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U5 = (gamma*V5 + rho*(torch.mm(W5,V4) + b5.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W5, b5 = updateWb_org(U5,V4,W5,b5,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b5.repeat(1, N), W5, a4_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b5.repeat(1, N_test), W5, a4_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V5,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,U5,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4\n",
    "\n",
    "    CR_1=((total_variabels)+(d4*d5))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#this postion to add new row into existing table\n",
    "    #df=pd.read_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "    #new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "    #           'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "    #           'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1], 'seed':seed} \n",
    "    #df=df.append(new_row,ignore_index=True)\n",
    "    #df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"XavierNormal_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895c825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30f34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
