{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccc0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6113fe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 5 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 1.48870849609375 - sq_loss: 661.6954956054688 - tot_loss: 1023.9433062161843 - acc: 0.17995103373231774 - val_acc: 0.1866304716661011\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 1.2653183937072754 - sq_loss: 294.0868225097656 - tot_loss: 475.9661811636761 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 1.2622356414794922 - sq_loss: 160.82797241210938 - tot_loss: 261.37832728773355 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 1.2444887161254883 - sq_loss: 87.1128158569336 - tot_loss: 147.4463349059224 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 1.2362642288208008 - sq_loss: 46.864768981933594 - tot_loss: 85.90754327829927 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 1.250316858291626 - sq_loss: 25.152524948120117 - tot_loss: 52.451280190609396 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 1.233778715133667 - sq_loss: 13.509041786193848 - tot_loss: 34.060235478915274 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 1.2563419342041016 - sq_loss: 7.2772135734558105 - tot_loss: 23.753542995080352 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 1.2353925704956055 - sq_loss: 3.939967632293701 - tot_loss: 17.819368972908705 - acc: 0.19069640914036998 - val_acc: 0.1849338310145911\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 1.2180895805358887 - sq_loss: 2.1485750675201416 - tot_loss: 14.260277705034241 - acc: 0.3180087051142546 - val_acc: 0.2813030200203597\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 1.2339832782745361 - sq_loss: 1.183120846748352 - tot_loss: 12.003410993842408 - acc: 0.4466811751904244 - val_acc: 0.41126569392602647\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 1.2271919250488281 - sq_loss: 0.6598246693611145 - tot_loss: 10.47327873390168 - acc: 0.5085690968443961 - val_acc: 0.47539871055310484\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 1.2186472415924072 - sq_loss: 0.3740192651748657 - tot_loss: 9.356231700163335 - acc: 0.528563656147987 - val_acc: 0.5147607736681371\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 1.2276270389556885 - sq_loss: 0.216374471783638 - tot_loss: 8.479189865291119 - acc: 0.5378128400435256 - val_acc: 0.5279945707499152\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 1.225712537765503 - sq_loss: 0.12833745777606964 - tot_loss: 7.74329976469744 - acc: 0.5420293797606094 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 1.2336955070495605 - sq_loss: 0.07841715961694717 - tot_loss: 7.103591864462942 - acc: 0.544885745375408 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 1.2332148551940918 - sq_loss: 0.049587592482566833 - tot_loss: 6.535302218399011 - acc: 0.5471980413492927 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 1.227004051208496 - sq_loss: 0.0325760580599308 - tot_loss: 6.015790918609127 - acc: 0.5516866158868335 - val_acc: 0.5324058364438412\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 1.2277474403381348 - sq_loss: 0.02228744886815548 - tot_loss: 5.550345285097137 - acc: 0.573721436343852 - val_acc: 0.5453003053953173\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 1.2381596565246582 - sq_loss: 0.015890659764409065 - tot_loss: 5.117901538207661 - acc: 0.5992927094668118 - val_acc: 0.5700712589073634\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 1.2144749164581299 - sq_loss: 0.011789589188992977 - tot_loss: 4.735791047743987 - acc: 0.6251360174102285 - val_acc: 0.5941635561588056\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 1.2299129962921143 - sq_loss: 0.009074152447283268 - tot_loss: 4.3858036994352005 - acc: 0.6478509249183896 - val_acc: 0.6090939938920936\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 1.225928544998169 - sq_loss: 0.007213648408651352 - tot_loss: 4.059058680519229 - acc: 0.6726060935799782 - val_acc: 0.6226671191041737\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 1.2458784580230713 - sq_loss: 0.005893180146813393 - tot_loss: 3.7712720676208846 - acc: 0.6866158868335147 - val_acc: 0.6294536817102138\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 1.2435548305511475 - sq_loss: 0.004923727363348007 - tot_loss: 3.510497904906515 - acc: 0.6958650707290533 - val_acc: 0.6396335256192739\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 1.219115972518921 - sq_loss: 0.0041894312016665936 - tot_loss: 3.2738323739613406 - acc: 0.7044341675734495 - val_acc: 0.6515100101798439\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 1.228910207748413 - sq_loss: 0.0036171460524201393 - tot_loss: 3.0508476926916046 - acc: 0.713683351468988 - val_acc: 0.6623685103495079\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 1.2352607250213623 - sq_loss: 0.003159557469189167 - tot_loss: 2.8579436458676355 - acc: 0.719260065288357 - val_acc: 0.6762809636918901\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 1.2346315383911133 - sq_loss: 0.0027860181871801615 - tot_loss: 2.681056553381495 - acc: 0.7253808487486398 - val_acc: 0.6854428232100441\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 1.235919713973999 - sq_loss: 0.0024755303747951984 - tot_loss: 2.511940876385779 - acc: 0.7331338411316648 - val_acc: 0.6929080420766881\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 1.222707986831665 - sq_loss: 0.0022137844935059547 - tot_loss: 2.3568007223002496 - acc: 0.7404787812840044 - val_acc: 0.7024092297251442\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 1.2300522327423096 - sq_loss: 0.001990091986954212 - tot_loss: 2.214227515818493 - acc: 0.7493199129488575 - val_acc: 0.7095351204614863\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 1.22845458984375 - sq_loss: 0.0017975160153582692 - tot_loss: 2.0873117102964898 - acc: 0.7591131664853101 - val_acc: 0.7176789955887343\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 1.2436013221740723 - sq_loss: 0.0016294763190671802 - tot_loss: 1.9674833711687825 - acc: 0.7674102285092492 - val_acc: 0.7295554801493044\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 1.235743522644043 - sq_loss: 0.0014820363139733672 - tot_loss: 1.8580017722488265 - acc: 0.7748911860718172 - val_acc: 0.7380386834068544\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 1.2341020107269287 - sq_loss: 0.0013522445224225521 - tot_loss: 1.752329772025405 - acc: 0.7838683351468988 - val_acc: 0.7468612147947065\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 1.2372853755950928 - sq_loss: 0.001236997777596116 - tot_loss: 1.6564749115568702 - acc: 0.7924374319912949 - val_acc: 0.7580590430946725\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 1.2172470092773438 - sq_loss: 0.0011342151556164026 - tot_loss: 1.5681550842928118 - acc: 0.8027747551686616 - val_acc: 0.7668815744825246\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 1.2425765991210938 - sq_loss: 0.0010424623033031821 - tot_loss: 1.4883666594214446 - acc: 0.8103917301414582 - val_acc: 0.7794367153036986\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 1.2377347946166992 - sq_loss: 0.0009600222110748291 - tot_loss: 1.41447100870937 - acc: 0.8197769314472253 - val_acc: 0.7865626060400407\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 1.2379798889160156 - sq_loss: 0.0008858380606397986 - tot_loss: 1.340511844948196 - acc: 0.8279379760609358 - val_acc: 0.7950458092975907\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 1.2228806018829346 - sq_loss: 0.0008190638036467135 - tot_loss: 1.2711474978932529 - acc: 0.8367791077257889 - val_acc: 0.8031896844248388\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 1.2318344116210938 - sq_loss: 0.0007585666025988758 - tot_loss: 1.208934101214254 - acc: 0.8446681175190425 - val_acc: 0.8099762470308789\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 1.2264816761016846 - sq_loss: 0.0007035458693280816 - tot_loss: 1.1514170133232255 - acc: 0.8524211099020674 - val_acc: 0.8184594502884289\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 1.2319800853729248 - sq_loss: 0.0006533667910844088 - tot_loss: 1.0937392189007369 - acc: 0.8582698585418934 - val_acc: 0.8262639972853749\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 1.2284424304962158 - sq_loss: 0.0006074748234823346 - tot_loss: 1.0465651684717159 - acc: 0.8650707290533188 - val_acc: 0.8306752629793009\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 1.2277870178222656 - sq_loss: 0.0005653464468196034 - tot_loss: 0.9974268232035683 - acc: 0.8702393906420022 - val_acc: 0.837461825585341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 1.229506492614746 - sq_loss: 0.0005266965017654002 - tot_loss: 0.9510751719626569 - acc: 0.8743199129488575 - val_acc: 0.8432304038004751\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 1.234668254852295 - sq_loss: 0.0004912629956379533 - tot_loss: 0.9067427822392347 - acc: 0.8792165397170838 - val_acc: 0.8469630132337971\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 1.2370450496673584 - sq_loss: 0.00045858966768719256 - tot_loss: 0.8702449737229472 - acc: 0.8824809575625681 - val_acc: 0.8506956226671191\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 1.2300984859466553 - sq_loss: 0.00042841999675147235 - tot_loss: 0.8256994290986768 - acc: 0.8865614798694232 - val_acc: 0.8554462164913471\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 1.2239627838134766 - sq_loss: 0.0004005375667475164 - tot_loss: 0.7950219858212222 - acc: 0.889417845484222 - val_acc: 0.8601968103155752\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 1.2440094947814941 - sq_loss: 0.0003747817827388644 - tot_loss: 0.7579954639350035 - acc: 0.8925462459194777 - val_acc: 0.8652867322701052\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 1.235124111175537 - sq_loss: 0.000350930611602962 - tot_loss: 0.7279624840230099 - acc: 0.8944504896626768 - val_acc: 0.8666440447913132\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 1.2302944660186768 - sq_loss: 0.0003288795705884695 - tot_loss: 0.6950303605499357 - acc: 0.8959466811751904 - val_acc: 0.8710553104852392\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 1.2382805347442627 - sq_loss: 0.000308367918478325 - tot_loss: 0.6723770017306379 - acc: 0.8975788900979326 - val_acc: 0.8727519511367492\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 1.2326104640960693 - sq_loss: 0.00028925802325829864 - tot_loss: 0.6430974295853957 - acc: 0.8988030467899891 - val_acc: 0.8775025449609772\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 1.241093635559082 - sq_loss: 0.0002715522423386574 - tot_loss: 0.6242312961348944 - acc: 0.9004352557127312 - val_acc: 0.8791991856124872\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 1.2338268756866455 - sq_loss: 0.0002550905046518892 - tot_loss: 0.5947239534534674 - acc: 0.9036996735582155 - val_acc: 0.8815744825246012\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 1.238353967666626 - sq_loss: 0.00023977021919563413 - tot_loss: 0.5761353944380971 - acc: 0.9047878128400435 - val_acc: 0.8839497794367153\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 1.2155816555023193 - sq_loss: 0.0002255089784739539 - tot_loss: 0.5507152996897275 - acc: 0.9064200217627857 - val_acc: 0.8870037326094333\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 1.2351727485656738 - sq_loss: 0.0002121177822118625 - tot_loss: 0.5357471095139772 - acc: 0.9080522306855278 - val_acc: 0.8883610451306413\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 1.2324395179748535 - sq_loss: 0.00019968958804383874 - tot_loss: 0.5160035574972426 - acc: 0.9105005440696409 - val_acc: 0.8924329826942654\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 1.2397854328155518 - sq_loss: 0.00018809825996868312 - tot_loss: 0.4903657763616138 - acc: 0.911316648531012 - val_acc: 0.8934509670851714\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 1.2306065559387207 - sq_loss: 0.00017715005378704518 - tot_loss: 0.4800541376125693 - acc: 0.9134929270946681 - val_acc: 0.8965049202578894\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 1.238389492034912 - sq_loss: 0.0001669070916250348 - tot_loss: 0.4605877277926993 - acc: 0.9143090315560392 - val_acc: 0.8978622327790974\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 1.2394344806671143 - sq_loss: 0.00015738970250822604 - tot_loss: 0.4445037617651906 - acc: 0.9162132752992383 - val_acc: 0.9005768578215134\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 1.2347958087921143 - sq_loss: 0.00014843870303593576 - tot_loss: 0.4297574663660271 - acc: 0.9166213275299239 - val_acc: 0.9019341703427214\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 1.229598045349121 - sq_loss: 0.00014012522296980023 - tot_loss: 0.4137759308450768 - acc: 0.918525571273123 - val_acc: 0.9029521547336274\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 1.2430040836334229 - sq_loss: 0.00013230439799372107 - tot_loss: 0.40124669585475203 - acc: 0.9212459194776932 - val_acc: 0.9036308109942314\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 1.2366406917572021 - sq_loss: 0.00012500003504101187 - tot_loss: 0.3906575751516357 - acc: 0.9220620239390642 - val_acc: 0.9066847641669494\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 1.2290401458740234 - sq_loss: 0.00011813712626462802 - tot_loss: 0.38253735377566045 - acc: 0.9231501632208923 - val_acc: 0.9077027485578555\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 1.243734359741211 - sq_loss: 0.00011169276695000008 - tot_loss: 0.36713256250686754 - acc: 0.9239662676822633 - val_acc: 0.9100780454699695\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 1.2313644886016846 - sq_loss: 0.00010571124585112557 - tot_loss: 0.35344393503282845 - acc: 0.9249183895538629 - val_acc: 0.9110960298608755\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 1.246711254119873 - sq_loss: 0.00010010295227402821 - tot_loss: 0.3493765000375788 - acc: 0.926006528835691 - val_acc: 0.9127926705123854\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 1.24652099609375 - sq_loss: 9.478160063736141e-05 - tot_loss: 0.34015807266359843 - acc: 0.9272306855277476 - val_acc: 0.9134713267729895\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 1.244849443435669 - sq_loss: 8.981430437415838e-05 - tot_loss: 0.3250527758059434 - acc: 0.9281828073993471 - val_acc: 0.9148286392941974\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 1.233910322189331 - sq_loss: 8.518290997017175e-05 - tot_loss: 0.31902918097875954 - acc: 0.9298150163220892 - val_acc: 0.9161859518154055\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 1.237015724182129 - sq_loss: 8.080477709881961e-05 - tot_loss: 0.31340212805753254 - acc: 0.9309031556039173 - val_acc: 0.9172039362063115\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 1.2320175170898438 - sq_loss: 7.674627704545856e-05 - tot_loss: 0.2981014862880329 - acc: 0.9329434167573449 - val_acc: 0.9178825924669155\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 1.2326653003692627 - sq_loss: 7.291335350601003e-05 - tot_loss: 0.2918242858868325 - acc: 0.9336235038084875 - val_acc: 0.9182219205972175\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 1.234642744064331 - sq_loss: 6.930428207851946e-05 - tot_loss: 0.2859228997194805 - acc: 0.934575625680087 - val_acc: 0.9189005768578216\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 1.235255241394043 - sq_loss: 6.59268262097612e-05 - tot_loss: 0.2759840231144608 - acc: 0.9355277475516867 - val_acc: 0.9205972175093315\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 1.2276582717895508 - sq_loss: 6.275538908084854e-05 - tot_loss: 0.2664588809000179 - acc: 0.9367519042437432 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 1.2349705696105957 - sq_loss: 5.978594344924204e-05 - tot_loss: 0.26641763401312346 - acc: 0.9370239390642002 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 1.2202632427215576 - sq_loss: 5.699394750990905e-05 - tot_loss: 0.2579436859123234 - acc: 0.9381120783460283 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 1.2459752559661865 - sq_loss: 5.437283107312396e-05 - tot_loss: 0.24991196163205132 - acc: 0.9383841131664853 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 1.2288849353790283 - sq_loss: 5.1869836170226336e-05 - tot_loss: 0.24683139315152403 - acc: 0.9393362350380848 - val_acc: 0.9246691550729556\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 1.2295758724212646 - sq_loss: 4.9531641707289964e-05 - tot_loss: 0.2399543711367187 - acc: 0.940424374319913 - val_acc: 0.9246691550729556\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 1.227933406829834 - sq_loss: 4.7327564971055835e-05 - tot_loss: 0.23027400647856666 - acc: 0.940968443960827 - val_acc: 0.9267051238547676\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 1.2203035354614258 - sq_loss: 4.526216798694804e-05 - tot_loss: 0.22706084247238323 - acc: 0.941784548422198 - val_acc: 0.9263657957244655\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 1.241591215133667 - sq_loss: 4.3342344724806026e-05 - tot_loss: 0.22198974282378003 - acc: 0.9427366702937976 - val_acc: 0.9277231082456736\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 1.226670503616333 - sq_loss: 4.1522696847096086e-05 - tot_loss: 0.21590824872441772 - acc: 0.9435527747551686 - val_acc: 0.9277231082456736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 1.230912446975708 - sq_loss: 3.9809012378100306e-05 - tot_loss: 0.2136457551764579 - acc: 0.9446409140369967 - val_acc: 0.9284017645062775\n",
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 1.225926160812378 - sq_loss: 3.8170859625097364e-05 - tot_loss: 0.20955799668217878 - acc: 0.9455930359085963 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 1.2400472164154053 - sq_loss: 3.6617904697777703e-05 - tot_loss: 0.20736087135526304 - acc: 0.9464091403699674 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 1.2265515327453613 - sq_loss: 3.516402648529038e-05 - tot_loss: 0.20289951114364158 - acc: 0.9480413492927094 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 1.2345366477966309 - sq_loss: 3.381115311640315e-05 - tot_loss: 0.19858189864589804 - acc: 0.948449401523395 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 1.2267897129058838 - sq_loss: 3.2511394238099456e-05 - tot_loss: 0.1979731284235413 - acc: 0.949265505984766 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 1.2237005233764648 - sq_loss: 3.129416290903464e-05 - tot_loss: 0.19520945089732322 - acc: 0.9500816104461371 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 1.2241153717041016 - sq_loss: 3.014922549482435e-05 - tot_loss: 0.18731602226262112 - acc: 0.9506256800870512 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 1.2422008514404297 - sq_loss: 2.9040220397291705e-05 - tot_loss: 0.18661204548971 - acc: 0.9508977149075082 - val_acc: 0.9345096708517137\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 1.221041202545166 - sq_loss: 2.800075162667781e-05 - tot_loss: 0.18202272748885662 - acc: 0.9519858541893362 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 1.2299559116363525 - sq_loss: 2.7033767764805816e-05 - tot_loss: 0.17806357230676895 - acc: 0.9528019586507073 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 1.221954345703125 - sq_loss: 2.6109993996215053e-05 - tot_loss: 0.17123715635489134 - acc: 0.9530739934711643 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 1.2397723197937012 - sq_loss: 2.5231836843886413e-05 - tot_loss: 0.1699772925828711 - acc: 0.9544341675734495 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 1.2391564846038818 - sq_loss: 2.440526986902114e-05 - tot_loss: 0.16927761901308713 - acc: 0.9555223068552775 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 1.2267677783966064 - sq_loss: 2.3630067516933195e-05 - tot_loss: 0.1682573042814397 - acc: 0.956474428726877 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 1.2358050346374512 - sq_loss: 2.2886759325047024e-05 - tot_loss: 0.1700259053008608 - acc: 0.9571545157780196 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 1.2347753047943115 - sq_loss: 2.217699511675164e-05 - tot_loss: 0.16218380842661873 - acc: 0.9581066376496191 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 1.2267212867736816 - sq_loss: 2.1518926587305032e-05 - tot_loss: 0.15811492738492916 - acc: 0.9586507072905331 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 1.2441787719726562 - sq_loss: 2.089574081765022e-05 - tot_loss: 0.15799203843636178 - acc: 0.9596028291621328 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 1.214189052581787 - sq_loss: 2.031371695920825e-05 - tot_loss: 0.15230204550681492 - acc: 0.9602829162132753 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 1.230884313583374 - sq_loss: 1.975817940547131e-05 - tot_loss: 0.1507597359205306 - acc: 0.9606909684439608 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 1.2374277114868164 - sq_loss: 1.921503644553013e-05 - tot_loss: 0.15192543975302897 - acc: 0.9610990206746464 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 1.2285683155059814 - sq_loss: 1.870631422207225e-05 - tot_loss: 0.14398684033244535 - acc: 0.9624591947769314 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 1.2344045639038086 - sq_loss: 1.822454942157492e-05 - tot_loss: 0.1471708339303177 - acc: 0.9627312295973884 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 1.225816011428833 - sq_loss: 1.7762784409569576e-05 - tot_loss: 0.1475671601900217 - acc: 0.9632752992383025 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 1.2292819023132324 - sq_loss: 1.732891541905701e-05 - tot_loss: 0.14465971523827648 - acc: 0.9638193688792165 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 1.229973554611206 - sq_loss: 1.690940189291723e-05 - tot_loss: 0.1452937577300304 - acc: 0.9642274211099021 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 1.2400283813476562 - sq_loss: 1.651060301810503e-05 - tot_loss: 0.14470729677390182 - acc: 0.9642274211099021 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 1.2293891906738281 - sq_loss: 1.6128053175634705e-05 - tot_loss: 0.13983904905887812 - acc: 0.9649075081610446 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 1.2313518524169922 - sq_loss: 1.5761912436573766e-05 - tot_loss: 0.13663200620609928 - acc: 0.9653155603917302 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 1.236236572265625 - sq_loss: 1.5409945262945257e-05 - tot_loss: 0.13503049080139817 - acc: 0.9661316648531012 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 1.232851505279541 - sq_loss: 1.5075949704623781e-05 - tot_loss: 0.13013357553128913 - acc: 0.9662676822633297 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 1.2415237426757812 - sq_loss: 1.4761083548364695e-05 - tot_loss: 0.12914442296352036 - acc: 0.9668117519042437 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 1.2486073970794678 - sq_loss: 1.4464134437730536e-05 - tot_loss: 0.1281670122525611 - acc: 0.9672198041349293 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 1.250673770904541 - sq_loss: 1.4182672202878166e-05 - tot_loss: 0.1278832234735603 - acc: 0.9673558215451578 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 1.246840000152588 - sq_loss: 1.3911449968873058e-05 - tot_loss: 0.12847502258580334 - acc: 0.9676278563656148 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 1.2472951412200928 - sq_loss: 1.3657049748871941e-05 - tot_loss: 0.12765960368727747 - acc: 0.9681719260065288 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 1.2486708164215088 - sq_loss: 1.3411437066679355e-05 - tot_loss: 0.12405873159116254 - acc: 0.9681719260065288 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 1.25870943069458 - sq_loss: 1.3179235793359112e-05 - tot_loss: 0.12231822162837602 - acc: 0.9684439608269858 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 1.2434659004211426 - sq_loss: 1.2954558769706637e-05 - tot_loss: 0.11716506888120648 - acc: 0.9691240478781284 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 1.2385444641113281 - sq_loss: 1.2742678336508106e-05 - tot_loss: 0.11852013091342428 - acc: 0.969804134929271 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 1.222609519958496 - sq_loss: 1.2544135643111076e-05 - tot_loss: 0.12126106491888322 - acc: 0.970076169749728 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 1.230668306350708 - sq_loss: 1.2348232303338591e-05 - tot_loss: 0.1253890962755122 - acc: 0.9707562568008705 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 1.226384162902832 - sq_loss: 1.216980854223948e-05 - tot_loss: 0.11817876902790658 - acc: 0.9710282916213275 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 1.2189812660217285 - sq_loss: 1.1995209206361324e-05 - tot_loss: 0.11842173576710024 - acc: 0.971164309031556 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 1.2258625030517578 - sq_loss: 1.1820374311355408e-05 - tot_loss: 0.1165436301804732 - acc: 0.9713003264417845 - val_acc: 0.9474041398031897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 1.2444467544555664 - sq_loss: 1.1652759894786868e-05 - tot_loss: 0.11450806616683451 - acc: 0.9715723612622416 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 1.2304761409759521 - sq_loss: 1.1490313227113802e-05 - tot_loss: 0.11146313077928482 - acc: 0.9717083786724701 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 1.2280206680297852 - sq_loss: 1.1336218449287117e-05 - tot_loss: 0.11373281137807112 - acc: 0.9719804134929271 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 1.225017786026001 - sq_loss: 1.1186999472556636e-05 - tot_loss: 0.1140615238701912 - acc: 0.9723884657236126 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 1.2234947681427002 - sq_loss: 1.104075363400625e-05 - tot_loss: 0.11380007563924721 - acc: 0.9726605005440696 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 1.233715295791626 - sq_loss: 1.090690875571454e-05 - tot_loss: 0.11003711485936662 - acc: 0.9726605005440696 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 1.225306749343872 - sq_loss: 1.0780491720652208e-05 - tot_loss: 0.11112898421163209 - acc: 0.9727965179542981 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 1.220898151397705 - sq_loss: 1.0663336979632732e-05 - tot_loss: 0.10851908814710498 - acc: 0.9734766050054406 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 1.2344908714294434 - sq_loss: 1.0537914022279438e-05 - tot_loss: 0.10849694306008928 - acc: 0.9734766050054406 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 1.2274301052093506 - sq_loss: 1.0416969416837674e-05 - tot_loss: 0.10714885250058614 - acc: 0.9737486398258978 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 1.2213566303253174 - sq_loss: 1.0303921044396702e-05 - tot_loss: 0.10849579862775727 - acc: 0.9740206746463548 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 1.229346513748169 - sq_loss: 1.0198492418567184e-05 - tot_loss: 0.10537175895863982 - acc: 0.9741566920565833 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 1.2203028202056885 - sq_loss: 1.0087734153785277e-05 - tot_loss: 0.10306674863423382 - acc: 0.9742927094668118 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 1.2247569561004639 - sq_loss: 9.989484169636853e-06 - tot_loss: 0.10748418098010859 - acc: 0.9744287268770403 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 1.2299551963806152 - sq_loss: 9.887473424896598e-06 - tot_loss: 0.10090924322122419 - acc: 0.9744287268770403 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 1.244396686553955 - sq_loss: 9.79133528744569e-06 - tot_loss: 0.11083906786356579 - acc: 0.9745647442872688 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 1.2268867492675781 - sq_loss: 9.69514439930208e-06 - tot_loss: 0.10713990006632912 - acc: 0.9745647442872688 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 1.2210471630096436 - sq_loss: 9.608923392079305e-06 - tot_loss: 0.10670734587488084 - acc: 0.9745647442872688 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 1.2271709442138672 - sq_loss: 9.52028676692862e-06 - tot_loss: 0.10175253365855497 - acc: 0.9745647442872688 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 1.2135124206542969 - sq_loss: 9.43660234042909e-06 - tot_loss: 0.10196669710273909 - acc: 0.9751088139281828 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 1.2303416728973389 - sq_loss: 9.365990990772843e-06 - tot_loss: 0.10114068757958705 - acc: 0.9752448313384113 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 1.2351593971252441 - sq_loss: 9.286862223234493e-06 - tot_loss: 0.09748551712262099 - acc: 0.9755168661588683 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 1.2292795181274414 - sq_loss: 9.208373739966191e-06 - tot_loss: 0.09820242830453196 - acc: 0.9757889009793254 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 1.2306747436523438 - sq_loss: 9.136982953350525e-06 - tot_loss: 0.10040744078395392 - acc: 0.9757889009793254 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 1.2469062805175781 - sq_loss: 9.065478479897138e-06 - tot_loss: 0.10196357197258976 - acc: 0.9763329706202394 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 1.246959924697876 - sq_loss: 8.990495189209469e-06 - tot_loss: 0.10058105077055046 - acc: 0.9763329706202394 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 1.2350854873657227 - sq_loss: 8.929150681069586e-06 - tot_loss: 0.10175142340045085 - acc: 0.9766050054406964 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 1.2334403991699219 - sq_loss: 8.864737537805922e-06 - tot_loss: 0.09901746808118617 - acc: 0.9770130576713819 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 1.2260823249816895 - sq_loss: 8.79859635460889e-06 - tot_loss: 0.09313611002333744 - acc: 0.9771490750816104 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 1.2314655780792236 - sq_loss: 8.744043043407146e-06 - tot_loss: 0.0968929340396727 - acc: 0.9775571273122959 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 1.2234320640563965 - sq_loss: 8.683051419211552e-06 - tot_loss: 0.09409849541923876 - acc: 0.9775571273122959 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 1.2343103885650635 - sq_loss: 8.62167689774651e-06 - tot_loss: 0.09491918596945936 - acc: 0.977829162132753 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 1.2388741970062256 - sq_loss: 8.562916264054365e-06 - tot_loss: 0.09441598406101548 - acc: 0.9782372143634385 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 1.2524902820587158 - sq_loss: 8.507918209943455e-06 - tot_loss: 0.0988300592934408 - acc: 0.9783732317736671 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 1.2334668636322021 - sq_loss: 8.455953320662957e-06 - tot_loss: 0.0988429179855359 - acc: 0.9783732317736671 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 1.233374834060669 - sq_loss: 8.397108103963546e-06 - tot_loss: 0.09688602960460457 - acc: 0.9786452665941241 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 1.2365198135375977 - sq_loss: 8.344881280208938e-06 - tot_loss: 0.09366872198965837 - acc: 0.9786452665941241 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 1.2169849872589111 - sq_loss: 8.293308383144904e-06 - tot_loss: 0.0937624805281132 - acc: 0.9786452665941241 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 1.234673023223877 - sq_loss: 8.245421668107156e-06 - tot_loss: 0.08976065047028214 - acc: 0.9786452665941241 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 1.2358083724975586 - sq_loss: 8.19924480310874e-06 - tot_loss: 0.09056602598322172 - acc: 0.9786452665941241 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 1.2340657711029053 - sq_loss: 8.151831025315914e-06 - tot_loss: 0.09261232726544932 - acc: 0.9786452665941241 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 1.2272889614105225 - sq_loss: 8.107274879876059e-06 - tot_loss: 0.0906578981269277 - acc: 0.9787812840043526 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 1.2205700874328613 - sq_loss: 8.062089364102576e-06 - tot_loss: 0.08856335449894459 - acc: 0.9787812840043526 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 1.230520248413086 - sq_loss: 8.016841093194671e-06 - tot_loss: 0.0907563232732187 - acc: 0.9789173014145811 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 1.2237467765808105 - sq_loss: 7.967394594743382e-06 - tot_loss: 0.09101711165296678 - acc: 0.9789173014145811 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 1.2232778072357178 - sq_loss: 7.922836630314123e-06 - tot_loss: 0.08892481484684112 - acc: 0.9795973884657236 - val_acc: 0.9535120461486257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 1.2253210544586182 - sq_loss: 7.88451507105492e-06 - tot_loss: 0.08659895380464633 - acc: 0.9798694232861807 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 1.225210428237915 - sq_loss: 7.848397217458114e-06 - tot_loss: 0.08830163215559139 - acc: 0.9800054406964092 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 1.2336430549621582 - sq_loss: 7.81031576480018e-06 - tot_loss: 0.09390944907036669 - acc: 0.9798694232861807 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 1.227698564529419 - sq_loss: 7.773846846248489e-06 - tot_loss: 0.09328882117586801 - acc: 0.9800054406964092 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 1.2331383228302002 - sq_loss: 7.732060112175532e-06 - tot_loss: 0.08724376901262332 - acc: 0.9800054406964092 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 1.222416639328003 - sq_loss: 7.690699931117706e-06 - tot_loss: 0.08773834500114219 - acc: 0.9800054406964092 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 1.2249269485473633 - sq_loss: 7.655635272385553e-06 - tot_loss: 0.08953484904840536 - acc: 0.9801414581066377 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 1.2316625118255615 - sq_loss: 7.620561973453732e-06 - tot_loss: 0.09337455561225738 - acc: 0.9801414581066377 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 1.2380990982055664 - sq_loss: 7.583106707897969e-06 - tot_loss: 0.0883661281146857 - acc: 0.9804134929270947 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 1.2302677631378174 - sq_loss: 7.547522272943752e-06 - tot_loss: 0.08643993589834054 - acc: 0.9808215451577802 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 1.2305912971496582 - sq_loss: 7.513453056162689e-06 - tot_loss: 0.08982003345067113 - acc: 0.9808215451577802 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 1.2329208850860596 - sq_loss: 7.4816443884628825e-06 - tot_loss: 0.08931178308026944 - acc: 0.9806855277475517 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 1.2368872165679932 - sq_loss: 7.446668860211503e-06 - tot_loss: 0.08476589502504339 - acc: 0.9810935799782372 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 1.2294011116027832 - sq_loss: 7.412019385810709e-06 - tot_loss: 0.08728642074294157 - acc: 0.9812295973884657 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 1.2263331413269043 - sq_loss: 7.379848284472246e-06 - tot_loss: 0.08911320892738672 - acc: 0.9815016322089227 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 1.2432374954223633 - sq_loss: 7.3500013968441635e-06 - tot_loss: 0.08592938952671858 - acc: 0.9815016322089227 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 1.2354774475097656 - sq_loss: 7.321472821786301e-06 - tot_loss: 0.08413347112480807 - acc: 0.9816376496191512 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 1.231208324432373 - sq_loss: 7.294034276128514e-06 - tot_loss: 0.089022927513696 - acc: 0.9819096844396082 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 1.2347614765167236 - sq_loss: 7.261594419105677e-06 - tot_loss: 0.08519902329756945 - acc: 0.9819096844396082 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 1.2265880107879639 - sq_loss: 7.2325015025853645e-06 - tot_loss: 0.08512944398199096 - acc: 0.9820457018498367 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 1.232208251953125 - sq_loss: 7.2017523962131236e-06 - tot_loss: 0.08475272425927471 - acc: 0.9823177366702938 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 1.218611717224121 - sq_loss: 7.173430731199915e-06 - tot_loss: 0.084172424247555 - acc: 0.9821817192600653 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 1.224609613418579 - sq_loss: 7.146770713006845e-06 - tot_loss: 0.08062697238310079 - acc: 0.9823177366702938 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 1.22837233543396 - sq_loss: 7.11949769538478e-06 - tot_loss: 0.08649352440243518 - acc: 0.9821817192600653 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 1.232111930847168 - sq_loss: 7.090078725013882e-06 - tot_loss: 0.08309691931625451 - acc: 0.9823177366702938 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 1.2186486721038818 - sq_loss: 7.06011405782192e-06 - tot_loss: 0.08388693229686339 - acc: 0.9823177366702938 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 1.2267398834228516 - sq_loss: 7.032621851976728e-06 - tot_loss: 0.08629180436776451 - acc: 0.9825897714907508 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 1.2297072410583496 - sq_loss: 7.003462087595835e-06 - tot_loss: 0.08199221190769279 - acc: 0.9823177366702938 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 1.2390789985656738 - sq_loss: 6.976551503612427e-06 - tot_loss: 0.08397803963620731 - acc: 0.9824537540805223 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 1.2353367805480957 - sq_loss: 6.951074283279013e-06 - tot_loss: 0.08224197936042543 - acc: 0.9824537540805223 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 1.2353646755218506 - sq_loss: 6.926409241714282e-06 - tot_loss: 0.08082425098131907 - acc: 0.9825897714907508 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 1.226757287979126 - sq_loss: 6.897557341289939e-06 - tot_loss: 0.07781520468310532 - acc: 0.9827257889009793 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 1.2358224391937256 - sq_loss: 6.868452146591153e-06 - tot_loss: 0.08230416268802188 - acc: 0.9832698585418934 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 1.2246067523956299 - sq_loss: 6.84356018609833e-06 - tot_loss: 0.08247496935387844 - acc: 0.9832698585418934 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 1.2178492546081543 - sq_loss: 6.819097961852094e-06 - tot_loss: 0.08131495877873718 - acc: 0.9832698585418934 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 1.234384536743164 - sq_loss: 6.796976322220871e-06 - tot_loss: 0.0790970291844566 - acc: 0.9832698585418934 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 1.2242891788482666 - sq_loss: 6.774592293368187e-06 - tot_loss: 0.08121298997825477 - acc: 0.9834058759521219 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 1.221440315246582 - sq_loss: 6.751100499968743e-06 - tot_loss: 0.08724132025514919 - acc: 0.9834058759521219 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 1.232659101486206 - sq_loss: 6.726856099703582e-06 - tot_loss: 0.07936563045220879 - acc: 0.9834058759521219 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 1.2204744815826416 - sq_loss: 6.704894531139871e-06 - tot_loss: 0.07744552732095755 - acc: 0.9834058759521219 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 1.234027624130249 - sq_loss: 6.6797715589927975e-06 - tot_loss: 0.08102157397880205 - acc: 0.9835418933623504 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 1.227034091949463 - sq_loss: 6.657969606749248e-06 - tot_loss: 0.08015931362564999 - acc: 0.9835418933623504 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 1.237499713897705 - sq_loss: 6.63566606817767e-06 - tot_loss: 0.07985091324557914 - acc: 0.9838139281828074 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 1.2333614826202393 - sq_loss: 6.613615369133186e-06 - tot_loss: 0.08554037147839111 - acc: 0.983949945593036 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 1.230682373046875 - sq_loss: 6.591859346372075e-06 - tot_loss: 0.08247804348532384 - acc: 0.9840859630032645 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 1.237001657485962 - sq_loss: 6.571467110916274e-06 - tot_loss: 0.07987561942622534 - acc: 0.984221980413493 - val_acc: 0.9558873430607397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 1.2288713455200195 - sq_loss: 6.5508070292708e-06 - tot_loss: 0.08674969976779323 - acc: 0.9840859630032645 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 1.2327024936676025 - sq_loss: 6.5296603679598775e-06 - tot_loss: 0.07925366928815336 - acc: 0.984221980413493 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 1.2333886623382568 - sq_loss: 6.507271336886333e-06 - tot_loss: 0.07994514939901265 - acc: 0.984221980413493 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 1.2392454147338867 - sq_loss: 6.483181095973123e-06 - tot_loss: 0.0819471296698957 - acc: 0.9843579978237215 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 1.2420971393585205 - sq_loss: 6.461362772824941e-06 - tot_loss: 0.0835959974508711 - acc: 0.9843579978237215 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 1.238846778869629 - sq_loss: 6.440652214223519e-06 - tot_loss: 0.07721553012067517 - acc: 0.9843579978237215 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 1.2308940887451172 - sq_loss: 6.420973022613907e-06 - tot_loss: 0.07626910696249922 - acc: 0.98449401523395 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 1.2463109493255615 - sq_loss: 6.401210612239083e-06 - tot_loss: 0.08084982462313306 - acc: 0.9846300326441785 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 1.2494981288909912 - sq_loss: 6.383163508871803e-06 - tot_loss: 0.07689013806369971 - acc: 0.9846300326441785 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 1.2406530380249023 - sq_loss: 6.362444764818065e-06 - tot_loss: 0.07809491173499694 - acc: 0.984766050054407 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 1.2506763935089111 - sq_loss: 6.342586402752204e-06 - tot_loss: 0.0808164228010888 - acc: 0.984766050054407 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 1.255943775177002 - sq_loss: 6.324487458186923e-06 - tot_loss: 0.07952593170310962 - acc: 0.985038084874864 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 1.2422435283660889 - sq_loss: 6.303170721366769e-06 - tot_loss: 0.07462776701305174 - acc: 0.9851741022850925 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 1.2444732189178467 - sq_loss: 6.284203664108645e-06 - tot_loss: 0.07847815833049765 - acc: 0.985310119695321 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 1.235328197479248 - sq_loss: 6.263737304834649e-06 - tot_loss: 0.08149330930205423 - acc: 0.9851741022850925 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 1.2182369232177734 - sq_loss: 6.243910320335999e-06 - tot_loss: 0.07934834938436452 - acc: 0.9851741022850925 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 1.228050708770752 - sq_loss: 6.224422577361111e-06 - tot_loss: 0.08169544576373156 - acc: 0.9851741022850925 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 1.2314198017120361 - sq_loss: 6.206372745509725e-06 - tot_loss: 0.0789783865109861 - acc: 0.9854461371055495 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 1.23311185836792 - sq_loss: 6.189167834236287e-06 - tot_loss: 0.07786444812207094 - acc: 0.9854461371055495 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 1.2330412864685059 - sq_loss: 6.170325832499657e-06 - tot_loss: 0.0742581635819981 - acc: 0.9854461371055495 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 1.2315423488616943 - sq_loss: 6.150686658656923e-06 - tot_loss: 0.07721609386605621 - acc: 0.9854461371055495 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 1.227628469467163 - sq_loss: 6.131561804068042e-06 - tot_loss: 0.07647292343223455 - acc: 0.9854461371055495 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 1.230752944946289 - sq_loss: 6.1156183619459625e-06 - tot_loss: 0.07447585389082434 - acc: 0.9854461371055495 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 1.2294435501098633 - sq_loss: 6.1005466704955325e-06 - tot_loss: 0.07118675867533852 - acc: 0.9854461371055495 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 1.2225453853607178 - sq_loss: 6.082843810872873e-06 - tot_loss: 0.08257291740452288 - acc: 0.985582154515778 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 1.2308900356292725 - sq_loss: 6.06548746873159e-06 - tot_loss: 0.07597691619315583 - acc: 0.985582154515778 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 1.2306604385375977 - sq_loss: 6.05030845690635e-06 - tot_loss: 0.07795515978408574 - acc: 0.9854461371055495 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 1.2341389656066895 - sq_loss: 6.033455065335147e-06 - tot_loss: 0.07720051338884559 - acc: 0.9854461371055495 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 1.2210614681243896 - sq_loss: 6.014139216858894e-06 - tot_loss: 0.07597462502978303 - acc: 0.9854461371055495 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 1.2342534065246582 - sq_loss: 5.993736976961372e-06 - tot_loss: 0.07362654290958304 - acc: 0.985582154515778 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 1.2364749908447266 - sq_loss: 5.9765256992250215e-06 - tot_loss: 0.07934847495029373 - acc: 0.985582154515778 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 1.2272112369537354 - sq_loss: 5.958218025625683e-06 - tot_loss: 0.0824181390869505 - acc: 0.985582154515778 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 1.2206931114196777 - sq_loss: 5.942832103755791e-06 - tot_loss: 0.08090350761377607 - acc: 0.985582154515778 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 1.2369835376739502 - sq_loss: 5.926659923716215e-06 - tot_loss: 0.07491785023598041 - acc: 0.985582154515778 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 1.218700647354126 - sq_loss: 5.9106300795974676e-06 - tot_loss: 0.0747071725883508 - acc: 0.9854461371055495 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 1.2391149997711182 - sq_loss: 5.896903076063609e-06 - tot_loss: 0.07646279975041281 - acc: 0.985582154515778 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 1.2223949432373047 - sq_loss: 5.882958703296026e-06 - tot_loss: 0.07356229646256551 - acc: 0.985582154515778 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 1.2359023094177246 - sq_loss: 5.866094397788402e-06 - tot_loss: 0.07760189470360146 - acc: 0.9857181719260065 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 1.2159440517425537 - sq_loss: 5.8505102060735226e-06 - tot_loss: 0.07732575722845425 - acc: 0.985854189336235 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 1.2375342845916748 - sq_loss: 5.833197974425275e-06 - tot_loss: 0.07640438431191043 - acc: 0.985854189336235 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 1.237008810043335 - sq_loss: 5.816683824377833e-06 - tot_loss: 0.0782857852109089 - acc: 0.985854189336235 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 1.236124038696289 - sq_loss: 5.802301529911347e-06 - tot_loss: 0.07600151237916819 - acc: 0.9859902067464635 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 1.2370595932006836 - sq_loss: 5.785076155007118e-06 - tot_loss: 0.07743544143838932 - acc: 0.9859902067464635 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 1.2399225234985352 - sq_loss: 5.769232302554883e-06 - tot_loss: 0.07618980297287692 - acc: 0.9859902067464635 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 1.2224979400634766 - sq_loss: 5.7540946727385744e-06 - tot_loss: 0.07339368276699787 - acc: 0.9862622415669206 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 1.2338485717773438 - sq_loss: 5.739685093431035e-06 - tot_loss: 0.07130800686225314 - acc: 0.9862622415669206 - val_acc: 0.9586019681031558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 1.2362642288208008 - sq_loss: 5.726003564632265e-06 - tot_loss: 0.07616000438943615 - acc: 0.9862622415669206 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 1.2368266582489014 - sq_loss: 5.7113179536827374e-06 - tot_loss: 0.07333442916467448 - acc: 0.986126224156692 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 1.2170264720916748 - sq_loss: 5.695940672012512e-06 - tot_loss: 0.07419272447771164 - acc: 0.986126224156692 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 1.2378497123718262 - sq_loss: 5.680429239873774e-06 - tot_loss: 0.07290497608968849 - acc: 0.9859902067464635 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 1.236699104309082 - sq_loss: 5.666747256327653e-06 - tot_loss: 0.07266517939805439 - acc: 0.986126224156692 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 1.2182645797729492 - sq_loss: 5.650004823110066e-06 - tot_loss: 0.07565810954704943 - acc: 0.986126224156692 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 1.2310004234313965 - sq_loss: 5.635623438138282e-06 - tot_loss: 0.07338789578252047 - acc: 0.986126224156692 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 1.2286169528961182 - sq_loss: 5.622246590064606e-06 - tot_loss: 0.07768850926489179 - acc: 0.986126224156692 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 1.2375340461730957 - sq_loss: 5.606331797025632e-06 - tot_loss: 0.07476770038186586 - acc: 0.9863982589771491 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 1.2289719581604004 - sq_loss: 5.589205102296546e-06 - tot_loss: 0.07211377237728911 - acc: 0.9865342763873776 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 1.2350904941558838 - sq_loss: 5.574790520768147e-06 - tot_loss: 0.07254370345817307 - acc: 0.9865342763873776 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 1.2375316619873047 - sq_loss: 5.561336820392171e-06 - tot_loss: 0.07210678351208344 - acc: 0.9865342763873776 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 1.232450246810913 - sq_loss: 5.545438398257829e-06 - tot_loss: 0.07135466210215569 - acc: 0.9863982589771491 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 1.225038766860962 - sq_loss: 5.53201880393317e-06 - tot_loss: 0.07613416388722527 - acc: 0.9866702937976061 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 1.2274386882781982 - sq_loss: 5.519160367839504e-06 - tot_loss: 0.07596275937023123 - acc: 0.9865342763873776 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 1.2236113548278809 - sq_loss: 5.506671186594758e-06 - tot_loss: 0.07079237821985629 - acc: 0.9866702937976061 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 1.2180941104888916 - sq_loss: 5.494428478414193e-06 - tot_loss: 0.07308581515544077 - acc: 0.9866702937976061 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 1.2403640747070312 - sq_loss: 5.481265816342784e-06 - tot_loss: 0.07649293070297247 - acc: 0.9866702937976061 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 1.2127819061279297 - sq_loss: 5.4678744163538795e-06 - tot_loss: 0.07575089640380739 - acc: 0.9866702937976061 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 1.2274360656738281 - sq_loss: 5.455246537167113e-06 - tot_loss: 0.07366223748177703 - acc: 0.9868063112078346 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 1.2340896129608154 - sq_loss: 5.442624114948558e-06 - tot_loss: 0.06910729159961093 - acc: 0.9869423286180631 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 1.2188746929168701 - sq_loss: 5.428638814919395e-06 - tot_loss: 0.06890860142676658 - acc: 0.9869423286180631 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 1.223909854888916 - sq_loss: 5.416256499302108e-06 - tot_loss: 0.06889601203468132 - acc: 0.9869423286180631 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 1.2348787784576416 - sq_loss: 5.404174316936405e-06 - tot_loss: 0.0806255528855857 - acc: 0.9869423286180631 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 1.2268238067626953 - sq_loss: 5.390454589360161e-06 - tot_loss: 0.07120794367220995 - acc: 0.9869423286180631 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 1.2358441352844238 - sq_loss: 5.376115041144658e-06 - tot_loss: 0.0732173835033123 - acc: 0.9872143634385201 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 1.2307929992675781 - sq_loss: 5.363538548408542e-06 - tot_loss: 0.07295854808656799 - acc: 0.9870783460282916 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 1.2354629039764404 - sq_loss: 5.351515483198455e-06 - tot_loss: 0.07541045287990755 - acc: 0.9873503808487486 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 1.2238199710845947 - sq_loss: 5.340542884368915e-06 - tot_loss: 0.07163163269103734 - acc: 0.9874863982589771 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 1.2257194519042969 - sq_loss: 5.3299872888601385e-06 - tot_loss: 0.07474343127949368 - acc: 0.9872143634385201 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 1.2123191356658936 - sq_loss: 5.316431725077564e-06 - tot_loss: 0.07039224242290487 - acc: 0.9877584330794341 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 1.2195260524749756 - sq_loss: 5.305224021867616e-06 - tot_loss: 0.0698719939732122 - acc: 0.9874863982589771 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 1.2313611507415771 - sq_loss: 5.291887646308169e-06 - tot_loss: 0.0717598999450928 - acc: 0.9876224156692056 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 1.2197587490081787 - sq_loss: 5.277148375171237e-06 - tot_loss: 0.07524275356225729 - acc: 0.9872143634385201 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 1.2374677658081055 - sq_loss: 5.264708306640387e-06 - tot_loss: 0.07321034206864496 - acc: 0.9874863982589771 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 1.2325682640075684 - sq_loss: 5.255303676676704e-06 - tot_loss: 0.06853309899293691 - acc: 0.9877584330794341 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 1.2309308052062988 - sq_loss: 5.2452346608333755e-06 - tot_loss: 0.07691951819283105 - acc: 0.9877584330794341 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 1.2187347412109375 - sq_loss: 5.232177045400022e-06 - tot_loss: 0.07471825190238235 - acc: 0.9878944504896626 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 1.2101075649261475 - sq_loss: 5.2197851800883655e-06 - tot_loss: 0.07156169167976145 - acc: 0.9878944504896626 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 1.2156410217285156 - sq_loss: 5.206938112678472e-06 - tot_loss: 0.0716686015117638 - acc: 0.9878944504896626 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 1.214402198791504 - sq_loss: 5.1929896471847314e-06 - tot_loss: 0.07455821704892429 - acc: 0.9880304678998912 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 1.2320592403411865 - sq_loss: 5.181604137760587e-06 - tot_loss: 0.07143922298379835 - acc: 0.9878944504896626 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 1.2307875156402588 - sq_loss: 5.170697477296926e-06 - tot_loss: 0.07794930589266258 - acc: 0.9880304678998912 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 1.2304747104644775 - sq_loss: 5.160155069461325e-06 - tot_loss: 0.07455606574038676 - acc: 0.9878944504896626 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 1.2258780002593994 - sq_loss: 5.149011940375203e-06 - tot_loss: 0.07349946831580922 - acc: 0.9878944504896626 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 1.2321467399597168 - sq_loss: 5.137289917911403e-06 - tot_loss: 0.07638144289933102 - acc: 0.9880304678998912 - val_acc: 0.9602986087546658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 1.2301123142242432 - sq_loss: 5.125672942085657e-06 - tot_loss: 0.07398223096248735 - acc: 0.9878944504896626 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 1.246960163116455 - sq_loss: 5.116426109452732e-06 - tot_loss: 0.07450805084256551 - acc: 0.9880304678998912 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 1.2335853576660156 - sq_loss: 5.105210220790468e-06 - tot_loss: 0.06955515412327173 - acc: 0.9880304678998912 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 1.2283406257629395 - sq_loss: 5.09200162923662e-06 - tot_loss: 0.07057095743021513 - acc: 0.9880304678998912 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 1.2306890487670898 - sq_loss: 5.081744802737376e-06 - tot_loss: 0.07233495017769265 - acc: 0.9881664853101197 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 1.2303760051727295 - sq_loss: 5.071027771919034e-06 - tot_loss: 0.0728395682792744 - acc: 0.9881664853101197 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 1.227144718170166 - sq_loss: 5.062396667199209e-06 - tot_loss: 0.07275005868107698 - acc: 0.9880304678998912 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 1.2301695346832275 - sq_loss: 5.052012056694366e-06 - tot_loss: 0.07214256198773406 - acc: 0.9881664853101197 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 1.2306125164031982 - sq_loss: 5.040021278546192e-06 - tot_loss: 0.07431794217382048 - acc: 0.9881664853101197 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 1.2352325916290283 - sq_loss: 5.028609848523047e-06 - tot_loss: 0.07100162900281859 - acc: 0.9883025027203483 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 1.2100193500518799 - sq_loss: 5.016901468479773e-06 - tot_loss: 0.07859020411718376 - acc: 0.9881664853101197 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 1.2308504581451416 - sq_loss: 5.005052571505075e-06 - tot_loss: 0.06928127374943216 - acc: 0.9881664853101197 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 1.2148098945617676 - sq_loss: 4.994736173102865e-06 - tot_loss: 0.07371518199639127 - acc: 0.9881664853101197 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 1.2309160232543945 - sq_loss: 4.983338385500247e-06 - tot_loss: 0.07506546640246547 - acc: 0.9881664853101197 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 1.222642421722412 - sq_loss: 4.971295766154071e-06 - tot_loss: 0.07227226150499177 - acc: 0.9881664853101197 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 1.2285594940185547 - sq_loss: 4.961692411598051e-06 - tot_loss: 0.07183323248278839 - acc: 0.9883025027203483 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 1.226452112197876 - sq_loss: 4.95492031404865e-06 - tot_loss: 0.07342690640346206 - acc: 0.9884385201305768 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 1.226912498474121 - sq_loss: 4.946592980559217e-06 - tot_loss: 0.07796270493846258 - acc: 0.9884385201305768 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 1.2330937385559082 - sq_loss: 4.934576281812042e-06 - tot_loss: 0.07337558236721087 - acc: 0.9883025027203483 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 1.230433702468872 - sq_loss: 4.9245331865677144e-06 - tot_loss: 0.06913882345498479 - acc: 0.9884385201305768 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 1.226830005645752 - sq_loss: 4.911960786557756e-06 - tot_loss: 0.07378892798129222 - acc: 0.9884385201305768 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 1.2335574626922607 - sq_loss: 4.9014984142559115e-06 - tot_loss: 0.07603966154358766 - acc: 0.9884385201305768 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 1.222895622253418 - sq_loss: 4.890582658845233e-06 - tot_loss: 0.06769230618536959 - acc: 0.9884385201305768 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 1.2139174938201904 - sq_loss: 4.878206254943507e-06 - tot_loss: 0.07200338977542664 - acc: 0.9884385201305768 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 1.2257425785064697 - sq_loss: 4.865664777753409e-06 - tot_loss: 0.06779723432080331 - acc: 0.9885745375408053 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 1.224576473236084 - sq_loss: 4.857095973420655e-06 - tot_loss: 0.06961428328360952 - acc: 0.9884385201305768 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 1.2415204048156738 - sq_loss: 4.844900104217231e-06 - tot_loss: 0.07257516958614296 - acc: 0.9885745375408053 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 1.2462043762207031 - sq_loss: 4.834051651414484e-06 - tot_loss: 0.0683773705802988 - acc: 0.9884385201305768 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 1.2354111671447754 - sq_loss: 4.824992174690124e-06 - tot_loss: 0.07355091564148886 - acc: 0.9885745375408053 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 1.2291512489318848 - sq_loss: 4.81493043480441e-06 - tot_loss: 0.07029267117311733 - acc: 0.9884385201305768 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 1.2298908233642578 - sq_loss: 4.805415755981812e-06 - tot_loss: 0.06848452747085965 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 1.2296929359436035 - sq_loss: 4.794922915607458e-06 - tot_loss: 0.07477308468338606 - acc: 0.9884385201305768 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 1.2234091758728027 - sq_loss: 4.784873908647569e-06 - tot_loss: 0.06957306776180339 - acc: 0.9887105549510338 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 1.2364609241485596 - sq_loss: 4.7749063014634885e-06 - tot_loss: 0.0735187973104452 - acc: 0.9885745375408053 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 1.229752779006958 - sq_loss: 4.76511922897771e-06 - tot_loss: 0.06954531208060288 - acc: 0.9885745375408053 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 1.232043743133545 - sq_loss: 4.7558546611981e-06 - tot_loss: 0.07147235905769556 - acc: 0.9885745375408053 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 1.2357561588287354 - sq_loss: 4.746879312733654e-06 - tot_loss: 0.07207399750712362 - acc: 0.9887105549510338 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 1.2318618297576904 - sq_loss: 4.739435553346993e-06 - tot_loss: 0.07907596923179483 - acc: 0.9885745375408053 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 1.2310798168182373 - sq_loss: 4.730608907266287e-06 - tot_loss: 0.07323894552520294 - acc: 0.9885745375408053 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 1.234098196029663 - sq_loss: 4.720271590485936e-06 - tot_loss: 0.06931512214919522 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 1.2214734554290771 - sq_loss: 4.712023837782908e-06 - tot_loss: 0.07664916648704967 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 1.2188992500305176 - sq_loss: 4.701491889136378e-06 - tot_loss: 0.07275589554718742 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 1.2291686534881592 - sq_loss: 4.690839887189213e-06 - tot_loss: 0.06904162123957747 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 1.2299649715423584 - sq_loss: 4.679462108470034e-06 - tot_loss: 0.07443897421828005 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 1.2228071689605713 - sq_loss: 4.66959545519785e-06 - tot_loss: 0.06600312823824694 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 1.2428019046783447 - sq_loss: 4.66026904177852e-06 - tot_loss: 0.07320757343990891 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 1.2279503345489502 - sq_loss: 4.649939000955783e-06 - tot_loss: 0.07157157461708685 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 1.2364115715026855 - sq_loss: 4.6420018406934105e-06 - tot_loss: 0.07890465863733276 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 1.226186752319336 - sq_loss: 4.632435320672812e-06 - tot_loss: 0.07263476909608002 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 1.2370696067810059 - sq_loss: 4.624668235919671e-06 - tot_loss: 0.06854007620228764 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 1.2354519367218018 - sq_loss: 4.617805188900093e-06 - tot_loss: 0.06858293985491848 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 1.2360937595367432 - sq_loss: 4.610893029166618e-06 - tot_loss: 0.06895136511093547 - acc: 0.9887105549510338 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 1.235842227935791 - sq_loss: 4.600724423653446e-06 - tot_loss: 0.06950328388369442 - acc: 0.9887105549510338 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 1.2349801063537598 - sq_loss: 4.592141522152815e-06 - tot_loss: 0.06782440794150979 - acc: 0.9887105549510338 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 1.226280927658081 - sq_loss: 4.585476290230872e-06 - tot_loss: 0.0728326948732132 - acc: 0.9888465723612623 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 1.242079257965088 - sq_loss: 4.578864718496334e-06 - tot_loss: 0.07373672976217804 - acc: 0.9888465723612623 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 1.2403619289398193 - sq_loss: 4.569560587697197e-06 - tot_loss: 0.06937784473926101 - acc: 0.9889825897714908 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 1.2341740131378174 - sq_loss: 4.560078195936512e-06 - tot_loss: 0.06789497983792714 - acc: 0.9889825897714908 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 1.2204930782318115 - sq_loss: 4.5506085371016525e-06 - tot_loss: 0.06862079254810993 - acc: 0.9891186071817193 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 1.2277545928955078 - sq_loss: 4.541487214737572e-06 - tot_loss: 0.06681967693435631 - acc: 0.9891186071817193 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 1.225881576538086 - sq_loss: 4.532842922344571e-06 - tot_loss: 0.07533297667083794 - acc: 0.9891186071817193 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 1.2259900569915771 - sq_loss: 4.524285031948239e-06 - tot_loss: 0.07174849374284697 - acc: 0.9889825897714908 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 1.2292912006378174 - sq_loss: 4.514001830102643e-06 - tot_loss: 0.07263816182305938 - acc: 0.9891186071817193 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 1.226015567779541 - sq_loss: 4.5060855882184114e-06 - tot_loss: 0.06803845667599973 - acc: 0.9889825897714908 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 1.244619369506836 - sq_loss: 4.499918304645689e-06 - tot_loss: 0.07309242508229019 - acc: 0.9891186071817193 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 1.2376978397369385 - sq_loss: 4.494843778957147e-06 - tot_loss: 0.0700823134424482 - acc: 0.9891186071817193 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 1.2435731887817383 - sq_loss: 4.485800218390068e-06 - tot_loss: 0.07256263815662045 - acc: 0.9891186071817193 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 1.2468783855438232 - sq_loss: 4.476957656152081e-06 - tot_loss: 0.07068809477041427 - acc: 0.9891186071817193 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 1.2431955337524414 - sq_loss: 4.46857484348584e-06 - tot_loss: 0.07096160071823654 - acc: 0.9889825897714908 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 1.2282509803771973 - sq_loss: 4.4575126594281755e-06 - tot_loss: 0.07516824132753541 - acc: 0.9891186071817193 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 1.2266910076141357 - sq_loss: 4.448717845662031e-06 - tot_loss: 0.06669969457381875 - acc: 0.9891186071817193 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 1.236961841583252 - sq_loss: 4.440280008566333e-06 - tot_loss: 0.07051229439288065 - acc: 0.9891186071817193 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 1.2223446369171143 - sq_loss: 4.434536549524637e-06 - tot_loss: 0.07139654573095022 - acc: 0.9889825897714908 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 1.2182278633117676 - sq_loss: 4.4280895963311195e-06 - tot_loss: 0.07062905650766815 - acc: 0.9889825897714908 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 1.2305631637573242 - sq_loss: 4.41998963651713e-06 - tot_loss: 0.06956405611106398 - acc: 0.9889825897714908 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 1.2330002784729004 - sq_loss: 4.411098871059949e-06 - tot_loss: 0.07275670754614261 - acc: 0.9889825897714908 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 1.222785234451294 - sq_loss: 4.400651050673332e-06 - tot_loss: 0.07126016740416574 - acc: 0.9889825897714908 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 1.2274408340454102 - sq_loss: 4.392875780467875e-06 - tot_loss: 0.07778837901798852 - acc: 0.9889825897714908 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 1.2178678512573242 - sq_loss: 4.384531166579109e-06 - tot_loss: 0.07132572184111474 - acc: 0.9891186071817193 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 1.235175609588623 - sq_loss: 4.37587777923909e-06 - tot_loss: 0.06726840178094662 - acc: 0.9889825897714908 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 1.2341253757476807 - sq_loss: 4.369464932096889e-06 - tot_loss: 0.06414238294245678 - acc: 0.9889825897714908 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 1.2237443923950195 - sq_loss: 4.363188054412603e-06 - tot_loss: 0.06279840462975272 - acc: 0.9891186071817193 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 1.220550537109375 - sq_loss: 4.3562786231632344e-06 - tot_loss: 0.0712367498399562 - acc: 0.9891186071817193 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 1.2309401035308838 - sq_loss: 4.348313723312458e-06 - tot_loss: 0.06525119651573519 - acc: 0.9889825897714908 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 1.235487461090088 - sq_loss: 4.3413783714640886e-06 - tot_loss: 0.07261494672213331 - acc: 0.9889825897714908 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 1.2305819988250732 - sq_loss: 4.33496143159573e-06 - tot_loss: 0.06987899773745632 - acc: 0.9891186071817193 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 1.233633041381836 - sq_loss: 4.327831902628532e-06 - tot_loss: 0.06559001947344356 - acc: 0.9891186071817193 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 1.2250189781188965 - sq_loss: 4.320262178225676e-06 - tot_loss: 0.06764748583565883 - acc: 0.9891186071817193 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 1.2260127067565918 - sq_loss: 4.311963039071998e-06 - tot_loss: 0.06815304403253819 - acc: 0.9889825897714908 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 1.2163901329040527 - sq_loss: 4.303390142013086e-06 - tot_loss: 0.072796124864972 - acc: 0.9891186071817193 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 1.2190780639648438 - sq_loss: 4.295186954550445e-06 - tot_loss: 0.07276374663877583 - acc: 0.9891186071817193 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 1.238313913345337 - sq_loss: 4.289078333385987e-06 - tot_loss: 0.06978220547931357 - acc: 0.9891186071817193 - val_acc: 0.9619952494061758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 1.232377290725708 - sq_loss: 4.28333441959694e-06 - tot_loss: 0.0661136376691207 - acc: 0.9891186071817193 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 1.2196357250213623 - sq_loss: 4.276167146599619e-06 - tot_loss: 0.0713358755817719 - acc: 0.9892546245919478 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 1.2392079830169678 - sq_loss: 4.268322754796827e-06 - tot_loss: 0.06807492965224426 - acc: 0.9891186071817193 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 1.2195594310760498 - sq_loss: 4.259314209775766e-06 - tot_loss: 0.06993012080353012 - acc: 0.9891186071817193 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 1.2185957431793213 - sq_loss: 4.251588052284205e-06 - tot_loss: 0.06699194223761396 - acc: 0.9892546245919478 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 1.2317993640899658 - sq_loss: 4.244392584951129e-06 - tot_loss: 0.069995310315079 - acc: 0.9891186071817193 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 1.241659164428711 - sq_loss: 4.2368478716525715e-06 - tot_loss: 0.06730556374303198 - acc: 0.9892546245919478 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 1.2348039150238037 - sq_loss: 4.231174443702912e-06 - tot_loss: 0.06958812801119585 - acc: 0.9892546245919478 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 1.248624563217163 - sq_loss: 4.22315542891738e-06 - tot_loss: 0.0688055829664318 - acc: 0.9893906420021763 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 1.242969274520874 - sq_loss: 4.215913577354513e-06 - tot_loss: 0.07273852185713814 - acc: 0.9893906420021763 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 1.250333309173584 - sq_loss: 4.209906364849303e-06 - tot_loss: 0.06591414467082934 - acc: 0.9892546245919478 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 1.2502429485321045 - sq_loss: 4.20300511905225e-06 - tot_loss: 0.07491492987504778 - acc: 0.9891186071817193 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 1.239727258682251 - sq_loss: 4.195979727228405e-06 - tot_loss: 0.07423464114563316 - acc: 0.9891186071817193 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 1.257685899734497 - sq_loss: 4.188509592495393e-06 - tot_loss: 0.06695257194695081 - acc: 0.9892546245919478 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 1.2526781558990479 - sq_loss: 4.181410531600704e-06 - tot_loss: 0.06688201116419457 - acc: 0.9892546245919478 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 1.2505557537078857 - sq_loss: 4.175769845460309e-06 - tot_loss: 0.06929846700341002 - acc: 0.9892546245919478 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 1.2505853176116943 - sq_loss: 4.1689136196509935e-06 - tot_loss: 0.06214821199922049 - acc: 0.9892546245919478 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 1.2502169609069824 - sq_loss: 4.1627331484050956e-06 - tot_loss: 0.06958942942222279 - acc: 0.9891186071817193 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 1.2466139793395996 - sq_loss: 4.155781425652094e-06 - tot_loss: 0.07063922936993627 - acc: 0.9892546245919478 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 1.2412447929382324 - sq_loss: 4.147369509155396e-06 - tot_loss: 0.06755224067346433 - acc: 0.9892546245919478 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 1.2390220165252686 - sq_loss: 4.140682449360611e-06 - tot_loss: 0.06888407004352182 - acc: 0.9892546245919478 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 1.2360038757324219 - sq_loss: 4.132888989261119e-06 - tot_loss: 0.06484671884627957 - acc: 0.9892546245919478 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 1.2340850830078125 - sq_loss: 4.12582585340715e-06 - tot_loss: 0.06533604891767375 - acc: 0.9892546245919478 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 1.2389087677001953 - sq_loss: 4.119157438253751e-06 - tot_loss: 0.06690635168953385 - acc: 0.9892546245919478 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 1.2395267486572266 - sq_loss: 4.111842827114742e-06 - tot_loss: 0.06854210523528792 - acc: 0.9892546245919478 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 1.2302579879760742 - sq_loss: 4.1044722820515744e-06 - tot_loss: 0.06975488600307678 - acc: 0.9893906420021763 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 1.238175868988037 - sq_loss: 4.098036242794478e-06 - tot_loss: 0.06549035167801698 - acc: 0.9893906420021763 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 1.221256971359253 - sq_loss: 4.091165919817286e-06 - tot_loss: 0.07082889835390738 - acc: 0.9893906420021763 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 1.2413926124572754 - sq_loss: 4.085533873876557e-06 - tot_loss: 0.06637803404192866 - acc: 0.9892546245919478 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 1.2379169464111328 - sq_loss: 4.079411610291572e-06 - tot_loss: 0.07163148982084522 - acc: 0.9893906420021763 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 1.234253168106079 - sq_loss: 4.07387005907367e-06 - tot_loss: 0.06573099960414375 - acc: 0.9893906420021763 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 1.2269465923309326 - sq_loss: 4.0676550270291045e-06 - tot_loss: 0.0678646796894462 - acc: 0.9893906420021763 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 1.2299444675445557 - sq_loss: 4.0602612898510415e-06 - tot_loss: 0.07393958221102892 - acc: 0.9893906420021763 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 1.228912353515625 - sq_loss: 4.0550667108618654e-06 - tot_loss: 0.06445612264976042 - acc: 0.9893906420021763 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 1.2472224235534668 - sq_loss: 4.0485579120286275e-06 - tot_loss: 0.06882355429974041 - acc: 0.9895266594124048 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 1.2351045608520508 - sq_loss: 4.040260591864353e-06 - tot_loss: 0.06518599996467422 - acc: 0.9893906420021763 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 1.2399177551269531 - sq_loss: 4.031921434943797e-06 - tot_loss: 0.06858365296860391 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 1.2176854610443115 - sq_loss: 4.0251106838695705e-06 - tot_loss: 0.07246509323091743 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 1.2188975811004639 - sq_loss: 4.017457285954151e-06 - tot_loss: 0.06650815801034682 - acc: 0.9893906420021763 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 1.2257444858551025 - sq_loss: 4.012056251667673e-06 - tot_loss: 0.0642850598412501 - acc: 0.9893906420021763 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 1.2247235774993896 - sq_loss: 4.006275503343204e-06 - tot_loss: 0.0646005731312691 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 1.230093240737915 - sq_loss: 4.00178987547406e-06 - tot_loss: 0.0686783017416488 - acc: 0.9893906420021763 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 1.23887300491333 - sq_loss: 3.9948704397829715e-06 - tot_loss: 0.0660463397878619 - acc: 0.9893906420021763 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 1.2240064144134521 - sq_loss: 3.988448952441104e-06 - tot_loss: 0.06991866735146068 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 1.237273931503296 - sq_loss: 3.983393526141299e-06 - tot_loss: 0.06827343352513005 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 1.2349042892456055 - sq_loss: 3.9791893868823536e-06 - tot_loss: 0.0632434320943478 - acc: 0.9893906420021763 - val_acc: 0.9643705463182898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 1.2523934841156006 - sq_loss: 3.9732140066917054e-06 - tot_loss: 0.07018287624613428 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 1.2538316249847412 - sq_loss: 3.966154508816544e-06 - tot_loss: 0.06923038360159417 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 1.249070644378662 - sq_loss: 3.9600604395673145e-06 - tot_loss: 0.07235206349589696 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 1.2500474452972412 - sq_loss: 3.954189196520019e-06 - tot_loss: 0.06416270422792536 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 1.2504703998565674 - sq_loss: 3.948240191675723e-06 - tot_loss: 0.06729071131825037 - acc: 0.9896626768226333 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 1.2466683387756348 - sq_loss: 3.942018338420894e-06 - tot_loss: 0.06836474976745777 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 1.2457890510559082 - sq_loss: 3.936174380214652e-06 - tot_loss: 0.06858824958165322 - acc: 0.9895266594124048 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 1.2514064311981201 - sq_loss: 3.930247657990549e-06 - tot_loss: 0.06768562376365139 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 1.2513620853424072 - sq_loss: 3.924435532098869e-06 - tot_loss: 0.06657681370055002 - acc: 0.9895266594124048 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 1.2371268272399902 - sq_loss: 3.91816229239339e-06 - tot_loss: 0.07052341902341297 - acc: 0.9895266594124048 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 1.237330436706543 - sq_loss: 3.913249202014413e-06 - tot_loss: 0.06752097109009547 - acc: 0.9895266594124048 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 1.2346680164337158 - sq_loss: 3.908455255441368e-06 - tot_loss: 0.06457051869997343 - acc: 0.9895266594124048 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 1.2384772300720215 - sq_loss: 3.90155173590756e-06 - tot_loss: 0.0684109425852153 - acc: 0.9895266594124048 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 1.2394354343414307 - sq_loss: 3.894470864906907e-06 - tot_loss: 0.07158791488107319 - acc: 0.9895266594124048 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 1.235640048980713 - sq_loss: 3.887148068315582e-06 - tot_loss: 0.06849631317296812 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 1.220703363418579 - sq_loss: 3.880059921357315e-06 - tot_loss: 0.07034306998198758 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 1.2301874160766602 - sq_loss: 3.875296442856779e-06 - tot_loss: 0.06332980071510796 - acc: 0.9895266594124048 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 1.2290050983428955 - sq_loss: 3.868219209834933e-06 - tot_loss: 0.06461788291595205 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 1.2201411724090576 - sq_loss: 3.8609728107985575e-06 - tot_loss: 0.07133376056844654 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 1.2261865139007568 - sq_loss: 3.855538579955464e-06 - tot_loss: 0.07465963360153793 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 1.2354991436004639 - sq_loss: 3.8513758227054495e-06 - tot_loss: 0.06939509206269712 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 1.237070083618164 - sq_loss: 3.845671926683281e-06 - tot_loss: 0.06899688494877942 - acc: 0.9895266594124048 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 1.2352237701416016 - sq_loss: 3.839190867438447e-06 - tot_loss: 0.06278121187871122 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 1.2296884059906006 - sq_loss: 3.834119524981361e-06 - tot_loss: 0.06841970435569777 - acc: 0.9895266594124048 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 1.2189562320709229 - sq_loss: 3.827016371360514e-06 - tot_loss: 0.06973999382367246 - acc: 0.9895266594124048 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 1.2264864444732666 - sq_loss: 3.821737209364073e-06 - tot_loss: 0.0726196503964438 - acc: 0.9895266594124048 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 1.2343909740447998 - sq_loss: 3.815715899690986e-06 - tot_loss: 0.06865261757773489 - acc: 0.9895266594124048 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 1.2268550395965576 - sq_loss: 3.8113091704872204e-06 - tot_loss: 0.06517042386156824 - acc: 0.9895266594124048 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 1.2200140953063965 - sq_loss: 3.8060647966631223e-06 - tot_loss: 0.06988818406893671 - acc: 0.9896626768226333 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 1.2496230602264404 - sq_loss: 3.801035745709669e-06 - tot_loss: 0.06617650093703098 - acc: 0.9896626768226333 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 1.2284517288208008 - sq_loss: 3.7959534893161617e-06 - tot_loss: 0.06692299436903681 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 1.226691722869873 - sq_loss: 3.7912543575657764e-06 - tot_loss: 0.06804861778830151 - acc: 0.9896626768226333 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 1.2340667247772217 - sq_loss: 3.783174634008901e-06 - tot_loss: 0.06322921146375471 - acc: 0.9896626768226333 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 1.2381565570831299 - sq_loss: 3.7751101444882806e-06 - tot_loss: 0.06088272606967848 - acc: 0.9895266594124048 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 1.2307758331298828 - sq_loss: 3.769107252082904e-06 - tot_loss: 0.0662702782251543 - acc: 0.9895266594124048 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 1.2290699481964111 - sq_loss: 3.7640895698132226e-06 - tot_loss: 0.065206215028212 - acc: 0.9895266594124048 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 1.2390201091766357 - sq_loss: 3.7566321680060355e-06 - tot_loss: 0.0710250210979595 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 1.2195239067077637 - sq_loss: 3.7497015910048503e-06 - tot_loss: 0.06579856545194396 - acc: 0.9896626768226333 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 1.2204248905181885 - sq_loss: 3.743622983165551e-06 - tot_loss: 0.06876103338131045 - acc: 0.9895266594124048 - val_acc: 0.9640312181879878\n",
      "CR_1 = 0.16759738116197184   CR_2 = 0.1667972504806152\n",
      "/home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 5\n",
    "alpha = 1\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "\n",
    "#alpha1 = alpha2 = alpha3 = alpha4 = alpha5 = alpha6 = alpha7 = alpha8 = alpha9 = alpha10 = alpha\n",
    "#for rank in (35,): #(25,30,35)(100,180,220,260,300,340,380)(20,60,100,140,180,220,260,300,340,380)\n",
    "#    for tau in (400,500): #(300,400,500)(10,50,100,200,300)(10,50,100,200,300)\n",
    "#        for gamma in (0.5,0.8,2): #(0.5,0.8,2)(0.5,0.8)(0.5,1,1.5,2,3)\n",
    "            #gamma1 = gamma2 = gamma3 = gamma4 = gamma5 = gamma\n",
    "#            for rho in (0.5,0.8,2): #(0.5,0.8)(1,2)\n",
    "                #rho1 = rho2 = rho3 = rho4 = rho5= rho\n",
    "#                for alpha in (0.5,1,1.5,2):\n",
    "#                    print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "                    #print('Compression Ratio', ((1024*28*28+10*1024+(8*(rank)+32*np.square(rank))*2)/(1024*28*28+10*1024+1024*1024*2)), (8*(rank)+32*np.square(rank))*2/(1024*1024*2))\n",
    "        \n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    d0 = 561 #561 =3*11*17\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 6 \n",
    "\n",
    "    W1 = 0.2*init.xavier_uniform_(torch.empty(d1, d0, device=device), gain=1.0)\n",
    "    #W1 = 0.01*torch.randn(d1, d0, device=device)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    W2 = 0.2*init.xavier_uniform_(torch.empty(d2, d1, device=device), gain=1.0)\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles factors, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    W3 = 0.2*init.xavier_uniform_(torch.empty(d3, d2, device=device), gain=1.0)\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    W4 = 0.2*init.xavier_uniform_(torch.empty(d4, d3, device=device), gain=1.0)\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "\n",
    "    W5 = 0.2*init.xavier_uniform_(torch.empty(d5, d4, device=device), gain=1.0)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = U5 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V5 = (y_one_hot + gamma*U5 + alpha*V5)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U5 = (gamma*V5 + rho*(torch.mm(W5,V4) + b5.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W5, b5 = updateWb_org(U5,V4,W5,b5,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b5.repeat(1, N), W5, a4_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b5.repeat(1, N_test), W5, a4_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V5,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,U5,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4\n",
    "\n",
    "    CR_1=((total_variabels)+(d4*d5))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#this postion to add new row into existing table\n",
    "    #df=pd.read_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "    #new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "    #           'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "    #           'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1], 'seed':seed} \n",
    "    #df=df.append(new_row,ignore_index=True)\n",
    "    #df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"XavierUniform_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895c825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30f34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
