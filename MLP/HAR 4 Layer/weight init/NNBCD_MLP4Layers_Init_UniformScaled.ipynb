{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccc0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6113fe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 5 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 1.2650587558746338 - sq_loss: 661.6840209960938 - tot_loss: 979.3175804925067 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 1.2495293617248535 - sq_loss: 294.08172607421875 - tot_loss: 477.50140278600156 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 1.2457494735717773 - sq_loss: 163.0446319580078 - tot_loss: 261.5023195575923 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 1.2583062648773193 - sq_loss: 88.92915344238281 - tot_loss: 146.12165162945166 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 1.2427732944488525 - sq_loss: 48.00612258911133 - tot_loss: 83.93502086866647 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 1.2760634422302246 - sq_loss: 25.812044143676758 - tot_loss: 50.308233003132045 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 1.2694859504699707 - sq_loss: 13.87830638885498 - tot_loss: 31.979065916500986 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 1.2476143836975098 - sq_loss: 7.4815521240234375 - tot_loss: 21.849004208110273 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 1.2775473594665527 - sq_loss: 4.0527544021606445 - tot_loss: 16.12550768139772 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 1.2600023746490479 - sq_loss: 2.2110495567321777 - tot_loss: 12.777322667185217 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 1.227752923965454 - sq_loss: 1.2180479764938354 - tot_loss: 10.717355854343623 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 1.2732996940612793 - sq_loss: 0.6796642541885376 - tot_loss: 9.362877289066091 - acc: 0.25258433079434167 - val_acc: 0.22531387852052936\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 1.255124568939209 - sq_loss: 0.38556623458862305 - tot_loss: 8.387570242281072 - acc: 0.39540261153427636 - val_acc: 0.3654563963352562\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 1.245624303817749 - sq_loss: 0.22332654893398285 - tot_loss: 7.637826965074055 - acc: 0.47456474428726875 - val_acc: 0.4356973193077706\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 1.2295291423797607 - sq_loss: 0.13270704448223114 - tot_loss: 7.008201932883821 - acc: 0.5195865070729053 - val_acc: 0.4916864608076009\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 1.2240574359893799 - sq_loss: 0.08130786567926407 - tot_loss: 6.457920838613063 - acc: 0.5321001088139282 - val_acc: 0.5222259925347811\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 1.2232654094696045 - sq_loss: 0.0516100712120533 - tot_loss: 5.954006606189068 - acc: 0.5416213275299239 - val_acc: 0.5303698676620292\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 1.223144769668579 - sq_loss: 0.03406963124871254 - tot_loss: 5.489950414339546 - acc: 0.5495103373231773 - val_acc: 0.5320665083135392\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 1.239546298980713 - sq_loss: 0.02344430983066559 - tot_loss: 5.062382216448896 - acc: 0.580114254624592 - val_acc: 0.5517475398710553\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 1.2288873195648193 - sq_loss: 0.0168229378759861 - tot_loss: 4.667762218596181 - acc: 0.6107181719260065 - val_acc: 0.5883949779436716\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 1.2540767192840576 - sq_loss: 0.012564821168780327 - tot_loss: 4.307562289875932 - acc: 0.6372415669205659 - val_acc: 0.6063793688496777\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 1.2276649475097656 - sq_loss: 0.009731865487992764 - tot_loss: 3.9778694566630293 - acc: 0.6474428726877041 - val_acc: 0.6213098065829658\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 1.228830337524414 - sq_loss: 0.007778538856655359 - tot_loss: 3.679327481047949 - acc: 0.6490750816104461 - val_acc: 0.6226671191041737\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 1.232520341873169 - sq_loss: 0.006383874919265509 - tot_loss: 3.4126761335064657 - acc: 0.6507072905331882 - val_acc: 0.6287750254496097\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 1.2317757606506348 - sq_loss: 0.005351877771317959 - tot_loss: 3.167987208653358 - acc: 0.6600924918389554 - val_acc: 0.6318289786223278\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 1.2297754287719727 - sq_loss: 0.004562961868941784 - tot_loss: 2.944970752185327 - acc: 0.6709738846572362 - val_acc: 0.6352222599253479\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 1.231811761856079 - sq_loss: 0.003943415824323893 - tot_loss: 2.746669641666813 - acc: 0.6788628944504896 - val_acc: 0.6403121818798778\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 1.2255258560180664 - sq_loss: 0.0034443018957972527 - tot_loss: 2.563430921516556 - acc: 0.684031556039173 - val_acc: 0.6464200882253138\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 1.2274820804595947 - sq_loss: 0.0030341274105012417 - tot_loss: 2.3975701911040233 - acc: 0.6946409140369967 - val_acc: 0.6579572446555819\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 1.2285306453704834 - sq_loss: 0.0026913590263575315 - tot_loss: 2.2456013744304073 - acc: 0.7026659412404788 - val_acc: 0.6705123854767561\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 1.2331640720367432 - sq_loss: 0.0024012834765017033 - tot_loss: 2.108499674417544 - acc: 0.7115070729053319 - val_acc: 0.6827281981676281\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 1.2211976051330566 - sq_loss: 0.002152866916731 - tot_loss: 1.979583686690603 - acc: 0.7178998911860718 - val_acc: 0.6915507295554801\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 1.2360663414001465 - sq_loss: 0.0019385392079129815 - tot_loss: 1.8636400029645301 - acc: 0.7256528835690969 - val_acc: 0.6990159484221242\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 1.2419371604919434 - sq_loss: 0.001751784235239029 - tot_loss: 1.7600917735799158 - acc: 0.7354461371055495 - val_acc: 0.7078384798099763\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 1.2357196807861328 - sq_loss: 0.001588477403856814 - tot_loss: 1.6565289260470308 - acc: 0.7445593035908596 - val_acc: 0.7176789955887343\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 1.2238500118255615 - sq_loss: 0.0014449215959757566 - tot_loss: 1.5590387146476132 - acc: 0.7529923830250272 - val_acc: 0.7251442144553784\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 1.2203049659729004 - sq_loss: 0.001318274182267487 - tot_loss: 1.4725895179290092 - acc: 0.7596572361262242 - val_acc: 0.7309127926705123\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 1.2185087203979492 - sq_loss: 0.0012058677384629846 - tot_loss: 1.393556039482064 - acc: 0.7668661588683352 - val_acc: 0.7370206990159485\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 1.2211413383483887 - sq_loss: 0.0011059475364163518 - tot_loss: 1.3197685056875343 - acc: 0.7727149075081611 - val_acc: 0.7431286053613845\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 1.2319860458374023 - sq_loss: 0.0010165645508095622 - tot_loss: 1.2519853988924297 - acc: 0.7795157780195865 - val_acc: 0.7533084492704445\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 1.219024419784546 - sq_loss: 0.0009363185381516814 - tot_loss: 1.1867017262738955 - acc: 0.7848204570184983 - val_acc: 0.7607736681370886\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 1.2223598957061768 - sq_loss: 0.0008638575091026723 - tot_loss: 1.1275464926475252 - acc: 0.7924374319912949 - val_acc: 0.7695961995249406\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 1.2634525299072266 - sq_loss: 0.000798517488874495 - tot_loss: 1.0689221633965644 - acc: 0.801278563656148 - val_acc: 0.7774007465218866\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 1.258664608001709 - sq_loss: 0.0007391689578071237 - tot_loss: 1.0184913795965258 - acc: 0.8102557127312296 - val_acc: 0.7875805904309467\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 1.2283203601837158 - sq_loss: 0.0006851884536445141 - tot_loss: 0.9726954795223719 - acc: 0.8193688792165397 - val_acc: 0.7957244655581948\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 1.260930061340332 - sq_loss: 0.0006361122359521687 - tot_loss: 0.9212831711211038 - acc: 0.8263057671381937 - val_acc: 0.8008143875127248\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 1.2528831958770752 - sq_loss: 0.000591261254157871 - tot_loss: 0.8762189112949272 - acc: 0.8351468988030468 - val_acc: 0.8079402782490669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 1.229198932647705 - sq_loss: 0.0005501354462467134 - tot_loss: 0.8355491286729375 - acc: 0.8430359085963003 - val_acc: 0.8157448252460129\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 1.2907612323760986 - sq_loss: 0.0005122909205965698 - tot_loss: 0.7989914854806557 - acc: 0.8495647442872688 - val_acc: 0.821174075330845\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 1.2535686492919922 - sq_loss: 0.0004773948749061674 - tot_loss: 0.7580494280136918 - acc: 0.8566376496191512 - val_acc: 0.8266033254156769\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 1.2322325706481934 - sq_loss: 0.0004454321460798383 - tot_loss: 0.7245077839925216 - acc: 0.8628944504896626 - val_acc: 0.835086528673227\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 1.2753174304962158 - sq_loss: 0.0004158554074820131 - tot_loss: 0.6929346535907825 - acc: 0.8694232861806311 - val_acc: 0.8428910756701731\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 1.2575092315673828 - sq_loss: 0.0003884805191773921 - tot_loss: 0.6644924506545067 - acc: 0.8764961915125136 - val_acc: 0.8479809976247031\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 1.2462406158447266 - sq_loss: 0.0003632530861068517 - tot_loss: 0.6351669924542875 - acc: 0.8805767138193689 - val_acc: 0.8523922633186292\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 1.2731266021728516 - sq_loss: 0.0003400585555937141 - tot_loss: 0.6120030586334906 - acc: 0.8856093579978237 - val_acc: 0.8574821852731591\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 1.2684886455535889 - sq_loss: 0.0003185446548741311 - tot_loss: 0.5816232855913768 - acc: 0.8887377584330794 - val_acc: 0.8622327790973872\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 1.245009183883667 - sq_loss: 0.0002986393228638917 - tot_loss: 0.5615304300899879 - acc: 0.8900979325353645 - val_acc: 0.8683406854428232\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 1.2841155529022217 - sq_loss: 0.0002801810624077916 - tot_loss: 0.5371938524804136 - acc: 0.8932263329706203 - val_acc: 0.8737699355276553\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 1.2312636375427246 - sq_loss: 0.0002630158851388842 - tot_loss: 0.5163950662536081 - acc: 0.8959466811751904 - val_acc: 0.8758059043094673\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 1.2628107070922852 - sq_loss: 0.0002471335174050182 - tot_loss: 0.4950629889663105 - acc: 0.8978509249183896 - val_acc: 0.8788598574821853\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 1.249272108078003 - sq_loss: 0.00023236384731717408 - tot_loss: 0.474169045742201 - acc: 0.9007072905331882 - val_acc: 0.8832711231761113\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 1.2314801216125488 - sq_loss: 0.00021855192608200014 - tot_loss: 0.45581901215336984 - acc: 0.9026115342763874 - val_acc: 0.8880217170003394\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 1.2593340873718262 - sq_loss: 0.00020573950314428657 - tot_loss: 0.4406772017491676 - acc: 0.904379760609358 - val_acc: 0.8887003732609433\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 1.2701876163482666 - sq_loss: 0.00019376054115127772 - tot_loss: 0.4249747317735455 - acc: 0.9056039173014145 - val_acc: 0.8924329826942654\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 1.2678918838500977 - sq_loss: 0.00018260804063174874 - tot_loss: 0.40776766195085656 - acc: 0.9084602829162133 - val_acc: 0.8958262639972854\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 1.2509593963623047 - sq_loss: 0.0001721256267046556 - tot_loss: 0.39316574464373844 - acc: 0.9095484221980413 - val_acc: 0.8978622327790974\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 1.2497131824493408 - sq_loss: 0.00016227917512878776 - tot_loss: 0.3817501218622965 - acc: 0.9107725788900979 - val_acc: 0.9015948422124194\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 1.2460012435913086 - sq_loss: 0.00015312423056457192 - tot_loss: 0.3666086675302722 - acc: 0.9121327529923831 - val_acc: 0.9039701391245334\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 1.2449932098388672 - sq_loss: 0.00014447364083025604 - tot_loss: 0.35552997281820353 - acc: 0.9136289445048966 - val_acc: 0.9046487953851374\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 1.240443468093872 - sq_loss: 0.00013640127144753933 - tot_loss: 0.3407654994493896 - acc: 0.9147170837867247 - val_acc: 0.9077027485578555\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 1.2601280212402344 - sq_loss: 0.00012874245294369757 - tot_loss: 0.3303255304090271 - acc: 0.9166213275299239 - val_acc: 0.9090600610790635\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 1.2596421241760254 - sq_loss: 0.00012156416778452694 - tot_loss: 0.3173227418155875 - acc: 0.91879760609358 - val_acc: 0.9107567017305734\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 1.2545616626739502 - sq_loss: 0.0001147659495472908 - tot_loss: 0.3073992359195472 - acc: 0.9197497279651795 - val_acc: 0.9117746861214795\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 1.2601962089538574 - sq_loss: 0.00010845410724868998 - tot_loss: 0.29600084517278447 - acc: 0.920157780195865 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 1.2452688217163086 - sq_loss: 0.00010246471356367692 - tot_loss: 0.28866033321082796 - acc: 0.9217899891186072 - val_acc: 0.9144893111638955\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 1.24029541015625 - sq_loss: 9.686848352430388e-05 - tot_loss: 0.2812422420624898 - acc: 0.9232861806311208 - val_acc: 0.9155072955548015\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 1.2472083568572998 - sq_loss: 9.164748917100951e-05 - tot_loss: 0.26991021142885074 - acc: 0.9245103373231773 - val_acc: 0.9165252799457075\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 1.2453231811523438 - sq_loss: 8.671230898471549e-05 - tot_loss: 0.2629572547907628 - acc: 0.9255984766050055 - val_acc: 0.9178825924669155\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 1.2597270011901855 - sq_loss: 8.211467502405867e-05 - tot_loss: 0.2535699863087757 - acc: 0.9266866158868335 - val_acc: 0.9185612487275195\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 1.2522554397583008 - sq_loss: 7.777326391078532e-05 - tot_loss: 0.24498686507763523 - acc: 0.9285908596300326 - val_acc: 0.9189005768578216\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 1.2606556415557861 - sq_loss: 7.368378282990307e-05 - tot_loss: 0.24121114727859094 - acc: 0.9300870511425462 - val_acc: 0.9205972175093315\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 1.2376294136047363 - sq_loss: 6.978207966312766e-05 - tot_loss: 0.23647135110900308 - acc: 0.9314472252448314 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 1.2417628765106201 - sq_loss: 6.615386519115418e-05 - tot_loss: 0.22641372181033148 - acc: 0.9329434167573449 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 1.242793321609497 - sq_loss: 6.276094791246578e-05 - tot_loss: 0.22255010125832086 - acc: 0.933487486398259 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 1.227292537689209 - sq_loss: 5.957884786766954e-05 - tot_loss: 0.21833532375421782 - acc: 0.9344396082698585 - val_acc: 0.9236511706820495\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 1.227306842803955 - sq_loss: 5.6538086937507614e-05 - tot_loss: 0.2105438176010921 - acc: 0.9344396082698585 - val_acc: 0.9236511706820495\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 1.224435806274414 - sq_loss: 5.370330109144561e-05 - tot_loss: 0.2048817356815107 - acc: 0.9351196953210011 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 1.2278521060943604 - sq_loss: 5.1018811063840985e-05 - tot_loss: 0.19900601672202356 - acc: 0.9359357997823722 - val_acc: 0.9246691550729556\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 1.2255430221557617 - sq_loss: 4.854118742514402e-05 - tot_loss: 0.19232707290302642 - acc: 0.9364798694232862 - val_acc: 0.9253478113335596\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 1.2234065532684326 - sq_loss: 4.618910315912217e-05 - tot_loss: 0.19214573799513346 - acc: 0.9377040261153428 - val_acc: 0.9256871394638616\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 1.2249586582183838 - sq_loss: 4.395314317662269e-05 - tot_loss: 0.18673837177766472 - acc: 0.9382480957562568 - val_acc: 0.9263657957244655\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 1.233119249343872 - sq_loss: 4.1875788156175986e-05 - tot_loss: 0.17984541662985976 - acc: 0.9393362350380848 - val_acc: 0.9280624363759755\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 1.305480718612671 - sq_loss: 3.9889633626444265e-05 - tot_loss: 0.17882309988647194 - acc: 0.9397442872687704 - val_acc: 0.9300984051577876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 1.3104820251464844 - sq_loss: 3.803599247476086e-05 - tot_loss: 0.17528392294275363 - acc: 0.9405603917301415 - val_acc: 0.9311163895486936\n",
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 1.3558707237243652 - sq_loss: 3.628957347245887e-05 - tot_loss: 0.1732549317853227 - acc: 0.9421926006528836 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 1.419360876083374 - sq_loss: 3.4658140066312626e-05 - tot_loss: 0.16778548177001085 - acc: 0.9427366702937976 - val_acc: 0.9321343739395996\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 1.3590667247772217 - sq_loss: 3.3131414966192096e-05 - tot_loss: 0.1651759258936636 - acc: 0.9434167573449401 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 1.285623550415039 - sq_loss: 3.169097180943936e-05 - tot_loss: 0.15994372833495163 - acc: 0.9443688792165397 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 1.2732329368591309 - sq_loss: 3.0318775316118263e-05 - tot_loss: 0.1568558660076178 - acc: 0.9449129488574538 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 1.2961993217468262 - sq_loss: 2.9024975447100587e-05 - tot_loss: 0.15340242389015657 - acc: 0.9460010881392819 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 1.338930368423462 - sq_loss: 2.7800064344774e-05 - tot_loss: 0.1560162853853626 - acc: 0.9465451577801959 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 1.3442368507385254 - sq_loss: 2.6663752578315325e-05 - tot_loss: 0.1508865736898315 - acc: 0.9474972796517954 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 1.3582055568695068 - sq_loss: 2.558065898483619e-05 - tot_loss: 0.14816482419763588 - acc: 0.9483133841131665 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 1.3276515007019043 - sq_loss: 2.4547025532228872e-05 - tot_loss: 0.14256564319208564 - acc: 0.948993471164309 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 1.3407938480377197 - sq_loss: 2.355742071813438e-05 - tot_loss: 0.14081128014430533 - acc: 0.9499455930359086 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 1.3623509407043457 - sq_loss: 2.2669153622700833e-05 - tot_loss: 0.1385123828127348 - acc: 0.9504896626768227 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 1.3337655067443848 - sq_loss: 2.1812580598634668e-05 - tot_loss: 0.13579473212536186 - acc: 0.9517138193688792 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 1.3027489185333252 - sq_loss: 2.100667370541487e-05 - tot_loss: 0.13592106714344254 - acc: 0.9528019586507073 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 1.3409674167633057 - sq_loss: 2.0249441149644554e-05 - tot_loss: 0.13048546240844416 - acc: 0.9532100108813928 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 1.3162095546722412 - sq_loss: 1.9528642951627262e-05 - tot_loss: 0.12961174715064772 - acc: 0.9540261153427638 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 1.2692923545837402 - sq_loss: 1.8838134565157816e-05 - tot_loss: 0.12822578801353757 - acc: 0.9549782372143635 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 1.2676301002502441 - sq_loss: 1.819397948565893e-05 - tot_loss: 0.12658104019561733 - acc: 0.955930359085963 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 1.2945480346679688 - sq_loss: 1.75918175955303e-05 - tot_loss: 0.12257602629063058 - acc: 0.9566104461371056 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 1.2727761268615723 - sq_loss: 1.7029653463396244e-05 - tot_loss: 0.1225331936526004 - acc: 0.9575625680087051 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 1.251237392425537 - sq_loss: 1.6497389879077673e-05 - tot_loss: 0.12059444345402426 - acc: 0.9583786724700761 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 1.2570061683654785 - sq_loss: 1.5986854123184457e-05 - tot_loss: 0.1187867759144865 - acc: 0.9587867247007617 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 1.255974531173706 - sq_loss: 1.5503888789680786e-05 - tot_loss: 0.11587307491456045 - acc: 0.9594668117519043 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 1.2768704891204834 - sq_loss: 1.5038613128126599e-05 - tot_loss: 0.1166656566547033 - acc: 0.9604189336235038 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 1.235567569732666 - sq_loss: 1.4607136108679697e-05 - tot_loss: 0.11114593453339694 - acc: 0.9613710554951034 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 1.2332262992858887 - sq_loss: 1.4199527868186124e-05 - tot_loss: 0.11587183747366225 - acc: 0.9619151251360174 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 1.2323706150054932 - sq_loss: 1.381140282319393e-05 - tot_loss: 0.1153744184892389 - acc: 0.9628672470076169 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 1.2340331077575684 - sq_loss: 1.3434813808999024e-05 - tot_loss: 0.11232547147702121 - acc: 0.9632752992383025 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 1.2378532886505127 - sq_loss: 1.3091716937196907e-05 - tot_loss: 0.11279439520106394 - acc: 0.9640914036996736 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 1.2466483116149902 - sq_loss: 1.2753528608300257e-05 - tot_loss: 0.10791017996245955 - acc: 0.9644994559303591 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 1.2358050346374512 - sq_loss: 1.2443317245924845e-05 - tot_loss: 0.10663407061650787 - acc: 0.9650435255712732 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 1.249760627746582 - sq_loss: 1.21456569104339e-05 - tot_loss: 0.10555726764854967 - acc: 0.9655875952121872 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 1.2471904754638672 - sq_loss: 1.1862775863846764e-05 - tot_loss: 0.10454337322272522 - acc: 0.9662676822633297 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 1.235091209411621 - sq_loss: 1.1601438018260524e-05 - tot_loss: 0.10501399549119128 - acc: 0.9665397170837867 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 1.2623064517974854 - sq_loss: 1.1349327905918472e-05 - tot_loss: 0.10073357371828706 - acc: 0.9665397170837867 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 1.2284717559814453 - sq_loss: 1.1094647561549209e-05 - tot_loss: 0.10177686317793189 - acc: 0.9666757344940152 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 1.2469472885131836 - sq_loss: 1.0868622666748706e-05 - tot_loss: 0.09949506680663944 - acc: 0.9670837867247007 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 1.226236343383789 - sq_loss: 1.0656603080860805e-05 - tot_loss: 0.09742737879577135 - acc: 0.9678998911860718 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 1.2330639362335205 - sq_loss: 1.045223598339362e-05 - tot_loss: 0.09579967380915377 - acc: 0.9683079434167573 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 1.2419469356536865 - sq_loss: 1.0260397175443359e-05 - tot_loss: 0.10023669523958745 - acc: 0.9687159956474428 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 1.234879732131958 - sq_loss: 1.0071823453472462e-05 - tot_loss: 0.09840811264845684 - acc: 0.9691240478781284 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 1.2160770893096924 - sq_loss: 9.89010095509002e-06 - tot_loss: 0.09474833651854908 - acc: 0.969260065288357 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 1.219022512435913 - sq_loss: 9.712446626508608e-06 - tot_loss: 0.09187648503645107 - acc: 0.9693960826985855 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 1.247410774230957 - sq_loss: 9.550682079861872e-06 - tot_loss: 0.09113052603807148 - acc: 0.9696681175190425 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 1.226947546005249 - sq_loss: 9.389551451022271e-06 - tot_loss: 0.0938236276959401 - acc: 0.9699401523394995 - val_acc: 0.9494401085850017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 1.2429444789886475 - sq_loss: 9.229899660567753e-06 - tot_loss: 0.09315242474394836 - acc: 0.970076169749728 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 1.2490947246551514 - sq_loss: 9.089393643080257e-06 - tot_loss: 0.08966992223707848 - acc: 0.970348204570185 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 1.2300620079040527 - sq_loss: 8.954821169027127e-06 - tot_loss: 0.09170651703792032 - acc: 0.970620239390642 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 1.2226660251617432 - sq_loss: 8.821052688290365e-06 - tot_loss: 0.09033332423734919 - acc: 0.970620239390642 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 1.2660174369812012 - sq_loss: 8.701922524778638e-06 - tot_loss: 0.09034833141701881 - acc: 0.9707562568008705 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 1.2599577903747559 - sq_loss: 8.586089279560838e-06 - tot_loss: 0.08494296406550461 - acc: 0.9707562568008705 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 1.2233197689056396 - sq_loss: 8.47624869493302e-06 - tot_loss: 0.08967638902093711 - acc: 0.9713003264417845 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 1.2168893814086914 - sq_loss: 8.368504495592788e-06 - tot_loss: 0.09046310261232549 - acc: 0.9717083786724701 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 1.2612354755401611 - sq_loss: 8.265738870250061e-06 - tot_loss: 0.08576718106971981 - acc: 0.9715723612622416 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 1.272515058517456 - sq_loss: 8.165904546331149e-06 - tot_loss: 0.08699689805688848 - acc: 0.9721164309031556 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 1.2316927909851074 - sq_loss: 8.068480383371934e-06 - tot_loss: 0.08749360648153015 - acc: 0.9722524483133841 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 1.2631986141204834 - sq_loss: 7.98011024016887e-06 - tot_loss: 0.08387661486484888 - acc: 0.9727965179542981 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 1.237030029296875 - sq_loss: 7.888478648965247e-06 - tot_loss: 0.08618543718785787 - acc: 0.9727965179542981 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 1.2183833122253418 - sq_loss: 7.80303616920719e-06 - tot_loss: 0.0821152633918345 - acc: 0.9729325353645266 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 1.217940092086792 - sq_loss: 7.716913387412205e-06 - tot_loss: 0.08339426720106502 - acc: 0.9729325353645266 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 1.2499525547027588 - sq_loss: 7.64076776249567e-06 - tot_loss: 0.08350089095118562 - acc: 0.9730685527747551 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 1.2546172142028809 - sq_loss: 7.566412477899576e-06 - tot_loss: 0.0834465066406409 - acc: 0.9732045701849836 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 1.2220473289489746 - sq_loss: 7.490714779123664e-06 - tot_loss: 0.084078600634939 - acc: 0.9733405875952121 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 1.2440648078918457 - sq_loss: 7.424905561492778e-06 - tot_loss: 0.08079283183413821 - acc: 0.9740206746463548 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 1.2414515018463135 - sq_loss: 7.360829840763472e-06 - tot_loss: 0.08157631661980957 - acc: 0.9740206746463548 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 1.22110915184021 - sq_loss: 7.292546797543764e-06 - tot_loss: 0.07875634559488276 - acc: 0.9747007616974973 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 1.245234727859497 - sq_loss: 7.2311477197217755e-06 - tot_loss: 0.08135734884729828 - acc: 0.9749727965179543 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 1.2601397037506104 - sq_loss: 7.176359304139623e-06 - tot_loss: 0.07838821403037599 - acc: 0.9753808487486398 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 1.2194321155548096 - sq_loss: 7.120930604287423e-06 - tot_loss: 0.07977856891707091 - acc: 0.9756528835690969 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 1.233198881149292 - sq_loss: 7.060172265482834e-06 - tot_loss: 0.07638839691415455 - acc: 0.9760609357997824 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 1.236936330795288 - sq_loss: 7.000543064350495e-06 - tot_loss: 0.07637517594922372 - acc: 0.9761969532100109 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 1.2371537685394287 - sq_loss: 6.9479438025155105e-06 - tot_loss: 0.07712207310283503 - acc: 0.9763329706202394 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 1.2185473442077637 - sq_loss: 6.89755233906908e-06 - tot_loss: 0.0752407517853797 - acc: 0.9764689880304679 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 1.248642921447754 - sq_loss: 6.8433128035394475e-06 - tot_loss: 0.07540272973967888 - acc: 0.9764689880304679 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 1.2519640922546387 - sq_loss: 6.790950010326924e-06 - tot_loss: 0.07754769202306022 - acc: 0.9764689880304679 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 1.2287342548370361 - sq_loss: 6.741478955518687e-06 - tot_loss: 0.0769472573143446 - acc: 0.9766050054406964 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 1.2501397132873535 - sq_loss: 6.692904662486399e-06 - tot_loss: 0.07307622494693788 - acc: 0.9767410228509249 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 1.2433934211730957 - sq_loss: 6.65002471578191e-06 - tot_loss: 0.07444857706935082 - acc: 0.9767410228509249 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 1.292473316192627 - sq_loss: 6.606026090594241e-06 - tot_loss: 0.07244832473557139 - acc: 0.9768770402611534 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 1.2334790229797363 - sq_loss: 6.563671831827378e-06 - tot_loss: 0.07250959018378467 - acc: 0.9772850924918389 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 1.2351410388946533 - sq_loss: 6.524980108224554e-06 - tot_loss: 0.07412595314750092 - acc: 0.9772850924918389 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 1.2308900356292725 - sq_loss: 6.485262019850779e-06 - tot_loss: 0.07090440249432106 - acc: 0.977829162132753 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 1.2325482368469238 - sq_loss: 6.448289695981657e-06 - tot_loss: 0.0733828360788813 - acc: 0.97810119695321 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 1.2251684665679932 - sq_loss: 6.40951930108713e-06 - tot_loss: 0.07109949478570954 - acc: 0.9779651795429815 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 1.218724012374878 - sq_loss: 6.376045348588377e-06 - tot_loss: 0.07380203258481899 - acc: 0.9782372143634385 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 1.2198724746704102 - sq_loss: 6.343069799186196e-06 - tot_loss: 0.071531514903306 - acc: 0.9786452665941241 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 1.22725510597229 - sq_loss: 6.308314823399996e-06 - tot_loss: 0.07243073196816852 - acc: 0.9787812840043526 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 1.2186152935028076 - sq_loss: 6.273957751545822e-06 - tot_loss: 0.07088879067973508 - acc: 0.9789173014145811 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 1.222393274307251 - sq_loss: 6.24008407612564e-06 - tot_loss: 0.07134811630793791 - acc: 0.9790533188248096 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 1.2202696800231934 - sq_loss: 6.206718353496399e-06 - tot_loss: 0.0696037406662171 - acc: 0.9790533188248096 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 1.2224297523498535 - sq_loss: 6.174247573653702e-06 - tot_loss: 0.06964071043067577 - acc: 0.9793253536452666 - val_acc: 0.9548693586698337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 1.2212586402893066 - sq_loss: 6.145111001387704e-06 - tot_loss: 0.0710675093153732 - acc: 0.9794613710554951 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 1.2243781089782715 - sq_loss: 6.114502411946887e-06 - tot_loss: 0.07082230359879205 - acc: 0.9794613710554951 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 1.2293376922607422 - sq_loss: 6.08220079811872e-06 - tot_loss: 0.07198410282628842 - acc: 0.9797334058759521 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 1.2258822917938232 - sq_loss: 6.051996933820192e-06 - tot_loss: 0.07053473959171086 - acc: 0.9797334058759521 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 1.2253904342651367 - sq_loss: 6.022582510922803e-06 - tot_loss: 0.06933709599539029 - acc: 0.9798694232861807 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 1.2233898639678955 - sq_loss: 5.9932799558737315e-06 - tot_loss: 0.07095945111326785 - acc: 0.9800054406964092 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 1.2226223945617676 - sq_loss: 5.963485364191001e-06 - tot_loss: 0.07021501231431415 - acc: 0.9804134929270947 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 1.222336769104004 - sq_loss: 5.936225079494761e-06 - tot_loss: 0.06673503795066793 - acc: 0.9804134929270947 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 1.2184491157531738 - sq_loss: 5.9086396504426375e-06 - tot_loss: 0.06868330765303199 - acc: 0.9804134929270947 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 1.2240633964538574 - sq_loss: 5.882982350158272e-06 - tot_loss: 0.06638977955844538 - acc: 0.9805495103373232 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 1.221712350845337 - sq_loss: 5.860248165845405e-06 - tot_loss: 0.0697993734273652 - acc: 0.9809575625680087 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 1.2164556980133057 - sq_loss: 5.83648352403543e-06 - tot_loss: 0.06983333236194866 - acc: 0.9812295973884657 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 1.2252728939056396 - sq_loss: 5.8090954553335905e-06 - tot_loss: 0.06597736610837046 - acc: 0.9812295973884657 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 1.2194480895996094 - sq_loss: 5.784781478723744e-06 - tot_loss: 0.06753775611755941 - acc: 0.9812295973884657 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 1.2219622135162354 - sq_loss: 5.760412022937089e-06 - tot_loss: 0.0674270462581461 - acc: 0.9816376496191512 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 1.2251124382019043 - sq_loss: 5.729429176426493e-06 - tot_loss: 0.06298204870246593 - acc: 0.9815016322089227 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 1.2396876811981201 - sq_loss: 5.7053057389566675e-06 - tot_loss: 0.06572809859954276 - acc: 0.9816376496191512 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 1.221125602722168 - sq_loss: 5.684960342478007e-06 - tot_loss: 0.06715221684734374 - acc: 0.9819096844396082 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 1.2407007217407227 - sq_loss: 5.6641151786607224e-06 - tot_loss: 0.06928137938602674 - acc: 0.9820457018498367 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 1.2294795513153076 - sq_loss: 5.639091796183493e-06 - tot_loss: 0.06509495904492724 - acc: 0.9821817192600653 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 1.2216577529907227 - sq_loss: 5.619356215902371e-06 - tot_loss: 0.06853080518068921 - acc: 0.9821817192600653 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 1.2250926494598389 - sq_loss: 5.5971499932638835e-06 - tot_loss: 0.06395048316570495 - acc: 0.9821817192600653 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 1.2256436347961426 - sq_loss: 5.573593625740614e-06 - tot_loss: 0.06478575350344329 - acc: 0.9821817192600653 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 1.2398908138275146 - sq_loss: 5.553219125431497e-06 - tot_loss: 0.06649285864974885 - acc: 0.9823177366702938 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 1.2683532238006592 - sq_loss: 5.5340660765068606e-06 - tot_loss: 0.06651233710011795 - acc: 0.9824537540805223 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 1.2422449588775635 - sq_loss: 5.514989879884524e-06 - tot_loss: 0.06713019733435033 - acc: 0.9821817192600653 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 1.2761096954345703 - sq_loss: 5.495040568348486e-06 - tot_loss: 0.06594435103726326 - acc: 0.9820457018498367 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 1.2671794891357422 - sq_loss: 5.477541435539024e-06 - tot_loss: 0.06339629973508565 - acc: 0.9824537540805223 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 1.2491071224212646 - sq_loss: 5.4562829063797835e-06 - tot_loss: 0.06795652579258515 - acc: 0.9823177366702938 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 1.240262746810913 - sq_loss: 5.434508693724638e-06 - tot_loss: 0.06300969967582404 - acc: 0.9824537540805223 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 1.2715516090393066 - sq_loss: 5.413485723693157e-06 - tot_loss: 0.06453492652359927 - acc: 0.9824537540805223 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 1.2368175983428955 - sq_loss: 5.396703272708692e-06 - tot_loss: 0.06367197003853065 - acc: 0.9825897714907508 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 1.2450881004333496 - sq_loss: 5.378149580792524e-06 - tot_loss: 0.06697598853381592 - acc: 0.9824537540805223 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 1.24477219581604 - sq_loss: 5.359088845580118e-06 - tot_loss: 0.06360511400931657 - acc: 0.9827257889009793 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 1.233020305633545 - sq_loss: 5.342483291315148e-06 - tot_loss: 0.06368184134922572 - acc: 0.9827257889009793 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 1.225318431854248 - sq_loss: 5.321671324054478e-06 - tot_loss: 0.0666672492585505 - acc: 0.9828618063112078 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 1.2539734840393066 - sq_loss: 5.304608293954516e-06 - tot_loss: 0.06158373082652702 - acc: 0.9825897714907508 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 1.2478086948394775 - sq_loss: 5.2849313760816585e-06 - tot_loss: 0.0641155430448137 - acc: 0.9829978237214363 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 1.265007495880127 - sq_loss: 5.2642317314166576e-06 - tot_loss: 0.06005387076695712 - acc: 0.9829978237214363 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 1.258866786956787 - sq_loss: 5.244140538707143e-06 - tot_loss: 0.06314409806990895 - acc: 0.9831338411316648 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 1.2261550426483154 - sq_loss: 5.226912435318809e-06 - tot_loss: 0.060596719893840856 - acc: 0.9832698585418934 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 1.259282112121582 - sq_loss: 5.208487436902942e-06 - tot_loss: 0.06216417958018283 - acc: 0.9831338411316648 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 1.2291216850280762 - sq_loss: 5.193352535570739e-06 - tot_loss: 0.06374565358162343 - acc: 0.9829978237214363 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 1.221477746963501 - sq_loss: 5.175755632080836e-06 - tot_loss: 0.061399259966790964 - acc: 0.9832698585418934 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 1.2444357872009277 - sq_loss: 5.1604820328066126e-06 - tot_loss: 0.0628493009209059 - acc: 0.9832698585418934 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 1.2205333709716797 - sq_loss: 5.143859198142309e-06 - tot_loss: 0.061288667632638294 - acc: 0.9834058759521219 - val_acc: 0.9555480149304377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 1.2220814228057861 - sq_loss: 5.125708867126377e-06 - tot_loss: 0.06371520783604367 - acc: 0.9834058759521219 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 1.220705509185791 - sq_loss: 5.110386155138258e-06 - tot_loss: 0.06629589262702495 - acc: 0.9832698585418934 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 1.2213850021362305 - sq_loss: 5.093066192785045e-06 - tot_loss: 0.06329836128486832 - acc: 0.9835418933623504 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 1.2242672443389893 - sq_loss: 5.079349648440257e-06 - tot_loss: 0.062485630996723884 - acc: 0.9836779107725789 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 1.2194857597351074 - sq_loss: 5.065609911980573e-06 - tot_loss: 0.06085188855005619 - acc: 0.9835418933623504 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 1.2338354587554932 - sq_loss: 5.049693754699547e-06 - tot_loss: 0.0610597728976181 - acc: 0.9835418933623504 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 1.2215747833251953 - sq_loss: 5.0338258006377146e-06 - tot_loss: 0.058870058623867294 - acc: 0.9834058759521219 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 1.2168257236480713 - sq_loss: 5.018571300752228e-06 - tot_loss: 0.06082526192750315 - acc: 0.9834058759521219 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 1.2218492031097412 - sq_loss: 5.0004136937786825e-06 - tot_loss: 0.0597032188233122 - acc: 0.9835418933623504 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 1.2468359470367432 - sq_loss: 4.984578481526114e-06 - tot_loss: 0.062391358243520045 - acc: 0.9835418933623504 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 1.2216565608978271 - sq_loss: 4.969343990524067e-06 - tot_loss: 0.05898669213442709 - acc: 0.9838139281828074 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 1.2277095317840576 - sq_loss: 4.954311862093164e-06 - tot_loss: 0.060652797556567606 - acc: 0.9840859630032645 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 1.2359189987182617 - sq_loss: 4.939466180076124e-06 - tot_loss: 0.06057089223782164 - acc: 0.9840859630032645 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 1.2283053398132324 - sq_loss: 4.924923814542126e-06 - tot_loss: 0.06108715319048841 - acc: 0.98449401523395 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 1.2683773040771484 - sq_loss: 4.9089562708104495e-06 - tot_loss: 0.059373985508131 - acc: 0.98449401523395 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 1.253650188446045 - sq_loss: 4.893425284535624e-06 - tot_loss: 0.06270813209852832 - acc: 0.9846300326441785 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 1.2277412414550781 - sq_loss: 4.877423634752631e-06 - tot_loss: 0.06080185802175819 - acc: 0.9846300326441785 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 1.250805139541626 - sq_loss: 4.864291440753732e-06 - tot_loss: 0.06296890742863681 - acc: 0.9846300326441785 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 1.235262393951416 - sq_loss: 4.850056029681582e-06 - tot_loss: 0.06067521478024496 - acc: 0.9846300326441785 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 1.2487819194793701 - sq_loss: 4.835925665247487e-06 - tot_loss: 0.05702078723028414 - acc: 0.9849020674646355 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 1.2430081367492676 - sq_loss: 4.823593826586148e-06 - tot_loss: 0.06347422373245593 - acc: 0.9849020674646355 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 1.2637174129486084 - sq_loss: 4.8108499868249055e-06 - tot_loss: 0.06299902982366135 - acc: 0.984766050054407 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 1.2594680786132812 - sq_loss: 4.797267138201278e-06 - tot_loss: 0.0599989096621556 - acc: 0.985038084874864 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 1.2468957901000977 - sq_loss: 4.782909400091739e-06 - tot_loss: 0.058130002330363695 - acc: 0.9851741022850925 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 1.2484321594238281 - sq_loss: 4.768065537064103e-06 - tot_loss: 0.06229995132478905 - acc: 0.9851741022850925 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 1.2359185218811035 - sq_loss: 4.7535618250549305e-06 - tot_loss: 0.05893871365073089 - acc: 0.985310119695321 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 1.2742159366607666 - sq_loss: 4.739753876492614e-06 - tot_loss: 0.06046761573879955 - acc: 0.985038084874864 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 1.2781479358673096 - sq_loss: 4.72907140647294e-06 - tot_loss: 0.05799708249326763 - acc: 0.985310119695321 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 1.257262945175171 - sq_loss: 4.714411716122413e-06 - tot_loss: 0.0596978524806655 - acc: 0.985310119695321 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 1.2787590026855469 - sq_loss: 4.703049853560515e-06 - tot_loss: 0.062495238322995306 - acc: 0.985310119695321 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 1.235825538635254 - sq_loss: 4.691804861067794e-06 - tot_loss: 0.058585802645742646 - acc: 0.985310119695321 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 1.228391170501709 - sq_loss: 4.679720859712688e-06 - tot_loss: 0.05688794115815732 - acc: 0.9851741022850925 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 1.2524254322052002 - sq_loss: 4.667934263125062e-06 - tot_loss: 0.05929432756990494 - acc: 0.985310119695321 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 1.2242679595947266 - sq_loss: 4.654707936424529e-06 - tot_loss: 0.059047097188118514 - acc: 0.985310119695321 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 1.2386269569396973 - sq_loss: 4.6431473492702935e-06 - tot_loss: 0.05972197548441471 - acc: 0.985310119695321 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 1.2229368686676025 - sq_loss: 4.6328814278240316e-06 - tot_loss: 0.0575990427081301 - acc: 0.985310119695321 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 1.2229015827178955 - sq_loss: 4.62218986285734e-06 - tot_loss: 0.05794738524856413 - acc: 0.985310119695321 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 1.2236213684082031 - sq_loss: 4.609141342371004e-06 - tot_loss: 0.05823870153381705 - acc: 0.985310119695321 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 1.2353689670562744 - sq_loss: 4.59796137874946e-06 - tot_loss: 0.05698462564617124 - acc: 0.985310119695321 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 1.235114336013794 - sq_loss: 4.585001533996547e-06 - tot_loss: 0.05866884523663707 - acc: 0.985310119695321 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 1.2352368831634521 - sq_loss: 4.571569661493413e-06 - tot_loss: 0.06271193436223754 - acc: 0.9854461371055495 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 1.2221078872680664 - sq_loss: 4.558685304800747e-06 - tot_loss: 0.06023119709962188 - acc: 0.9854461371055495 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 1.2444815635681152 - sq_loss: 4.546045147435507e-06 - tot_loss: 0.05834826254664627 - acc: 0.985582154515778 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 1.2212061882019043 - sq_loss: 4.533138508122647e-06 - tot_loss: 0.05643472132029714 - acc: 0.985582154515778 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 1.2201919555664062 - sq_loss: 4.522251856542425e-06 - tot_loss: 0.05919844653725548 - acc: 0.985582154515778 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 1.2201502323150635 - sq_loss: 4.511561201070435e-06 - tot_loss: 0.06127418512991234 - acc: 0.9854461371055495 - val_acc: 0.9586019681031558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 1.2235870361328125 - sq_loss: 4.5000292629993055e-06 - tot_loss: 0.05915650541076012 - acc: 0.985582154515778 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 1.2339684963226318 - sq_loss: 4.488995273277396e-06 - tot_loss: 0.05538795451801448 - acc: 0.9857181719260065 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 1.2212536334991455 - sq_loss: 4.4797502596338745e-06 - tot_loss: 0.055870027855249305 - acc: 0.9854461371055495 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 1.2514348030090332 - sq_loss: 4.470084149943432e-06 - tot_loss: 0.05415501215862939 - acc: 0.985582154515778 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 1.241487741470337 - sq_loss: 4.459436695469776e-06 - tot_loss: 0.05547401949359276 - acc: 0.985854189336235 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 1.2227563858032227 - sq_loss: 4.448379968380323e-06 - tot_loss: 0.059584751303766836 - acc: 0.985854189336235 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 1.2210443019866943 - sq_loss: 4.436868039192632e-06 - tot_loss: 0.05723071741292607 - acc: 0.9859902067464635 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 1.223418951034546 - sq_loss: 4.425643965078052e-06 - tot_loss: 0.05876671857923377 - acc: 0.9859902067464635 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 1.252626895904541 - sq_loss: 4.413301667227643e-06 - tot_loss: 0.0583653557570063 - acc: 0.985854189336235 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 1.2594513893127441 - sq_loss: 4.402846570883412e-06 - tot_loss: 0.059191350520855224 - acc: 0.986126224156692 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 1.2478907108306885 - sq_loss: 4.392300979816355e-06 - tot_loss: 0.060510309854411304 - acc: 0.9862622415669206 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 1.2541491985321045 - sq_loss: 4.379703113954747e-06 - tot_loss: 0.05917018288465492 - acc: 0.9865342763873776 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 1.2446391582489014 - sq_loss: 4.366880148154451e-06 - tot_loss: 0.05581861412377087 - acc: 0.9865342763873776 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 1.2348055839538574 - sq_loss: 4.358188562036958e-06 - tot_loss: 0.05816811504311303 - acc: 0.9863982589771491 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 1.2325282096862793 - sq_loss: 4.3461291170387994e-06 - tot_loss: 0.05822709177761354 - acc: 0.9866702937976061 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 1.2524750232696533 - sq_loss: 4.334244295023382e-06 - tot_loss: 0.05472656187751035 - acc: 0.9866702937976061 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 1.2232356071472168 - sq_loss: 4.323782377468888e-06 - tot_loss: 0.05621197946035217 - acc: 0.9868063112078346 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 1.219895839691162 - sq_loss: 4.313776116759982e-06 - tot_loss: 0.05612098238499463 - acc: 0.9868063112078346 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 1.2476022243499756 - sq_loss: 4.304854883230291e-06 - tot_loss: 0.05798892348896345 - acc: 0.9866702937976061 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 1.2547049522399902 - sq_loss: 4.295155122235883e-06 - tot_loss: 0.05576820330406029 - acc: 0.9868063112078346 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 1.2435519695281982 - sq_loss: 4.284773240215145e-06 - tot_loss: 0.05711030760403979 - acc: 0.9869423286180631 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 1.2332415580749512 - sq_loss: 4.275320861779619e-06 - tot_loss: 0.056270504835152835 - acc: 0.9869423286180631 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 1.241621971130371 - sq_loss: 4.265475581632927e-06 - tot_loss: 0.055808196969113766 - acc: 0.9869423286180631 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 1.2366647720336914 - sq_loss: 4.254229679645505e-06 - tot_loss: 0.054116798970568425 - acc: 0.9869423286180631 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 1.2498714923858643 - sq_loss: 4.244935553288087e-06 - tot_loss: 0.05707442636977689 - acc: 0.9870783460282916 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 1.234473466873169 - sq_loss: 4.234263087710133e-06 - tot_loss: 0.055877265632647166 - acc: 0.9870783460282916 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 1.2289528846740723 - sq_loss: 4.224366875860142e-06 - tot_loss: 0.055828553665479674 - acc: 0.9870783460282916 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 1.221050500869751 - sq_loss: 4.215040462440811e-06 - tot_loss: 0.058255735044019374 - acc: 0.9870783460282916 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 1.222954511642456 - sq_loss: 4.20784272137098e-06 - tot_loss: 0.055916473907220876 - acc: 0.9870783460282916 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 1.2454149723052979 - sq_loss: 4.197677753836615e-06 - tot_loss: 0.054743606118492494 - acc: 0.9872143634385201 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 1.2385146617889404 - sq_loss: 4.188197181065334e-06 - tot_loss: 0.056437660860465755 - acc: 0.9873503808487486 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 1.229816198348999 - sq_loss: 4.180349151283735e-06 - tot_loss: 0.05814301106118869 - acc: 0.9873503808487486 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 1.2503809928894043 - sq_loss: 4.169911335338838e-06 - tot_loss: 0.054805854696084566 - acc: 0.9873503808487486 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 1.247786283493042 - sq_loss: 4.159611762588611e-06 - tot_loss: 0.05429628581953416 - acc: 0.9873503808487486 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 1.2196214199066162 - sq_loss: 4.1491193769616075e-06 - tot_loss: 0.05498312576664155 - acc: 0.9873503808487486 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 1.2194271087646484 - sq_loss: 4.137790256208973e-06 - tot_loss: 0.05764074966024069 - acc: 0.9873503808487486 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 1.219735860824585 - sq_loss: 4.128300588490674e-06 - tot_loss: 0.05374210613629771 - acc: 0.9873503808487486 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 1.2145462036132812 - sq_loss: 4.118485321669141e-06 - tot_loss: 0.054118329197493154 - acc: 0.9873503808487486 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 1.230426549911499 - sq_loss: 4.110681402380578e-06 - tot_loss: 0.0572545281417014 - acc: 0.9874863982589771 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 1.2177999019622803 - sq_loss: 4.1034063542610966e-06 - tot_loss: 0.04972021890580791 - acc: 0.9874863982589771 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 1.221376657485962 - sq_loss: 4.095721578778466e-06 - tot_loss: 0.05197617371370811 - acc: 0.9874863982589771 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 1.2507262229919434 - sq_loss: 4.087940851604799e-06 - tot_loss: 0.05777616586691181 - acc: 0.9874863982589771 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 1.234344244003296 - sq_loss: 4.077882294950541e-06 - tot_loss: 0.05730029776082013 - acc: 0.9874863982589771 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 1.2585818767547607 - sq_loss: 4.067630470672157e-06 - tot_loss: 0.05388975617626102 - acc: 0.9874863982589771 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 1.22637939453125 - sq_loss: 4.057944352098275e-06 - tot_loss: 0.053219653776508835 - acc: 0.9874863982589771 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 1.2260055541992188 - sq_loss: 4.051593350595795e-06 - tot_loss: 0.0587762217283867 - acc: 0.9874863982589771 - val_acc: 0.9613165931455717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 1.2334909439086914 - sq_loss: 4.0438276300847065e-06 - tot_loss: 0.05483849529569618 - acc: 0.9874863982589771 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 1.2353639602661133 - sq_loss: 4.034876837977208e-06 - tot_loss: 0.05388809941672967 - acc: 0.9874863982589771 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 1.236842155456543 - sq_loss: 4.0267327676701825e-06 - tot_loss: 0.05315090214898177 - acc: 0.9874863982589771 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 1.231215476989746 - sq_loss: 4.017878382001072e-06 - tot_loss: 0.05106918089120782 - acc: 0.9874863982589771 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 1.2235352993011475 - sq_loss: 4.008482846984407e-06 - tot_loss: 0.05482889479731945 - acc: 0.9876224156692056 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 1.2208607196807861 - sq_loss: 3.9992842175706755e-06 - tot_loss: 0.053830790618247804 - acc: 0.9878944504896626 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 1.2189416885375977 - sq_loss: 3.989498054579599e-06 - tot_loss: 0.05789553915428414 - acc: 0.9876224156692056 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 1.2248966693878174 - sq_loss: 3.97992107536993e-06 - tot_loss: 0.054789112761572056 - acc: 0.9877584330794341 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 1.2180185317993164 - sq_loss: 3.972543709096499e-06 - tot_loss: 0.054578710708304 - acc: 0.9878944504896626 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 1.2205443382263184 - sq_loss: 3.965566520491848e-06 - tot_loss: 0.053872772310205264 - acc: 0.9877584330794341 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 1.2234973907470703 - sq_loss: 3.958829893235816e-06 - tot_loss: 0.05495551886155603 - acc: 0.9877584330794341 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 1.219857931137085 - sq_loss: 3.948247467633337e-06 - tot_loss: 0.05621240710373776 - acc: 0.9878944504896626 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 1.2192065715789795 - sq_loss: 3.9402016227541026e-06 - tot_loss: 0.052860681882860305 - acc: 0.9876224156692056 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 1.2194156646728516 - sq_loss: 3.931283117708517e-06 - tot_loss: 0.053878202994797064 - acc: 0.9876224156692056 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 1.222480058670044 - sq_loss: 3.92285619454924e-06 - tot_loss: 0.055808153404296235 - acc: 0.9878944504896626 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 1.2199716567993164 - sq_loss: 3.913451109838206e-06 - tot_loss: 0.055814029832806256 - acc: 0.9876224156692056 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 1.2248632907867432 - sq_loss: 3.904892309947172e-06 - tot_loss: 0.052846967190424365 - acc: 0.9878944504896626 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 1.2227742671966553 - sq_loss: 3.896097496181028e-06 - tot_loss: 0.0545512286492702 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 1.2214598655700684 - sq_loss: 3.887086677423213e-06 - tot_loss: 0.05232103389055709 - acc: 0.9877584330794341 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 1.219562292098999 - sq_loss: 3.8774187487433665e-06 - tot_loss: 0.053724594499847456 - acc: 0.9878944504896626 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 1.2183828353881836 - sq_loss: 3.869085503538372e-06 - tot_loss: 0.05415585383713584 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 1.2198472023010254 - sq_loss: 3.8603798202530015e-06 - tot_loss: 0.053590007344899604 - acc: 0.9877584330794341 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 1.223344087600708 - sq_loss: 3.853631369565846e-06 - tot_loss: 0.053913289471262615 - acc: 0.9877584330794341 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 1.2191493511199951 - sq_loss: 3.846108484140132e-06 - tot_loss: 0.0533397325284799 - acc: 0.9877584330794341 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 1.217804193496704 - sq_loss: 3.837937583739404e-06 - tot_loss: 0.05514551197272688 - acc: 0.9877584330794341 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 1.223231554031372 - sq_loss: 3.830410605587531e-06 - tot_loss: 0.0538179111690642 - acc: 0.9877584330794341 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 1.2260584831237793 - sq_loss: 3.822603048320161e-06 - tot_loss: 0.05586336948068116 - acc: 0.9877584330794341 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 1.2212140560150146 - sq_loss: 3.8143984966154676e-06 - tot_loss: 0.05219631510536615 - acc: 0.9877584330794341 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 1.2267014980316162 - sq_loss: 3.808502469837549e-06 - tot_loss: 0.055930960226906024 - acc: 0.9876224156692056 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 1.2266063690185547 - sq_loss: 3.8019613839423982e-06 - tot_loss: 0.055995381865702853 - acc: 0.9878944504896626 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 1.2207584381103516 - sq_loss: 3.795999191424926e-06 - tot_loss: 0.051000025646146696 - acc: 0.9878944504896626 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 1.2237820625305176 - sq_loss: 3.788910817092983e-06 - tot_loss: 0.05475246821167268 - acc: 0.9878944504896626 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 1.224501609802246 - sq_loss: 3.7795493881276343e-06 - tot_loss: 0.053176975146719485 - acc: 0.9877584330794341 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 1.2205054759979248 - sq_loss: 3.7719555621151812e-06 - tot_loss: 0.05479004749965455 - acc: 0.9878944504896626 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 1.229891300201416 - sq_loss: 3.765346036743722e-06 - tot_loss: 0.05323985786041163 - acc: 0.9878944504896626 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 1.2268285751342773 - sq_loss: 3.7585923564620316e-06 - tot_loss: 0.05556991676608192 - acc: 0.9878944504896626 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 1.222963809967041 - sq_loss: 3.752731572603807e-06 - tot_loss: 0.054852519434756886 - acc: 0.9880304678998912 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 1.2339367866516113 - sq_loss: 3.7464467368408805e-06 - tot_loss: 0.05450540702332951 - acc: 0.9880304678998912 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 1.239149808883667 - sq_loss: 3.739892463272554e-06 - tot_loss: 0.05406051466453299 - acc: 0.9878944504896626 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 1.2411201000213623 - sq_loss: 3.7335075830924325e-06 - tot_loss: 0.05249851025298469 - acc: 0.9881664853101197 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 1.2359027862548828 - sq_loss: 3.7271522614901187e-06 - tot_loss: 0.0569057471905996 - acc: 0.9880304678998912 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 1.2708029747009277 - sq_loss: 3.7198194604570745e-06 - tot_loss: 0.05313899709712544 - acc: 0.9881664853101197 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 1.234126329421997 - sq_loss: 3.711076260515256e-06 - tot_loss: 0.05635280193018133 - acc: 0.9883025027203483 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 1.238297700881958 - sq_loss: 3.7033041735412553e-06 - tot_loss: 0.05361000479652489 - acc: 0.9881664853101197 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 1.244488000869751 - sq_loss: 3.6965805065847235e-06 - tot_loss: 0.049623652017958264 - acc: 0.9881664853101197 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 1.230750560760498 - sq_loss: 3.6876908779959194e-06 - tot_loss: 0.05203058773928859 - acc: 0.9878944504896626 - val_acc: 0.9606379368849678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 1.2460644245147705 - sq_loss: 3.680769395941752e-06 - tot_loss: 0.05494824272952137 - acc: 0.9880304678998912 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 1.2371625900268555 - sq_loss: 3.6733606521011097e-06 - tot_loss: 0.05361683711200094 - acc: 0.9880304678998912 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 1.219374418258667 - sq_loss: 3.665293434096384e-06 - tot_loss: 0.057042502710118015 - acc: 0.9883025027203483 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 1.244290828704834 - sq_loss: 3.6568503674061503e-06 - tot_loss: 0.05124627500945422 - acc: 0.9883025027203483 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 1.223787784576416 - sq_loss: 3.65064556717698e-06 - tot_loss: 0.05372543558866738 - acc: 0.9881664853101197 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 1.2199530601501465 - sq_loss: 3.645029892140883e-06 - tot_loss: 0.05086818137335136 - acc: 0.9880304678998912 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 1.2429156303405762 - sq_loss: 3.6384478789841523e-06 - tot_loss: 0.051180848223179254 - acc: 0.9881664853101197 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 1.2208657264709473 - sq_loss: 3.6332805848360294e-06 - tot_loss: 0.051494531361726104 - acc: 0.9881664853101197 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 1.2198560237884521 - sq_loss: 3.6255873965274077e-06 - tot_loss: 0.050959920519346724 - acc: 0.9881664853101197 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 1.2389369010925293 - sq_loss: 3.619469225668581e-06 - tot_loss: 0.050307726378498785 - acc: 0.9881664853101197 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 1.2243406772613525 - sq_loss: 3.613397439039545e-06 - tot_loss: 0.05114126356629001 - acc: 0.9880304678998912 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 1.2448902130126953 - sq_loss: 3.6074891340831527e-06 - tot_loss: 0.053105077314363314 - acc: 0.9881664853101197 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 1.2444632053375244 - sq_loss: 3.6003498280479107e-06 - tot_loss: 0.04882874703825024 - acc: 0.9881664853101197 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 1.2310004234313965 - sq_loss: 3.5920904792874353e-06 - tot_loss: 0.050745000350563174 - acc: 0.9883025027203483 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 1.2517993450164795 - sq_loss: 3.584450269045192e-06 - tot_loss: 0.05084624353668943 - acc: 0.9884385201305768 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 1.237523078918457 - sq_loss: 3.5785415093414485e-06 - tot_loss: 0.05023381736516441 - acc: 0.9881664853101197 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 1.234391450881958 - sq_loss: 3.57160911335086e-06 - tot_loss: 0.05446965971140649 - acc: 0.9883025027203483 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 1.2569377422332764 - sq_loss: 3.5650589325086912e-06 - tot_loss: 0.05020250249699565 - acc: 0.9884385201305768 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 1.2272987365722656 - sq_loss: 3.558732714736834e-06 - tot_loss: 0.051532418182612005 - acc: 0.9883025027203483 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 1.2441766262054443 - sq_loss: 3.5545567698136438e-06 - tot_loss: 0.05196142409137927 - acc: 0.9884385201305768 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 1.2286863327026367 - sq_loss: 3.5469026897771982e-06 - tot_loss: 0.051086492569462294 - acc: 0.9884385201305768 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 1.230719804763794 - sq_loss: 3.5393707094044657e-06 - tot_loss: 0.0544240583336304 - acc: 0.9884385201305768 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 1.2282681465148926 - sq_loss: 3.5339739952178206e-06 - tot_loss: 0.05287870387313376 - acc: 0.9884385201305768 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 1.2234435081481934 - sq_loss: 3.528958586684894e-06 - tot_loss: 0.05226968782323915 - acc: 0.9884385201305768 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 1.2401525974273682 - sq_loss: 3.521799953887239e-06 - tot_loss: 0.04875058889032324 - acc: 0.9887105549510338 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 1.242253065109253 - sq_loss: 3.514511263347231e-06 - tot_loss: 0.05086404912790954 - acc: 0.9887105549510338 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 1.2384917736053467 - sq_loss: 3.508391273499001e-06 - tot_loss: 0.05529524240574446 - acc: 0.9887105549510338 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 1.2271268367767334 - sq_loss: 3.500873390294146e-06 - tot_loss: 0.05106465915084524 - acc: 0.9887105549510338 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 1.2501864433288574 - sq_loss: 3.493750682537211e-06 - tot_loss: 0.05475111602631788 - acc: 0.9887105549510338 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 1.2359066009521484 - sq_loss: 3.4868685361288954e-06 - tot_loss: 0.05066591717576863 - acc: 0.9887105549510338 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 1.2511143684387207 - sq_loss: 3.4809711451089242e-06 - tot_loss: 0.05308735022977373 - acc: 0.9888465723612623 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 1.2539615631103516 - sq_loss: 3.475512812656234e-06 - tot_loss: 0.05016821701631091 - acc: 0.9892546245919478 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 1.2428274154663086 - sq_loss: 3.4685892842389876e-06 - tot_loss: 0.05010259651045157 - acc: 0.9887105549510338 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 1.2623462677001953 - sq_loss: 3.463342181930784e-06 - tot_loss: 0.04997773220621049 - acc: 0.9888465723612623 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 1.2484610080718994 - sq_loss: 3.4575041354401037e-06 - tot_loss: 0.048018803216326233 - acc: 0.9888465723612623 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 1.2210099697113037 - sq_loss: 3.451696102274582e-06 - tot_loss: 0.05044647878787334 - acc: 0.9887105549510338 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 1.2311618328094482 - sq_loss: 3.4460992992535466e-06 - tot_loss: 0.04920958278777032 - acc: 0.9888465723612623 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 1.2332379817962646 - sq_loss: 3.4414592846587766e-06 - tot_loss: 0.049750262455320104 - acc: 0.9891186071817193 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 1.2293932437896729 - sq_loss: 3.4356141895841574e-06 - tot_loss: 0.05039307110829494 - acc: 0.9891186071817193 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 1.234400987625122 - sq_loss: 3.4286308618902694e-06 - tot_loss: 0.05283014663284202 - acc: 0.9889825897714908 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 1.2355568408966064 - sq_loss: 3.423723455853178e-06 - tot_loss: 0.05454384596966033 - acc: 0.9888465723612623 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 1.2223684787750244 - sq_loss: 3.4184392916358775e-06 - tot_loss: 0.04928113826029534 - acc: 0.9891186071817193 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 1.253615379333496 - sq_loss: 3.4132949622289743e-06 - tot_loss: 0.050232675697057694 - acc: 0.9892546245919478 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 1.235161542892456 - sq_loss: 3.4075383155141026e-06 - tot_loss: 0.05260367630070917 - acc: 0.9892546245919478 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 1.2298262119293213 - sq_loss: 3.4010931813099887e-06 - tot_loss: 0.04906264760655521 - acc: 0.9892546245919478 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 1.2285873889923096 - sq_loss: 3.396501142560737e-06 - tot_loss: 0.053631552912333014 - acc: 0.9891186071817193 - val_acc: 0.9619952494061758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 1.2603552341461182 - sq_loss: 3.3926446576515445e-06 - tot_loss: 0.05252368245577266 - acc: 0.9891186071817193 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 1.2683119773864746 - sq_loss: 3.3867872843984514e-06 - tot_loss: 0.04988822496542955 - acc: 0.9891186071817193 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 1.2292306423187256 - sq_loss: 3.3807493764470564e-06 - tot_loss: 0.053747309910685104 - acc: 0.9893906420021763 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 1.2561426162719727 - sq_loss: 3.373228764758096e-06 - tot_loss: 0.05409394979574422 - acc: 0.9893906420021763 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 1.2220633029937744 - sq_loss: 3.3662147416180233e-06 - tot_loss: 0.04932406130324818 - acc: 0.9895266594124048 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 1.2195301055908203 - sq_loss: 3.361734115969739e-06 - tot_loss: 0.04897960879743746 - acc: 0.9892546245919478 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 1.2234539985656738 - sq_loss: 3.3568803701200522e-06 - tot_loss: 0.050871983970982804 - acc: 0.9893906420021763 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 1.2278778553009033 - sq_loss: 3.350760835019173e-06 - tot_loss: 0.04966798465382993 - acc: 0.9895266594124048 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 1.2255222797393799 - sq_loss: 3.3428066217311425e-06 - tot_loss: 0.05590632407188956 - acc: 0.9895266594124048 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 1.2154581546783447 - sq_loss: 3.3363362490490545e-06 - tot_loss: 0.05071196968026026 - acc: 0.9895266594124048 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 1.2330021858215332 - sq_loss: 3.330878371343715e-06 - tot_loss: 0.05294479633977822 - acc: 0.9895266594124048 - val_acc: 0.9616559212758737\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 1.2231574058532715 - sq_loss: 3.3255407743126852e-06 - tot_loss: 0.050964369772378504 - acc: 0.9895266594124048 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 1.2218208312988281 - sq_loss: 3.320013775010011e-06 - tot_loss: 0.054466309161997906 - acc: 0.9895266594124048 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 1.2265493869781494 - sq_loss: 3.315275762361125e-06 - tot_loss: 0.05141182311292081 - acc: 0.9895266594124048 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 1.2229785919189453 - sq_loss: 3.311020918772556e-06 - tot_loss: 0.050294440540141316 - acc: 0.9895266594124048 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 1.2206196784973145 - sq_loss: 3.3060564419429284e-06 - tot_loss: 0.05315238738488137 - acc: 0.9895266594124048 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 1.2377142906188965 - sq_loss: 3.3024691674654605e-06 - tot_loss: 0.052985558314987635 - acc: 0.9895266594124048 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 1.2440259456634521 - sq_loss: 3.2960240332613466e-06 - tot_loss: 0.04760564391733624 - acc: 0.9895266594124048 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 1.2293190956115723 - sq_loss: 3.2897346500249114e-06 - tot_loss: 0.04732103052987213 - acc: 0.9895266594124048 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 1.2205312252044678 - sq_loss: 3.28315218212083e-06 - tot_loss: 0.04908415785511533 - acc: 0.9895266594124048 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 1.2207043170928955 - sq_loss: 3.2773248221928952e-06 - tot_loss: 0.052817554135223155 - acc: 0.9895266594124048 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 1.256026029586792 - sq_loss: 3.271711648267228e-06 - tot_loss: 0.04785795165740314 - acc: 0.9895266594124048 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 1.220747470855713 - sq_loss: 3.2667071536707226e-06 - tot_loss: 0.05045713288664899 - acc: 0.9895266594124048 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 1.2207541465759277 - sq_loss: 3.262301333961659e-06 - tot_loss: 0.050567457304500074 - acc: 0.9895266594124048 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 1.2262539863586426 - sq_loss: 3.2567916150583187e-06 - tot_loss: 0.05071372092027282 - acc: 0.9895266594124048 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 1.2424283027648926 - sq_loss: 3.2529183044971433e-06 - tot_loss: 0.04916234875608172 - acc: 0.9895266594124048 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 1.2366843223571777 - sq_loss: 3.2467323762830347e-06 - tot_loss: 0.05487296815011078 - acc: 0.9895266594124048 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 1.2316222190856934 - sq_loss: 3.242903630962246e-06 - tot_loss: 0.052755533193487913 - acc: 0.9895266594124048 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 1.2315564155578613 - sq_loss: 3.2375569389841985e-06 - tot_loss: 0.05490620138559077 - acc: 0.9895266594124048 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 1.2340209484100342 - sq_loss: 3.233141342207091e-06 - tot_loss: 0.05284863828344388 - acc: 0.9895266594124048 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 1.2243244647979736 - sq_loss: 3.2289829050569097e-06 - tot_loss: 0.04559266233488568 - acc: 0.9895266594124048 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 1.2422692775726318 - sq_loss: 3.2239622669294477e-06 - tot_loss: 0.047842279711598046 - acc: 0.9895266594124048 - val_acc: 0.9619952494061758\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 1.2453484535217285 - sq_loss: 3.217795892851427e-06 - tot_loss: 0.050389184888689265 - acc: 0.9895266594124048 - val_acc: 0.9623345775364778\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 1.2338225841522217 - sq_loss: 3.2118391573021654e-06 - tot_loss: 0.05154933489568059 - acc: 0.9895266594124048 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 1.2240197658538818 - sq_loss: 3.2059506338555366e-06 - tot_loss: 0.05121100412458013 - acc: 0.9895266594124048 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 1.2728888988494873 - sq_loss: 3.2011676012189128e-06 - tot_loss: 0.052073750823063314 - acc: 0.9895266594124048 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 1.253861904144287 - sq_loss: 3.1970425879990216e-06 - tot_loss: 0.04996693747755909 - acc: 0.9895266594124048 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 1.2428820133209229 - sq_loss: 3.1931617741065565e-06 - tot_loss: 0.04805620747626271 - acc: 0.9895266594124048 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 1.263963222503662 - sq_loss: 3.188778464391362e-06 - tot_loss: 0.049029637741877075 - acc: 0.9895266594124048 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 1.2550151348114014 - sq_loss: 3.1843474062043242e-06 - tot_loss: 0.05086412620910341 - acc: 0.9895266594124048 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 1.2287399768829346 - sq_loss: 3.1805884646018967e-06 - tot_loss: 0.04917686064985105 - acc: 0.9895266594124048 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 1.2614755630493164 - sq_loss: 3.176435939167277e-06 - tot_loss: 0.04947989972319089 - acc: 0.9895266594124048 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 1.254023790359497 - sq_loss: 3.1717008823761716e-06 - tot_loss: 0.04974233969396735 - acc: 0.9895266594124048 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 1.241744041442871 - sq_loss: 3.1681581731390906e-06 - tot_loss: 0.04800284664348364 - acc: 0.9895266594124048 - val_acc: 0.9626739056667798\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 1.2664356231689453 - sq_loss: 3.1633812795917038e-06 - tot_loss: 0.05067589594064881 - acc: 0.9893906420021763 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 1.2547736167907715 - sq_loss: 3.159176458211732e-06 - tot_loss: 0.04895384641487954 - acc: 0.9895266594124048 - val_acc: 0.9633525619273838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 1.245422601699829 - sq_loss: 3.1541821954306215e-06 - tot_loss: 0.05024249575145667 - acc: 0.9893906420021763 - val_acc: 0.9630132337970818\n",
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 1.285954236984253 - sq_loss: 3.1484269129578024e-06 - tot_loss: 0.048905031404544275 - acc: 0.9895266594124048 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 1.2513461112976074 - sq_loss: 3.1410902465722756e-06 - tot_loss: 0.04884333635335736 - acc: 0.9895266594124048 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 1.2341954708099365 - sq_loss: 3.137212161163916e-06 - tot_loss: 0.05078060117785732 - acc: 0.9895266594124048 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 1.2686574459075928 - sq_loss: 3.1320378184318542e-06 - tot_loss: 0.051153717368921825 - acc: 0.9895266594124048 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 1.230724811553955 - sq_loss: 3.126103365502786e-06 - tot_loss: 0.050251315528138996 - acc: 0.9893906420021763 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 1.224762201309204 - sq_loss: 3.1206438961817184e-06 - tot_loss: 0.05068286308870196 - acc: 0.9895266594124048 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 1.216810703277588 - sq_loss: 3.115382924079313e-06 - tot_loss: 0.05125691315705261 - acc: 0.9895266594124048 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 1.2188799381256104 - sq_loss: 3.110512579951319e-06 - tot_loss: 0.04971970447554952 - acc: 0.9896626768226333 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 1.22275710105896 - sq_loss: 3.1060067158250604e-06 - tot_loss: 0.050187843832286916 - acc: 0.9896626768226333 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 1.2171897888183594 - sq_loss: 3.101475840594503e-06 - tot_loss: 0.04884206622291476 - acc: 0.9896626768226333 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 1.229067087173462 - sq_loss: 3.0963963126851013e-06 - tot_loss: 0.05139811677369366 - acc: 0.9896626768226333 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 1.2283687591552734 - sq_loss: 3.09294841827068e-06 - tot_loss: 0.04899972988528578 - acc: 0.9896626768226333 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 1.225229263305664 - sq_loss: 3.089007577727898e-06 - tot_loss: 0.051340930603925194 - acc: 0.9896626768226333 - val_acc: 0.9633525619273838\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 1.220590353012085 - sq_loss: 3.08465837406402e-06 - tot_loss: 0.05139981584730968 - acc: 0.9896626768226333 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 1.2399694919586182 - sq_loss: 3.0807436814939138e-06 - tot_loss: 0.04955788675409156 - acc: 0.9896626768226333 - val_acc: 0.9636918900576857\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 1.2329821586608887 - sq_loss: 3.077049768762663e-06 - tot_loss: 0.04946177194947321 - acc: 0.9896626768226333 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 1.2313592433929443 - sq_loss: 3.0734458960068878e-06 - tot_loss: 0.05055174603622614 - acc: 0.9896626768226333 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 1.2331264019012451 - sq_loss: 3.0698420232511126e-06 - tot_loss: 0.04899849223105601 - acc: 0.9896626768226333 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 1.2319750785827637 - sq_loss: 3.0671258173242677e-06 - tot_loss: 0.05086255838728437 - acc: 0.9896626768226333 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 1.2231628894805908 - sq_loss: 3.061973075091373e-06 - tot_loss: 0.05206139298869772 - acc: 0.9896626768226333 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 1.225728988647461 - sq_loss: 3.057556568819564e-06 - tot_loss: 0.04996447583252284 - acc: 0.9896626768226333 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 1.2217531204223633 - sq_loss: 3.0518610856233863e-06 - tot_loss: 0.05049514246738873 - acc: 0.9896626768226333 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 1.2199785709381104 - sq_loss: 3.048033477170975e-06 - tot_loss: 0.052115661561104254 - acc: 0.9896626768226333 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 1.2224149703979492 - sq_loss: 3.042099251615582e-06 - tot_loss: 0.04672769170608593 - acc: 0.9895266594124048 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 1.2367465496063232 - sq_loss: 3.036615453311242e-06 - tot_loss: 0.04838514826269069 - acc: 0.9896626768226333 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 1.2214608192443848 - sq_loss: 3.0300975595309865e-06 - tot_loss: 0.04697482024813393 - acc: 0.9896626768226333 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 1.2400462627410889 - sq_loss: 3.024326133527211e-06 - tot_loss: 0.04670303456834901 - acc: 0.9896626768226333 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 1.229273796081543 - sq_loss: 3.0189332846930483e-06 - tot_loss: 0.053645527331396714 - acc: 0.9896626768226333 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 1.2385215759277344 - sq_loss: 3.0146238714223728e-06 - tot_loss: 0.050407027390108716 - acc: 0.9896626768226333 - val_acc: 0.9640312181879878\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 1.2174806594848633 - sq_loss: 3.011147555298521e-06 - tot_loss: 0.05108992562267911 - acc: 0.9895266594124048 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 1.2627825736999512 - sq_loss: 3.0082037483225577e-06 - tot_loss: 0.050571358414226 - acc: 0.9896626768226333 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 1.2350797653198242 - sq_loss: 3.0043818242120324e-06 - tot_loss: 0.047221857711589266 - acc: 0.9896626768226333 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 1.2428131103515625 - sq_loss: 3.0001415325386915e-06 - tot_loss: 0.0491854955767117 - acc: 0.9895266594124048 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 1.2321314811706543 - sq_loss: 2.995359182023094e-06 - tot_loss: 0.04799772592903473 - acc: 0.9896626768226333 - val_acc: 0.9643705463182898\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 1.2186648845672607 - sq_loss: 2.9910447665315587e-06 - tot_loss: 0.04696461264085894 - acc: 0.9895266594124048 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 1.2480709552764893 - sq_loss: 2.9868467663618503e-06 - tot_loss: 0.0478753365054132 - acc: 0.9895266594124048 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 1.26529860496521 - sq_loss: 2.9824916509824106e-06 - tot_loss: 0.04962307880652972 - acc: 0.9895266594124048 - val_acc: 0.9647098744485918\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 1.2637279033660889 - sq_loss: 2.978364364025765e-06 - tot_loss: 0.047377429088846235 - acc: 0.9896626768226333 - val_acc: 0.9640312181879878\n",
      "CR_1 = 0.16759738116197184   CR_2 = 0.1667972504806152\n",
      "/home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 5\n",
    "alpha = 1\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "\n",
    "#alpha1 = alpha2 = alpha3 = alpha4 = alpha5 = alpha6 = alpha7 = alpha8 = alpha9 = alpha10 = alpha\n",
    "#for rank in (35,): #(25,30,35)(100,180,220,260,300,340,380)(20,60,100,140,180,220,260,300,340,380)\n",
    "#    for tau in (400,500): #(300,400,500)(10,50,100,200,300)(10,50,100,200,300)\n",
    "#        for gamma in (0.5,0.8,2): #(0.5,0.8,2)(0.5,0.8)(0.5,1,1.5,2,3)\n",
    "            #gamma1 = gamma2 = gamma3 = gamma4 = gamma5 = gamma\n",
    "#            for rho in (0.5,0.8,2): #(0.5,0.8)(1,2)\n",
    "                #rho1 = rho2 = rho3 = rho4 = rho5= rho\n",
    "#                for alpha in (0.5,1,1.5,2):\n",
    "#                    print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "                    #print('Compression Ratio', ((1024*28*28+10*1024+(8*(rank)+32*np.square(rank))*2)/(1024*28*28+10*1024+1024*1024*2)), (8*(rank)+32*np.square(rank))*2/(1024*1024*2))\n",
    "        \n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    d0 = 561 #561 =3*11*17\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 6 \n",
    "\n",
    "    W1 = init.uniform_(torch.empty(d1, d0, device=device), a=-0.01, b=0.01)\n",
    "    #W1 = 0.01*torch.randn(d1, d0, device=device)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    W2 = init.uniform_(torch.empty(d2, d1, device=device), a=-0.01, b=0.01)\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles factors, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    W3 = init.uniform_(torch.empty(d3, d2, device=device), a=-0.01, b=0.01)\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    W4 = init.uniform_(torch.empty(d4, d3, device=device), a=-0.01, b=0.01)\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "\n",
    "    W5 = init.uniform_(torch.empty(d5, d4, device=device), a=-0.01, b=0.01)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = U5 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V5 = (y_one_hot + gamma*U5 + alpha*V5)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U5 = (gamma*V5 + rho*(torch.mm(W5,V4) + b5.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W5, b5 = updateWb_org(U5,V4,W5,b5,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b5.repeat(1, N), W5, a4_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b5.repeat(1, N_test), W5, a4_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V5,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,U5,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4\n",
    "\n",
    "    CR_1=((total_variabels)+(d4*d5))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#this postion to add new row into existing table\n",
    "    #df=pd.read_csv('C:/Users/Mark/Desktop/rank40_100times.csv')\n",
    "    #new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "    #           'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "    #           'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1], 'seed':seed} \n",
    "    #df=df.append(new_row,ignore_index=True)\n",
    "    #df.to_csv('C:/Users/Mark/Desktop/rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"UniformScaled_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/4 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895c825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30f34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
