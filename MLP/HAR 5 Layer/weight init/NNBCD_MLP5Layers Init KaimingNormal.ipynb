{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4cb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a157bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a5c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087d0e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 3 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 1.747732400894165 - sq_loss: 661.7024536132812 - tot_loss: 1120.028665292557 - acc: 0.19518498367791076 - val_acc: 0.19002375296912113\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 1.5102794170379639 - sq_loss: 294.08990478515625 - tot_loss: 516.7308813240379 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 1.4997429847717285 - sq_loss: 161.03677368164062 - tot_loss: 287.20736234635115 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 1.4970824718475342 - sq_loss: 87.26002502441406 - tot_loss: 168.03364862222224 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 1.5029571056365967 - sq_loss: 46.950496673583984 - tot_loss: 103.16803779546171 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 1.560260534286499 - sq_loss: 25.20108413696289 - tot_loss: 67.31312403548509 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 1.5740323066711426 - sq_loss: 13.536910057067871 - tot_loss: 47.04826326761395 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 1.5626261234283447 - sq_loss: 7.293503761291504 - tot_loss: 35.28761220583692 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 1.533703088760376 - sq_loss: 3.9495747089385986 - tot_loss: 28.12504521990195 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 1.4908926486968994 - sq_loss: 2.154202461242676 - tot_loss: 23.52911618957296 - acc: 0.1913764961915125 - val_acc: 0.1825585341024771\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 1.5252037048339844 - sq_loss: 1.1862974166870117 - tot_loss: 20.40285648824647 - acc: 0.19355277475516866 - val_acc: 0.18900576857821513\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 1.5022704601287842 - sq_loss: 0.6614391803741455 - tot_loss: 18.084701993968338 - acc: 0.21708378672470077 - val_acc: 0.20766881574482524\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 1.5030884742736816 - sq_loss: 0.3746183216571808 - tot_loss: 16.291786023415625 - acc: 0.25666485310119697 - val_acc: 0.24058364438411944\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 1.516552448272705 - sq_loss: 0.2163003385066986 - tot_loss: 14.822167480364442 - acc: 0.3072633297062024 - val_acc: 0.27383780115371564\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 1.4992413520812988 - sq_loss: 0.12781652808189392 - tot_loss: 13.623294142773375 - acc: 0.3326985854189336 - val_acc: 0.3098065829657279\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 1.4988596439361572 - sq_loss: 0.07760672271251678 - tot_loss: 12.525028626201674 - acc: 0.345348204570185 - val_acc: 0.337631489650492\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 1.5060133934020996 - sq_loss: 0.04859320819377899 - tot_loss: 11.61180999292992 - acc: 0.3521490750816104 - val_acc: 0.3484899898201561\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 1.5138359069824219 - sq_loss: 0.03147564455866814 - tot_loss: 10.766245606006123 - acc: 0.35663764961915123 - val_acc: 0.3505259586019681\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 1.5048854351043701 - sq_loss: 0.021138552576303482 - tot_loss: 10.052028993843123 - acc: 0.3573177366702938 - val_acc: 0.3505259586019681\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 1.5104188919067383 - sq_loss: 0.014732632786035538 - tot_loss: 9.38599757157499 - acc: 0.35772578890097934 - val_acc: 0.3505259586019681\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 1.5243654251098633 - sq_loss: 0.0106503302231431 - tot_loss: 8.77243472187547 - acc: 0.35813384113166485 - val_acc: 0.3505259586019681\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 1.5099937915802002 - sq_loss: 0.007972680032253265 - tot_loss: 8.25707419635728 - acc: 0.36099020674646354 - val_acc: 0.3515439429928741\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 1.494692325592041 - sq_loss: 0.006163154728710651 - tot_loss: 7.782059212040622 - acc: 0.3665669205658324 - val_acc: 0.35527655242619616\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 1.4989056587219238 - sq_loss: 0.004903572145849466 - tot_loss: 7.3406543920282274 - acc: 0.3754080522306855 - val_acc: 0.36206311503223615\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 1.505983829498291 - sq_loss: 0.004000439774245024 - tot_loss: 7.0005948618927505 - acc: 0.3907780195865071 - val_acc: 0.37597556837461826\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 1.5023972988128662 - sq_loss: 0.0033342442475259304 - tot_loss: 6.6179200635815505 - acc: 0.41961371055495106 - val_acc: 0.40176450627757043\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 1.5051958560943604 - sq_loss: 0.0028311011847108603 - tot_loss: 6.263356949057197 - acc: 0.4545701849836779 - val_acc: 0.44044791313199866\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 1.4807398319244385 - sq_loss: 0.002439765725284815 - tot_loss: 5.944552199376631 - acc: 0.49347116430903154 - val_acc: 0.4696301323379708\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 1.4999029636383057 - sq_loss: 0.0021295773331075907 - tot_loss: 5.650810230348725 - acc: 0.5311479869423286 - val_acc: 0.504580929759077\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 1.5044896602630615 - sq_loss: 0.0018786011496558785 - tot_loss: 5.388143712814781 - acc: 0.5673286180631121 - val_acc: 0.5334238208347472\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 1.5013809204101562 - sq_loss: 0.0016714002704247832 - tot_loss: 5.171470858724206 - acc: 0.5983405875952121 - val_acc: 0.5663386494740414\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 1.4991765022277832 - sq_loss: 0.0014980660052970052 - tot_loss: 4.918659873248544 - acc: 0.6273122959738846 - val_acc: 0.5938242280285035\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 1.519113540649414 - sq_loss: 0.0013507308904081583 - tot_loss: 4.717432953177195 - acc: 0.6507072905331882 - val_acc: 0.6145232439769257\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 1.5221869945526123 - sq_loss: 0.0012241078075021505 - tot_loss: 4.494171574966458 - acc: 0.6712459194776932 - val_acc: 0.6375975568374618\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 1.5125658512115479 - sq_loss: 0.001113835140131414 - tot_loss: 4.325499813290662 - acc: 0.6875680087051143 - val_acc: 0.6532066508313539\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 1.5024967193603516 - sq_loss: 0.0010176774812862277 - tot_loss: 4.129889835356153 - acc: 0.7010337323177367 - val_acc: 0.666779776043434\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 1.5027658939361572 - sq_loss: 0.0009329626336693764 - tot_loss: 3.9319956372273737 - acc: 0.7144994559303591 - val_acc: 0.6783169324737021\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 1.5134499073028564 - sq_loss: 0.0008569713099859655 - tot_loss: 3.8171802437718725 - acc: 0.7285092491838956 - val_acc: 0.6939260264675942\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 1.5120511054992676 - sq_loss: 0.0007892597350291908 - tot_loss: 3.6749463194209966 - acc: 0.7369423286180631 - val_acc: 0.7102137767220903\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 1.499152660369873 - sq_loss: 0.000728477374650538 - tot_loss: 3.5018772327093757 - acc: 0.7465995647442872 - val_acc: 0.7200542925008483\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 1.4895131587982178 - sq_loss: 0.0006740404642187059 - tot_loss: 3.4006864912116725 - acc: 0.7566648531011969 - val_acc: 0.7254835425856804\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 1.49129319190979 - sq_loss: 0.0006245813565328717 - tot_loss: 3.2575195894169156 - acc: 0.763873775843308 - val_acc: 0.7322701051917204\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 1.5058176517486572 - sq_loss: 0.0005795502802357078 - tot_loss: 3.136582969687879 - acc: 0.7712187159956474 - val_acc: 0.7397353240583644\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 1.4998514652252197 - sq_loss: 0.0005384415271691978 - tot_loss: 3.030026764543436 - acc: 0.7763873775843307 - val_acc: 0.7455039022734985\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 1.507054328918457 - sq_loss: 0.0005010522436350584 - tot_loss: 2.9356698232440976 - acc: 0.7814200217627857 - val_acc: 0.7512724804886325\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 1.5120255947113037 - sq_loss: 0.00046687672147527337 - tot_loss: 2.821345048247167 - acc: 0.7864526659412405 - val_acc: 0.7560230743128605\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 1.508542537689209 - sq_loss: 0.00043540989281609654 - tot_loss: 2.7003668352772365 - acc: 0.7918933623503809 - val_acc: 0.7600950118764845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 1.483574628829956 - sq_loss: 0.0004062313528265804 - tot_loss: 2.620841612617369 - acc: 0.7962459194776932 - val_acc: 0.7631489650492026\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 1.484426498413086 - sq_loss: 0.0003792922361753881 - tot_loss: 2.522106731961685 - acc: 0.7993743199129488 - val_acc: 0.7682388870037327\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 1.4953410625457764 - sq_loss: 0.0003544948121998459 - tot_loss: 2.4947021558400593 - acc: 0.8037268770402611 - val_acc: 0.7733288089582626\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 1.4986674785614014 - sq_loss: 0.0003315550275146961 - tot_loss: 2.3950337015303376 - acc: 0.8064472252448314 - val_acc: 0.7760434340006787\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 1.488668441772461 - sq_loss: 0.00031020824098959565 - tot_loss: 2.3085467228793277 - acc: 0.80930359085963 - val_acc: 0.7790973871733967\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 1.5009796619415283 - sq_loss: 0.00029044950497336686 - tot_loss: 2.2279534288554714 - acc: 0.8114798694232862 - val_acc: 0.7848659653885307\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 1.5111541748046875 - sq_loss: 0.00027205341029912233 - tot_loss: 2.1412546939882304 - acc: 0.8150163220892275 - val_acc: 0.7882592466915507\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 1.4930100440979004 - sq_loss: 0.00025494248257018626 - tot_loss: 2.096790991961825 - acc: 0.8169205658324266 - val_acc: 0.7926705123854768\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 1.4962005615234375 - sq_loss: 0.00023921123647596687 - tot_loss: 2.054490302640261 - acc: 0.8207290533188248 - val_acc: 0.7960637936884968\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 1.4924700260162354 - sq_loss: 0.00022444591741077602 - tot_loss: 1.9973065411104471 - acc: 0.823449401523395 - val_acc: 0.7984390906006108\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 1.4712142944335938 - sq_loss: 0.00021065573673695326 - tot_loss: 1.9063455159503064 - acc: 0.8257616974972797 - val_acc: 0.8021717000339328\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 1.4902985095977783 - sq_loss: 0.00019791402155533433 - tot_loss: 1.8795649384046555 - acc: 0.8284820457018498 - val_acc: 0.8042076688157448\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 1.53139066696167 - sq_loss: 0.00018605220247991383 - tot_loss: 1.8317578449550638 - acc: 0.8316104461371056 - val_acc: 0.8072616219884629\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 1.5150372982025146 - sq_loss: 0.0001748983486322686 - tot_loss: 1.774410844373051 - acc: 0.8324265505984766 - val_acc: 0.8103155751611809\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 1.5044822692871094 - sq_loss: 0.0001645417360123247 - tot_loss: 1.7056008346717135 - acc: 0.8333786724700761 - val_acc: 0.8116728876823889\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 1.5184259414672852 - sq_loss: 0.00015491826343350112 - tot_loss: 1.6808888273480989 - acc: 0.8354189336235038 - val_acc: 0.8133695283338989\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 1.5048587322235107 - sq_loss: 0.00014580271090380847 - tot_loss: 1.651797365127095 - acc: 0.838139281828074 - val_acc: 0.8150661689854088\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 1.49888014793396 - sq_loss: 0.0001373826526105404 - tot_loss: 1.5562148594272003 - acc: 0.8405875952121872 - val_acc: 0.8194774346793349\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 1.5468392372131348 - sq_loss: 0.00012944066838826984 - tot_loss: 1.562945256434432 - acc: 0.8423558215451578 - val_acc: 0.820834747200543\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 1.5542356967926025 - sq_loss: 0.00012197214527986944 - tot_loss: 1.4894841264376737 - acc: 0.8449401523394995 - val_acc: 0.8225313878520529\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 1.4832940101623535 - sq_loss: 0.0001150120806414634 - tot_loss: 1.4492691289469803 - acc: 0.8476605005440696 - val_acc: 0.825246012894469\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 1.4923653602600098 - sq_loss: 0.00010844392090803012 - tot_loss: 1.4770317254251495 - acc: 0.8501088139281828 - val_acc: 0.828978622327791\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 1.5114312171936035 - sq_loss: 0.00010228970495518297 - tot_loss: 1.3847383321626694 - acc: 0.8518770402611534 - val_acc: 0.829317950458093\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 1.491044282913208 - sq_loss: 9.65621366049163e-05 - tot_loss: 1.3808865005767075 - acc: 0.85310119695321 - val_acc: 0.832371903630811\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 1.4955954551696777 - sq_loss: 9.118253365159035e-05 - tot_loss: 1.3347486706516065 - acc: 0.8551414581066377 - val_acc: 0.833050559891415\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 1.4749891757965088 - sq_loss: 8.607351628597826e-05 - tot_loss: 1.3101023978815647 - acc: 0.8579978237214363 - val_acc: 0.835425856803529\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 1.4776651859283447 - sq_loss: 8.129886555252597e-05 - tot_loss: 1.276199347075817 - acc: 0.8593579978237215 - val_acc: 0.8388191381065491\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 1.5062122344970703 - sq_loss: 7.679001282667741e-05 - tot_loss: 1.2631553309583978 - acc: 0.8612622415669206 - val_acc: 0.8408551068883611\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 1.5071487426757812 - sq_loss: 7.256154640344903e-05 - tot_loss: 1.2256094972963183 - acc: 0.8628944504896626 - val_acc: 0.8432304038004751\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 1.47987961769104 - sq_loss: 6.856957770651206e-05 - tot_loss: 1.1806531487441134 - acc: 0.8645266594124048 - val_acc: 0.843909060061079\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 1.476503849029541 - sq_loss: 6.478628347394988e-05 - tot_loss: 1.1853099325107905 - acc: 0.8653427638737758 - val_acc: 0.8452663725822871\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 1.482409954071045 - sq_loss: 6.129164103185758e-05 - tot_loss: 1.1199611510764953 - acc: 0.8665669205658324 - val_acc: 0.8456057007125891\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 1.4883227348327637 - sq_loss: 5.798243000754155e-05 - tot_loss: 1.1031070541853296 - acc: 0.8676550598476604 - val_acc: 0.8456057007125891\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 1.4980053901672363 - sq_loss: 5.487678208737634e-05 - tot_loss: 1.096861707302196 - acc: 0.8694232861806311 - val_acc: 0.8466236851034951\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 1.4789648056030273 - sq_loss: 5.189126750337891e-05 - tot_loss: 1.0555466159976277 - acc: 0.8702393906420022 - val_acc: 0.848320325755005\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 1.480586290359497 - sq_loss: 4.917382466373965e-05 - tot_loss: 1.045133001432987 - acc: 0.8722796517954298 - val_acc: 0.8486596538853071\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 1.484994649887085 - sq_loss: 4.6636330807814375e-05 - tot_loss: 1.0371174127803897 - acc: 0.873911860718172 - val_acc: 0.8486596538853071\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 1.5101358890533447 - sq_loss: 4.419167817104608e-05 - tot_loss: 1.0225424433724584 - acc: 0.8756800870511425 - val_acc: 0.8493383101459111\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 1.5381357669830322 - sq_loss: 4.18750787503086e-05 - tot_loss: 1.0137576846045704 - acc: 0.8773122959738846 - val_acc: 0.8510349507974211\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 1.5569477081298828 - sq_loss: 3.9732309232931584e-05 - tot_loss: 0.9701672601927385 - acc: 0.8789445048966268 - val_acc: 0.8527315914489311\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 1.564192533493042 - sq_loss: 3.771727278945036e-05 - tot_loss: 0.9253606548534208 - acc: 0.8803046789989118 - val_acc: 0.8537495758398371\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 1.505542278289795 - sq_loss: 3.575590017135255e-05 - tot_loss: 0.9509430394339233 - acc: 0.8822089227421109 - val_acc: 0.8544282321004412\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 1.5035676956176758 - sq_loss: 3.390343772480264e-05 - tot_loss: 0.9289747088171225 - acc: 0.8830250272034821 - val_acc: 0.8554462164913471\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 1.5135648250579834 - sq_loss: 3.2262563763652e-05 - tot_loss: 0.9198031670159708 - acc: 0.8846572361262242 - val_acc: 0.8568035290125552\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 1.5156137943267822 - sq_loss: 3.070136153837666e-05 - tot_loss: 0.8923068306312416 - acc: 0.8860174102285092 - val_acc: 0.8578215134034611\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 1.4782471656799316 - sq_loss: 2.9183789592934772e-05 - tot_loss: 0.8712758505801048 - acc: 0.8865614798694232 - val_acc: 0.8585001696640652\n",
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 1.4979798793792725 - sq_loss: 2.7776453862315975e-05 - tot_loss: 0.8526988883459126 - acc: 0.8875136017410229 - val_acc: 0.8595181540549711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 1.5013854503631592 - sq_loss: 2.6474568585399538e-05 - tot_loss: 0.8641120160175433 - acc: 0.889145810663765 - val_acc: 0.8598574821852731\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 1.4946446418762207 - sq_loss: 2.5199746232829057e-05 - tot_loss: 0.8072599687750426 - acc: 0.889961915125136 - val_acc: 0.8605361384458772\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 1.5004525184631348 - sq_loss: 2.4036740796873346e-05 - tot_loss: 0.8003528210815603 - acc: 0.8915941240478781 - val_acc: 0.8618934509670851\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 1.5190937519073486 - sq_loss: 2.2960601199883968e-05 - tot_loss: 0.8027522411164227 - acc: 0.8924102285092492 - val_acc: 0.8612147947064812\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 1.4902091026306152 - sq_loss: 2.189930273743812e-05 - tot_loss: 0.7845368557500478 - acc: 0.8932263329706203 - val_acc: 0.8632507634882932\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 1.4996137619018555 - sq_loss: 2.0883426259388216e-05 - tot_loss: 0.7862049617818911 - acc: 0.8943144722524483 - val_acc: 0.8642687478791992\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 1.4872896671295166 - sq_loss: 1.9977187548647635e-05 - tot_loss: 0.7933867801631322 - acc: 0.8954026115342764 - val_acc: 0.8656260604004072\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 1.4911959171295166 - sq_loss: 1.9103654267382808e-05 - tot_loss: 0.7625363402772791 - acc: 0.8963547334058759 - val_acc: 0.8676620291822192\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 1.4753797054290771 - sq_loss: 1.8242813894175924e-05 - tot_loss: 0.7932192930768451 - acc: 0.8978509249183896 - val_acc: 0.8680013573125213\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 1.4947376251220703 - sq_loss: 1.747195710777305e-05 - tot_loss: 0.7274210138222088 - acc: 0.8992110990206746 - val_acc: 0.8696979979640312\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 1.5039432048797607 - sq_loss: 1.673973019933328e-05 - tot_loss: 0.741532843332152 - acc: 0.9009793253536452 - val_acc: 0.8707159823549372\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 1.490211009979248 - sq_loss: 1.608215279702563e-05 - tot_loss: 0.7206275482498086 - acc: 0.9024755168661589 - val_acc: 0.8724126230064473\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 1.4897289276123047 - sq_loss: 1.54519293573685e-05 - tot_loss: 0.7418105294771067 - acc: 0.9030195865070729 - val_acc: 0.8724126230064473\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 1.4984030723571777 - sq_loss: 1.4807920706516597e-05 - tot_loss: 0.6891386265692745 - acc: 0.904651795429815 - val_acc: 0.8741092636579573\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 1.4703783988952637 - sq_loss: 1.4206358173396438e-05 - tot_loss: 0.6535741322528565 - acc: 0.905195865070729 - val_acc: 0.8747879199185612\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 1.500655174255371 - sq_loss: 1.3628367014462128e-05 - tot_loss: 0.6941767521975635 - acc: 0.9058759521218716 - val_acc: 0.8758059043094673\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 1.505995273590088 - sq_loss: 1.3090744687360711e-05 - tot_loss: 0.6715823709824917 - acc: 0.9065560391730142 - val_acc: 0.8768238887003733\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 1.4881927967071533 - sq_loss: 1.2581805094669107e-05 - tot_loss: 0.6755621722381875 - acc: 0.9079162132752993 - val_acc: 0.8781812012215813\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 1.5008137226104736 - sq_loss: 1.2124416571168695e-05 - tot_loss: 0.6658609220019684 - acc: 0.9083242655059848 - val_acc: 0.8785205293518833\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 1.4937188625335693 - sq_loss: 1.1681591786327772e-05 - tot_loss: 0.6929956109881346 - acc: 0.9088683351468988 - val_acc: 0.8788598574821853\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 1.5017755031585693 - sq_loss: 1.1240842468396295e-05 - tot_loss: 0.6563458341767046 - acc: 0.9090043525571273 - val_acc: 0.8795385137427892\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 1.4947950839996338 - sq_loss: 1.0841028597496916e-05 - tot_loss: 0.6454053776434421 - acc: 0.9096844396082698 - val_acc: 0.8805564981336953\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 1.503432273864746 - sq_loss: 1.0471220775798429e-05 - tot_loss: 0.6368079580211088 - acc: 0.9105005440696409 - val_acc: 0.8829317950458093\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 1.497319221496582 - sq_loss: 1.0121058949152939e-05 - tot_loss: 0.6229298230578593 - acc: 0.9107725788900979 - val_acc: 0.8849677638276213\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 1.4993607997894287 - sq_loss: 9.766036782821175e-06 - tot_loss: 0.6720322858794248 - acc: 0.911860718171926 - val_acc: 0.8863250763488293\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 1.4937536716461182 - sq_loss: 9.445730029256083e-06 - tot_loss: 0.6129122649634837 - acc: 0.9129488574537541 - val_acc: 0.8873430607397353\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 1.4824168682098389 - sq_loss: 9.1258889369783e-06 - tot_loss: 0.6089659324808849 - acc: 0.9134929270946681 - val_acc: 0.8873430607397353\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 1.4677207469940186 - sq_loss: 8.827044439385645e-06 - tot_loss: 0.5910951388663079 - acc: 0.9145810663764962 - val_acc: 0.8887003732609433\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 1.5162649154663086 - sq_loss: 8.555349268135615e-06 - tot_loss: 0.6042645677137557 - acc: 0.9145810663764962 - val_acc: 0.8910756701730573\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 1.5031239986419678 - sq_loss: 8.316847015521489e-06 - tot_loss: 0.5773715412856291 - acc: 0.9155331882480957 - val_acc: 0.8917543264336614\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 1.4999339580535889 - sq_loss: 8.07452670414932e-06 - tot_loss: 0.6042315632329291 - acc: 0.9158052230685527 - val_acc: 0.8914149983033594\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 1.5213472843170166 - sq_loss: 7.852603630453814e-06 - tot_loss: 0.5630776392729331 - acc: 0.9173014145810664 - val_acc: 0.8910756701730573\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 1.4888808727264404 - sq_loss: 7.631920198036823e-06 - tot_loss: 0.5475956675583973 - acc: 0.9182535364526659 - val_acc: 0.8914149983033594\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 1.5007810592651367 - sq_loss: 7.413511866616318e-06 - tot_loss: 0.5757291482382527 - acc: 0.9189336235038085 - val_acc: 0.8924329826942654\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 1.5067002773284912 - sq_loss: 7.2169450504588895e-06 - tot_loss: 0.549831228790282 - acc: 0.920157780195865 - val_acc: 0.8931116389548693\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 1.4937376976013184 - sq_loss: 7.011845355009427e-06 - tot_loss: 0.5741547932780975 - acc: 0.9205658324265505 - val_acc: 0.8934509670851714\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 1.5071184635162354 - sq_loss: 6.8175745582266245e-06 - tot_loss: 0.5350996562384296 - acc: 0.9212459194776932 - val_acc: 0.8944689514760774\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 1.4832632541656494 - sq_loss: 6.64410481476807e-06 - tot_loss: 0.5402897572889742 - acc: 0.9220620239390642 - val_acc: 0.8948082796063793\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 1.4878103733062744 - sq_loss: 6.490057330665877e-06 - tot_loss: 0.5196601447765943 - acc: 0.9232861806311208 - val_acc: 0.8958262639972854\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 1.502563714981079 - sq_loss: 6.333799774438376e-06 - tot_loss: 0.5344822590756166 - acc: 0.9236942328618063 - val_acc: 0.8975229046487954\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 1.486879587173462 - sq_loss: 6.193619356054114e-06 - tot_loss: 0.5466067600684994 - acc: 0.9242383025027203 - val_acc: 0.8988802171700034\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 1.4957563877105713 - sq_loss: 6.071901225368492e-06 - tot_loss: 0.5099245617771828 - acc: 0.9253264417845484 - val_acc: 0.8998982015609094\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 1.497227668762207 - sq_loss: 5.938310550845927e-06 - tot_loss: 0.5069575523747858 - acc: 0.9261425462459195 - val_acc: 0.9002375296912114\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 1.4944627285003662 - sq_loss: 5.822190360049717e-06 - tot_loss: 0.4905773042475232 - acc: 0.9270946681175191 - val_acc: 0.8998982015609094\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 1.4929533004760742 - sq_loss: 5.702729595213896e-06 - tot_loss: 0.4977980047875121 - acc: 0.9277747551686616 - val_acc: 0.9002375296912114\n",
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 1.5084609985351562 - sq_loss: 5.579338903771713e-06 - tot_loss: 0.5165515736699433 - acc: 0.9287268770402611 - val_acc: 0.9005768578215134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 1.501483678817749 - sq_loss: 5.473082637763582e-06 - tot_loss: 0.5101880476490948 - acc: 0.9289989118607181 - val_acc: 0.9022734984730234\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 1.5095438957214355 - sq_loss: 5.362458068702836e-06 - tot_loss: 0.4677324719718854 - acc: 0.9298150163220892 - val_acc: 0.9032914828639295\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 1.503016471862793 - sq_loss: 5.247424269327894e-06 - tot_loss: 0.4792457077082304 - acc: 0.9302230685527747 - val_acc: 0.9043094672548354\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 1.51513671875 - sq_loss: 5.147996489540674e-06 - tot_loss: 0.4792513644929528 - acc: 0.9311751904243744 - val_acc: 0.9043094672548354\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 1.5258362293243408 - sq_loss: 5.048670573160052e-06 - tot_loss: 0.45714805869121733 - acc: 0.9315832426550599 - val_acc: 0.9056667797760435\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 1.511655569076538 - sq_loss: 4.961523245583521e-06 - tot_loss: 0.45903605971386696 - acc: 0.9322633297062024 - val_acc: 0.9066847641669494\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 1.5172789096832275 - sq_loss: 4.861578418058343e-06 - tot_loss: 0.4757759886192332 - acc: 0.9326713819368879 - val_acc: 0.9073634204275535\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 1.5083410739898682 - sq_loss: 4.788440946867922e-06 - tot_loss: 0.47421921285013013 - acc: 0.9333514689880305 - val_acc: 0.9080420766881574\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 1.503938913345337 - sq_loss: 4.7066237129911315e-06 - tot_loss: 0.4437450102972207 - acc: 0.934031556039173 - val_acc: 0.9073634204275535\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 1.4919261932373047 - sq_loss: 4.631590400094865e-06 - tot_loss: 0.47500285501510575 - acc: 0.9341675734494015 - val_acc: 0.9077027485578555\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 1.5042715072631836 - sq_loss: 4.5702622628596146e-06 - tot_loss: 0.47014396736244635 - acc: 0.93430359085963 - val_acc: 0.9077027485578555\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 1.4977343082427979 - sq_loss: 4.51988444183371e-06 - tot_loss: 0.4798262631789356 - acc: 0.9351196953210011 - val_acc: 0.9087207329487614\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 1.5238957405090332 - sq_loss: 4.461203843675321e-06 - tot_loss: 0.4523542435081822 - acc: 0.9353917301414582 - val_acc: 0.9097387173396675\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 1.4924836158752441 - sq_loss: 4.3857617129106075e-06 - tot_loss: 0.5097900678794502 - acc: 0.9357997823721437 - val_acc: 0.9097387173396675\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 1.502011775970459 - sq_loss: 4.3227300920989364e-06 - tot_loss: 0.43320378506439283 - acc: 0.9362078346028292 - val_acc: 0.9104173736002714\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 1.4950058460235596 - sq_loss: 4.26175256507122e-06 - tot_loss: 0.4256526073786375 - acc: 0.9364798694232862 - val_acc: 0.9110960298608755\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 1.5006670951843262 - sq_loss: 4.20795049649314e-06 - tot_loss: 0.43945374926546776 - acc: 0.9374319912948857 - val_acc: 0.9121140142517815\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 1.496978759765625 - sq_loss: 4.14933083447977e-06 - tot_loss: 0.43148840844715153 - acc: 0.9377040261153428 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 1.5105509757995605 - sq_loss: 4.101762442587642e-06 - tot_loss: 0.4300098444976683 - acc: 0.9382480957562568 - val_acc: 0.9134713267729895\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 1.504509449005127 - sq_loss: 4.052041276736418e-06 - tot_loss: 0.44616720535074705 - acc: 0.9381120783460283 - val_acc: 0.9141499830335935\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 1.5069971084594727 - sq_loss: 4.019311290903715e-06 - tot_loss: 0.44193978652918986 - acc: 0.9381120783460283 - val_acc: 0.9141499830335935\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 1.5089359283447266 - sq_loss: 3.982812813774217e-06 - tot_loss: 0.4648898193048794 - acc: 0.9385201305767138 - val_acc: 0.9151679674244995\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 1.5008540153503418 - sq_loss: 3.940614078601357e-06 - tot_loss: 0.4352844991340632 - acc: 0.9386561479869423 - val_acc: 0.9158466236851035\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 1.5083532333374023 - sq_loss: 3.90495279134484e-06 - tot_loss: 0.42956095286340457 - acc: 0.9393362350380848 - val_acc: 0.9175432643366135\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 1.4949829578399658 - sq_loss: 3.873115019814577e-06 - tot_loss: 0.4379037178900447 - acc: 0.9396082698585418 - val_acc: 0.9185612487275195\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 1.5367214679718018 - sq_loss: 3.832594302366488e-06 - tot_loss: 0.426870166881649 - acc: 0.9398803046789989 - val_acc: 0.9185612487275195\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 1.5495846271514893 - sq_loss: 3.806898348557297e-06 - tot_loss: 0.42532393548844993 - acc: 0.9405603917301415 - val_acc: 0.9192399049881235\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 1.5657145977020264 - sq_loss: 3.774358901864616e-06 - tot_loss: 0.44155554728415325 - acc: 0.9408324265505985 - val_acc: 0.9192399049881235\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 1.4960038661956787 - sq_loss: 3.734941628863453e-06 - tot_loss: 0.4333714287490906 - acc: 0.94069640914037 - val_acc: 0.9195792331184255\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 1.486536979675293 - sq_loss: 3.698939508467447e-06 - tot_loss: 0.4087958607836839 - acc: 0.940968443960827 - val_acc: 0.9199185612487275\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 1.4813683032989502 - sq_loss: 3.6723797620652476e-06 - tot_loss: 0.4226878223276387 - acc: 0.941240478781284 - val_acc: 0.9205972175093315\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 1.498335599899292 - sq_loss: 3.6432377328310395e-06 - tot_loss: 0.3898550351766801 - acc: 0.9416485310119695 - val_acc: 0.9205972175093315\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 1.4957947731018066 - sq_loss: 3.61969432560727e-06 - tot_loss: 0.40176592022110214 - acc: 0.9413764961915125 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 1.4967279434204102 - sq_loss: 3.5896291592507623e-06 - tot_loss: 0.39519246123887797 - acc: 0.941784548422198 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 1.5130364894866943 - sq_loss: 3.558259095370886e-06 - tot_loss: 0.39682104796845863 - acc: 0.9426006528835691 - val_acc: 0.9226331862911435\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 1.5085363388061523 - sq_loss: 3.526619366311934e-06 - tot_loss: 0.41873364232078103 - acc: 0.9426006528835691 - val_acc: 0.9226331862911435\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 1.517017126083374 - sq_loss: 3.4965883060067426e-06 - tot_loss: 0.41406576506945214 - acc: 0.9426006528835691 - val_acc: 0.9229725144214456\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 1.5047531127929688 - sq_loss: 3.471543323030346e-06 - tot_loss: 0.4152363568530717 - acc: 0.9434167573449401 - val_acc: 0.9229725144214456\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 1.4666862487792969 - sq_loss: 3.449400537647307e-06 - tot_loss: 0.43805198987428184 - acc: 0.9438248095756256 - val_acc: 0.9236511706820495\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 1.499556541442871 - sq_loss: 3.421980181883555e-06 - tot_loss: 0.3701114888005961 - acc: 0.9436887921653971 - val_acc: 0.9246691550729556\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 1.50223708152771 - sq_loss: 3.3950500437640585e-06 - tot_loss: 0.3740587869234844 - acc: 0.9439608269858542 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 1.4914252758026123 - sq_loss: 3.372709670657059e-06 - tot_loss: 0.34883951260900403 - acc: 0.9447769314472253 - val_acc: 0.9246691550729556\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 1.4971637725830078 - sq_loss: 3.359006541359122e-06 - tot_loss: 0.37019744711624014 - acc: 0.9449129488574538 - val_acc: 0.9246691550729556\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 1.4907190799713135 - sq_loss: 3.3361309306201292e-06 - tot_loss: 0.39626799262940793 - acc: 0.9457290533188248 - val_acc: 0.9253478113335596\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 1.4958410263061523 - sq_loss: 3.3218996122741373e-06 - tot_loss: 0.39371370525075733 - acc: 0.9457290533188248 - val_acc: 0.9256871394638616\n",
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 1.5153720378875732 - sq_loss: 3.304455731267808e-06 - tot_loss: 0.36581865175749684 - acc: 0.9458650707290533 - val_acc: 0.9260264675941635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 1.5078575611114502 - sq_loss: 3.288208290541661e-06 - tot_loss: 0.3740496403875966 - acc: 0.9462731229597389 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 1.5162296295166016 - sq_loss: 3.276325969636673e-06 - tot_loss: 0.3998713019700908 - acc: 0.9468171926006529 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 1.4892592430114746 - sq_loss: 3.255600631746347e-06 - tot_loss: 0.36013551065693505 - acc: 0.9473612622415669 - val_acc: 0.9280624363759755\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 1.5047457218170166 - sq_loss: 3.233539928260143e-06 - tot_loss: 0.38233223004454686 - acc: 0.9476332970620239 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 1.5144708156585693 - sq_loss: 3.2129653391166357e-06 - tot_loss: 0.37705162790193114 - acc: 0.9483133841131665 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 1.5100979804992676 - sq_loss: 3.1994552500691498e-06 - tot_loss: 0.3528600787557927 - acc: 0.9480413492927094 - val_acc: 0.9290804207668816\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 1.4888179302215576 - sq_loss: 3.1770878194947727e-06 - tot_loss: 0.38538310224077676 - acc: 0.949265505984766 - val_acc: 0.9297590770274856\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 1.5028901100158691 - sq_loss: 3.1623319500795333e-06 - tot_loss: 0.39877672013438925 - acc: 0.9495375408052231 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 1.5033204555511475 - sq_loss: 3.146252083752188e-06 - tot_loss: 0.3850312634490294 - acc: 0.9495375408052231 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 1.5066590309143066 - sq_loss: 3.1288645914173685e-06 - tot_loss: 0.3866554373007389 - acc: 0.9496735582154516 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 1.5211105346679688 - sq_loss: 3.1113397653825814e-06 - tot_loss: 0.4141890682706624 - acc: 0.9498095756256801 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 1.5212721824645996 - sq_loss: 3.100371941400226e-06 - tot_loss: 0.36875385183329357 - acc: 0.9499455930359086 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 1.522688865661621 - sq_loss: 3.086568767685094e-06 - tot_loss: 0.40622967593701986 - acc: 0.9499455930359086 - val_acc: 0.9297590770274856\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 1.494234561920166 - sq_loss: 3.0705698463862063e-06 - tot_loss: 0.3673653432289825 - acc: 0.9504896626768227 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 1.5098936557769775 - sq_loss: 3.0613211947638774e-06 - tot_loss: 0.3783480920153366 - acc: 0.9504896626768227 - val_acc: 0.9287410926365796\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 1.500436544418335 - sq_loss: 3.0458993478532648e-06 - tot_loss: 0.3587889772904447 - acc: 0.9503536452665942 - val_acc: 0.9297590770274856\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 1.5106830596923828 - sq_loss: 3.0264895940490533e-06 - tot_loss: 0.3893162655883913 - acc: 0.9508977149075082 - val_acc: 0.9297590770274856\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 1.476207971572876 - sq_loss: 3.012929028045619e-06 - tot_loss: 0.41562815659441554 - acc: 0.9511697497279652 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 1.498619794845581 - sq_loss: 2.9980142244312447e-06 - tot_loss: 0.37023821185372086 - acc: 0.9513057671381937 - val_acc: 0.9297590770274856\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 1.4895045757293701 - sq_loss: 2.987104153362452e-06 - tot_loss: 0.34442383595579784 - acc: 0.9510337323177367 - val_acc: 0.9297590770274856\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 1.5069935321807861 - sq_loss: 2.9690727387787774e-06 - tot_loss: 0.37514629120689946 - acc: 0.9511697497279652 - val_acc: 0.9297590770274856\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 1.485215425491333 - sq_loss: 2.9584261937998235e-06 - tot_loss: 0.3697911725443177 - acc: 0.9517138193688792 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 1.5026772022247314 - sq_loss: 2.9495499802578706e-06 - tot_loss: 0.3371533532552107 - acc: 0.9518498367791077 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 1.4881086349487305 - sq_loss: 2.9422474199236603e-06 - tot_loss: 0.3402721650364846 - acc: 0.9519858541893362 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 1.5016238689422607 - sq_loss: 2.927100695160334e-06 - tot_loss: 0.3438418113654258 - acc: 0.9523939064200218 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 1.5071485042572021 - sq_loss: 2.9166981221351307e-06 - tot_loss: 0.36471820323820836 - acc: 0.9525299238302503 - val_acc: 0.9311163895486936\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 1.5389232635498047 - sq_loss: 2.9040970730420668e-06 - tot_loss: 0.3603659852197403 - acc: 0.9526659412404788 - val_acc: 0.9311163895486936\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 1.5114967823028564 - sq_loss: 2.893270448112162e-06 - tot_loss: 0.3734859552066325 - acc: 0.9521218715995647 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 1.4890837669372559 - sq_loss: 2.88125011138618e-06 - tot_loss: 0.348255104410196 - acc: 0.9525299238302503 - val_acc: 0.9311163895486936\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 1.5022203922271729 - sq_loss: 2.8697336347249802e-06 - tot_loss: 0.3534968681942452 - acc: 0.9528019586507073 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 1.5198264122009277 - sq_loss: 2.8598540211532963e-06 - tot_loss: 0.3755619375046102 - acc: 0.9530739934711643 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 1.5041441917419434 - sq_loss: 2.8494023354141973e-06 - tot_loss: 0.3371755590415084 - acc: 0.9528019586507073 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 1.4820973873138428 - sq_loss: 2.8381521133269416e-06 - tot_loss: 0.3274929069562127 - acc: 0.9530739934711643 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 1.5037710666656494 - sq_loss: 2.8254385142645333e-06 - tot_loss: 0.34115555516195784 - acc: 0.9530739934711643 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 1.5242273807525635 - sq_loss: 2.816784217429813e-06 - tot_loss: 0.3418101079448732 - acc: 0.9530739934711643 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 1.510624885559082 - sq_loss: 2.8065417154721217e-06 - tot_loss: 0.35868370735059685 - acc: 0.9533460282916213 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 1.5075101852416992 - sq_loss: 2.7910405151487794e-06 - tot_loss: 0.35809540216765967 - acc: 0.9536180631120783 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 1.4854211807250977 - sq_loss: 2.7795640562544577e-06 - tot_loss: 0.36072210983060415 - acc: 0.9534820457018498 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 1.5098092555999756 - sq_loss: 2.7691544346453156e-06 - tot_loss: 0.365708446520582 - acc: 0.9534820457018498 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 1.5066592693328857 - sq_loss: 2.7602520731306868e-06 - tot_loss: 0.3683263562199244 - acc: 0.9536180631120783 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 1.504568099975586 - sq_loss: 2.7556041004572762e-06 - tot_loss: 0.37576069891449393 - acc: 0.9538900979325353 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 1.493781566619873 - sq_loss: 2.75055822385184e-06 - tot_loss: 0.3624366450839478 - acc: 0.9540261153427638 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 1.5081212520599365 - sq_loss: 2.738626562859281e-06 - tot_loss: 0.3424923268764726 - acc: 0.9547062023939065 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 1.5101666450500488 - sq_loss: 2.7319938453729264e-06 - tot_loss: 0.33400844695396437 - acc: 0.954842219804135 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 1.5204875469207764 - sq_loss: 2.72172314907948e-06 - tot_loss: 0.3409776379009841 - acc: 0.9549782372143635 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 1.5150947570800781 - sq_loss: 2.7108110316476086e-06 - tot_loss: 0.3360514155155805 - acc: 0.9557943416757345 - val_acc: 0.9341703427214116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 1.5190489292144775 - sq_loss: 2.70137525149039e-06 - tot_loss: 0.3300193219481464 - acc: 0.9557943416757345 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 1.5012755393981934 - sq_loss: 2.6926804821414407e-06 - tot_loss: 0.3432456712325678 - acc: 0.95620239390642 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 1.5081782341003418 - sq_loss: 2.683694674487924e-06 - tot_loss: 0.31054140838003264 - acc: 0.9563384113166485 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 1.5178146362304688 - sq_loss: 2.675262066986761e-06 - tot_loss: 0.35784003759657246 - acc: 0.9566104461371056 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 1.4979145526885986 - sq_loss: 2.6668178634281503e-06 - tot_loss: 0.3361210073799601 - acc: 0.9567464635473341 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 1.4988462924957275 - sq_loss: 2.6605641778587596e-06 - tot_loss: 0.37184738997183153 - acc: 0.9567464635473341 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 1.5025677680969238 - sq_loss: 2.6520278879615944e-06 - tot_loss: 0.3465763897295986 - acc: 0.9567464635473341 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 1.4789307117462158 - sq_loss: 2.6437796805112157e-06 - tot_loss: 0.3322835493683307 - acc: 0.9570184983677911 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 1.4988312721252441 - sq_loss: 2.6351362976129167e-06 - tot_loss: 0.3594582067592338 - acc: 0.9572905331882481 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 1.5054292678833008 - sq_loss: 2.628886704769684e-06 - tot_loss: 0.3354085631997137 - acc: 0.9571545157780196 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 1.5194735527038574 - sq_loss: 2.6217362574243452e-06 - tot_loss: 0.3360627080386145 - acc: 0.9574265505984766 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 1.5086627006530762 - sq_loss: 2.616480514916475e-06 - tot_loss: 0.35612503334822065 - acc: 0.9571545157780196 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 1.5120115280151367 - sq_loss: 2.60854449152248e-06 - tot_loss: 0.35437264614682107 - acc: 0.9576985854189336 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 1.5215833187103271 - sq_loss: 2.6003422135545406e-06 - tot_loss: 0.34089803471658087 - acc: 0.9574265505984766 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 1.5130209922790527 - sq_loss: 2.591948941699229e-06 - tot_loss: 0.33682826320398007 - acc: 0.9575625680087051 - val_acc: 0.9382422802850356\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 1.51059889793396 - sq_loss: 2.579682131909067e-06 - tot_loss: 0.33948001636152547 - acc: 0.9582426550598476 - val_acc: 0.9382422802850356\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 1.4786710739135742 - sq_loss: 2.5726151307026157e-06 - tot_loss: 0.36573540198938304 - acc: 0.9582426550598476 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 1.4981563091278076 - sq_loss: 2.560695520514855e-06 - tot_loss: 0.33541775180671607 - acc: 0.9581066376496191 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 1.5087499618530273 - sq_loss: 2.550075578255928e-06 - tot_loss: 0.35149804635221393 - acc: 0.9582426550598476 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 1.5216691493988037 - sq_loss: 2.543919208619627e-06 - tot_loss: 0.33453568926194954 - acc: 0.9582426550598476 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 1.4823520183563232 - sq_loss: 2.5380400074936915e-06 - tot_loss: 0.3356872890981535 - acc: 0.9582426550598476 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 1.4895882606506348 - sq_loss: 2.5326028207928175e-06 - tot_loss: 0.311149605585479 - acc: 0.9583786724700761 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 1.4830009937286377 - sq_loss: 2.5282629394496325e-06 - tot_loss: 0.3423382708952616 - acc: 0.9587867247007617 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 1.4877383708953857 - sq_loss: 2.523094735806808e-06 - tot_loss: 0.3513994386115957 - acc: 0.9587867247007617 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 1.4848716259002686 - sq_loss: 2.5153426577162463e-06 - tot_loss: 0.35094483165042867 - acc: 0.9586507072905331 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 1.478156328201294 - sq_loss: 2.503309815438115e-06 - tot_loss: 0.3408238027794539 - acc: 0.9590587595212187 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 1.4769186973571777 - sq_loss: 2.4936182398960227e-06 - tot_loss: 0.3316230667173343 - acc: 0.9589227421109902 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 1.5010082721710205 - sq_loss: 2.4877197120076744e-06 - tot_loss: 0.32879643403178527 - acc: 0.9589227421109902 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 1.5060348510742188 - sq_loss: 2.4795062927296385e-06 - tot_loss: 0.3050465352046654 - acc: 0.9593307943416758 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 1.505652904510498 - sq_loss: 2.4706798740226077e-06 - tot_loss: 0.32267272284194526 - acc: 0.9591947769314473 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 1.5068752765655518 - sq_loss: 2.4645808025525184e-06 - tot_loss: 0.36270998522442355 - acc: 0.9596028291621328 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 1.4963696002960205 - sq_loss: 2.460510586388409e-06 - tot_loss: 0.3218398410381802 - acc: 0.9596028291621328 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 1.4721429347991943 - sq_loss: 2.45579417423869e-06 - tot_loss: 0.3116425643048135 - acc: 0.9598748639825898 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 1.4965953826904297 - sq_loss: 2.4480143565597245e-06 - tot_loss: 0.3239038271731989 - acc: 0.9598748639825898 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 1.4887218475341797 - sq_loss: 2.4370388018724043e-06 - tot_loss: 0.3494979700202059 - acc: 0.9597388465723613 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 1.4793672561645508 - sq_loss: 2.430841732348199e-06 - tot_loss: 0.35357959320884014 - acc: 0.9598748639825898 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 1.4865999221801758 - sq_loss: 2.422242005195585e-06 - tot_loss: 0.3264888625860909 - acc: 0.9597388465723613 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 1.4967000484466553 - sq_loss: 2.418180201857467e-06 - tot_loss: 0.33522404739881395 - acc: 0.9593307943416758 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 1.5041844844818115 - sq_loss: 2.413582706140005e-06 - tot_loss: 0.32922470626185074 - acc: 0.9597388465723613 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 1.5101232528686523 - sq_loss: 2.4098519588733325e-06 - tot_loss: 0.32433382178563086 - acc: 0.9598748639825898 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 1.4994864463806152 - sq_loss: 2.401457550149644e-06 - tot_loss: 0.3329517323571114 - acc: 0.9602829162132753 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 1.4988417625427246 - sq_loss: 2.3942786810948746e-06 - tot_loss: 0.34450056326808287 - acc: 0.9602829162132753 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 1.5183296203613281 - sq_loss: 2.385008201599703e-06 - tot_loss: 0.3440467917487524 - acc: 0.9605549510337323 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 1.498838186264038 - sq_loss: 2.3800712369848043e-06 - tot_loss: 0.34208395043516227 - acc: 0.9602829162132753 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 1.5237607955932617 - sq_loss: 2.3719840100966394e-06 - tot_loss: 0.3402210457575663 - acc: 0.9606909684439608 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 1.5195157527923584 - sq_loss: 2.3669003894610796e-06 - tot_loss: 0.3262912325539915 - acc: 0.9608269858541894 - val_acc: 0.9423142178486597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 1.5164015293121338 - sq_loss: 2.359212885494344e-06 - tot_loss: 0.32870431488199614 - acc: 0.9609630032644179 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 1.501964807510376 - sq_loss: 2.355447122681653e-06 - tot_loss: 0.3014856093911149 - acc: 0.9606909684439608 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 1.5056579113006592 - sq_loss: 2.350493559788447e-06 - tot_loss: 0.3279577453233333 - acc: 0.9608269858541894 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 1.4887018203735352 - sq_loss: 2.3434888589690672e-06 - tot_loss: 0.33993214224085655 - acc: 0.9613710554951034 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 1.4862923622131348 - sq_loss: 2.3374286683974788e-06 - tot_loss: 0.34198278552980454 - acc: 0.9615070729053319 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 1.4796874523162842 - sq_loss: 2.3287600470212055e-06 - tot_loss: 0.32138012338182165 - acc: 0.9615070729053319 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 1.5043530464172363 - sq_loss: 2.322255568287801e-06 - tot_loss: 0.32558225760375414 - acc: 0.9617791077257889 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 1.4879159927368164 - sq_loss: 2.3180755306384526e-06 - tot_loss: 0.35860239820248907 - acc: 0.9619151251360174 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 1.5084760189056396 - sq_loss: 2.3101431452232646e-06 - tot_loss: 0.3094946951565145 - acc: 0.9619151251360174 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 1.4968156814575195 - sq_loss: 2.303529981872998e-06 - tot_loss: 0.3184998457257002 - acc: 0.9620511425462459 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 1.484851598739624 - sq_loss: 2.3018860701995436e-06 - tot_loss: 0.3414629863680805 - acc: 0.9619151251360174 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 1.5078213214874268 - sq_loss: 2.2993847323959926e-06 - tot_loss: 0.31504551938132863 - acc: 0.9619151251360174 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 1.4815170764923096 - sq_loss: 2.2952981453272514e-06 - tot_loss: 0.3160893402091993 - acc: 0.9621871599564744 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 1.4841723442077637 - sq_loss: 2.2918386548553826e-06 - tot_loss: 0.3477352561836753 - acc: 0.9620511425462459 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 1.490349292755127 - sq_loss: 2.2874735350342235e-06 - tot_loss: 0.3317512868229109 - acc: 0.9619151251360174 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 1.4936575889587402 - sq_loss: 2.27895361604169e-06 - tot_loss: 0.3612156559910211 - acc: 0.9619151251360174 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 1.5006139278411865 - sq_loss: 2.275843371535302e-06 - tot_loss: 0.32593411077083445 - acc: 0.9623231773667029 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 1.5066847801208496 - sq_loss: 2.2703991362504894e-06 - tot_loss: 0.3022205047804576 - acc: 0.9620511425462459 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 1.479940414428711 - sq_loss: 2.2640192582912277e-06 - tot_loss: 0.3556912693911336 - acc: 0.9620511425462459 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 1.502995252609253 - sq_loss: 2.2552378595719347e-06 - tot_loss: 0.35298220476883735 - acc: 0.9620511425462459 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 1.4922730922698975 - sq_loss: 2.2483864086098038e-06 - tot_loss: 0.3534135621281784 - acc: 0.9624591947769314 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 1.4814300537109375 - sq_loss: 2.2416461433749646e-06 - tot_loss: 0.37877384085999743 - acc: 0.9625952121871599 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 1.4869344234466553 - sq_loss: 2.2379135771188885e-06 - tot_loss: 0.326430074889565 - acc: 0.9627312295973884 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 1.4984300136566162 - sq_loss: 2.232870201623882e-06 - tot_loss: 0.352189117068729 - acc: 0.9627312295973884 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 1.4918346405029297 - sq_loss: 2.226211563538527e-06 - tot_loss: 0.30865279511907495 - acc: 0.9628672470076169 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 1.500533103942871 - sq_loss: 2.219768930444843e-06 - tot_loss: 0.3453530284125623 - acc: 0.9630032644178455 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 1.5059466361999512 - sq_loss: 2.2142025954963174e-06 - tot_loss: 0.33188439108223555 - acc: 0.9632752992383025 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 1.5025148391723633 - sq_loss: 2.2083772819314618e-06 - tot_loss: 0.3129342143907774 - acc: 0.963411316648531 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 1.4989190101623535 - sq_loss: 2.201087909270427e-06 - tot_loss: 0.3307106321960145 - acc: 0.9632752992383025 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 1.4897146224975586 - sq_loss: 2.194607759520295e-06 - tot_loss: 0.35196314461416556 - acc: 0.963411316648531 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 1.4969508647918701 - sq_loss: 2.187463906011544e-06 - tot_loss: 0.321568163188779 - acc: 0.963683351468988 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 1.5104670524597168 - sq_loss: 2.1833518530911533e-06 - tot_loss: 0.3342373541862731 - acc: 0.9638193688792165 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 1.494713306427002 - sq_loss: 2.178330078095314e-06 - tot_loss: 0.31333639112438405 - acc: 0.9638193688792165 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 1.5092127323150635 - sq_loss: 2.1733578705607215e-06 - tot_loss: 0.30188257831653154 - acc: 0.9638193688792165 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 1.494283676147461 - sq_loss: 2.1661421669705305e-06 - tot_loss: 0.3192587895011503 - acc: 0.9638193688792165 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 1.5090768337249756 - sq_loss: 2.160182475563488e-06 - tot_loss: 0.3034442781150961 - acc: 0.963683351468988 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 1.504533290863037 - sq_loss: 2.1571145225607324e-06 - tot_loss: 0.3630209039967198 - acc: 0.9635473340587595 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 1.5035712718963623 - sq_loss: 2.1529449441004544e-06 - tot_loss: 0.34845242331061677 - acc: 0.9635473340587595 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 1.5355629920959473 - sq_loss: 2.1489627215487417e-06 - tot_loss: 0.34736519994577364 - acc: 0.9642274211099021 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 1.513803482055664 - sq_loss: 2.1449043288157554e-06 - tot_loss: 0.31467293661340534 - acc: 0.9642274211099021 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 1.5040175914764404 - sq_loss: 2.1406060568551766e-06 - tot_loss: 0.3731712823020903 - acc: 0.9643634385201306 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 1.4921660423278809 - sq_loss: 2.1340683815651573e-06 - tot_loss: 0.31205952105722723 - acc: 0.9642274211099021 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 1.5090878009796143 - sq_loss: 2.1301948436303064e-06 - tot_loss: 0.3293557005803649 - acc: 0.9643634385201306 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 1.5006864070892334 - sq_loss: 2.126537083313451e-06 - tot_loss: 0.38619352240318783 - acc: 0.9642274211099021 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 1.4971249103546143 - sq_loss: 2.1229930098343175e-06 - tot_loss: 0.3292198598692515 - acc: 0.963683351468988 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 1.5043435096740723 - sq_loss: 2.1202151856414275e-06 - tot_loss: 0.31731651109556935 - acc: 0.9640914036996736 - val_acc: 0.9453681710213777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 1.5148100852966309 - sq_loss: 2.111140020133462e-06 - tot_loss: 0.40525744931006 - acc: 0.9639553862894451 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 1.524599313735962 - sq_loss: 2.1075916265544947e-06 - tot_loss: 0.3331333565344341 - acc: 0.9640914036996736 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 1.5118377208709717 - sq_loss: 2.10231314667908e-06 - tot_loss: 0.3288837512563916 - acc: 0.9640914036996736 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 1.514941692352295 - sq_loss: 2.0969391698599793e-06 - tot_loss: 0.317444891142852 - acc: 0.9640914036996736 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 1.4981038570404053 - sq_loss: 2.0942779883625917e-06 - tot_loss: 0.2996512735296939 - acc: 0.9642274211099021 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 1.4960808753967285 - sq_loss: 2.087925849991734e-06 - tot_loss: 0.31849048415977155 - acc: 0.9644994559303591 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 1.4886348247528076 - sq_loss: 2.086594577122014e-06 - tot_loss: 0.33125581503863977 - acc: 0.9647714907508161 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 1.5100643634796143 - sq_loss: 2.080378180835396e-06 - tot_loss: 0.32991777231885866 - acc: 0.9647714907508161 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 1.514723539352417 - sq_loss: 2.075915062960121e-06 - tot_loss: 0.3227241073216742 - acc: 0.9654515778019587 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 1.5047693252563477 - sq_loss: 2.071315066132229e-06 - tot_loss: 0.33181551652745167 - acc: 0.9653155603917302 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 1.5080230236053467 - sq_loss: 2.0656480046454817e-06 - tot_loss: 0.32129070209813104 - acc: 0.9653155603917302 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 1.487168550491333 - sq_loss: 2.0622458123398246e-06 - tot_loss: 0.29286777939828657 - acc: 0.9653155603917302 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 1.5047285556793213 - sq_loss: 2.058591917375452e-06 - tot_loss: 0.3425297992178358 - acc: 0.9653155603917302 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 1.5047574043273926 - sq_loss: 2.054319338640198e-06 - tot_loss: 0.3050403422023349 - acc: 0.9653155603917302 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 1.4917120933532715 - sq_loss: 2.0524153114820365e-06 - tot_loss: 0.32501992359162113 - acc: 0.9657236126224157 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 1.5176596641540527 - sq_loss: 2.0477045836742036e-06 - tot_loss: 0.3405968770417962 - acc: 0.9657236126224157 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 1.4840612411499023 - sq_loss: 2.0424490685400087e-06 - tot_loss: 0.33786808558807735 - acc: 0.9655875952121872 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 1.5174787044525146 - sq_loss: 2.0357856556074694e-06 - tot_loss: 0.3309974636081945 - acc: 0.9650435255712732 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 1.5104851722717285 - sq_loss: 2.0318300357757835e-06 - tot_loss: 0.3349488510010703 - acc: 0.9657236126224157 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 1.4993317127227783 - sq_loss: 2.024718696702621e-06 - tot_loss: 0.33204823307176223 - acc: 0.9657236126224157 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 1.4957644939422607 - sq_loss: 2.019943849518313e-06 - tot_loss: 0.3115204634664188 - acc: 0.9654515778019587 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 1.5097479820251465 - sq_loss: 2.0155719084868906e-06 - tot_loss: 0.341629795368144 - acc: 0.9657236126224157 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 1.5121703147888184 - sq_loss: 2.0118300199101213e-06 - tot_loss: 0.2980640214643069 - acc: 0.9659956474428727 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 1.5125699043273926 - sq_loss: 2.005443548114272e-06 - tot_loss: 0.3199687316058828 - acc: 0.9658596300326442 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 1.5121676921844482 - sq_loss: 2.0018437680846546e-06 - tot_loss: 0.3104002715159577 - acc: 0.9661316648531012 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 1.503373146057129 - sq_loss: 1.9955950847361237e-06 - tot_loss: 0.3424284459547371 - acc: 0.9661316648531012 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 1.4987950325012207 - sq_loss: 1.9930248527089134e-06 - tot_loss: 0.31754280658799594 - acc: 0.9664036996735582 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 1.4963746070861816 - sq_loss: 1.9873466499120696e-06 - tot_loss: 0.32987275689615814 - acc: 0.9661316648531012 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 1.4893734455108643 - sq_loss: 1.9835329112538602e-06 - tot_loss: 0.31665787025824876 - acc: 0.9661316648531012 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 1.5139663219451904 - sq_loss: 1.9791900740528945e-06 - tot_loss: 0.3054685696681618 - acc: 0.9662676822633297 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 1.5114479064941406 - sq_loss: 1.9738724859053036e-06 - tot_loss: 0.3154906930574102 - acc: 0.9662676822633297 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 1.5191946029663086 - sq_loss: 1.9694252841873094e-06 - tot_loss: 0.31867419044686507 - acc: 0.9662676822633297 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 1.4992156028747559 - sq_loss: 1.964776402019197e-06 - tot_loss: 0.3526045250570373 - acc: 0.9664036996735582 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 1.524498462677002 - sq_loss: 1.961773250513943e-06 - tot_loss: 0.36337714026050616 - acc: 0.9664036996735582 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 1.516188621520996 - sq_loss: 1.959433120646281e-06 - tot_loss: 0.3354614005767891 - acc: 0.9665397170837867 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 1.5095665454864502 - sq_loss: 1.9559797692636494e-06 - tot_loss: 0.3120861169092546 - acc: 0.9665397170837867 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 1.4976410865783691 - sq_loss: 1.951881813511136e-06 - tot_loss: 0.3394830282411929 - acc: 0.9664036996735582 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 1.5040476322174072 - sq_loss: 1.948558747244533e-06 - tot_loss: 0.33166719305861925 - acc: 0.9662676822633297 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 1.4965357780456543 - sq_loss: 1.9453491404419765e-06 - tot_loss: 0.31505052245207477 - acc: 0.9664036996735582 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 1.485698938369751 - sq_loss: 1.944083805938135e-06 - tot_loss: 0.32217175760394046 - acc: 0.9664036996735582 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 1.4864311218261719 - sq_loss: 1.939331468747696e-06 - tot_loss: 0.31315239251076044 - acc: 0.9664036996735582 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 1.5091252326965332 - sq_loss: 1.9347123725310666e-06 - tot_loss: 0.3345495868089108 - acc: 0.9666757344940152 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 1.506812334060669 - sq_loss: 1.9282583707536105e-06 - tot_loss: 0.3079766970855031 - acc: 0.9664036996735582 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 1.4943954944610596 - sq_loss: 1.9242099824623438e-06 - tot_loss: 0.3233086378763188 - acc: 0.9674918389553863 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 1.4934420585632324 - sq_loss: 1.9201752365916036e-06 - tot_loss: 0.3400862233409132 - acc: 0.9673558215451578 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 1.496166706085205 - sq_loss: 1.917269401019439e-06 - tot_loss: 0.34896053876844313 - acc: 0.9668117519042437 - val_acc: 0.9480827960637936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 1.4946808815002441 - sq_loss: 1.9127141968056094e-06 - tot_loss: 0.33857715344301287 - acc: 0.9674918389553863 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 1.5009996891021729 - sq_loss: 1.9082763174083084e-06 - tot_loss: 0.34700187092092794 - acc: 0.9669477693144722 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 1.5079121589660645 - sq_loss: 1.9039842982238042e-06 - tot_loss: 0.2829070221640011 - acc: 0.9676278563656148 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 1.514195442199707 - sq_loss: 1.8997869801751222e-06 - tot_loss: 0.3026107529937647 - acc: 0.9676278563656148 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 1.5044610500335693 - sq_loss: 1.8976089677380514e-06 - tot_loss: 0.3155206507150927 - acc: 0.9673558215451578 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 1.4974758625030518 - sq_loss: 1.8955291807287722e-06 - tot_loss: 0.34297346770425197 - acc: 0.9680359085963003 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 1.517035961151123 - sq_loss: 1.8951442370962468e-06 - tot_loss: 0.3340064307305033 - acc: 0.9681719260065288 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 1.5124173164367676 - sq_loss: 1.891898364192457e-06 - tot_loss: 0.3345556003390646 - acc: 0.9684439608269858 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 1.4986956119537354 - sq_loss: 1.887593157334777e-06 - tot_loss: 0.30971199508156744 - acc: 0.9689880304678999 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 1.497262716293335 - sq_loss: 1.8834500679076882e-06 - tot_loss: 0.346965465882799 - acc: 0.9683079434167573 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 1.5042598247528076 - sq_loss: 1.877022668850259e-06 - tot_loss: 0.35766184823566594 - acc: 0.9683079434167573 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 1.4957871437072754 - sq_loss: 1.8729519979387987e-06 - tot_loss: 0.31754066172014195 - acc: 0.9678998911860718 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 1.5014519691467285 - sq_loss: 1.8688712088987813e-06 - tot_loss: 0.3396027221027733 - acc: 0.9684439608269858 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 1.5154547691345215 - sq_loss: 1.8646167063707253e-06 - tot_loss: 0.32481497366300616 - acc: 0.9685799782372143 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 1.5039863586425781 - sq_loss: 1.8585790257930057e-06 - tot_loss: 0.3306598041347941 - acc: 0.9688520130576714 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 1.498837947845459 - sq_loss: 1.855879077083955e-06 - tot_loss: 0.2987883460230263 - acc: 0.9687159956474428 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 1.5301403999328613 - sq_loss: 1.8500142004995723e-06 - tot_loss: 0.34281061334900187 - acc: 0.9688520130576714 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 1.5152740478515625 - sq_loss: 1.848162696660438e-06 - tot_loss: 0.34659350472551775 - acc: 0.9684439608269858 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 1.5216302871704102 - sq_loss: 1.8435022184348782e-06 - tot_loss: 0.3349636179010629 - acc: 0.9687159956474428 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 1.5131542682647705 - sq_loss: 1.839291030591994e-06 - tot_loss: 0.3065909925533017 - acc: 0.9687159956474428 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 1.5210576057434082 - sq_loss: 1.8351141761741019e-06 - tot_loss: 0.28851927223939633 - acc: 0.9688520130576714 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 1.5365259647369385 - sq_loss: 1.832161956372147e-06 - tot_loss: 0.32778421204355723 - acc: 0.9688520130576714 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 1.5077171325683594 - sq_loss: 1.8297939732292434e-06 - tot_loss: 0.33994173957949414 - acc: 0.9687159956474428 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 1.5302672386169434 - sq_loss: 1.8270002328790724e-06 - tot_loss: 0.30399147856950215 - acc: 0.9687159956474428 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 1.5337045192718506 - sq_loss: 1.8229760598842404e-06 - tot_loss: 0.36050227377499766 - acc: 0.9688520130576714 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 1.5115489959716797 - sq_loss: 1.8187195109931054e-06 - tot_loss: 0.3191058735125001 - acc: 0.9687159956474428 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 1.513645887374878 - sq_loss: 1.8159429373554303e-06 - tot_loss: 0.3310550822408782 - acc: 0.9687159956474428 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 1.5181853771209717 - sq_loss: 1.8111738881998463e-06 - tot_loss: 0.308629298352999 - acc: 0.9687159956474428 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 1.5097284317016602 - sq_loss: 1.8093822973241913e-06 - tot_loss: 0.31883225081510336 - acc: 0.9687159956474428 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 1.5277605056762695 - sq_loss: 1.8074598528983188e-06 - tot_loss: 0.36813640147634086 - acc: 0.9688520130576714 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 1.5284888744354248 - sq_loss: 1.804049816200859e-06 - tot_loss: 0.3311227683650735 - acc: 0.9688520130576714 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 1.5210771560668945 - sq_loss: 1.8002702972808038e-06 - tot_loss: 0.3227630775833008 - acc: 0.9689880304678999 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 1.5072598457336426 - sq_loss: 1.7977995412366e-06 - tot_loss: 0.349357017816196 - acc: 0.9688520130576714 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 1.4992167949676514 - sq_loss: 1.7940100178748253e-06 - tot_loss: 0.3323829554235198 - acc: 0.969804134929271 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 1.5401089191436768 - sq_loss: 1.7923085806614836e-06 - tot_loss: 0.34205982761074605 - acc: 0.9693960826985855 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 1.4767177104949951 - sq_loss: 1.7888301044877153e-06 - tot_loss: 0.31662824848385807 - acc: 0.9689880304678999 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 1.505681037902832 - sq_loss: 1.7847154367700568e-06 - tot_loss: 0.3268756069301393 - acc: 0.9693960826985855 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 1.5128939151763916 - sq_loss: 1.7828144791565137e-06 - tot_loss: 0.33483671393918524 - acc: 0.9702121871599565 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 1.5201406478881836 - sq_loss: 1.7781816268325201e-06 - tot_loss: 0.3298311367840938 - acc: 0.9693960826985855 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 1.5224268436431885 - sq_loss: 1.7719499965096475e-06 - tot_loss: 0.35345808202811035 - acc: 0.9704842219804135 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 1.5121290683746338 - sq_loss: 1.7668895679889829e-06 - tot_loss: 0.3233388384771825 - acc: 0.9704842219804135 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 1.5303709506988525 - sq_loss: 1.7640514897721005e-06 - tot_loss: 0.36312759773945213 - acc: 0.9704842219804135 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 1.5122039318084717 - sq_loss: 1.7628364048505318e-06 - tot_loss: 0.3323722536937632 - acc: 0.9704842219804135 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 1.5338997840881348 - sq_loss: 1.7618336869418272e-06 - tot_loss: 0.35036464706201276 - acc: 0.970348204570185 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 1.5261342525482178 - sq_loss: 1.7601204262973624e-06 - tot_loss: 0.3241749311037765 - acc: 0.9704842219804135 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 1.5043880939483643 - sq_loss: 1.7575226820554235e-06 - tot_loss: 0.31844083911496224 - acc: 0.9704842219804135 - val_acc: 0.9497794367153037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 1.5123319625854492 - sq_loss: 1.7551220707900939e-06 - tot_loss: 0.32382453224920926 - acc: 0.9704842219804135 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 1.512721061706543 - sq_loss: 1.7510916450191871e-06 - tot_loss: 0.3201326106953468 - acc: 0.970076169749728 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 1.5157065391540527 - sq_loss: 1.747920578054618e-06 - tot_loss: 0.318557154312864 - acc: 0.9702121871599565 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 1.516000747680664 - sq_loss: 1.7445431694795843e-06 - tot_loss: 0.31212945877480447 - acc: 0.970348204570185 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 1.5170247554779053 - sq_loss: 1.7410778809789917e-06 - tot_loss: 0.3234533375574813 - acc: 0.970348204570185 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 1.5077383518218994 - sq_loss: 1.7383588328812039e-06 - tot_loss: 0.30660041167561314 - acc: 0.970348204570185 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 1.5110230445861816 - sq_loss: 1.7337798681182903e-06 - tot_loss: 0.35255105998350533 - acc: 0.9704842219804135 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 1.5254368782043457 - sq_loss: 1.7302860442214296e-06 - tot_loss: 0.299151025192403 - acc: 0.970348204570185 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 1.5257782936096191 - sq_loss: 1.7262864275835454e-06 - tot_loss: 0.3314574047761525 - acc: 0.9707562568008705 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 1.5333919525146484 - sq_loss: 1.7239717635675333e-06 - tot_loss: 0.33319391295642564 - acc: 0.9710282916213275 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 1.532789945602417 - sq_loss: 1.7213161527251941e-06 - tot_loss: 0.30402701877446336 - acc: 0.971164309031556 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 1.522489070892334 - sq_loss: 1.7197213537656353e-06 - tot_loss: 0.3291393910978 - acc: 0.971164309031556 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 1.5156219005584717 - sq_loss: 1.7170369801533525e-06 - tot_loss: 0.306612930352836 - acc: 0.971436343852013 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 1.539916753768921 - sq_loss: 1.714136828923074e-06 - tot_loss: 0.3213109859404062 - acc: 0.971436343852013 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 1.5198485851287842 - sq_loss: 1.7089956827476271e-06 - tot_loss: 0.3299635845706259 - acc: 0.9717083786724701 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 1.5295360088348389 - sq_loss: 1.7051028180503636e-06 - tot_loss: 0.33326572143787203 - acc: 0.9717083786724701 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 1.516629695892334 - sq_loss: 1.7021862959154532e-06 - tot_loss: 0.3729887713669715 - acc: 0.9717083786724701 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 1.5238063335418701 - sq_loss: 1.699896984064253e-06 - tot_loss: 0.3351755803222458 - acc: 0.9717083786724701 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 1.5251579284667969 - sq_loss: 1.6987220305964001e-06 - tot_loss: 0.3423611127888151 - acc: 0.971436343852013 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 1.5228021144866943 - sq_loss: 1.6958016431090073e-06 - tot_loss: 0.29833439687638563 - acc: 0.9717083786724701 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 1.517397403717041 - sq_loss: 1.69377415204508e-06 - tot_loss: 0.3055417017143309 - acc: 0.9719804134929271 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 1.5404551029205322 - sq_loss: 1.68962412772089e-06 - tot_loss: 0.35842861577065044 - acc: 0.9715723612622416 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 1.522956371307373 - sq_loss: 1.684213543740043e-06 - tot_loss: 0.3175491414017504 - acc: 0.9719804134929271 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 1.5088860988616943 - sq_loss: 1.6796478803371429e-06 - tot_loss: 0.3481397648374731 - acc: 0.9719804134929271 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 1.5404465198516846 - sq_loss: 1.6782106513346662e-06 - tot_loss: 0.34998979317187917 - acc: 0.9719804134929271 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 1.517225742340088 - sq_loss: 1.6774259847807116e-06 - tot_loss: 0.3159291368867274 - acc: 0.9721164309031556 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 1.5103967189788818 - sq_loss: 1.674663963058265e-06 - tot_loss: 0.3647200926960368 - acc: 0.9721164309031556 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 1.5214385986328125 - sq_loss: 1.6729690059946734e-06 - tot_loss: 0.3396973397013001 - acc: 0.9721164309031556 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 1.5407638549804688 - sq_loss: 1.6700240621503326e-06 - tot_loss: 0.313990735299976 - acc: 0.9719804134929271 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 1.521589994430542 - sq_loss: 1.6682942032275605e-06 - tot_loss: 0.34149780611649927 - acc: 0.9717083786724701 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 1.5411672592163086 - sq_loss: 1.6639946807117667e-06 - tot_loss: 0.31907808421220096 - acc: 0.9722524483133841 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 1.5132310390472412 - sq_loss: 1.6605791870460962e-06 - tot_loss: 0.33665829133039527 - acc: 0.9721164309031556 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 1.5130765438079834 - sq_loss: 1.6569441640967852e-06 - tot_loss: 0.3132712317752313 - acc: 0.9722524483133841 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 1.5164759159088135 - sq_loss: 1.6538984937142232e-06 - tot_loss: 0.31284712875834053 - acc: 0.9721164309031556 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 1.529989242553711 - sq_loss: 1.6498481727467151e-06 - tot_loss: 0.35673567898693737 - acc: 0.9723884657236126 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 1.5175645351409912 - sq_loss: 1.6473890127599589e-06 - tot_loss: 0.36241896209102453 - acc: 0.9726605005440696 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 1.5189456939697266 - sq_loss: 1.6465759244965739e-06 - tot_loss: 0.32648101960617115 - acc: 0.9727965179542981 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 1.5172419548034668 - sq_loss: 1.6428001572421636e-06 - tot_loss: 0.35105713338654443 - acc: 0.9722524483133841 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 1.525285005569458 - sq_loss: 1.6390049495385028e-06 - tot_loss: 0.3297954953629638 - acc: 0.9718443960826986 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 1.5085375308990479 - sq_loss: 1.6363457007173565e-06 - tot_loss: 0.35926118569428755 - acc: 0.9719804134929271 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 1.5121238231658936 - sq_loss: 1.6325698197761085e-06 - tot_loss: 0.3791680368246517 - acc: 0.9727965179542981 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 1.523378610610962 - sq_loss: 1.628595668989874e-06 - tot_loss: 0.33450670443773767 - acc: 0.9732045701849836 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 1.533700942993164 - sq_loss: 1.624779770281748e-06 - tot_loss: 0.3453240897439951 - acc: 0.9736126224156693 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 1.5136091709136963 - sq_loss: 1.6235243265327881e-06 - tot_loss: 0.3344085832397097 - acc: 0.9736126224156693 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 1.5233700275421143 - sq_loss: 1.6237224826909369e-06 - tot_loss: 0.3050987705673087 - acc: 0.9732045701849836 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 1.5049419403076172 - sq_loss: 1.6213077742577298e-06 - tot_loss: 0.30801569762528924 - acc: 0.9736126224156693 - val_acc: 0.9511367492365117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 1.518796682357788 - sq_loss: 1.616961299077957e-06 - tot_loss: 0.3363725191018778 - acc: 0.9732045701849836 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 1.5393218994140625 - sq_loss: 1.6149010662047658e-06 - tot_loss: 0.33301120991203703 - acc: 0.9736126224156693 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 1.520601749420166 - sq_loss: 1.6121723547257716e-06 - tot_loss: 0.3158680360960071 - acc: 0.9730685527747551 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 1.528000831604004 - sq_loss: 1.6107549072330585e-06 - tot_loss: 0.33596893381235216 - acc: 0.9730685527747551 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 1.5100915431976318 - sq_loss: 1.6087697076727636e-06 - tot_loss: 0.3356267255134471 - acc: 0.9719804134929271 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 1.5011541843414307 - sq_loss: 1.6068247532530222e-06 - tot_loss: 0.3352690862417367 - acc: 0.9722524483133841 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 1.5133552551269531 - sq_loss: 1.6051960756158223e-06 - tot_loss: 0.36329678250641617 - acc: 0.9725244831338411 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 1.5106449127197266 - sq_loss: 1.6038482044677949e-06 - tot_loss: 0.3347060020973265 - acc: 0.9730685527747551 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 1.5225682258605957 - sq_loss: 1.5992887938409694e-06 - tot_loss: 0.3548776532283906 - acc: 0.9729325353645266 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 1.5183539390563965 - sq_loss: 1.5954235550452722e-06 - tot_loss: 0.30468306019641567 - acc: 0.9732045701849836 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 1.5190021991729736 - sq_loss: 1.593768843122234e-06 - tot_loss: 0.33047288205551784 - acc: 0.9732045701849836 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 1.5169508457183838 - sq_loss: 1.590401780049433e-06 - tot_loss: 0.34238928157819437 - acc: 0.9732045701849836 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 1.5454113483428955 - sq_loss: 1.5873968095547752e-06 - tot_loss: 0.32958198939258043 - acc: 0.9732045701849836 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 1.5408809185028076 - sq_loss: 1.5842199445614824e-06 - tot_loss: 0.3300670574342117 - acc: 0.9732045701849836 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 1.5264790058135986 - sq_loss: 1.5816336826901534e-06 - tot_loss: 0.3326246904049528 - acc: 0.9730685527747551 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 1.5298535823822021 - sq_loss: 1.5777551425344427e-06 - tot_loss: 0.2978565295919813 - acc: 0.9730685527747551 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 1.5150015354156494 - sq_loss: 1.574911038915161e-06 - tot_loss: 0.3393001262901647 - acc: 0.9730685527747551 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 1.5220932960510254 - sq_loss: 1.5729685856058495e-06 - tot_loss: 0.3612013424871021 - acc: 0.9730685527747551 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 1.53593111038208 - sq_loss: 1.5714686014689505e-06 - tot_loss: 0.3518112740528405 - acc: 0.9730685527747551 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 1.5323231220245361 - sq_loss: 1.5698199149483116e-06 - tot_loss: 0.3676829418365859 - acc: 0.9733405875952121 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 1.52089524269104 - sq_loss: 1.566361220284307e-06 - tot_loss: 0.35563811546824464 - acc: 0.9733405875952121 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 1.5628507137298584 - sq_loss: 1.5652843785574078e-06 - tot_loss: 0.3635382509945595 - acc: 0.9733405875952121 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 1.5173742771148682 - sq_loss: 1.5623930949004716e-06 - tot_loss: 0.3417044941859606 - acc: 0.9733405875952121 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 1.537614345550537 - sq_loss: 1.5622990758856758e-06 - tot_loss: 0.3597268645326368 - acc: 0.9737486398258978 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 1.5249965190887451 - sq_loss: 1.5592323734381353e-06 - tot_loss: 0.3270757970981011 - acc: 0.9742927094668118 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 1.5166070461273193 - sq_loss: 1.5565771036563092e-06 - tot_loss: 0.34141038289391457 - acc: 0.9744287268770403 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 1.5171949863433838 - sq_loss: 1.5549188674413017e-06 - tot_loss: 0.32700732467964766 - acc: 0.9744287268770403 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 1.5321805477142334 - sq_loss: 1.5535804323008051e-06 - tot_loss: 0.35871577775001917 - acc: 0.9745647442872688 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 1.5399880409240723 - sq_loss: 1.5528692074440187e-06 - tot_loss: 0.3254733180356304 - acc: 0.9745647442872688 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 1.5270822048187256 - sq_loss: 1.5489814586544526e-06 - tot_loss: 0.323744604977831 - acc: 0.9745647442872688 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 1.5084812641143799 - sq_loss: 1.5453908872586908e-06 - tot_loss: 0.37392414634961213 - acc: 0.9744287268770403 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 1.5038864612579346 - sq_loss: 1.541229835311242e-06 - tot_loss: 0.3486265510153119 - acc: 0.9747007616974973 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 1.5082707405090332 - sq_loss: 1.53769815369742e-06 - tot_loss: 0.3803103057808217 - acc: 0.9747007616974973 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 1.515129804611206 - sq_loss: 1.5346171267083264e-06 - tot_loss: 0.3005141980675159 - acc: 0.9747007616974973 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 1.532987117767334 - sq_loss: 1.530577151243051e-06 - tot_loss: 0.35215453242600336 - acc: 0.9748367791077258 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 1.5276050567626953 - sq_loss: 1.5282251979442663e-06 - tot_loss: 0.35463157030263215 - acc: 0.9745647442872688 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 1.5116565227508545 - sq_loss: 1.5260580994436168e-06 - tot_loss: 0.337388971911337 - acc: 0.9748367791077258 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 1.514591932296753 - sq_loss: 1.5222479987642146e-06 - tot_loss: 0.3054954068063971 - acc: 0.9748367791077258 - val_acc: 0.9524940617577197\n",
      "CR_1 = 0.17665842270710058   CR_2 = 0.17592699696476163\n",
      "/home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 3\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "alpha = 1\n",
    "\n",
    "\n",
    "\n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "    d0 = 561 #561 =3*11*17\n",
    "\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 512\n",
    "    d6 = 6 \n",
    "\n",
    "\n",
    "    W1 = 0.2*init.kaiming_normal_(torch.empty(d1, d0, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    W2 = 0.2*init.kaiming_normal_(torch.empty(d2, d1, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles factors, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    W3 = 0.2*init.kaiming_normal_(torch.empty(d3, d2, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    W4 = 0.2*init.kaiming_normal_(torch.empty(d4, d3, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    W5 = 0.2*init.kaiming_normal_(torch.empty(d5, d4, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())\n",
    "    factors5 = tensor_train(W5_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "\n",
    "    W6 = 0.2*init.kaiming_normal_(torch.empty(d6, d5, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    b6 = 0*torch.ones(d6, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = nn.ReLU()(U5)\n",
    "    U6 = torch.addmm(b6.repeat(1, N), W6, V5)\n",
    "    V6 = U6 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V6 = (y_one_hot + gamma*U6 + alpha*V6)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U6 = (gamma*V6 + rho*(torch.mm(W6,V5) + b6.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W6, b6 = updateWb_org(U6,V5,W6,b6,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "        # update for 5th layer\n",
    "        # update V3\n",
    "        V5 = updateV(U5,U6,W6,b6,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U5 = relu_prox(V5,(rho*torch.addmm(b5.repeat(1,N), W5, V4) + alpha*U5)/(rho + alpha),(rho + alpha)/gamma,d5,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W5, b5 = updateWb(U5,V4,W5,b5,W5_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4))\n",
    "        W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors5 = tensor_train(W5_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        a5_train = nn.ReLU()(torch.addmm(b5.repeat(1, N), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b6.repeat(1, N), W6, a5_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        a5_test = nn.ReLU()(torch.addmm(b5.repeat(1, N_test), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b6.repeat(1, N_test), W6, a5_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V6,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b6.repeat(1,N), W6, V5),U6,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,nn.ReLU()(U5),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V6,U6,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W5.reshape((4,4,4,4,4,4,4,4,4)),torch.as_tensor(W5_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "    factors5_shape=[f.shape for f in factors5]\n",
    "    Sum_of_variables_factors5=sum(list(x*y*z for x,y,z in factors5_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4+Sum_of_variables_factors5\n",
    "\n",
    "    CR_1=((total_variabels)+(d5*d6))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5+d5*d6)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#     #this postion to add new row into existing table\n",
    "#         df=pd.read_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "#         new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "#                    'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "#                    'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1],'seed':seed} \n",
    "#         df=df.append(new_row,ignore_index=True)\n",
    "#         df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"KaimingNormal_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e5c2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133d333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
