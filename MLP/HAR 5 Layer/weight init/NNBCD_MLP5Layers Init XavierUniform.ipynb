{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4cb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a157bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a5c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087d0e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 3 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 3.3170061111450195 - sq_loss: 661.6710205078125 - tot_loss: 962.7074280442848 - acc: 0.17478237214363437 - val_acc: 0.167288768238887\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 2.860927104949951 - sq_loss: 294.07598876953125 - tot_loss: 484.4423112773802 - acc: 0.18620783460282916 - val_acc: 0.17645062775704107\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 2.822197914123535 - sq_loss: 163.58180236816406 - tot_loss: 263.883510355372 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 2.8540472984313965 - sq_loss: 89.09494018554688 - tot_loss: 148.20156379742548 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 2.8872599601745605 - sq_loss: 48.01134490966797 - tot_loss: 85.97253378527239 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 2.854246139526367 - sq_loss: 25.78118324279785 - tot_loss: 52.208319302182645 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 2.9012584686279297 - sq_loss: 13.85289478302002 - tot_loss: 33.728779416531324 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 2.794618606567383 - sq_loss: 7.468990802764893 - tot_loss: 23.43118598172441 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 2.8535640239715576 - sq_loss: 4.0497727394104 - tot_loss: 17.558110959944315 - acc: 0.24483133841131666 - val_acc: 0.23786901934170343\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 2.829759359359741 - sq_loss: 2.212993860244751 - tot_loss: 14.084177856100723 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 2.8020193576812744 - sq_loss: 1.2216771841049194 - tot_loss: 11.884769330616109 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 2.7659177780151367 - sq_loss: 0.6832965612411499 - tot_loss: 10.365010054316372 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 2.8780264854431152 - sq_loss: 0.3885408937931061 - tot_loss: 9.237535368418321 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 2.8376686573028564 - sq_loss: 0.2254902422428131 - tot_loss: 8.322481795679778 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 2.818857192993164 - sq_loss: 0.1341242641210556 - tot_loss: 7.557693889713846 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 2.796055316925049 - sq_loss: 0.08210127800703049 - tot_loss: 6.894520129542798 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 2.862257719039917 - sq_loss: 0.05190325155854225 - tot_loss: 6.312623987789266 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 2.829108715057373 - sq_loss: 0.03397207334637642 - tot_loss: 5.802065971831325 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 2.810450553894043 - sq_loss: 0.02305046282708645 - tot_loss: 5.35093907645205 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 2.910637378692627 - sq_loss: 0.01621175743639469 - tot_loss: 4.967051015992183 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 2.7799599170684814 - sq_loss: 0.011802620254456997 - tot_loss: 4.607596105430275 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 2.8121964931488037 - sq_loss: 0.008874100632965565 - tot_loss: 4.316990041959798 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 2.8035688400268555 - sq_loss: 0.00687106279656291 - tot_loss: 4.026957417387166 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 2.8445258140563965 - sq_loss: 0.005461203400045633 - tot_loss: 3.7821772949537262 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 2.7929608821868896 - sq_loss: 0.00444104615598917 - tot_loss: 3.5597565927455435 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 2.799903392791748 - sq_loss: 0.0036836822982877493 - tot_loss: 3.3615053364337655 - acc: 0.19613710554951033 - val_acc: 0.18866644044791314\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 2.8512232303619385 - sq_loss: 0.003107245545834303 - tot_loss: 3.1675556822665385 - acc: 0.2324537540805223 - val_acc: 0.2130980658296573\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 2.7908637523651123 - sq_loss: 0.002659126650542021 - tot_loss: 2.999092972037033 - acc: 0.28305223068552776 - val_acc: 0.26128266033254155\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 2.775496482849121 - sq_loss: 0.0023037621285766363 - tot_loss: 2.8545298122262466 - acc: 0.3258977149075082 - val_acc: 0.3013233797081778\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 2.856768846511841 - sq_loss: 0.002017080085352063 - tot_loss: 2.7039581342687597 - acc: 0.3407236126224157 - val_acc: 0.334577536477774\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 2.8201539516448975 - sq_loss: 0.00178165000397712 - tot_loss: 2.5793783243425423 - acc: 0.3486126224156692 - val_acc: 0.3484899898201561\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 2.8172876834869385 - sq_loss: 0.0015855766832828522 - tot_loss: 2.4501116362880566 - acc: 0.35514145810663766 - val_acc: 0.3505259586019681\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 2.8560409545898438 - sq_loss: 0.00141988939139992 - tot_loss: 2.3450313529756386 - acc: 0.3574537540805223 - val_acc: 0.3505259586019681\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 2.7971551418304443 - sq_loss: 0.0012785594444721937 - tot_loss: 2.25223376127542 - acc: 0.35813384113166485 - val_acc: 0.3512046148625721\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 2.805633544921875 - sq_loss: 0.0011567143956199288 - tot_loss: 2.147654918357148 - acc: 0.3673830250272035 - val_acc: 0.35595520868680014\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 2.847689390182495 - sq_loss: 0.0010510466527193785 - tot_loss: 2.0571698881176417 - acc: 0.4047878128400435 - val_acc: 0.3878520529351883\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 2.818296432495117 - sq_loss: 0.0009586829110048711 - tot_loss: 1.9705462055753742 - acc: 0.46055495103373234 - val_acc: 0.44316253817441464\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 2.908128499984741 - sq_loss: 0.0008772372384555638 - tot_loss: 1.8965415823986405 - acc: 0.5057127312295974 - val_acc: 0.48897183576518494\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 2.8276827335357666 - sq_loss: 0.000805258343461901 - tot_loss: 1.8277022585571103 - acc: 0.5258433079434167 - val_acc: 0.5140821174075331\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 2.8301198482513428 - sq_loss: 0.0007409113459289074 - tot_loss: 1.7495338620065013 - acc: 0.5378128400435256 - val_acc: 0.5242619613165932\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 2.8078453540802 - sq_loss: 0.0006833314546383917 - tot_loss: 1.6784269287127245 - acc: 0.5420293797606094 - val_acc: 0.5276552426196132\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 2.773427724838257 - sq_loss: 0.0006316726794466376 - tot_loss: 1.6199666642496595 - acc: 0.5431175190424374 - val_acc: 0.5293518832711231\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 2.8259027004241943 - sq_loss: 0.0005850787274539471 - tot_loss: 1.5593185763282236 - acc: 0.5444776931447225 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 2.861703395843506 - sq_loss: 0.000542660360224545 - tot_loss: 1.502495377433661 - acc: 0.5450217627856365 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 2.834434747695923 - sq_loss: 0.0005042697302997112 - tot_loss: 1.4451080020444351 - acc: 0.545429815016322 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 2.851759672164917 - sq_loss: 0.0004692875372711569 - tot_loss: 1.3953544038158725 - acc: 0.5462459194776932 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 2.8093461990356445 - sq_loss: 0.0004374394775368273 - tot_loss: 1.3504174016288744 - acc: 0.5467899891186072 - val_acc: 0.5310485239226331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 2.7758679389953613 - sq_loss: 0.0004084503452759236 - tot_loss: 1.2991925797941803 - acc: 0.5478781284004353 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 2.8293449878692627 - sq_loss: 0.000381750549422577 - tot_loss: 1.2592062403091404 - acc: 0.5485582154515778 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 2.7669570446014404 - sq_loss: 0.0003570599656086415 - tot_loss: 1.2211416346071928 - acc: 0.5525027203482046 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 2.865910291671753 - sq_loss: 0.00033427696325816214 - tot_loss: 1.1769297117189126 - acc: 0.5575353645266594 - val_acc: 0.5313878520529352\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 2.792396306991577 - sq_loss: 0.0003134086146019399 - tot_loss: 1.1377173734344979 - acc: 0.5639281828073993 - val_acc: 0.5330844927044452\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 2.8082211017608643 - sq_loss: 0.0002941115526482463 - tot_loss: 1.0868324898638093 - acc: 0.5738574537540805 - val_acc: 0.5364777740074652\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 2.793207883834839 - sq_loss: 0.0002762300136964768 - tot_loss: 1.0607261750174075 - acc: 0.588139281828074 - val_acc: 0.5415676959619953\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 2.7868850231170654 - sq_loss: 0.00025967953843064606 - tot_loss: 1.035343249932339 - acc: 0.6014689880304679 - val_acc: 0.5469969460468272\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 2.8210229873657227 - sq_loss: 0.00024423556169494987 - tot_loss: 0.9939901416364592 - acc: 0.6139825897714908 - val_acc: 0.5541228367831693\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 2.79718017578125 - sq_loss: 0.00022987715783528984 - tot_loss: 0.9570286244070303 - acc: 0.6266322089227421 - val_acc: 0.5646420088225313\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 2.7880923748016357 - sq_loss: 0.00021644821390509605 - tot_loss: 0.9316429661394068 - acc: 0.6380576713819369 - val_acc: 0.5771971496437055\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 2.7909815311431885 - sq_loss: 0.00020384891831781715 - tot_loss: 0.9087406086382543 - acc: 0.6481229597388466 - val_acc: 0.5924669155072956\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 2.829125165939331 - sq_loss: 0.00019205283024348319 - tot_loss: 0.8684699248678953 - acc: 0.6617247007616975 - val_acc: 0.6046827281981676\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 2.764202356338501 - sq_loss: 0.00018105794151779264 - tot_loss: 0.8475567859322837 - acc: 0.6741022850924918 - val_acc: 0.6172378690193417\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 2.8157622814178467 - sq_loss: 0.00017086422303691506 - tot_loss: 0.8207523921591928 - acc: 0.6860718171926007 - val_acc: 0.6277570410587038\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 2.8008360862731934 - sq_loss: 0.00016134257020894438 - tot_loss: 0.7942466239655914 - acc: 0.6924646354733406 - val_acc: 0.6382762130980658\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 2.8545820713043213 - sq_loss: 0.00015240884386003017 - tot_loss: 0.7694239905204086 - acc: 0.6998095756256801 - val_acc: 0.6498133695283339\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 2.845993995666504 - sq_loss: 0.00014403137902263552 - tot_loss: 0.7512981415411559 - acc: 0.7082426550598476 - val_acc: 0.6555819477434679\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 2.7973015308380127 - sq_loss: 0.00013616663636639714 - tot_loss: 0.7369067761765109 - acc: 0.7157236126224157 - val_acc: 0.6620291822192059\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 2.7792325019836426 - sq_loss: 0.00012873865489382297 - tot_loss: 0.716518974479186 - acc: 0.7225244831338411 - val_acc: 0.669833729216152\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 2.770055055618286 - sq_loss: 0.00012165604130132124 - tot_loss: 0.6766917086097237 - acc: 0.7298694232861807 - val_acc: 0.6769596199524941\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 2.7675135135650635 - sq_loss: 0.00011508785974001512 - tot_loss: 0.6692028166362434 - acc: 0.7359902067464635 - val_acc: 0.6854428232100441\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 2.845902442932129 - sq_loss: 0.00010886901145568117 - tot_loss: 0.6468645095874308 - acc: 0.7406147986942329 - val_acc: 0.6918900576857822\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 2.819260358810425 - sq_loss: 0.00010301647853339091 - tot_loss: 0.6432951661290645 - acc: 0.7436071817192601 - val_acc: 0.6956226671191041\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 2.781813859939575 - sq_loss: 9.754455095389858e-05 - tot_loss: 0.6145500946786342 - acc: 0.75 - val_acc: 0.7007125890736342\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 2.754312515258789 - sq_loss: 9.23659754334949e-05 - tot_loss: 0.5845447258852801 - acc: 0.7550326441784548 - val_acc: 0.7071598235493722\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 2.7964396476745605 - sq_loss: 8.746517414692789e-05 - tot_loss: 0.574814173568484 - acc: 0.7582970620239391 - val_acc: 0.7122497455039023\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 2.7890820503234863 - sq_loss: 8.283331408165395e-05 - tot_loss: 0.5630179385775591 - acc: 0.7612894450489662 - val_acc: 0.7136070580251103\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 2.8014707565307617 - sq_loss: 7.847892993595451e-05 - tot_loss: 0.5575520538550336 - acc: 0.7637377584330794 - val_acc: 0.7180183237190363\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 2.7663543224334717 - sq_loss: 7.431962876580656e-05 - tot_loss: 0.5338502670761045 - acc: 0.7667301414581066 - val_acc: 0.7224295894129623\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 2.8526742458343506 - sq_loss: 7.042006473056972e-05 - tot_loss: 0.5273872544139522 - acc: 0.7691784548422198 - val_acc: 0.7251442144553784\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 2.805267333984375 - sq_loss: 6.673860480077565e-05 - tot_loss: 0.5179192494633753 - acc: 0.7706746463547334 - val_acc: 0.7288768238887003\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 2.806094169616699 - sq_loss: 6.322329863905907e-05 - tot_loss: 0.4910709890423277 - acc: 0.7725788900979326 - val_acc: 0.7339667458432304\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 2.7896039485931396 - sq_loss: 5.991006037220359e-05 - tot_loss: 0.48766055162468547 - acc: 0.7743471164309031 - val_acc: 0.7376993552765524\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 2.816234827041626 - sq_loss: 5.678435627487488e-05 - tot_loss: 0.48120265778516114 - acc: 0.7773394994559304 - val_acc: 0.7421106209704784\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 2.8179633617401123 - sq_loss: 5.380879156291485e-05 - tot_loss: 0.4650745009462298 - acc: 0.780195865070729 - val_acc: 0.7434679334916865\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 2.8157923221588135 - sq_loss: 5.101271744933911e-05 - tot_loss: 0.45701749163526983 - acc: 0.7814200217627857 - val_acc: 0.7468612147947065\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 2.8968520164489746 - sq_loss: 4.837172673433088e-05 - tot_loss: 0.4372740731680551 - acc: 0.7830522306855278 - val_acc: 0.7478791991856125\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 2.8297128677368164 - sq_loss: 4.589108721120283e-05 - tot_loss: 0.42940591006140494 - acc: 0.7857725788900979 - val_acc: 0.7505938242280285\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 2.817957639694214 - sq_loss: 4.353848271421157e-05 - tot_loss: 0.4240527032291084 - acc: 0.7875408052230686 - val_acc: 0.7536477774007465\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 2.807776927947998 - sq_loss: 4.13340276281815e-05 - tot_loss: 0.41311647857219214 - acc: 0.7891730141458106 - val_acc: 0.7573803868340685\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 2.8338208198547363 - sq_loss: 3.924598786397837e-05 - tot_loss: 0.40334335973807356 - acc: 0.7910772578890098 - val_acc: 0.7611129962673906\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 2.7748308181762695 - sq_loss: 3.720766835613176e-05 - tot_loss: 0.39672887200981677 - acc: 0.7929815016322089 - val_acc: 0.7624703087885986\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 2.8011136054992676 - sq_loss: 3.53174218616914e-05 - tot_loss: 0.3873140088553555 - acc: 0.7958378672470077 - val_acc: 0.7638276213098066\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 2.8093223571777344 - sq_loss: 3.351037230459042e-05 - tot_loss: 0.3763325423344668 - acc: 0.7985582154515778 - val_acc: 0.7662029182219205\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 2.820697784423828 - sq_loss: 3.180040584993549e-05 - tot_loss: 0.3678523439093624 - acc: 0.801006528835691 - val_acc: 0.7692568713946386\n",
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 2.8262946605682373 - sq_loss: 3.0208062526071444e-05 - tot_loss: 0.3680481384290033 - acc: 0.8039989118607181 - val_acc: 0.7702748557855447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 2.7742269039154053 - sq_loss: 2.865177702915389e-05 - tot_loss: 0.3522958973792356 - acc: 0.8065832426550599 - val_acc: 0.7723108245673567\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 2.8498504161834717 - sq_loss: 2.7211714041186497e-05 - tot_loss: 0.3435066642794027 - acc: 0.80930359085963 - val_acc: 0.7743467933491687\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 2.7989277839660645 - sq_loss: 2.5860144887701608e-05 - tot_loss: 0.3526974258554674 - acc: 0.8128400435255713 - val_acc: 0.7784187309127927\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 2.784961700439453 - sq_loss: 2.457087794027757e-05 - tot_loss: 0.33941718610753924 - acc: 0.8148803046789989 - val_acc: 0.7807940278249067\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 2.783499002456665 - sq_loss: 2.336964098503813e-05 - tot_loss: 0.3330163651211251 - acc: 0.8176006528835691 - val_acc: 0.7831693247370207\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 2.8244359493255615 - sq_loss: 2.2211879695532843e-05 - tot_loss: 0.33179725440948005 - acc: 0.8204570184983678 - val_acc: 0.7862232779097387\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 2.785179615020752 - sq_loss: 2.1125249986653216e-05 - tot_loss: 0.3188127356440873 - acc: 0.8223612622415669 - val_acc: 0.7882592466915507\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 2.8026435375213623 - sq_loss: 2.0111669073230587e-05 - tot_loss: 0.3131787270978066 - acc: 0.8248095756256801 - val_acc: 0.7896165592127588\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 2.8365445137023926 - sq_loss: 1.9131824956275523e-05 - tot_loss: 0.30104147902738987 - acc: 0.8272578890097932 - val_acc: 0.7919918561248728\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 2.7935287952423096 - sq_loss: 1.823712227633223e-05 - tot_loss: 0.2957439652057019 - acc: 0.8294341675734495 - val_acc: 0.7940278249066848\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 2.8126797676086426 - sq_loss: 1.7353073417325504e-05 - tot_loss: 0.287840406640953 - acc: 0.8332426550598476 - val_acc: 0.7960637936884968\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 2.775930643081665 - sq_loss: 1.649517798796296e-05 - tot_loss: 0.28849556795216813 - acc: 0.8363710554951034 - val_acc: 0.7980997624703088\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 2.777987003326416 - sq_loss: 1.572264045535121e-05 - tot_loss: 0.28312972137439374 - acc: 0.838411316648531 - val_acc: 0.7991177468612148\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 2.8361847400665283 - sq_loss: 1.4986361748015042e-05 - tot_loss: 0.28327294662301483 - acc: 0.8411316648531012 - val_acc: 0.8008143875127248\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 2.7984538078308105 - sq_loss: 1.4282751180871855e-05 - tot_loss: 0.2796873375141331 - acc: 0.8439880304678999 - val_acc: 0.8055649813369529\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 2.760617971420288 - sq_loss: 1.3605733329313807e-05 - tot_loss: 0.27363383033650734 - acc: 0.8469804134929271 - val_acc: 0.8086189345096708\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 2.8218655586242676 - sq_loss: 1.2978274753550068e-05 - tot_loss: 0.2680945641618564 - acc: 0.8495647442872688 - val_acc: 0.8106549032914828\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 2.855113983154297 - sq_loss: 1.237533342646202e-05 - tot_loss: 0.2628302584892026 - acc: 0.8521490750816104 - val_acc: 0.8126908720732948\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 2.755242347717285 - sq_loss: 1.1815020116046071e-05 - tot_loss: 0.25513415069434586 - acc: 0.8547334058759521 - val_acc: 0.8150661689854088\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 2.8252580165863037 - sq_loss: 1.1264917702646926e-05 - tot_loss: 0.25017490349006266 - acc: 0.8577257889009793 - val_acc: 0.8177807940278249\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 2.7881977558135986 - sq_loss: 1.0739904610090889e-05 - tot_loss: 0.2520284909098791 - acc: 0.85949401523395 - val_acc: 0.8204954190702409\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 2.7804694175720215 - sq_loss: 1.026257268677e-05 - tot_loss: 0.2448220585230274 - acc: 0.8630304678998912 - val_acc: 0.8242280285035629\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 2.7883474826812744 - sq_loss: 9.802216482057702e-06 - tot_loss: 0.240184866977188 - acc: 0.8645266594124048 - val_acc: 0.8266033254156769\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 2.7707557678222656 - sq_loss: 9.375128684041556e-06 - tot_loss: 0.23907590200479945 - acc: 0.8661588683351469 - val_acc: 0.830335934848999\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 2.7913410663604736 - sq_loss: 8.975232049124315e-06 - tot_loss: 0.23590352170759843 - acc: 0.8688792165397171 - val_acc: 0.832032575500509\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 2.806922435760498 - sq_loss: 8.580962457926944e-06 - tot_loss: 0.23342634695904962 - acc: 0.8705114254624592 - val_acc: 0.833050559891415\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 2.7817273139953613 - sq_loss: 8.216540663852356e-06 - tot_loss: 0.22975259373828294 - acc: 0.8730957562568009 - val_acc: 0.835425856803529\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 2.787497043609619 - sq_loss: 7.85226347943535e-06 - tot_loss: 0.2242067422619698 - acc: 0.875 - val_acc: 0.8367831693247371\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 2.7261288166046143 - sq_loss: 7.507711870857747e-06 - tot_loss: 0.23047651428112204 - acc: 0.8769042437431991 - val_acc: 0.8411944350186631\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 2.7837159633636475 - sq_loss: 7.2036896199279e-06 - tot_loss: 0.22957032463961013 - acc: 0.8793525571273123 - val_acc: 0.8428910756701731\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 2.7881977558135986 - sq_loss: 6.905507689225487e-06 - tot_loss: 0.2154158913953097 - acc: 0.8808487486398259 - val_acc: 0.8469630132337971\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 2.8266727924346924 - sq_loss: 6.615871825488284e-06 - tot_loss: 0.21726981235545395 - acc: 0.8826169749727966 - val_acc: 0.8489989820156091\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 2.7684500217437744 - sq_loss: 6.3463726291956846e-06 - tot_loss: 0.2189444825669682 - acc: 0.8839771490750816 - val_acc: 0.8489989820156091\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 2.820925712585449 - sq_loss: 6.096287052059779e-06 - tot_loss: 0.2086867862336419 - acc: 0.8858813928182807 - val_acc: 0.8500169664065151\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 2.772240400314331 - sq_loss: 5.851548849022947e-06 - tot_loss: 0.20196273040534152 - acc: 0.8865614798694232 - val_acc: 0.8517136070580251\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 2.762423038482666 - sq_loss: 5.614037945633754e-06 - tot_loss: 0.21600680046918797 - acc: 0.8884657236126224 - val_acc: 0.8544282321004412\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 2.76230525970459 - sq_loss: 5.386055363487685e-06 - tot_loss: 0.21467715125871223 - acc: 0.89050598476605 - val_acc: 0.8554462164913471\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 2.8388938903808594 - sq_loss: 5.171804787096335e-06 - tot_loss: 0.20678969893356225 - acc: 0.8926822633297062 - val_acc: 0.8585001696640652\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 2.8110220432281494 - sq_loss: 4.977585376764182e-06 - tot_loss: 0.19765603876564342 - acc: 0.8934983677910773 - val_acc: 0.8608754665761792\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 2.826680898666382 - sq_loss: 4.777338290296029e-06 - tot_loss: 0.19307936408210935 - acc: 0.8943144722524483 - val_acc: 0.8615541228367831\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 2.890298843383789 - sq_loss: 4.586105660564499e-06 - tot_loss: 0.19474703400010185 - acc: 0.8955386289445049 - val_acc: 0.8622327790973872\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 2.8433644771575928 - sq_loss: 4.428631655173376e-06 - tot_loss: 0.19822949443610582 - acc: 0.8962187159956474 - val_acc: 0.8646080760095012\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 2.8617992401123047 - sq_loss: 4.263838036422385e-06 - tot_loss: 0.19206990310607353 - acc: 0.8974428726877041 - val_acc: 0.8652867322701052\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 2.8699116706848145 - sq_loss: 4.104411345906556e-06 - tot_loss: 0.19013310457228272 - acc: 0.8983949945593036 - val_acc: 0.8673227010519172\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 2.76871395111084 - sq_loss: 3.955495685659116e-06 - tot_loss: 0.19938915269921154 - acc: 0.8978509249183896 - val_acc: 0.8686800135731252\n",
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 2.8524374961853027 - sq_loss: 3.819062385446159e-06 - tot_loss: 0.18344567585661764 - acc: 0.8990750816104461 - val_acc: 0.8696979979640312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 2.7693183422088623 - sq_loss: 3.6993537833041046e-06 - tot_loss: 0.1901927966928696 - acc: 0.9005712731229597 - val_acc: 0.8710553104852392\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 2.797130584716797 - sq_loss: 3.5830450997309526e-06 - tot_loss: 0.17425993827251318 - acc: 0.9009793253536452 - val_acc: 0.8713946386155412\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 2.7576775550842285 - sq_loss: 3.464802148300805e-06 - tot_loss: 0.17066809119309312 - acc: 0.9012513601741022 - val_acc: 0.8720732948761453\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 2.7778985500335693 - sq_loss: 3.355077069500112e-06 - tot_loss: 0.17137175681266115 - acc: 0.9016594124047879 - val_acc: 0.8751272480488632\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 2.7867214679718018 - sq_loss: 3.2466728043800686e-06 - tot_loss: 0.16528850192126754 - acc: 0.9015233949945594 - val_acc: 0.8764845605700713\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 2.7968251705169678 - sq_loss: 3.1433348794962512e-06 - tot_loss: 0.1914574710566228 - acc: 0.9020674646354734 - val_acc: 0.8775025449609772\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 2.730984687805176 - sq_loss: 3.0467938358924584e-06 - tot_loss: 0.18183618526533962 - acc: 0.9032916213275299 - val_acc: 0.8781812012215813\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 2.7718613147735596 - sq_loss: 2.9539471597672673e-06 - tot_loss: 0.1714291535052439 - acc: 0.9042437431991295 - val_acc: 0.8788598574821853\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 2.763371229171753 - sq_loss: 2.8736340027535334e-06 - tot_loss: 0.17134544328840207 - acc: 0.9045157780195865 - val_acc: 0.8802171700033933\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 2.720144033432007 - sq_loss: 2.788725169011741e-06 - tot_loss: 0.17477173107931776 - acc: 0.9058759521218716 - val_acc: 0.8839497794367153\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 2.803164482116699 - sq_loss: 2.7012538339477032e-06 - tot_loss: 0.17175060660011354 - acc: 0.9064200217627857 - val_acc: 0.8839497794367153\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 2.837749481201172 - sq_loss: 2.6284483283234295e-06 - tot_loss: 0.177083394852815 - acc: 0.9071001088139282 - val_acc: 0.8856464200882254\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 2.7954699993133545 - sq_loss: 2.5555627871653996e-06 - tot_loss: 0.17093453977392414 - acc: 0.9083242655059848 - val_acc: 0.8873430607397353\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 2.811976432800293 - sq_loss: 2.486876610419131e-06 - tot_loss: 0.1676557469542601 - acc: 0.9091403699673558 - val_acc: 0.8876823888700374\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 2.8042008876800537 - sq_loss: 2.4216185465775197e-06 - tot_loss: 0.1659677076610464 - acc: 0.9094124047878128 - val_acc: 0.8876823888700374\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 2.801281213760376 - sq_loss: 2.354904836465721e-06 - tot_loss: 0.15924965117953604 - acc: 0.9107725788900979 - val_acc: 0.8880217170003394\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 2.834333658218384 - sq_loss: 2.2957542569201905e-06 - tot_loss: 0.17089129557400895 - acc: 0.911316648531012 - val_acc: 0.8897183576518494\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 2.821683883666992 - sq_loss: 2.234012526969309e-06 - tot_loss: 0.159731376829221 - acc: 0.9125408052230686 - val_acc: 0.8914149983033594\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 2.799973249435425 - sq_loss: 2.1796392957185162e-06 - tot_loss: 0.1533618751807353 - acc: 0.9134929270946681 - val_acc: 0.8914149983033594\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 2.8431856632232666 - sq_loss: 2.1249556994007435e-06 - tot_loss: 0.15280667739355636 - acc: 0.9140369967355821 - val_acc: 0.8931116389548693\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 2.7720515727996826 - sq_loss: 2.0757809124916093e-06 - tot_loss: 0.15247326330320732 - acc: 0.9149891186071817 - val_acc: 0.8934509670851714\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 2.795567274093628 - sq_loss: 2.0302957182138925e-06 - tot_loss: 0.16213544284161685 - acc: 0.9151251360174102 - val_acc: 0.8941296233457754\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 2.769272804260254 - sq_loss: 1.9873630208167015e-06 - tot_loss: 0.1684015131642198 - acc: 0.9158052230685527 - val_acc: 0.8944689514760774\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 2.829854726791382 - sq_loss: 1.9445508314674953e-06 - tot_loss: 0.16494391873038694 - acc: 0.9164853101196954 - val_acc: 0.8954869358669834\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 2.8995137214660645 - sq_loss: 1.8946984710055403e-06 - tot_loss: 0.1562882108462631 - acc: 0.9167573449401524 - val_acc: 0.8961655921275874\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 2.800485849380493 - sq_loss: 1.8529713088355493e-06 - tot_loss: 0.1472686279470281 - acc: 0.9177094668117519 - val_acc: 0.8971835765184933\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 2.8943166732788086 - sq_loss: 1.820075908653962e-06 - tot_loss: 0.1451029549303655 - acc: 0.9183895538628944 - val_acc: 0.8988802171700034\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 2.7865970134735107 - sq_loss: 1.7871675481728744e-06 - tot_loss: 0.16022981392735147 - acc: 0.919069640914037 - val_acc: 0.8992195453003053\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 2.7895240783691406 - sq_loss: 1.753247147462389e-06 - tot_loss: 0.1555434714068724 - acc: 0.919613710554951 - val_acc: 0.9005768578215134\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 2.823779344558716 - sq_loss: 1.724552589621453e-06 - tot_loss: 0.14551825067470858 - acc: 0.9202937976060935 - val_acc: 0.9015948422124194\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 2.8261916637420654 - sq_loss: 1.6922796248763916e-06 - tot_loss: 0.15022576514822816 - acc: 0.920429815016322 - val_acc: 0.9029521547336274\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 2.8180224895477295 - sq_loss: 1.6612930267001502e-06 - tot_loss: 0.14260372356860174 - acc: 0.9205658324265505 - val_acc: 0.9036308109942314\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 2.82401180267334 - sq_loss: 1.6284730008919723e-06 - tot_loss: 0.14344596005301824 - acc: 0.9213819368879217 - val_acc: 0.9046487953851374\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 2.8008296489715576 - sq_loss: 1.606431965228694e-06 - tot_loss: 0.15362591487014754 - acc: 0.9219260065288357 - val_acc: 0.9046487953851374\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 2.7582874298095703 - sq_loss: 1.5802287407495896e-06 - tot_loss: 0.1475923924318927 - acc: 0.9216539717083787 - val_acc: 0.9060061079063454\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 2.8015549182891846 - sq_loss: 1.5522028888881323e-06 - tot_loss: 0.14900423250568906 - acc: 0.9220620239390642 - val_acc: 0.9063454360366474\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 2.741769313812256 - sq_loss: 1.525895868326188e-06 - tot_loss: 0.14909055386819503 - acc: 0.9226060935799782 - val_acc: 0.9066847641669494\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 2.80019211769104 - sq_loss: 1.507114802734577e-06 - tot_loss: 0.14234384191220784 - acc: 0.9228781284004353 - val_acc: 0.9070240922972514\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 2.8340506553649902 - sq_loss: 1.4925659570508287e-06 - tot_loss: 0.14389063968206273 - acc: 0.9230141458106638 - val_acc: 0.9077027485578555\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 2.782280921936035 - sq_loss: 1.4709381730426685e-06 - tot_loss: 0.1388164679286632 - acc: 0.9232861806311208 - val_acc: 0.9073634204275535\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 2.7421860694885254 - sq_loss: 1.4479300034508924e-06 - tot_loss: 0.13830347045215774 - acc: 0.9238302502720348 - val_acc: 0.9073634204275535\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 2.817059278488159 - sq_loss: 1.4250823596739792e-06 - tot_loss: 0.1438819143775696 - acc: 0.9239662676822633 - val_acc: 0.9070240922972514\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 2.8093247413635254 - sq_loss: 1.406772298651049e-06 - tot_loss: 0.14946050145489664 - acc: 0.9246463547334058 - val_acc: 0.9070240922972514\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 2.792567253112793 - sq_loss: 1.387778411299223e-06 - tot_loss: 0.14452721551512226 - acc: 0.9250544069640914 - val_acc: 0.9077027485578555\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 2.7892258167266846 - sq_loss: 1.3721745517614181e-06 - tot_loss: 0.1387184348902224 - acc: 0.9254624591947769 - val_acc: 0.9083814048184594\n",
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 2.894744634628296 - sq_loss: 1.3564165328716626e-06 - tot_loss: 0.15230939790834164 - acc: 0.926278563656148 - val_acc: 0.9087207329487614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 2.812690019607544 - sq_loss: 1.336239506599668e-06 - tot_loss: 0.13371201769212604 - acc: 0.926822633297062 - val_acc: 0.9087207329487614\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 2.835651397705078 - sq_loss: 1.3205475397626287e-06 - tot_loss: 0.15559485296033948 - acc: 0.9269586507072906 - val_acc: 0.9090600610790635\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 2.7866499423980713 - sq_loss: 1.3087940260447795e-06 - tot_loss: 0.1415278413978278 - acc: 0.9270946681175191 - val_acc: 0.9093993892093655\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 2.8695342540740967 - sq_loss: 1.2964392226422206e-06 - tot_loss: 0.1405101303931442 - acc: 0.9272306855277476 - val_acc: 0.9093993892093655\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 2.846831798553467 - sq_loss: 1.2859710523116519e-06 - tot_loss: 0.14415693000750984 - acc: 0.9276387377584331 - val_acc: 0.9097387173396675\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 2.7894787788391113 - sq_loss: 1.273480620511691e-06 - tot_loss: 0.13390069954007977 - acc: 0.9280467899891186 - val_acc: 0.9097387173396675\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 2.7827510833740234 - sq_loss: 1.260037947758974e-06 - tot_loss: 0.1303361171568529 - acc: 0.9289989118607181 - val_acc: 0.9107567017305734\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 2.855083465576172 - sq_loss: 1.2434576319719781e-06 - tot_loss: 0.134037875659045 - acc: 0.9292709466811752 - val_acc: 0.9114353579911775\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 2.7540194988250732 - sq_loss: 1.2311410273468937e-06 - tot_loss: 0.1360367929684685 - acc: 0.9295429815016322 - val_acc: 0.9117746861214795\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 2.8135623931884766 - sq_loss: 1.2217169569339603e-06 - tot_loss: 0.13895351497006025 - acc: 0.9299510337323177 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 2.792543888092041 - sq_loss: 1.2112424201404792e-06 - tot_loss: 0.13828452631715038 - acc: 0.9307671381936888 - val_acc: 0.9127926705123854\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 2.761489152908325 - sq_loss: 1.1995986142210313e-06 - tot_loss: 0.12974902605700578 - acc: 0.9310391730141458 - val_acc: 0.9131319986426875\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 2.804185390472412 - sq_loss: 1.1903880476893391e-06 - tot_loss: 0.14060809557147103 - acc: 0.9314472252448314 - val_acc: 0.9131319986426875\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 2.8595173358917236 - sq_loss: 1.1811737294920022e-06 - tot_loss: 0.13956118217604185 - acc: 0.9313112078346029 - val_acc: 0.9134713267729895\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 2.849132776260376 - sq_loss: 1.171216240436479e-06 - tot_loss: 0.13702262646381058 - acc: 0.9317192600652884 - val_acc: 0.9134713267729895\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 2.84580659866333 - sq_loss: 1.1598348237384926e-06 - tot_loss: 0.1298441708394389 - acc: 0.9319912948857454 - val_acc: 0.9134713267729895\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 2.818760871887207 - sq_loss: 1.148985575127881e-06 - tot_loss: 0.14179687413968622 - acc: 0.933215451577802 - val_acc: 0.9138106549032915\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 2.785707473754883 - sq_loss: 1.1381372360119713e-06 - tot_loss: 0.1434352568841586 - acc: 0.9336235038084875 - val_acc: 0.9141499830335935\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 2.7659811973571777 - sq_loss: 1.1293349189145374e-06 - tot_loss: 0.14012491117606274 - acc: 0.933759521218716 - val_acc: 0.9141499830335935\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 2.7971811294555664 - sq_loss: 1.120991441894148e-06 - tot_loss: 0.12989488623803247 - acc: 0.934031556039173 - val_acc: 0.9144893111638955\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 2.7818603515625 - sq_loss: 1.1151588523716782e-06 - tot_loss: 0.13355319109868535 - acc: 0.9349836779107725 - val_acc: 0.9144893111638955\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 2.7677488327026367 - sq_loss: 1.1075547945438302e-06 - tot_loss: 0.1341947824753813 - acc: 0.9353917301414582 - val_acc: 0.9144893111638955\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 2.7639000415802 - sq_loss: 1.0977644251397578e-06 - tot_loss: 0.13834224817998564 - acc: 0.9356637649619152 - val_acc: 0.9155072955548015\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 2.8607540130615234 - sq_loss: 1.0863922170756268e-06 - tot_loss: 0.13238982331167648 - acc: 0.9360718171926007 - val_acc: 0.9165252799457075\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 2.794755697250366 - sq_loss: 1.078565901480033e-06 - tot_loss: 0.12947494355097344 - acc: 0.9366158868335147 - val_acc: 0.9168646080760094\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 2.770681142807007 - sq_loss: 1.0747036185421166e-06 - tot_loss: 0.1207227372378501 - acc: 0.9370239390642002 - val_acc: 0.9172039362063115\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 2.7977874279022217 - sq_loss: 1.0707681212807074e-06 - tot_loss: 0.12866412568738905 - acc: 0.9375680087051143 - val_acc: 0.9178825924669155\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 2.8568918704986572 - sq_loss: 1.0639321317285066e-06 - tot_loss: 0.12726644300786294 - acc: 0.9377040261153428 - val_acc: 0.9185612487275195\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 2.7835118770599365 - sq_loss: 1.0580489515632507e-06 - tot_loss: 0.14167763339215256 - acc: 0.9385201305767138 - val_acc: 0.9189005768578216\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 2.772916793823242 - sq_loss: 1.049927732310607e-06 - tot_loss: 0.12774568116481788 - acc: 0.9389281828073993 - val_acc: 0.9192399049881235\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 2.8605737686157227 - sq_loss: 1.0421217666589655e-06 - tot_loss: 0.1325497624738734 - acc: 0.9392002176278563 - val_acc: 0.9195792331184255\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 2.7973825931549072 - sq_loss: 1.0370918062108103e-06 - tot_loss: 0.13158122847273912 - acc: 0.9394722524483133 - val_acc: 0.9199185612487275\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 2.8330469131469727 - sq_loss: 1.0332995543649304e-06 - tot_loss: 0.1266266137249925 - acc: 0.9394722524483133 - val_acc: 0.9202578893790295\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 2.7780940532684326 - sq_loss: 1.0279330808771192e-06 - tot_loss: 0.1320179945335216 - acc: 0.9402883569096845 - val_acc: 0.9205972175093315\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 2.887603282928467 - sq_loss: 1.0230503448838135e-06 - tot_loss: 0.12142009355219052 - acc: 0.9402883569096845 - val_acc: 0.9212758737699356\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 2.8095791339874268 - sq_loss: 1.0176527212024666e-06 - tot_loss: 0.13239734585377683 - acc: 0.9405603917301415 - val_acc: 0.9212758737699356\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 2.8353946208953857 - sq_loss: 1.0107323760166764e-06 - tot_loss: 0.13289603421338558 - acc: 0.9408324265505985 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 2.8017096519470215 - sq_loss: 1.0060934982902836e-06 - tot_loss: 0.12833399769182208 - acc: 0.940968443960827 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 2.8414034843444824 - sq_loss: 9.993279945774702e-07 - tot_loss: 0.12693537771551267 - acc: 0.9411044613710555 - val_acc: 0.9226331862911435\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 2.8063786029815674 - sq_loss: 9.912321274896385e-07 - tot_loss: 0.12960877152103656 - acc: 0.9413764961915125 - val_acc: 0.9229725144214456\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 2.8316421508789062 - sq_loss: 9.869580708254944e-07 - tot_loss: 0.11793097805309127 - acc: 0.9420565832426551 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 2.798527717590332 - sq_loss: 9.845714430412045e-07 - tot_loss: 0.12603601845305423 - acc: 0.9428726877040261 - val_acc: 0.9250084832032576\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 2.803089141845703 - sq_loss: 9.789989690034417e-07 - tot_loss: 0.14366838300829698 - acc: 0.9435527747551686 - val_acc: 0.9250084832032576\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 2.808560371398926 - sq_loss: 9.75104171629937e-07 - tot_loss: 0.13329947096956474 - acc: 0.9436887921653971 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 2.7878284454345703 - sq_loss: 9.67591518019617e-07 - tot_loss: 0.13659497713683866 - acc: 0.9438248095756256 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 2.8638384342193604 - sq_loss: 9.606003459339263e-07 - tot_loss: 0.12092102051638509 - acc: 0.9440968443960827 - val_acc: 0.9260264675941635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 2.802004814147949 - sq_loss: 9.556584927850054e-07 - tot_loss: 0.12666320703108447 - acc: 0.9445048966267682 - val_acc: 0.9267051238547676\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 2.8561830520629883 - sq_loss: 9.527251449981122e-07 - tot_loss: 0.11968084026341952 - acc: 0.9450489662676823 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 2.835371494293213 - sq_loss: 9.497707651462406e-07 - tot_loss: 0.1382327083348125 - acc: 0.9451849836779108 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 2.776829242706299 - sq_loss: 9.458809131501766e-07 - tot_loss: 0.1325781466477931 - acc: 0.9451849836779108 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 2.7986960411071777 - sq_loss: 9.408837513547041e-07 - tot_loss: 0.1316861217730434 - acc: 0.9460010881392819 - val_acc: 0.9277231082456736\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 2.7856087684631348 - sq_loss: 9.367300890517072e-07 - tot_loss: 0.12339675086656055 - acc: 0.9464091403699674 - val_acc: 0.9290804207668816\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 2.770087957382202 - sq_loss: 9.332175636700413e-07 - tot_loss: 0.1319115331792995 - acc: 0.9470892274211099 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 2.8495547771453857 - sq_loss: 9.306576771450636e-07 - tot_loss: 0.12115646166112803 - acc: 0.9473612622415669 - val_acc: 0.9290804207668816\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 2.790621280670166 - sq_loss: 9.271496992369066e-07 - tot_loss: 0.1324324721958492 - acc: 0.9477693144722524 - val_acc: 0.9290804207668816\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 2.758068323135376 - sq_loss: 9.247212346963352e-07 - tot_loss: 0.12342742904005277 - acc: 0.9480413492927094 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 2.855891704559326 - sq_loss: 9.218553600476298e-07 - tot_loss: 0.12445443261125888 - acc: 0.948177366702938 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 2.7607295513153076 - sq_loss: 9.197241297442815e-07 - tot_loss: 0.12987321144089137 - acc: 0.9485854189336235 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 2.8167762756347656 - sq_loss: 9.147385071628378e-07 - tot_loss: 0.12614071352720257 - acc: 0.9491294885745375 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 2.824152946472168 - sq_loss: 9.105579579227197e-07 - tot_loss: 0.13325993288054638 - acc: 0.9491294885745375 - val_acc: 0.9321343739395996\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 2.8075509071350098 - sq_loss: 9.073443720808427e-07 - tot_loss: 0.1282577936404219 - acc: 0.9498095756256801 - val_acc: 0.9321343739395996\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 2.7799072265625 - sq_loss: 9.032439152178995e-07 - tot_loss: 0.12668646038607845 - acc: 0.9499455930359086 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 2.8729615211486816 - sq_loss: 9.019353228723048e-07 - tot_loss: 0.11317345438869308 - acc: 0.9503536452665942 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 2.801694393157959 - sq_loss: 8.986158377410902e-07 - tot_loss: 0.11507730865988464 - acc: 0.9507616974972797 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 2.8042094707489014 - sq_loss: 8.946024649958417e-07 - tot_loss: 0.12894955487412485 - acc: 0.9510337323177367 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 2.782047748565674 - sq_loss: 8.898174428395578e-07 - tot_loss: 0.13470731410509185 - acc: 0.9511697497279652 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 2.8127763271331787 - sq_loss: 8.854755151332938e-07 - tot_loss: 0.12677199830564767 - acc: 0.9518498367791077 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 2.7740492820739746 - sq_loss: 8.827363444652292e-07 - tot_loss: 0.11720496283660164 - acc: 0.9522578890097932 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 2.817082166671753 - sq_loss: 8.798985504654411e-07 - tot_loss: 0.1339761060240776 - acc: 0.9522578890097932 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 2.7793967723846436 - sq_loss: 8.782815257291077e-07 - tot_loss: 0.12770532634249632 - acc: 0.9528019586507073 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 2.7432219982147217 - sq_loss: 8.778177971180412e-07 - tot_loss: 0.12882435540573578 - acc: 0.9528019586507073 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 2.8350467681884766 - sq_loss: 8.745266768528381e-07 - tot_loss: 0.1158595898515542 - acc: 0.9532100108813928 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 2.8277299404144287 - sq_loss: 8.687517834005121e-07 - tot_loss: 0.12849798227781806 - acc: 0.9533460282916213 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 2.794807195663452 - sq_loss: 8.637622386231669e-07 - tot_loss: 0.11816926704927644 - acc: 0.9537540805223068 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 2.7795543670654297 - sq_loss: 8.610364830019535e-07 - tot_loss: 0.11506165596189044 - acc: 0.9537540805223068 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 2.8263509273529053 - sq_loss: 8.566885867367091e-07 - tot_loss: 0.12130995651913334 - acc: 0.9540261153427638 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 2.752164125442505 - sq_loss: 8.541899774172634e-07 - tot_loss: 0.12561044321388204 - acc: 0.9547062023939065 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 2.8260679244995117 - sq_loss: 8.510397151439975e-07 - tot_loss: 0.12814623749704657 - acc: 0.9549782372143635 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 2.808046579360962 - sq_loss: 8.49013929382636e-07 - tot_loss: 0.12331287100528376 - acc: 0.955386289445049 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 2.832843065261841 - sq_loss: 8.479012194584357e-07 - tot_loss: 0.12232456636836808 - acc: 0.955658324265506 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 2.853699207305908 - sq_loss: 8.451299891021335e-07 - tot_loss: 0.12142166499832241 - acc: 0.956474428726877 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 2.786823272705078 - sq_loss: 8.437970109298476e-07 - tot_loss: 0.12021952386844426 - acc: 0.9570184983677911 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 2.784745693206787 - sq_loss: 8.413926479988731e-07 - tot_loss: 0.10846921908816531 - acc: 0.9572905331882481 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 2.7946388721466064 - sq_loss: 8.375387778869481e-07 - tot_loss: 0.12043626455986711 - acc: 0.9575625680087051 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 2.8058533668518066 - sq_loss: 8.347053039869934e-07 - tot_loss: 0.12131344873933259 - acc: 0.9575625680087051 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 2.776256561279297 - sq_loss: 8.318583013533498e-07 - tot_loss: 0.11092088272947942 - acc: 0.9581066376496191 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 2.831714630126953 - sq_loss: 8.299186902149813e-07 - tot_loss: 0.12785307011643665 - acc: 0.9582426550598476 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 2.7841684818267822 - sq_loss: 8.265946576102579e-07 - tot_loss: 0.11521141816891856 - acc: 0.9582426550598476 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 2.8506646156311035 - sq_loss: 8.238479267674848e-07 - tot_loss: 0.12209563310036264 - acc: 0.9585146898803046 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 2.80121111869812 - sq_loss: 8.217446065827971e-07 - tot_loss: 0.12301718700290643 - acc: 0.9587867247007617 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 2.826951503753662 - sq_loss: 8.193247253984737e-07 - tot_loss: 0.12560151435645617 - acc: 0.9590587595212187 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 2.8305795192718506 - sq_loss: 8.178726602636743e-07 - tot_loss: 0.12398724312142173 - acc: 0.9594668117519043 - val_acc: 0.9389209365456397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 2.805680274963379 - sq_loss: 8.155911928042769e-07 - tot_loss: 0.10924193533474735 - acc: 0.9596028291621328 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 2.8917500972747803 - sq_loss: 8.132436732921633e-07 - tot_loss: 0.12056348566927522 - acc: 0.9597388465723613 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 2.832566499710083 - sq_loss: 8.102566653178656e-07 - tot_loss: 0.10817261912438036 - acc: 0.9597388465723613 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 2.8460042476654053 - sq_loss: 8.08729964774102e-07 - tot_loss: 0.11928061595214201 - acc: 0.9601468988030468 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 2.8179383277893066 - sq_loss: 8.066113537097408e-07 - tot_loss: 0.12411754956787435 - acc: 0.9602829162132753 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 2.8069307804107666 - sq_loss: 8.063984182626882e-07 - tot_loss: 0.11901422363790148 - acc: 0.9605549510337323 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 2.801429033279419 - sq_loss: 8.060013101385266e-07 - tot_loss: 0.12217724290369825 - acc: 0.9608269858541894 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 2.7989673614501953 - sq_loss: 8.023863529160735e-07 - tot_loss: 0.1211955036420842 - acc: 0.9608269858541894 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 2.8296985626220703 - sq_loss: 7.994706834324461e-07 - tot_loss: 0.11588968604665828 - acc: 0.9609630032644179 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 2.8154335021972656 - sq_loss: 7.977498626132729e-07 - tot_loss: 0.11554183718835054 - acc: 0.9615070729053319 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 2.8330295085906982 - sq_loss: 7.936826591503632e-07 - tot_loss: 0.13213615410999502 - acc: 0.9615070729053319 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 2.8293285369873047 - sq_loss: 7.902238507995207e-07 - tot_loss: 0.10942051379759565 - acc: 0.9617791077257889 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 2.873276948928833 - sq_loss: 7.884076467234991e-07 - tot_loss: 0.12131220944368426 - acc: 0.9620511425462459 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 2.8173439502716064 - sq_loss: 7.862803386160522e-07 - tot_loss: 0.11613513459932268 - acc: 0.9621871599564744 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 2.789963483810425 - sq_loss: 7.848151994949149e-07 - tot_loss: 0.11669167588655505 - acc: 0.9621871599564744 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 2.781186819076538 - sq_loss: 7.824841645742708e-07 - tot_loss: 0.12596288616912465 - acc: 0.9623231773667029 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 2.772662878036499 - sq_loss: 7.800470029906137e-07 - tot_loss: 0.12828235260344778 - acc: 0.9627312295973884 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 2.775120735168457 - sq_loss: 7.758718538752873e-07 - tot_loss: 0.11820073979888424 - acc: 0.9628672470076169 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 2.811235189437866 - sq_loss: 7.741920740045316e-07 - tot_loss: 0.11309730859358069 - acc: 0.9628672470076169 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 2.7902002334594727 - sq_loss: 7.711895477768849e-07 - tot_loss: 0.11403235106883258 - acc: 0.9630032644178455 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 2.7800631523132324 - sq_loss: 7.680916382923897e-07 - tot_loss: 0.12146694303626893 - acc: 0.963139281828074 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 2.748953104019165 - sq_loss: 7.66223593018367e-07 - tot_loss: 0.12132737293995488 - acc: 0.963411316648531 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 2.8529646396636963 - sq_loss: 7.665918246857473e-07 - tot_loss: 0.11095184547908588 - acc: 0.963683351468988 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 2.835089683532715 - sq_loss: 7.642537411811645e-07 - tot_loss: 0.11393709987648615 - acc: 0.9639553862894451 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 2.751138925552368 - sq_loss: 7.621396775903122e-07 - tot_loss: 0.11832073156553813 - acc: 0.9644994559303591 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 2.727107286453247 - sq_loss: 7.598573574796319e-07 - tot_loss: 0.10688917909968065 - acc: 0.9646354733405876 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 2.8017756938934326 - sq_loss: 7.585797447973164e-07 - tot_loss: 0.11059009089357819 - acc: 0.9646354733405876 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 2.828956127166748 - sq_loss: 7.582290777463641e-07 - tot_loss: 0.1262692919496895 - acc: 0.9647714907508161 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 2.8217108249664307 - sq_loss: 7.570458251393575e-07 - tot_loss: 0.12761789415660107 - acc: 0.9647714907508161 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 2.7335753440856934 - sq_loss: 7.570686193503207e-07 - tot_loss: 0.12156114149530328 - acc: 0.9653155603917302 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 2.789031982421875 - sq_loss: 7.546499887212121e-07 - tot_loss: 0.11740429269801744 - acc: 0.9651795429815017 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 2.7791571617126465 - sq_loss: 7.523854606006353e-07 - tot_loss: 0.11908162605808803 - acc: 0.9654515778019587 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 2.8032901287078857 - sq_loss: 7.522884857280587e-07 - tot_loss: 0.1173202027200313 - acc: 0.9657236126224157 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 2.756963014602661 - sq_loss: 7.51718289393466e-07 - tot_loss: 0.10661116730746167 - acc: 0.9661316648531012 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 2.801288366317749 - sq_loss: 7.492049576285353e-07 - tot_loss: 0.11416718354652744 - acc: 0.9668117519042437 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 2.7801706790924072 - sq_loss: 7.465578732990252e-07 - tot_loss: 0.11427147060419296 - acc: 0.9666757344940152 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 2.7170095443725586 - sq_loss: 7.45756722153601e-07 - tot_loss: 0.12783412274472417 - acc: 0.9668117519042437 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 2.7861387729644775 - sq_loss: 7.444790526278666e-07 - tot_loss: 0.11684434631765139 - acc: 0.9669477693144722 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 2.777482509613037 - sq_loss: 7.426534693877329e-07 - tot_loss: 0.1228992492863239 - acc: 0.9672198041349293 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 2.714327335357666 - sq_loss: 7.411743467855558e-07 - tot_loss: 0.12331878968829679 - acc: 0.9670837867247007 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 2.809838056564331 - sq_loss: 7.402634878417302e-07 - tot_loss: 0.11814123670099619 - acc: 0.9673558215451578 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 2.7120676040649414 - sq_loss: 7.378166628768668e-07 - tot_loss: 0.12729406523138076 - acc: 0.9674918389553863 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 2.6718719005584717 - sq_loss: 7.335890472859319e-07 - tot_loss: 0.11588650625894736 - acc: 0.9676278563656148 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 2.707057476043701 - sq_loss: 7.334749057008594e-07 - tot_loss: 0.12125923462707311 - acc: 0.9678998911860718 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 2.7343430519104004 - sq_loss: 7.316048140637577e-07 - tot_loss: 0.11956874344262358 - acc: 0.9676278563656148 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 2.716874361038208 - sq_loss: 7.285382253030548e-07 - tot_loss: 0.12156737021987007 - acc: 0.9674918389553863 - val_acc: 0.9443501866304717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 2.750732421875 - sq_loss: 7.289005452548736e-07 - tot_loss: 0.12231543044881876 - acc: 0.9680359085963003 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 2.6803057193756104 - sq_loss: 7.282431511157483e-07 - tot_loss: 0.11951793974591962 - acc: 0.9683079434167573 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 2.6940178871154785 - sq_loss: 7.261968448801781e-07 - tot_loss: 0.12082975297581844 - acc: 0.9685799782372143 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 2.687427282333374 - sq_loss: 7.24057770185027e-07 - tot_loss: 0.10940366800652557 - acc: 0.9687159956474428 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 2.68622088432312 - sq_loss: 7.209629870885692e-07 - tot_loss: 0.12391020962467669 - acc: 0.9689880304678999 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 2.7242860794067383 - sq_loss: 7.186031893979816e-07 - tot_loss: 0.11434522282879467 - acc: 0.9689880304678999 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 2.717163324356079 - sq_loss: 7.174307938839775e-07 - tot_loss: 0.1148732163884234 - acc: 0.969260065288357 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 2.810368776321411 - sq_loss: 7.176558938226663e-07 - tot_loss: 0.10764142032089263 - acc: 0.969532100108814 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 2.7570502758026123 - sq_loss: 7.16851900506299e-07 - tot_loss: 0.12101800290002518 - acc: 0.9699401523394995 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 2.7257866859436035 - sq_loss: 7.149428711272776e-07 - tot_loss: 0.1170554854325081 - acc: 0.9699401523394995 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 2.7194557189941406 - sq_loss: 7.138759201552602e-07 - tot_loss: 0.11911351361926914 - acc: 0.970076169749728 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 2.667167901992798 - sq_loss: 7.114786626516434e-07 - tot_loss: 0.11591344140951243 - acc: 0.970076169749728 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 2.8207218647003174 - sq_loss: 7.089903988344304e-07 - tot_loss: 0.11773294003213453 - acc: 0.9704842219804135 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 2.8213071823120117 - sq_loss: 7.07739673089236e-07 - tot_loss: 0.12051444594316463 - acc: 0.970348204570185 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 2.7638847827911377 - sq_loss: 7.062067766128166e-07 - tot_loss: 0.1166395842953063 - acc: 0.9704842219804135 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 2.818967819213867 - sq_loss: 7.060373832246114e-07 - tot_loss: 0.10841807971063977 - acc: 0.970892274211099 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 2.799290180206299 - sq_loss: 7.0420719566755e-07 - tot_loss: 0.1252393818670987 - acc: 0.970892274211099 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 2.8286678791046143 - sq_loss: 7.023119792393118e-07 - tot_loss: 0.11623948222142766 - acc: 0.9710282916213275 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 2.805839776992798 - sq_loss: 7.003934001659218e-07 - tot_loss: 0.12307869333326216 - acc: 0.9713003264417845 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 2.7762842178344727 - sq_loss: 7.007396902736218e-07 - tot_loss: 0.11377411101255386 - acc: 0.971436343852013 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 2.7803657054901123 - sq_loss: 6.978882538533071e-07 - tot_loss: 0.12063354941872761 - acc: 0.9717083786724701 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 2.775240182876587 - sq_loss: 6.960394784982782e-07 - tot_loss: 0.12427490341043534 - acc: 0.9718443960826986 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 2.752648115158081 - sq_loss: 6.931932716724987e-07 - tot_loss: 0.11001147835595959 - acc: 0.9721164309031556 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 2.781785726547241 - sq_loss: 6.92307366989553e-07 - tot_loss: 0.11372748969343727 - acc: 0.9719804134929271 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 2.8734402656555176 - sq_loss: 6.908595651111682e-07 - tot_loss: 0.10826683321895447 - acc: 0.9721164309031556 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 2.779207944869995 - sq_loss: 6.889840165058558e-07 - tot_loss: 0.12155027737171342 - acc: 0.9721164309031556 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 2.818211317062378 - sq_loss: 6.866342232569878e-07 - tot_loss: 0.11705273418974182 - acc: 0.9722524483133841 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 2.7723543643951416 - sq_loss: 6.856056415927014e-07 - tot_loss: 0.11815661932041155 - acc: 0.9721164309031556 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 2.801985025405884 - sq_loss: 6.839954380666313e-07 - tot_loss: 0.12269155597200898 - acc: 0.9722524483133841 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 2.841864585876465 - sq_loss: 6.83117150401813e-07 - tot_loss: 0.1281100301830982 - acc: 0.9722524483133841 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 2.820666551589966 - sq_loss: 6.827823995081417e-07 - tot_loss: 0.10760535194829068 - acc: 0.9723884657236126 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 2.7907826900482178 - sq_loss: 6.807964609834016e-07 - tot_loss: 0.1116950481180361 - acc: 0.9725244831338411 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 2.8246734142303467 - sq_loss: 6.787757911297376e-07 - tot_loss: 0.11891682811377335 - acc: 0.9725244831338411 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 2.7727293968200684 - sq_loss: 6.764278168702731e-07 - tot_loss: 0.12603662545328875 - acc: 0.9725244831338411 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 2.778542995452881 - sq_loss: 6.750512966391398e-07 - tot_loss: 0.1253767106762178 - acc: 0.9727965179542981 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 2.814436674118042 - sq_loss: 6.740020239703881e-07 - tot_loss: 0.10806447987382994 - acc: 0.9732045701849836 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 2.8229382038116455 - sq_loss: 6.736501632076397e-07 - tot_loss: 0.10849306085363142 - acc: 0.9730685527747551 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 2.7897353172302246 - sq_loss: 6.729089250256948e-07 - tot_loss: 0.11731807701659536 - acc: 0.9734766050054406 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 2.807671546936035 - sq_loss: 6.705137138851569e-07 - tot_loss: 0.12022088571336154 - acc: 0.9733405875952121 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 2.788330078125 - sq_loss: 6.687204177069361e-07 - tot_loss: 0.10965450581202907 - acc: 0.9734766050054406 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 2.790506601333618 - sq_loss: 6.66863968490361e-07 - tot_loss: 0.11866388341942691 - acc: 0.9733405875952121 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 2.809283971786499 - sq_loss: 6.663735803158488e-07 - tot_loss: 0.12015724813833084 - acc: 0.9734766050054406 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 2.854755401611328 - sq_loss: 6.65175718950195e-07 - tot_loss: 0.11134789583596971 - acc: 0.9733405875952121 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 2.8260061740875244 - sq_loss: 6.643436449849105e-07 - tot_loss: 0.12168631663299978 - acc: 0.9736126224156693 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 2.775953531265259 - sq_loss: 6.623722583753988e-07 - tot_loss: 0.11636649574232516 - acc: 0.9738846572361263 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 2.8340768814086914 - sq_loss: 6.605325779673876e-07 - tot_loss: 0.11354494826700479 - acc: 0.9740206746463548 - val_acc: 0.9504580929759077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 2.770777940750122 - sq_loss: 6.592767363144958e-07 - tot_loss: 0.124574576224594 - acc: 0.9741566920565833 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 2.8037610054016113 - sq_loss: 6.585512437595753e-07 - tot_loss: 0.09958214698509793 - acc: 0.9740206746463548 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 2.7385292053222656 - sq_loss: 6.579221007996239e-07 - tot_loss: 0.09980788071412716 - acc: 0.9740206746463548 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 2.7800955772399902 - sq_loss: 6.581055345122877e-07 - tot_loss: 0.1390850302149398 - acc: 0.9742927094668118 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 2.7661707401275635 - sq_loss: 6.580598892469425e-07 - tot_loss: 0.11480962466386169 - acc: 0.9742927094668118 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 2.7890310287475586 - sq_loss: 6.568189405697922e-07 - tot_loss: 0.1306381133688359 - acc: 0.9745647442872688 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 2.8496878147125244 - sq_loss: 6.555521281370602e-07 - tot_loss: 0.12004395963709524 - acc: 0.9744287268770403 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 2.7955384254455566 - sq_loss: 6.545550377268228e-07 - tot_loss: 0.11406838839254552 - acc: 0.9747007616974973 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 2.82100248336792 - sq_loss: 6.534992280649021e-07 - tot_loss: 0.11546280049633006 - acc: 0.9747007616974973 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 2.8229622840881348 - sq_loss: 6.522386684082448e-07 - tot_loss: 0.10810031879269055 - acc: 0.9749727965179543 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 2.805992364883423 - sq_loss: 6.498305538116256e-07 - tot_loss: 0.11471866033209044 - acc: 0.9749727965179543 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 2.797337532043457 - sq_loss: 6.482532626250759e-07 - tot_loss: 0.11743745973466035 - acc: 0.9749727965179543 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 2.790424346923828 - sq_loss: 6.476582825598598e-07 - tot_loss: 0.12820945319907362 - acc: 0.9751088139281828 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 2.8151614665985107 - sq_loss: 6.465596129601181e-07 - tot_loss: 0.11569115020821874 - acc: 0.9751088139281828 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 2.8228037357330322 - sq_loss: 6.450297291848983e-07 - tot_loss: 0.11058152728998372 - acc: 0.9749727965179543 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 2.8580102920532227 - sq_loss: 6.451970762100245e-07 - tot_loss: 0.11840098499760399 - acc: 0.9751088139281828 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 2.783079147338867 - sq_loss: 6.449966463151213e-07 - tot_loss: 0.12431384362868059 - acc: 0.9751088139281828 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 2.7746315002441406 - sq_loss: 6.443608526751632e-07 - tot_loss: 0.11062201424276719 - acc: 0.9753808487486398 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 2.8164165019989014 - sq_loss: 6.430603889384656e-07 - tot_loss: 0.11493984675898727 - acc: 0.9755168661588683 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 2.7975287437438965 - sq_loss: 6.417582198992022e-07 - tot_loss: 0.10791529084688078 - acc: 0.9756528835690969 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 2.7770190238952637 - sq_loss: 6.400681513696327e-07 - tot_loss: 0.12260545999864059 - acc: 0.9757889009793254 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 2.79099702835083 - sq_loss: 6.388831366166414e-07 - tot_loss: 0.12089410525738908 - acc: 0.9760609357997824 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 2.7957253456115723 - sq_loss: 6.37999164609937e-07 - tot_loss: 0.11894518253802588 - acc: 0.9760609357997824 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 2.8411338329315186 - sq_loss: 6.381372941177688e-07 - tot_loss: 0.12953347020122274 - acc: 0.9760609357997824 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 2.8236069679260254 - sq_loss: 6.368370009113278e-07 - tot_loss: 0.10695664104965452 - acc: 0.9760609357997824 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 2.7503721714019775 - sq_loss: 6.347316343635612e-07 - tot_loss: 0.13181802224852612 - acc: 0.9763329706202394 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 2.7886805534362793 - sq_loss: 6.330081987471203e-07 - tot_loss: 0.11739454091655799 - acc: 0.9766050054406964 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 2.7651748657226562 - sq_loss: 6.323582510958659e-07 - tot_loss: 0.12192572727361295 - acc: 0.9763329706202394 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 2.8056225776672363 - sq_loss: 6.306275395218108e-07 - tot_loss: 0.12309136875424542 - acc: 0.9763329706202394 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 2.7788102626800537 - sq_loss: 6.294505396908789e-07 - tot_loss: 0.11285021643705617 - acc: 0.9767410228509249 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 2.8591954708099365 - sq_loss: 6.281018158915685e-07 - tot_loss: 0.11211174782739253 - acc: 0.9767410228509249 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 2.8089258670806885 - sq_loss: 6.271228016885289e-07 - tot_loss: 0.11522123519850047 - acc: 0.9767410228509249 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 2.837223529815674 - sq_loss: 6.258695748329046e-07 - tot_loss: 0.12339195840440476 - acc: 0.9767410228509249 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 2.815136194229126 - sq_loss: 6.252132607187377e-07 - tot_loss: 0.11083282888792056 - acc: 0.9768770402611534 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 2.7717580795288086 - sq_loss: 6.251463560147386e-07 - tot_loss: 0.12463440523095803 - acc: 0.9768770402611534 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 2.8099143505096436 - sq_loss: 6.238605578801071e-07 - tot_loss: 0.11277130003531166 - acc: 0.9770130576713819 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 2.798201560974121 - sq_loss: 6.229186055861646e-07 - tot_loss: 0.11166759133210258 - acc: 0.9772850924918389 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 2.761200189590454 - sq_loss: 6.222290380719642e-07 - tot_loss: 0.11283048091877745 - acc: 0.9774211099020674 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 2.802325487136841 - sq_loss: 6.219247552508023e-07 - tot_loss: 0.10852617036298962 - acc: 0.9774211099020674 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 2.8174989223480225 - sq_loss: 6.214281143002154e-07 - tot_loss: 0.12740133834104928 - acc: 0.9774211099020674 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 2.8245365619659424 - sq_loss: 6.206579428180703e-07 - tot_loss: 0.10987493656401015 - acc: 0.9774211099020674 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 2.775420904159546 - sq_loss: 6.18630053850211e-07 - tot_loss: 0.12286135398927378 - acc: 0.9775571273122959 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 2.775674343109131 - sq_loss: 6.163111265777843e-07 - tot_loss: 0.11635322104248091 - acc: 0.9775571273122959 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 2.8103129863739014 - sq_loss: 6.150996227916039e-07 - tot_loss: 0.1285948822559837 - acc: 0.9775571273122959 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 2.7923567295074463 - sq_loss: 6.148779334580468e-07 - tot_loss: 0.12143963192369234 - acc: 0.977829162132753 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 2.7905406951904297 - sq_loss: 6.144611006675404e-07 - tot_loss: 0.12982407458151446 - acc: 0.977829162132753 - val_acc: 0.9535120461486257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 2.745434522628784 - sq_loss: 6.138815251688357e-07 - tot_loss: 0.11719528860838957 - acc: 0.9776931447225244 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 2.845343589782715 - sq_loss: 6.117272164374299e-07 - tot_loss: 0.11297933249313585 - acc: 0.977829162132753 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 2.8812317848205566 - sq_loss: 6.111657739893417e-07 - tot_loss: 0.120605357410567 - acc: 0.977829162132753 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 2.7555992603302 - sq_loss: 6.10428912750649e-07 - tot_loss: 0.12184467655419273 - acc: 0.97810119695321 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 2.8354310989379883 - sq_loss: 6.097562845752691e-07 - tot_loss: 0.1085394648897493 - acc: 0.977829162132753 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 2.7851226329803467 - sq_loss: 6.083042194404698e-07 - tot_loss: 0.12073288332952758 - acc: 0.9782372143634385 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 2.773660898208618 - sq_loss: 6.083574248805235e-07 - tot_loss: 0.1329299838154856 - acc: 0.9779651795429815 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 2.568176507949829 - sq_loss: 6.065157549528521e-07 - tot_loss: 0.1108809373562254 - acc: 0.9782372143634385 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 1.4018149375915527 - sq_loss: 6.055997801013291e-07 - tot_loss: 0.10973562601252795 - acc: 0.9785092491838956 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 1.4273386001586914 - sq_loss: 6.031943371453963e-07 - tot_loss: 0.11699020180174768 - acc: 0.9785092491838956 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 1.3950273990631104 - sq_loss: 6.020471232659474e-07 - tot_loss: 0.12893719885469346 - acc: 0.9785092491838956 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 1.4034745693206787 - sq_loss: 6.007219326420454e-07 - tot_loss: 0.11739016747870612 - acc: 0.9785092491838956 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 1.4036812782287598 - sq_loss: 5.995497076582978e-07 - tot_loss: 0.11223185993650553 - acc: 0.9786452665941241 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 1.4079315662384033 - sq_loss: 5.983194455438934e-07 - tot_loss: 0.11964056399018297 - acc: 0.9787812840043526 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 1.4281854629516602 - sq_loss: 5.97936548274447e-07 - tot_loss: 0.1131425218148081 - acc: 0.9789173014145811 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 1.4039385318756104 - sq_loss: 5.962454565633379e-07 - tot_loss: 0.11055551734453828 - acc: 0.9789173014145811 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 1.4136550426483154 - sq_loss: 5.954782409389736e-07 - tot_loss: 0.12199885493716511 - acc: 0.9790533188248096 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 1.4335854053497314 - sq_loss: 5.945345264990465e-07 - tot_loss: 0.11718040833255516 - acc: 0.9790533188248096 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 1.395646333694458 - sq_loss: 5.945719294686569e-07 - tot_loss: 0.11203863551607474 - acc: 0.9790533188248096 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 1.3881947994232178 - sq_loss: 5.935227136433241e-07 - tot_loss: 0.12390951086181223 - acc: 0.9791893362350381 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 1.4034755229949951 - sq_loss: 5.924309220972646e-07 - tot_loss: 0.12878424569991953 - acc: 0.9791893362350381 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 1.432647943496704 - sq_loss: 5.91564173646475e-07 - tot_loss: 0.11531431307654638 - acc: 0.9791893362350381 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 1.4106636047363281 - sq_loss: 5.908193543291418e-07 - tot_loss: 0.12692261411041117 - acc: 0.9794613710554951 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 1.3996953964233398 - sq_loss: 5.90567310609913e-07 - tot_loss: 0.11643131124687378 - acc: 0.9793253536452666 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 1.3982281684875488 - sq_loss: 5.899639745621243e-07 - tot_loss: 0.12759088744447333 - acc: 0.9794613710554951 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 1.3967361450195312 - sq_loss: 5.882192226636107e-07 - tot_loss: 0.12020776191589544 - acc: 0.9795973884657236 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 1.4164326190948486 - sq_loss: 5.863429350938532e-07 - tot_loss: 0.12394595754717086 - acc: 0.9795973884657236 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 1.4164278507232666 - sq_loss: 5.84735630582145e-07 - tot_loss: 0.10588261554626133 - acc: 0.9797334058759521 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 1.414679765701294 - sq_loss: 5.837828780386189e-07 - tot_loss: 0.12028858787564722 - acc: 0.9795973884657236 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 1.4381821155548096 - sq_loss: 5.829169253956934e-07 - tot_loss: 0.11294206126121975 - acc: 0.9798694232861807 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 1.4119386672973633 - sq_loss: 5.821959803142818e-07 - tot_loss: 0.11135026822777494 - acc: 0.9797334058759521 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 1.4158358573913574 - sq_loss: 5.822581670145155e-07 - tot_loss: 0.10912695534223893 - acc: 0.9798694232861807 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 1.4231865406036377 - sq_loss: 5.817009878228419e-07 - tot_loss: 0.11878383702657702 - acc: 0.9798694232861807 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 1.4397833347320557 - sq_loss: 5.800669100608502e-07 - tot_loss: 0.12655523207512076 - acc: 0.9798694232861807 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 1.4055325984954834 - sq_loss: 5.787730970041594e-07 - tot_loss: 0.11746390437605458 - acc: 0.9801414581066377 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 1.44443941116333 - sq_loss: 5.77437845095119e-07 - tot_loss: 0.12382891420735787 - acc: 0.9801414581066377 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 1.4234974384307861 - sq_loss: 5.768256983174069e-07 - tot_loss: 0.11753864897328636 - acc: 0.9804134929270947 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 1.4387574195861816 - sq_loss: 5.765077730757184e-07 - tot_loss: 0.11310161501008087 - acc: 0.9804134929270947 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 1.4546949863433838 - sq_loss: 5.764854336121061e-07 - tot_loss: 0.12605467216617006 - acc: 0.9804134929270947 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 1.4145841598510742 - sq_loss: 5.75237493194436e-07 - tot_loss: 0.1260938573531324 - acc: 0.9805495103373232 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 1.4133403301239014 - sq_loss: 5.74602836422855e-07 - tot_loss: 0.1085428361755153 - acc: 0.9805495103373232 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 1.4500701427459717 - sq_loss: 5.730229872824566e-07 - tot_loss: 0.14137618542949604 - acc: 0.9806855277475517 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 1.4369862079620361 - sq_loss: 5.723127856072097e-07 - tot_loss: 0.11241334452183727 - acc: 0.9805495103373232 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 1.40531587600708 - sq_loss: 5.732915724365739e-07 - tot_loss: 0.12588255582301833 - acc: 0.9806855277475517 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 1.4058635234832764 - sq_loss: 5.729649501517997e-07 - tot_loss: 0.1315501631333451 - acc: 0.9808215451577802 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 1.4112396240234375 - sq_loss: 5.728625183110125e-07 - tot_loss: 0.12269848050683119 - acc: 0.9808215451577802 - val_acc: 0.9535120461486257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 1.4344096183776855 - sq_loss: 5.716491955354286e-07 - tot_loss: 0.12585430141742238 - acc: 0.9808215451577802 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 1.4283721446990967 - sq_loss: 5.708740218324238e-07 - tot_loss: 0.10547925080471865 - acc: 0.9808215451577802 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 1.4205472469329834 - sq_loss: 5.693449907084869e-07 - tot_loss: 0.10618927011937651 - acc: 0.9809575625680087 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 1.412541389465332 - sq_loss: 5.685473070116132e-07 - tot_loss: 0.11066049247950482 - acc: 0.9809575625680087 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 1.4237964153289795 - sq_loss: 5.682207984136767e-07 - tot_loss: 0.12440476191051097 - acc: 0.9808215451577802 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 1.4056994915008545 - sq_loss: 5.675791499015759e-07 - tot_loss: 0.11376342899764724 - acc: 0.9812295973884657 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 1.4409935474395752 - sq_loss: 5.668794642588182e-07 - tot_loss: 0.13542250655312438 - acc: 0.9812295973884657 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 1.4101753234863281 - sq_loss: 5.661508453158604e-07 - tot_loss: 0.11526253364660732 - acc: 0.9812295973884657 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 1.4034428596496582 - sq_loss: 5.646537033499044e-07 - tot_loss: 0.1247447976229964 - acc: 0.9812295973884657 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 1.4106321334838867 - sq_loss: 5.62702609840926e-07 - tot_loss: 0.11426443516436313 - acc: 0.9813656147986942 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 1.451582908630371 - sq_loss: 5.615759164356859e-07 - tot_loss: 0.11137159917659945 - acc: 0.9813656147986942 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 1.4270906448364258 - sq_loss: 5.60750152089895e-07 - tot_loss: 0.12718449554427624 - acc: 0.9815016322089227 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 1.3970446586608887 - sq_loss: 5.595697984972503e-07 - tot_loss: 0.12003095487440041 - acc: 0.9816376496191512 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 1.4412124156951904 - sq_loss: 5.57971929993073e-07 - tot_loss: 0.11374937017556574 - acc: 0.9816376496191512 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 1.410417079925537 - sq_loss: 5.575113277700439e-07 - tot_loss: 0.10272985284429004 - acc: 0.9815016322089227 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 1.4429903030395508 - sq_loss: 5.566478193941293e-07 - tot_loss: 0.12676699681097447 - acc: 0.9816376496191512 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 1.4341888427734375 - sq_loss: 5.56540953766671e-07 - tot_loss: 0.12163372445954934 - acc: 0.9816376496191512 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 1.4208667278289795 - sq_loss: 5.561568059420097e-07 - tot_loss: 0.12444714727711481 - acc: 0.9816376496191512 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 1.4209563732147217 - sq_loss: 5.555618258767936e-07 - tot_loss: 0.11959501968239228 - acc: 0.9816376496191512 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 1.4246909618377686 - sq_loss: 5.554409199248767e-07 - tot_loss: 0.11601536020911929 - acc: 0.9816376496191512 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 1.429692029953003 - sq_loss: 5.542640906242013e-07 - tot_loss: 0.12571630694556613 - acc: 0.9817736670293797 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 1.410154104232788 - sq_loss: 5.52771609818592e-07 - tot_loss: 0.11175178759323645 - acc: 0.9816376496191512 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 1.4145123958587646 - sq_loss: 5.519688102140208e-07 - tot_loss: 0.11804957083714751 - acc: 0.9816376496191512 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 1.4253568649291992 - sq_loss: 5.516520786841284e-07 - tot_loss: 0.1267771063343811 - acc: 0.9816376496191512 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 1.4137847423553467 - sq_loss: 5.512459324563679e-07 - tot_loss: 0.12215020234848706 - acc: 0.9817736670293797 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 1.4288876056671143 - sq_loss: 5.503426336872508e-07 - tot_loss: 0.12869904735944138 - acc: 0.9817736670293797 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 1.4044861793518066 - sq_loss: 5.50307845514908e-07 - tot_loss: 0.12884860457032266 - acc: 0.9816376496191512 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 1.4257423877716064 - sq_loss: 5.49811659311672e-07 - tot_loss: 0.1191573928548273 - acc: 0.9816376496191512 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 1.4196562767028809 - sq_loss: 5.49504136415635e-07 - tot_loss: 0.11734388532252515 - acc: 0.9816376496191512 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 1.4146409034729004 - sq_loss: 5.48489310858713e-07 - tot_loss: 0.11992617114424242 - acc: 0.9816376496191512 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 1.4320893287658691 - sq_loss: 5.482332881001639e-07 - tot_loss: 0.12968692408568894 - acc: 0.9816376496191512 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 1.4117584228515625 - sq_loss: 5.472039674714324e-07 - tot_loss: 0.12126154853363336 - acc: 0.9816376496191512 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 1.449228286743164 - sq_loss: 5.464644345920533e-07 - tot_loss: 0.11893759781552704 - acc: 0.9817736670293797 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 1.4207582473754883 - sq_loss: 5.457638962980127e-07 - tot_loss: 0.13216229239122368 - acc: 0.9817736670293797 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 1.4273252487182617 - sq_loss: 5.444603061732778e-07 - tot_loss: 0.13505313474381353 - acc: 0.9816376496191512 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 1.4162986278533936 - sq_loss: 5.429853331406775e-07 - tot_loss: 0.12091759930685442 - acc: 0.9816376496191512 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 1.4153425693511963 - sq_loss: 5.420130264610634e-07 - tot_loss: 0.12423522094552664 - acc: 0.9816376496191512 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 1.4300057888031006 - sq_loss: 5.403603609011043e-07 - tot_loss: 0.11891046385588977 - acc: 0.9816376496191512 - val_acc: 0.9548693586698337\n",
      "CR_1 = 0.17665842270710058   CR_2 = 0.17592699696476163\n",
      "/home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 3\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "alpha = 1\n",
    "\n",
    "\n",
    "\n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "    d0 = 561 #561 =3*11*17\n",
    "\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 512\n",
    "    d6 = 6 \n",
    "\n",
    "\n",
    "    W1 = 0.2*init.xavier_uniform_(torch.empty(d1, d0, device=device), gain=1.0)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    W2 = 0.2*init.xavier_uniform_(torch.empty(d2, d1, device=device), gain=1.0)\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles ‘factors’, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    W3 = 0.2*init.xavier_uniform_(torch.empty(d3, d2, device=device), gain=1.0)\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    W4 = 0.2*init.xavier_uniform_(torch.empty(d4, d3, device=device), gain=1.0)\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    W5 = 0.2*init.xavier_uniform_(torch.empty(d5, d4, device=device), gain=1.0)\n",
    "    W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())\n",
    "    factors5 = tensor_train(W5_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "\n",
    "    W6 = 0.2*init.xavier_uniform_(torch.empty(d6, d5, device=device), gain=1.0)\n",
    "    b6 = 0*torch.ones(d6, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = nn.ReLU()(U5)\n",
    "    U6 = torch.addmm(b6.repeat(1, N), W6, V5)\n",
    "    V6 = U6 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V6 = (y_one_hot + gamma*U6 + alpha*V6)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U6 = (gamma*V6 + rho*(torch.mm(W6,V5) + b6.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W6, b6 = updateWb_org(U6,V5,W6,b6,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "        # update for 5th layer\n",
    "        # update V3\n",
    "        V5 = updateV(U5,U6,W6,b6,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U5 = relu_prox(V5,(rho*torch.addmm(b5.repeat(1,N), W5, V4) + alpha*U5)/(rho + alpha),(rho + alpha)/gamma,d5,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W5, b5 = updateWb(U5,V4,W5,b5,W5_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4))\n",
    "        W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors5 = tensor_train(W5_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        a5_train = nn.ReLU()(torch.addmm(b5.repeat(1, N), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b6.repeat(1, N), W6, a5_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        a5_test = nn.ReLU()(torch.addmm(b5.repeat(1, N_test), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b6.repeat(1, N_test), W6, a5_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V6,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b6.repeat(1,N), W6, V5),U6,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,nn.ReLU()(U5),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V6,U6,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W5.reshape((4,4,4,4,4,4,4,4,4)),torch.as_tensor(W5_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "    factors5_shape=[f.shape for f in factors5]\n",
    "    Sum_of_variables_factors5=sum(list(x*y*z for x,y,z in factors5_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4+Sum_of_variables_factors5\n",
    "\n",
    "    CR_1=((total_variabels)+(d5*d6))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5+d5*d6)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#     #this postion to add new row into existing table\n",
    "#         df=pd.read_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "#         new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "#                    'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "#                    'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1],'seed':seed} \n",
    "#         df=df.append(new_row,ignore_index=True)\n",
    "#         df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"XavierUniform_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e5c2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133d333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
