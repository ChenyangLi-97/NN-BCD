{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4cb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a157bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a5c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087d0e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 3 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 4.330068826675415 - sq_loss: 661.6827392578125 - tot_loss: 967.5189884508873 - acc: 0.16825353645266594 - val_acc: 0.16762809636918902\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 3.783352851867676 - sq_loss: 294.0812072753906 - tot_loss: 493.16393100330606 - acc: 0.1761425462459195 - val_acc: 0.168306752629793\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 3.7504944801330566 - sq_loss: 164.3061981201172 - tot_loss: 269.82554174400866 - acc: 0.18049510337323177 - val_acc: 0.167288768238887\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 3.6591269969940186 - sq_loss: 89.59539794921875 - tot_loss: 152.4732067878358 - acc: 0.20239390642002175 - val_acc: 0.19273837801153715\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 3.742438793182373 - sq_loss: 48.28154754638672 - tot_loss: 89.32036096276715 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 3.769773483276367 - sq_loss: 25.913990020751953 - tot_loss: 54.990210780873895 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 3.7848522663116455 - sq_loss: 13.913860321044922 - tot_loss: 36.1059425577987 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 3.7430100440979004 - sq_loss: 7.494540214538574 - tot_loss: 25.57367061963305 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 3.7929999828338623 - sq_loss: 4.058708190917969 - tot_loss: 19.476139022270218 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 3.722722291946411 - sq_loss: 2.2146801948547363 - tot_loss: 15.826082172454335 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 3.705859422683716 - sq_loss: 1.2205803394317627 - tot_loss: 13.500020728213713 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 3.776728630065918 - sq_loss: 0.6814237833023071 - tot_loss: 11.893558516399935 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 3.774021863937378 - sq_loss: 0.38669389486312866 - tot_loss: 10.658109417650849 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 3.729641914367676 - sq_loss: 0.22394981980323792 - tot_loss: 9.67472633102443 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 3.6974542140960693 - sq_loss: 0.13293668627738953 - tot_loss: 8.841058165766299 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 3.70818829536438 - sq_loss: 0.08123478293418884 - tot_loss: 8.09604010405019 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 3.7725629806518555 - sq_loss: 0.05129901319742203 - tot_loss: 7.453832944855094 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 3.706530809402466 - sq_loss: 0.03357136994600296 - tot_loss: 6.864509932289366 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 3.823190450668335 - sq_loss: 0.022804180160164833 - tot_loss: 6.3675261964672245 - acc: 0.27026659412404785 - val_acc: 0.25822870715982355\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 3.914426326751709 - sq_loss: 0.01607702299952507 - tot_loss: 5.917366991692688 - acc: 0.36235038084874865 - val_acc: 0.35188327112317613\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 3.9899356365203857 - sq_loss: 0.01174719724804163 - tot_loss: 5.512131160299759 - acc: 0.3411316648531012 - val_acc: 0.3498473023413641\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 3.913015365600586 - sq_loss: 0.008873575367033482 - tot_loss: 5.14611524171778 - acc: 0.272170837867247 - val_acc: 0.29284017645062776\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 3.965883731842041 - sq_loss: 0.006906989496201277 - tot_loss: 4.843457140363171 - acc: 0.242791077257889 - val_acc: 0.24669155072955548\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 3.9324231147766113 - sq_loss: 0.005519570782780647 - tot_loss: 4.542565250550979 - acc: 0.25680087051142547 - val_acc: 0.2524601289446895\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 3.9523918628692627 - sq_loss: 0.004512146580964327 - tot_loss: 4.280000347076566 - acc: 0.29066920565832427 - val_acc: 0.2734984730234136\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 4.062472105026245 - sq_loss: 0.0037605855613946915 - tot_loss: 4.038949758760282 - acc: 0.3298422198041349 - val_acc: 0.2999660671869698\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 3.9362728595733643 - sq_loss: 0.003185870125889778 - tot_loss: 3.8224077429040335 - acc: 0.34657236126224156 - val_acc: 0.332880895826264\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 4.271153688430786 - sq_loss: 0.0027367344591766596 - tot_loss: 3.641280583178741 - acc: 0.3559575625680087 - val_acc: 0.3535799117746861\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 4.052266359329224 - sq_loss: 0.0023783762007951736 - tot_loss: 3.449395708674274 - acc: 0.36248639825897716 - val_acc: 0.35900916185951814\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 3.975097894668579 - sq_loss: 0.002087544882670045 - tot_loss: 3.275369410868734 - acc: 0.3646626768226333 - val_acc: 0.36104513064133015\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 4.117531776428223 - sq_loss: 0.0018476356053724885 - tot_loss: 3.140130630308704 - acc: 0.3665669205658324 - val_acc: 0.3647777400746522\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 4.6398797035217285 - sq_loss: 0.0016470288392156363 - tot_loss: 2.9921858290181262 - acc: 0.36983133841131666 - val_acc: 0.3671530369867662\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 3.5134353637695312 - sq_loss: 0.0014776427997276187 - tot_loss: 2.844171889060817 - acc: 0.374727965179543 - val_acc: 0.3732609433322022\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 3.275200843811035 - sq_loss: 0.0013332266826182604 - tot_loss: 2.7268951637815917 - acc: 0.381936887921654 - val_acc: 0.3807261621988463\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 3.202066659927368 - sq_loss: 0.0012084157206118107 - tot_loss: 2.617806732072495 - acc: 0.39200217627856365 - val_acc: 0.39429928741092635\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 3.2292935848236084 - sq_loss: 0.0010994150070473552 - tot_loss: 2.520360113849165 - acc: 0.40329162132752994 - val_acc: 0.40821174075330846\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 3.2199134826660156 - sq_loss: 0.0010041100904345512 - tot_loss: 2.413859154759848 - acc: 0.41702937976060933 - val_acc: 0.4282321004411266\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 3.2962279319763184 - sq_loss: 0.000920143153052777 - tot_loss: 2.3137652121513383 - acc: 0.4351196953210011 - val_acc: 0.4482524601289447\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 3.1897237300872803 - sq_loss: 0.0008457998046651483 - tot_loss: 2.235723406272882 - acc: 0.45239390642002175 - val_acc: 0.46114692908042076\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 3.2171921730041504 - sq_loss: 0.0007796394638717175 - tot_loss: 2.151621343782608 - acc: 0.4734766050054407 - val_acc: 0.4791313199864269\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 3.307464599609375 - sq_loss: 0.0007204824360087514 - tot_loss: 2.063142984832666 - acc: 0.49075081610446136 - val_acc: 0.48998982015609094\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 3.2545948028564453 - sq_loss: 0.0006675457116216421 - tot_loss: 2.0050330142221355 - acc: 0.5074809575625681 - val_acc: 0.500169664065151\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 3.296219825744629 - sq_loss: 0.0006196375470608473 - tot_loss: 1.9126249273576832 - acc: 0.5199945593035908 - val_acc: 0.5110281642348151\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 3.2746846675872803 - sq_loss: 0.0005762319779023528 - tot_loss: 1.8432778659298492 - acc: 0.529107725788901 - val_acc: 0.5174753987105531\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 3.4036052227020264 - sq_loss: 0.0005368842976167798 - tot_loss: 1.7668936351401499 - acc: 0.5391730141458106 - val_acc: 0.5232439769256871\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 3.3686211109161377 - sq_loss: 0.0005009687156416476 - tot_loss: 1.7070981615543133 - acc: 0.5511425462459195 - val_acc: 0.5283338988802172\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 3.273287296295166 - sq_loss: 0.0004681945138145238 - tot_loss: 1.661233031149095 - acc: 0.5632480957562568 - val_acc: 0.5364777740074652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 3.255863904953003 - sq_loss: 0.00043795761303044856 - tot_loss: 1.6077959999092855 - acc: 0.573993471164309 - val_acc: 0.5466576179165252\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 3.2832179069519043 - sq_loss: 0.000410299253417179 - tot_loss: 1.5474748185788485 - acc: 0.5885473340587595 - val_acc: 0.5541228367831693\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 3.325080394744873 - sq_loss: 0.0003849121567327529 - tot_loss: 1.4965629720227298 - acc: 0.6039173014145811 - val_acc: 0.5622667119104173\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 3.3134214878082275 - sq_loss: 0.00036144498153589666 - tot_loss: 1.4498755530148628 - acc: 0.6232317736670294 - val_acc: 0.5731252120800815\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 3.315077543258667 - sq_loss: 0.0003397279360797256 - tot_loss: 1.4030300931481179 - acc: 0.6433623503808488 - val_acc: 0.5877163216830675\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 3.193661689758301 - sq_loss: 0.0003195462340954691 - tot_loss: 1.3725508926108887 - acc: 0.6636289445048966 - val_acc: 0.6057007125890737\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 3.2313218116760254 - sq_loss: 0.0003007588966283947 - tot_loss: 1.2972961347240926 - acc: 0.6830794341675734 - val_acc: 0.6202918221920597\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 3.294711112976074 - sq_loss: 0.00028328780899755657 - tot_loss: 1.2597621210297802 - acc: 0.6994015233949945 - val_acc: 0.6338649474041398\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 3.3123810291290283 - sq_loss: 0.00026698046713136137 - tot_loss: 1.219434867696691 - acc: 0.7151795429815017 - val_acc: 0.6477774007465219\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 3.202705144882202 - sq_loss: 0.0002517136454116553 - tot_loss: 1.1909418612713125 - acc: 0.7268770402611534 - val_acc: 0.65931455717679\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 3.271219253540039 - sq_loss: 0.00023755073198117316 - tot_loss: 1.1531446489525479 - acc: 0.7385745375408053 - val_acc: 0.673566338649474\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 3.206939220428467 - sq_loss: 0.00022442267800215632 - tot_loss: 1.114511578382917 - acc: 0.7504080522306855 - val_acc: 0.6881574482524602\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 4.598545551300049 - sq_loss: 0.00021200455375947058 - tot_loss: 1.0711807953439347 - acc: 0.7588411316648531 - val_acc: 0.7003732609433322\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 4.525203227996826 - sq_loss: 0.00020030976156704128 - tot_loss: 1.0405204421504095 - acc: 0.7659140369967355 - val_acc: 0.7088564642008822\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 4.474012613296509 - sq_loss: 0.00018930193618871272 - tot_loss: 1.006876711685436 - acc: 0.7733949945593036 - val_acc: 0.7176789955887343\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 4.783822774887085 - sq_loss: 0.00017901035607792437 - tot_loss: 0.9962883752859852 - acc: 0.7803318824809575 - val_acc: 0.7265015269765863\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 4.87028694152832 - sq_loss: 0.00016926131502259523 - tot_loss: 0.9500370024306903 - acc: 0.786588683351469 - val_acc: 0.7353240583644384\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 6.2227513790130615 - sq_loss: 0.00016019890608731657 - tot_loss: 0.9352232489973176 - acc: 0.7933895538628944 - val_acc: 0.7427892772310825\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 6.717394113540649 - sq_loss: 0.00015152365085668862 - tot_loss: 0.8941644441674725 - acc: 0.7980141458106638 - val_acc: 0.7502544960977265\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 5.3258583545684814 - sq_loss: 0.0001434174191672355 - tot_loss: 0.8802838112951576 - acc: 0.801006528835691 - val_acc: 0.7567017305734646\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 4.2329089641571045 - sq_loss: 0.00013580302766058594 - tot_loss: 0.8406275448469387 - acc: 0.8046789989118607 - val_acc: 0.7631489650492026\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 4.22886323928833 - sq_loss: 0.00012867915211245418 - tot_loss: 0.8231506232750689 - acc: 0.8091675734494015 - val_acc: 0.7699355276552426\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 4.195903778076172 - sq_loss: 0.00012185341620352119 - tot_loss: 0.8119583233014964 - acc: 0.8128400435255713 - val_acc: 0.7746861214794707\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 4.147403717041016 - sq_loss: 0.00011545302550075576 - tot_loss: 0.7833927068645608 - acc: 0.8181447225244831 - val_acc: 0.7814726840855107\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 4.203630208969116 - sq_loss: 0.00010942275548586622 - tot_loss: 0.7428928311751406 - acc: 0.8218171926006529 - val_acc: 0.7865626060400407\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 4.1706461906433105 - sq_loss: 0.00010368243238190189 - tot_loss: 0.7207556213015778 - acc: 0.8258977149075082 - val_acc: 0.7913131998642687\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 4.1170337200164795 - sq_loss: 9.825394954532385e-05 - tot_loss: 0.7190700464034308 - acc: 0.8292981501632208 - val_acc: 0.7974211062097047\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 4.173426866531372 - sq_loss: 9.315279748989269e-05 - tot_loss: 0.7132118673698642 - acc: 0.8322905331882481 - val_acc: 0.8021717000339328\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 4.158024549484253 - sq_loss: 8.833713218336925e-05 - tot_loss: 0.6970307277306347 - acc: 0.8359630032644179 - val_acc: 0.8052256532066508\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 4.159112453460693 - sq_loss: 8.374749450013041e-05 - tot_loss: 0.6693927329870348 - acc: 0.8392274211099021 - val_acc: 0.8076009501187649\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 4.269943714141846 - sq_loss: 7.941411604406312e-05 - tot_loss: 0.6248477338021985 - acc: 0.8434439608269858 - val_acc: 0.8099762470308789\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 4.249610185623169 - sq_loss: 7.527505658799782e-05 - tot_loss: 0.619701051204629 - acc: 0.846436343852013 - val_acc: 0.8140481845945029\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 4.231438636779785 - sq_loss: 7.144156552385539e-05 - tot_loss: 0.6318468878753265 - acc: 0.8498367791077258 - val_acc: 0.8201560909399389\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 4.184473752975464 - sq_loss: 6.772524648113176e-05 - tot_loss: 0.5940821734830024 - acc: 0.8526931447225244 - val_acc: 0.8238887003732609\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 4.185823202133179 - sq_loss: 6.427019252441823e-05 - tot_loss: 0.6019355766247827 - acc: 0.8552774755168662 - val_acc: 0.826942653545979\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 4.071131229400635 - sq_loss: 6.098429366829805e-05 - tot_loss: 0.5730648237208698 - acc: 0.8559575625680087 - val_acc: 0.830335934848999\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 4.137521266937256 - sq_loss: 5.784302993561141e-05 - tot_loss: 0.5572317286967063 - acc: 0.8581338411316648 - val_acc: 0.835425856803529\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 4.0035271644592285 - sq_loss: 5.4873973567737266e-05 - tot_loss: 0.5449370093597281 - acc: 0.860854189336235 - val_acc: 0.838479809976247\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 4.110713720321655 - sq_loss: 5.207335198065266e-05 - tot_loss: 0.5279791590630794 - acc: 0.861126224156692 - val_acc: 0.841533763148965\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 4.10562539100647 - sq_loss: 4.945396722177975e-05 - tot_loss: 0.5191589538760581 - acc: 0.8622143634385201 - val_acc: 0.8428910756701731\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 4.291674613952637 - sq_loss: 4.695703319157474e-05 - tot_loss: 0.514617447089222 - acc: 0.8639825897714908 - val_acc: 0.846284356973193\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 4.05501127243042 - sq_loss: 4.455167436390184e-05 - tot_loss: 0.496016649854937 - acc: 0.8662948857453754 - val_acc: 0.8513742789277231\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 4.221932888031006 - sq_loss: 4.233614163240418e-05 - tot_loss: 0.4937472985409386 - acc: 0.8702393906420022 - val_acc: 0.8537495758398371\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 4.132256031036377 - sq_loss: 4.020940832560882e-05 - tot_loss: 0.47270059534639586 - acc: 0.8714635473340587 - val_acc: 0.8578215134034611\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 4.20567512512207 - sq_loss: 3.8164092984516174e-05 - tot_loss: 0.4635452247325702 - acc: 0.8715995647442872 - val_acc: 0.8615541228367831\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 4.075941324234009 - sq_loss: 3.62433165719267e-05 - tot_loss: 0.4605503102243347 - acc: 0.8722796517954298 - val_acc: 0.8635900916185952\n",
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 4.132991552352905 - sq_loss: 3.4419419534970075e-05 - tot_loss: 0.43754870189786743 - acc: 0.8748639825897715 - val_acc: 0.8642687478791992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 4.134057998657227 - sq_loss: 3.267559804953635e-05 - tot_loss: 0.44424647776349957 - acc: 0.8759521218715995 - val_acc: 0.8646080760095012\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 4.150705575942993 - sq_loss: 3.106782241957262e-05 - tot_loss: 0.4422376677136981 - acc: 0.8775843307943417 - val_acc: 0.8656260604004072\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 5.869747161865234 - sq_loss: 2.9569220714620315e-05 - tot_loss: 0.4288485581882924 - acc: 0.8782644178454843 - val_acc: 0.8666440447913132\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 5.681869268417358 - sq_loss: 2.8119064154452644e-05 - tot_loss: 0.41895821681146117 - acc: 0.8792165397170838 - val_acc: 0.8680013573125213\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 5.4727253913879395 - sq_loss: 2.6725696443463676e-05 - tot_loss: 0.40978872604591743 - acc: 0.8807127312295974 - val_acc: 0.8696979979640312\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 4.3922929763793945 - sq_loss: 2.5384129912708886e-05 - tot_loss: 0.40678609536485055 - acc: 0.8826169749727966 - val_acc: 0.8707159823549372\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 4.128461599349976 - sq_loss: 2.4154665879905224e-05 - tot_loss: 0.39605032088036296 - acc: 0.8827529923830251 - val_acc: 0.8724126230064473\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 4.131883859634399 - sq_loss: 2.2988233467913233e-05 - tot_loss: 0.3876337442121667 - acc: 0.8828890097932536 - val_acc: 0.8724126230064473\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 4.133099794387817 - sq_loss: 2.187474638049025e-05 - tot_loss: 0.3990790075856694 - acc: 0.8843852013057671 - val_acc: 0.8747879199185612\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 4.091691970825195 - sq_loss: 2.081034290313255e-05 - tot_loss: 0.38051726732487623 - acc: 0.8856093579978237 - val_acc: 0.8764845605700713\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 4.163894176483154 - sq_loss: 1.9801318558165804e-05 - tot_loss: 0.367170671675467 - acc: 0.8865614798694232 - val_acc: 0.8761452324397693\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 4.106470108032227 - sq_loss: 1.8855847883969545e-05 - tot_loss: 0.37920689671625496 - acc: 0.8881936887921654 - val_acc: 0.8761452324397693\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 4.210609436035156 - sq_loss: 1.7936599761014804e-05 - tot_loss: 0.36504685495151534 - acc: 0.889689880304679 - val_acc: 0.8761452324397693\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 4.192648410797119 - sq_loss: 1.707862611510791e-05 - tot_loss: 0.3346807919800767 - acc: 0.8900979325353645 - val_acc: 0.8775025449609772\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 4.1787800788879395 - sq_loss: 1.6242318451986648e-05 - tot_loss: 0.35522284797343673 - acc: 0.89050598476605 - val_acc: 0.8788598574821853\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 4.124042749404907 - sq_loss: 1.54964054672746e-05 - tot_loss: 0.3567218824938436 - acc: 0.8914581066376496 - val_acc: 0.8802171700033933\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 4.159377813339233 - sq_loss: 1.475439148634905e-05 - tot_loss: 0.336033208707363 - acc: 0.8914581066376496 - val_acc: 0.8829317950458093\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 4.080916404724121 - sq_loss: 1.4063711205380969e-05 - tot_loss: 0.3481770388913219 - acc: 0.8921381936887922 - val_acc: 0.8849677638276213\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 4.148077726364136 - sq_loss: 1.3397441762208473e-05 - tot_loss: 0.32773470616382383 - acc: 0.8933623503808488 - val_acc: 0.8856464200882254\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 3.9268627166748047 - sq_loss: 1.2783458259946201e-05 - tot_loss: 0.32251877204453194 - acc: 0.8934983677910773 - val_acc: 0.8863250763488293\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 6.549544811248779 - sq_loss: 1.2219944437674712e-05 - tot_loss: 0.3300693134503945 - acc: 0.8945865070729053 - val_acc: 0.8870037326094333\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 6.50402307510376 - sq_loss: 1.1649007319647353e-05 - tot_loss: 0.32842291448747574 - acc: 0.8958106637649619 - val_acc: 0.8876823888700374\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 6.324568510055542 - sq_loss: 1.1114196240669116e-05 - tot_loss: 0.3253736439111776 - acc: 0.8970348204570185 - val_acc: 0.8873430607397353\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 6.560356140136719 - sq_loss: 1.060423437593272e-05 - tot_loss: 0.30122402566667006 - acc: 0.8979869423286181 - val_acc: 0.8887003732609433\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 6.494176864624023 - sq_loss: 1.0120953447767533e-05 - tot_loss: 0.2934241217268436 - acc: 0.8986670293797606 - val_acc: 0.8890397013912453\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 6.516913175582886 - sq_loss: 9.669057362771127e-06 - tot_loss: 0.29234110603715635 - acc: 0.8994831338411317 - val_acc: 0.8897183576518494\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 6.539731740951538 - sq_loss: 9.245658475265373e-06 - tot_loss: 0.3115004674104398 - acc: 0.8998911860718172 - val_acc: 0.8907363420427553\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 6.4373438358306885 - sq_loss: 8.861567039275542e-06 - tot_loss: 0.29459057351289175 - acc: 0.9011153427638737 - val_acc: 0.8914149983033594\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 6.464644193649292 - sq_loss: 8.477541086904239e-06 - tot_loss: 0.30423262088845604 - acc: 0.9022034820457019 - val_acc: 0.8914149983033594\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 6.489981651306152 - sq_loss: 8.129074558382854e-06 - tot_loss: 0.2836583589234465 - acc: 0.9028835690968444 - val_acc: 0.8924329826942654\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 6.489022493362427 - sq_loss: 7.788259608787484e-06 - tot_loss: 0.277952935824203 - acc: 0.904107725788901 - val_acc: 0.8934509670851714\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 6.638021945953369 - sq_loss: 7.4656668402894866e-06 - tot_loss: 0.27218041160887196 - acc: 0.904107725788901 - val_acc: 0.8948082796063793\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 6.591733932495117 - sq_loss: 7.158240350690903e-06 - tot_loss: 0.284204354862851 - acc: 0.9050598476605005 - val_acc: 0.8954869358669834\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 6.532565355300903 - sq_loss: 6.8597946665249765e-06 - tot_loss: 0.2619355420763725 - acc: 0.9053318824809575 - val_acc: 0.8965049202578894\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 6.7850542068481445 - sq_loss: 6.5894196268345695e-06 - tot_loss: 0.26738762282184325 - acc: 0.9060119695321001 - val_acc: 0.8971835765184933\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 6.531934022903442 - sq_loss: 6.335002126434119e-06 - tot_loss: 0.2676685003277157 - acc: 0.9062840043525572 - val_acc: 0.8988802171700034\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 6.647078514099121 - sq_loss: 6.085797849664232e-06 - tot_loss: 0.2627256759781744 - acc: 0.9068280739934712 - val_acc: 0.8998982015609094\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 6.575183868408203 - sq_loss: 5.8454315876588225e-06 - tot_loss: 0.26260327808034845 - acc: 0.9081882480957563 - val_acc: 0.9012555140821175\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 6.597769737243652 - sq_loss: 5.615755071630701e-06 - tot_loss: 0.27620664923483673 - acc: 0.9091403699673558 - val_acc: 0.9039701391245334\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 6.0052289962768555 - sq_loss: 5.408568995335372e-06 - tot_loss: 0.2603854060565709 - acc: 0.9103645266594124 - val_acc: 0.9043094672548354\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 6.342889308929443 - sq_loss: 5.202659849601332e-06 - tot_loss: 0.25953081020190893 - acc: 0.9100924918389554 - val_acc: 0.9049881235154394\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 6.273643255233765 - sq_loss: 5.0073790589522105e-06 - tot_loss: 0.2594061347865875 - acc: 0.9102285092491839 - val_acc: 0.9046487953851374\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 6.408094644546509 - sq_loss: 4.831907062907703e-06 - tot_loss: 0.25816937986454036 - acc: 0.9109085963003264 - val_acc: 0.9046487953851374\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 6.519834995269775 - sq_loss: 4.6485142775054555e-06 - tot_loss: 0.24366084631276408 - acc: 0.911588683351469 - val_acc: 0.9056667797760435\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 6.0974037647247314 - sq_loss: 4.480315965338377e-06 - tot_loss: 0.24463262401232555 - acc: 0.9125408052230686 - val_acc: 0.9063454360366474\n",
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 6.124619007110596 - sq_loss: 4.326568614487769e-06 - tot_loss: 0.2457621802370511 - acc: 0.9130848748639826 - val_acc: 0.9073634204275535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 6.067206382751465 - sq_loss: 4.183798409940209e-06 - tot_loss: 0.24197582162520348 - acc: 0.9140369967355821 - val_acc: 0.9080420766881574\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 6.1403138637542725 - sq_loss: 4.0437516872771084e-06 - tot_loss: 0.24114397710329172 - acc: 0.9151251360174102 - val_acc: 0.9087207329487614\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 6.197977066040039 - sq_loss: 3.9174315134005155e-06 - tot_loss: 0.2479293088562855 - acc: 0.9160772578890098 - val_acc: 0.9090600610790635\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 6.11615777015686 - sq_loss: 3.7939471440040506e-06 - tot_loss: 0.23648041317107982 - acc: 0.9166213275299239 - val_acc: 0.9107567017305734\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 6.067431211471558 - sq_loss: 3.6687765714304987e-06 - tot_loss: 0.24599070481416163 - acc: 0.9170293797606094 - val_acc: 0.9107567017305734\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 6.072753190994263 - sq_loss: 3.555972170943278e-06 - tot_loss: 0.2388665761212252 - acc: 0.9179815016322089 - val_acc: 0.9117746861214795\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 6.18987774848938 - sq_loss: 3.4412755667290185e-06 - tot_loss: 0.24813424792645833 - acc: 0.9186615886833515 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 6.071563243865967 - sq_loss: 3.3404642181267263e-06 - tot_loss: 0.24025007490133987 - acc: 0.9192056583242655 - val_acc: 0.9134713267729895\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 6.093760013580322 - sq_loss: 3.2402795113739558e-06 - tot_loss: 0.24786667344068292 - acc: 0.919885745375408 - val_acc: 0.9141499830335935\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 6.013830661773682 - sq_loss: 3.144394668197492e-06 - tot_loss: 0.22498970932127804 - acc: 0.9207018498367792 - val_acc: 0.9138106549032915\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 6.017189264297485 - sq_loss: 3.0583350962842815e-06 - tot_loss: 0.2062586080254647 - acc: 0.9209738846572362 - val_acc: 0.9144893111638955\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 6.110605478286743 - sq_loss: 2.973868504341226e-06 - tot_loss: 0.20808393023295935 - acc: 0.9216539717083787 - val_acc: 0.9151679674244995\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 6.063800811767578 - sq_loss: 2.8915974326082505e-06 - tot_loss: 0.20920381573337465 - acc: 0.9216539717083787 - val_acc: 0.9155072955548015\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 6.086782693862915 - sq_loss: 2.8144236239313614e-06 - tot_loss: 0.20760729124356914 - acc: 0.9217899891186072 - val_acc: 0.9155072955548015\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 5.958595037460327 - sq_loss: 2.743802724580746e-06 - tot_loss: 0.21739765949055112 - acc: 0.9226060935799782 - val_acc: 0.9161859518154055\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 6.1543169021606445 - sq_loss: 2.679990757314954e-06 - tot_loss: 0.22657275364804264 - acc: 0.9231501632208923 - val_acc: 0.9178825924669155\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 6.226377248764038 - sq_loss: 2.6138877728953958e-06 - tot_loss: 0.2133947330230015 - acc: 0.9235582154515778 - val_acc: 0.9182219205972175\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 6.026866674423218 - sq_loss: 2.54616497841198e-06 - tot_loss: 0.2110858439798733 - acc: 0.9236942328618063 - val_acc: 0.9192399049881235\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 6.058992147445679 - sq_loss: 2.4903806661313865e-06 - tot_loss: 0.20930759936761234 - acc: 0.9241022850924918 - val_acc: 0.9199185612487275\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 6.187059640884399 - sq_loss: 2.430682798149064e-06 - tot_loss: 0.2425291462223811 - acc: 0.9245103373231773 - val_acc: 0.9199185612487275\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 6.090097427368164 - sq_loss: 2.3829820747778285e-06 - tot_loss: 0.19350888427426582 - acc: 0.9247823721436343 - val_acc: 0.9202578893790295\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 6.273540496826172 - sq_loss: 2.328159098397009e-06 - tot_loss: 0.20487236857589863 - acc: 0.9255984766050055 - val_acc: 0.9209365456396336\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 6.132278203964233 - sq_loss: 2.2817423541710014e-06 - tot_loss: 0.2278372130231503 - acc: 0.9261425462459195 - val_acc: 0.9212758737699356\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 6.122252702713013 - sq_loss: 2.238840806967346e-06 - tot_loss: 0.21495562332855656 - acc: 0.9270946681175191 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 6.2477545738220215 - sq_loss: 2.1926330191490706e-06 - tot_loss: 0.21075799896590297 - acc: 0.9273667029379761 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 6.131932973861694 - sq_loss: 2.147824034182122e-06 - tot_loss: 0.19890281837133017 - acc: 0.9285908596300326 - val_acc: 0.9226331862911435\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 6.110967397689819 - sq_loss: 2.1044479581178166e-06 - tot_loss: 0.20025484091546986 - acc: 0.9292709466811752 - val_acc: 0.9226331862911435\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 6.073246240615845 - sq_loss: 2.0690013116109185e-06 - tot_loss: 0.20537851060506895 - acc: 0.9296789989118607 - val_acc: 0.9229725144214456\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 6.119815111160278 - sq_loss: 2.033599685091758e-06 - tot_loss: 0.22833631610914296 - acc: 0.9299510337323177 - val_acc: 0.9226331862911435\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 6.115467309951782 - sq_loss: 2.001028406084515e-06 - tot_loss: 0.21535999252100524 - acc: 0.9302230685527747 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 6.326779842376709 - sq_loss: 1.9694145976245636e-06 - tot_loss: 0.20299532480190763 - acc: 0.9306311207834603 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 6.031007766723633 - sq_loss: 1.936612079589395e-06 - tot_loss: 0.2087574675119832 - acc: 0.9313112078346029 - val_acc: 0.9250084832032576\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 6.201416254043579 - sq_loss: 1.9046866555072484e-06 - tot_loss: 0.2082707309043954 - acc: 0.9314472252448314 - val_acc: 0.9256871394638616\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 6.174055814743042 - sq_loss: 1.8730161173152737e-06 - tot_loss: 0.20287521572148393 - acc: 0.9319912948857454 - val_acc: 0.9256871394638616\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 6.324730157852173 - sq_loss: 1.8457445776220993e-06 - tot_loss: 0.19246910235292702 - acc: 0.933215451577802 - val_acc: 0.9263657957244655\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 6.2789411544799805 - sq_loss: 1.819719386730867e-06 - tot_loss: 0.2021032165162424 - acc: 0.9333514689880305 - val_acc: 0.9263657957244655\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 6.406405210494995 - sq_loss: 1.7914870795721072e-06 - tot_loss: 0.20062633710282185 - acc: 0.93430359085963 - val_acc: 0.9267051238547676\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 5.688040733337402 - sq_loss: 1.7683596524875611e-06 - tot_loss: 0.20421254601579975 - acc: 0.9344396082698585 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 4.9354026317596436 - sq_loss: 1.7455400893595652e-06 - tot_loss: 0.18890488431496877 - acc: 0.9344396082698585 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 4.892928123474121 - sq_loss: 1.7194856809510384e-06 - tot_loss: 0.19502497558972465 - acc: 0.9347116430903155 - val_acc: 0.9280624363759755\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 5.0617876052856445 - sq_loss: 1.6962688960120431e-06 - tot_loss: 0.19741286042062356 - acc: 0.9353917301414582 - val_acc: 0.9284017645062775\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 4.976526260375977 - sq_loss: 1.6741403214837192e-06 - tot_loss: 0.19668034587027705 - acc: 0.9360718171926007 - val_acc: 0.9284017645062775\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 4.976719617843628 - sq_loss: 1.6513220089109382e-06 - tot_loss: 0.194136102750754 - acc: 0.9364798694232862 - val_acc: 0.9287410926365796\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 4.9958696365356445 - sq_loss: 1.6360726249331492e-06 - tot_loss: 0.19040889156096874 - acc: 0.9367519042437432 - val_acc: 0.9287410926365796\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 4.891678333282471 - sq_loss: 1.619873842173547e-06 - tot_loss: 0.20318187123430143 - acc: 0.9367519042437432 - val_acc: 0.9290804207668816\n",
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 4.897967576980591 - sq_loss: 1.6044518815760966e-06 - tot_loss: 0.20930877897214373 - acc: 0.9372959738846572 - val_acc: 0.9297590770274856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 4.919192314147949 - sq_loss: 1.587561087035283e-06 - tot_loss: 0.1765225948933562 - acc: 0.9378400435255713 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 4.982091188430786 - sq_loss: 1.5733000964246457e-06 - tot_loss: 0.1783394311001718 - acc: 0.9383841131664853 - val_acc: 0.9311163895486936\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 4.912284851074219 - sq_loss: 1.559342308610212e-06 - tot_loss: 0.19886950794602676 - acc: 0.9389281828073993 - val_acc: 0.9311163895486936\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 4.921783208847046 - sq_loss: 1.5470701555386768e-06 - tot_loss: 0.1986580704706693 - acc: 0.9393362350380848 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 4.974924087524414 - sq_loss: 1.5285953622878878e-06 - tot_loss: 0.1820906056034648 - acc: 0.9396082698585418 - val_acc: 0.9321343739395996\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 4.9469099044799805 - sq_loss: 1.5116245322133182e-06 - tot_loss: 0.19352659791250026 - acc: 0.940424374319913 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 4.933919191360474 - sq_loss: 1.4926689573258045e-06 - tot_loss: 0.19280911550177393 - acc: 0.9405603917301415 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 4.995354890823364 - sq_loss: 1.4755909205632634e-06 - tot_loss: 0.20508876002176812 - acc: 0.940968443960827 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 4.937957525253296 - sq_loss: 1.466424578211445e-06 - tot_loss: 0.1741455414845703 - acc: 0.9413764961915125 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 5.005097150802612 - sq_loss: 1.4588522390113212e-06 - tot_loss: 0.18410519067264453 - acc: 0.941512513601741 - val_acc: 0.9345096708517137\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 5.023723125457764 - sq_loss: 1.447308591195906e-06 - tot_loss: 0.19660667935275278 - acc: 0.9420565832426551 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 4.971909523010254 - sq_loss: 1.432436988579866e-06 - tot_loss: 0.2007989836874664 - acc: 0.9426006528835691 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 4.930344343185425 - sq_loss: 1.422767354597454e-06 - tot_loss: 0.18985249890549483 - acc: 0.9428726877040261 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 4.946086883544922 - sq_loss: 1.4133984223008156e-06 - tot_loss: 0.17503308436549858 - acc: 0.9432807399347116 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 4.95905613899231 - sq_loss: 1.4048150660528336e-06 - tot_loss: 0.17630651432853028 - acc: 0.9435527747551686 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 4.943664789199829 - sq_loss: 1.3963566516395076e-06 - tot_loss: 0.18686399486746552 - acc: 0.9436887921653971 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 4.922376394271851 - sq_loss: 1.3866592780686915e-06 - tot_loss: 0.1890583019411345 - acc: 0.9436887921653971 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 4.908196449279785 - sq_loss: 1.3773609452982782e-06 - tot_loss: 0.16603426408291266 - acc: 0.9440968443960827 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 4.964714765548706 - sq_loss: 1.3700429235541378e-06 - tot_loss: 0.18545095468056516 - acc: 0.9443688792165397 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 4.98958420753479 - sq_loss: 1.3620477830045274e-06 - tot_loss: 0.1936822484025713 - acc: 0.9453210010881393 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 4.86041259765625 - sq_loss: 1.351501509816444e-06 - tot_loss: 0.18792875599502157 - acc: 0.9457290533188248 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 4.872057199478149 - sq_loss: 1.3440711654766346e-06 - tot_loss: 0.18236802519912398 - acc: 0.9460010881392819 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 4.933740615844727 - sq_loss: 1.3342860256670974e-06 - tot_loss: 0.1914833263954714 - acc: 0.9464091403699674 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 4.925237417221069 - sq_loss: 1.3264228755360818e-06 - tot_loss: 0.19413196484390216 - acc: 0.9464091403699674 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 4.918894290924072 - sq_loss: 1.3159116178940167e-06 - tot_loss: 0.18339491207948644 - acc: 0.9466811751904244 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 4.8906779289245605 - sq_loss: 1.3058909189567203e-06 - tot_loss: 0.1693431307394917 - acc: 0.9470892274211099 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 6.273683547973633 - sq_loss: 1.299013888456102e-06 - tot_loss: 0.17999409672310396 - acc: 0.9474972796517954 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 5.24284291267395 - sq_loss: 1.2933558082295349e-06 - tot_loss: 0.17550965946737485 - acc: 0.9476332970620239 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 4.88063907623291 - sq_loss: 1.2870192449554452e-06 - tot_loss: 0.16910754411362117 - acc: 0.948177366702938 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 4.842259645462036 - sq_loss: 1.283160941056849e-06 - tot_loss: 0.1851470532285493 - acc: 0.948721436343852 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 4.875075817108154 - sq_loss: 1.2759555829688907e-06 - tot_loss: 0.1920451675283763 - acc: 0.9495375408052231 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 4.840123891830444 - sq_loss: 1.2708190979537903e-06 - tot_loss: 0.17293008255399211 - acc: 0.9496735582154516 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 4.835535764694214 - sq_loss: 1.2642367437365465e-06 - tot_loss: 0.1939916162502815 - acc: 0.9503536452665942 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 4.989675045013428 - sq_loss: 1.2561572475533467e-06 - tot_loss: 0.19557687989281813 - acc: 0.9508977149075082 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 4.9035484790802 - sq_loss: 1.2470687806853675e-06 - tot_loss: 0.16892126572077348 - acc: 0.9506256800870512 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 4.989603281021118 - sq_loss: 1.2388775303406874e-06 - tot_loss: 0.17008460989877605 - acc: 0.9513057671381937 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 4.870149612426758 - sq_loss: 1.2353485772109707e-06 - tot_loss: 0.17314795807506034 - acc: 0.9508977149075082 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 4.8768463134765625 - sq_loss: 1.2298697811274906e-06 - tot_loss: 0.17889452594157085 - acc: 0.9519858541893362 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 4.99095606803894 - sq_loss: 1.2226047374497284e-06 - tot_loss: 0.18452855353439457 - acc: 0.9523939064200218 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 4.865983724594116 - sq_loss: 1.2169020919827744e-06 - tot_loss: 0.1608239648230141 - acc: 0.9525299238302503 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 4.857662916183472 - sq_loss: 1.2117286587454146e-06 - tot_loss: 0.1786044361627841 - acc: 0.9529379760609358 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 4.873539447784424 - sq_loss: 1.2064188013027888e-06 - tot_loss: 0.1689234301067195 - acc: 0.9530739934711643 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 4.785144090652466 - sq_loss: 1.202527641908091e-06 - tot_loss: 0.16431127263307221 - acc: 0.9536180631120783 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 4.801656246185303 - sq_loss: 1.1992900681434548e-06 - tot_loss: 0.17039600818568523 - acc: 0.9538900979325353 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 4.965849876403809 - sq_loss: 1.1955127092733164e-06 - tot_loss: 0.1778286022318758 - acc: 0.9541621327529923 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 4.993997812271118 - sq_loss: 1.1920402585019474e-06 - tot_loss: 0.17826960330778174 - acc: 0.9542981501632208 - val_acc: 0.9440108585001696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 4.9269185066223145 - sq_loss: 1.185369910672307e-06 - tot_loss: 0.17329752751027172 - acc: 0.9544341675734495 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 4.8708319664001465 - sq_loss: 1.1819175824712147e-06 - tot_loss: 0.18306996391908736 - acc: 0.9544341675734495 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 4.945216417312622 - sq_loss: 1.1775130133173661e-06 - tot_loss: 0.17545733606416203 - acc: 0.9549782372143635 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 4.981777906417847 - sq_loss: 1.1721227792804711e-06 - tot_loss: 0.17514664962708437 - acc: 0.954842219804135 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 4.918649196624756 - sq_loss: 1.1643514881143346e-06 - tot_loss: 0.1744453083279538 - acc: 0.955386289445049 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 4.914364814758301 - sq_loss: 1.1588015240704408e-06 - tot_loss: 0.16732628734941457 - acc: 0.955658324265506 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 4.883793115615845 - sq_loss: 1.1543454547791043e-06 - tot_loss: 0.18496291634444617 - acc: 0.95620239390642 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 4.8893883228302 - sq_loss: 1.1493712008814327e-06 - tot_loss: 0.1879675953312807 - acc: 0.956474428726877 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 4.865317106246948 - sq_loss: 1.1468904403955094e-06 - tot_loss: 0.1682476250929108 - acc: 0.9566104461371056 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 4.826388835906982 - sq_loss: 1.1433892268541967e-06 - tot_loss: 0.1582663000313147 - acc: 0.9568824809575626 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 4.979949712753296 - sq_loss: 1.1394930652386392e-06 - tot_loss: 0.18396409665012214 - acc: 0.9572905331882481 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 4.982964515686035 - sq_loss: 1.1362903933331836e-06 - tot_loss: 0.1627168965781287 - acc: 0.9578346028291621 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 5.534360647201538 - sq_loss: 1.1324509614496492e-06 - tot_loss: 0.16461097469746555 - acc: 0.9582426550598476 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 6.197961330413818 - sq_loss: 1.1287495453871088e-06 - tot_loss: 0.17652776645277246 - acc: 0.9582426550598476 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 5.367053985595703 - sq_loss: 1.1255222034378676e-06 - tot_loss: 0.18425944054890575 - acc: 0.9582426550598476 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 5.15601372718811 - sq_loss: 1.1204455176994088e-06 - tot_loss: 0.1670125731058012 - acc: 0.9585146898803046 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 5.101229429244995 - sq_loss: 1.115739223678247e-06 - tot_loss: 0.17817669959622373 - acc: 0.9589227421109902 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 5.162531614303589 - sq_loss: 1.112599647967727e-06 - tot_loss: 0.19358561298879806 - acc: 0.9590587595212187 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 5.062472343444824 - sq_loss: 1.1102966936960001e-06 - tot_loss: 0.18061264702281887 - acc: 0.9594668117519043 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 5.250925779342651 - sq_loss: 1.1065202443205635e-06 - tot_loss: 0.166398892733151 - acc: 0.9605549510337323 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 5.17294716835022 - sq_loss: 1.104023226616846e-06 - tot_loss: 0.17057586777946998 - acc: 0.9604189336235038 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 5.160648584365845 - sq_loss: 1.0998949164786609e-06 - tot_loss: 0.17105569386422959 - acc: 0.9606909684439608 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 5.071991682052612 - sq_loss: 1.0946041584247723e-06 - tot_loss: 0.18320072903456586 - acc: 0.9610990206746464 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 5.027716875076294 - sq_loss: 1.0913918231381103e-06 - tot_loss: 0.17510461254757592 - acc: 0.9613710554951034 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 5.068734645843506 - sq_loss: 1.0878106877498794e-06 - tot_loss: 0.18044510735019692 - acc: 0.9616430903155604 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 5.12876033782959 - sq_loss: 1.0832503676283523e-06 - tot_loss: 0.17677575132682133 - acc: 0.9619151251360174 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 5.175649642944336 - sq_loss: 1.0799378742376575e-06 - tot_loss: 0.16928798230987985 - acc: 0.9620511425462459 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 5.0360331535339355 - sq_loss: 1.0756331221273285e-06 - tot_loss: 0.157270797390193 - acc: 0.9621871599564744 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 5.012734651565552 - sq_loss: 1.0725277661549626e-06 - tot_loss: 0.17107872712797612 - acc: 0.9624591947769314 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 5.0116753578186035 - sq_loss: 1.0690848739614012e-06 - tot_loss: 0.1773069787500785 - acc: 0.9625952121871599 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 5.117010116577148 - sq_loss: 1.0671334393919096e-06 - tot_loss: 0.17631581830690513 - acc: 0.9627312295973884 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 5.271753549575806 - sq_loss: 1.0630981250869809e-06 - tot_loss: 0.17357871343669196 - acc: 0.9628672470076169 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 5.318188428878784 - sq_loss: 1.0608566753944615e-06 - tot_loss: 0.15288756893720645 - acc: 0.9628672470076169 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 5.04994797706604 - sq_loss: 1.0569503956503468e-06 - tot_loss: 0.17050839998506273 - acc: 0.963139281828074 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 5.129277467727661 - sq_loss: 1.0547252031756216e-06 - tot_loss: 0.17124776332097102 - acc: 0.9630032644178455 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 5.054102897644043 - sq_loss: 1.0525568541197572e-06 - tot_loss: 0.17940580514696425 - acc: 0.9630032644178455 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 5.32723331451416 - sq_loss: 1.0498679330339655e-06 - tot_loss: 0.16869400652264277 - acc: 0.9632752992383025 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 5.216927766799927 - sq_loss: 1.045910494212876e-06 - tot_loss: 0.16616464344211268 - acc: 0.963683351468988 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 5.26226282119751 - sq_loss: 1.042372673509817e-06 - tot_loss: 0.17535292300061256 - acc: 0.963683351468988 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 5.248426914215088 - sq_loss: 1.038530285768502e-06 - tot_loss: 0.15855185978878783 - acc: 0.9638193688792165 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 4.917944669723511 - sq_loss: 1.0358415920563857e-06 - tot_loss: 0.18476591009348464 - acc: 0.9642274211099021 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 4.936495304107666 - sq_loss: 1.0317099849999067e-06 - tot_loss: 0.16446456302278234 - acc: 0.9638193688792165 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 4.937982559204102 - sq_loss: 1.0300899475623737e-06 - tot_loss: 0.1599030455520789 - acc: 0.9640914036996736 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 5.12313175201416 - sq_loss: 1.0272179906678502e-06 - tot_loss: 0.16471615118650362 - acc: 0.9650435255712732 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 5.2352728843688965 - sq_loss: 1.0246596957586007e-06 - tot_loss: 0.17295663017364538 - acc: 0.9649075081610446 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 5.061160087585449 - sq_loss: 1.0225269306829432e-06 - tot_loss: 0.16651975839925903 - acc: 0.9650435255712732 - val_acc: 0.9511367492365117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 5.111647129058838 - sq_loss: 1.020293552755902e-06 - tot_loss: 0.17350502224195274 - acc: 0.9650435255712732 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 5.02737283706665 - sq_loss: 1.0188218766415957e-06 - tot_loss: 0.16230862049734895 - acc: 0.9657236126224157 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 5.110271453857422 - sq_loss: 1.0158923942071851e-06 - tot_loss: 0.16477605197448764 - acc: 0.9655875952121872 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 5.021154165267944 - sq_loss: 1.0140723816220998e-06 - tot_loss: 0.17295974010695447 - acc: 0.9659956474428727 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 5.177645206451416 - sq_loss: 1.0125756944034947e-06 - tot_loss: 0.17369816573429508 - acc: 0.9659956474428727 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 5.02069354057312 - sq_loss: 1.0108361720995163e-06 - tot_loss: 0.16037505707663602 - acc: 0.9661316648531012 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 5.022022008895874 - sq_loss: 1.008598360385804e-06 - tot_loss: 0.17762458394837255 - acc: 0.9662676822633297 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 5.01863956451416 - sq_loss: 1.0064348998639616e-06 - tot_loss: 0.1726441163580863 - acc: 0.9661316648531012 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 5.213779449462891 - sq_loss: 1.0038099844678072e-06 - tot_loss: 0.1667244325957835 - acc: 0.9662676822633297 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 4.955238103866577 - sq_loss: 1.0010753612732515e-06 - tot_loss: 0.1772930035529683 - acc: 0.9662676822633297 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 5.183923721313477 - sq_loss: 9.981839639294776e-07 - tot_loss: 0.16693124073273635 - acc: 0.9664036996735582 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 5.108544826507568 - sq_loss: 9.963177944882773e-07 - tot_loss: 0.15194607696423468 - acc: 0.9665397170837867 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 5.092184782028198 - sq_loss: 9.946913905878318e-07 - tot_loss: 0.18493606687661002 - acc: 0.9666757344940152 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 5.070911169052124 - sq_loss: 9.922019899022416e-07 - tot_loss: 0.17823852631310988 - acc: 0.9670837867247007 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 5.101628303527832 - sq_loss: 9.890969749903888e-07 - tot_loss: 0.1767752836538059 - acc: 0.9674918389553863 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 5.003996849060059 - sq_loss: 9.869160066955374e-07 - tot_loss: 0.16664005315876773 - acc: 0.9676278563656148 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 5.2363364696502686 - sq_loss: 9.849411526374752e-07 - tot_loss: 0.18370110934918316 - acc: 0.9678998911860718 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 5.131785869598389 - sq_loss: 9.812043799684034e-07 - tot_loss: 0.17763122267793197 - acc: 0.9676278563656148 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 5.0696120262146 - sq_loss: 9.78940875029366e-07 - tot_loss: 0.1531928539946441 - acc: 0.9677638737758433 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 5.007478713989258 - sq_loss: 9.77130071078136e-07 - tot_loss: 0.18496216794698217 - acc: 0.9683079434167573 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 5.048328638076782 - sq_loss: 9.73589862951485e-07 - tot_loss: 0.1873888322747792 - acc: 0.9680359085963003 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 5.122356653213501 - sq_loss: 9.718173714645673e-07 - tot_loss: 0.1568293720966354 - acc: 0.9681719260065288 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 5.151797533035278 - sq_loss: 9.68664380707196e-07 - tot_loss: 0.14438607782330237 - acc: 0.9687159956474428 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 5.095425128936768 - sq_loss: 9.662021511758212e-07 - tot_loss: 0.16588236024598535 - acc: 0.9691240478781284 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 5.088571548461914 - sq_loss: 9.639705922381836e-07 - tot_loss: 0.16509311762747725 - acc: 0.9688520130576714 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 5.0235514640808105 - sq_loss: 9.61534396992647e-07 - tot_loss: 0.1655063649229902 - acc: 0.9693960826985855 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 4.995590925216675 - sq_loss: 9.591477692083572e-07 - tot_loss: 0.1628150572257021 - acc: 0.9693960826985855 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 5.223987102508545 - sq_loss: 9.565495702190674e-07 - tot_loss: 0.18716992011157751 - acc: 0.9696681175190425 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 5.2338173389434814 - sq_loss: 9.544038448439096e-07 - tot_loss: 0.1693742244344869 - acc: 0.9699401523394995 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 5.1621479988098145 - sq_loss: 9.522161690256326e-07 - tot_loss: 0.1640022853802403 - acc: 0.9702121871599565 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 5.141419410705566 - sq_loss: 9.490327101957519e-07 - tot_loss: 0.17406622511947756 - acc: 0.9699401523394995 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 5.091161251068115 - sq_loss: 9.471713156017358e-07 - tot_loss: 0.1697488713495625 - acc: 0.9702121871599565 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 5.069849967956543 - sq_loss: 9.454920473217499e-07 - tot_loss: 0.15075833516324 - acc: 0.969804134929271 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 5.144946098327637 - sq_loss: 9.435047445549571e-07 - tot_loss: 0.15639336094823664 - acc: 0.9696681175190425 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 5.162877321243286 - sq_loss: 9.41179052915686e-07 - tot_loss: 0.17985444318554977 - acc: 0.9699401523394995 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 5.115257978439331 - sq_loss: 9.386233728037041e-07 - tot_loss: 0.17975558115889134 - acc: 0.9699401523394995 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 5.0165112018585205 - sq_loss: 9.372509452987288e-07 - tot_loss: 0.16898008597214664 - acc: 0.9699401523394995 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 5.024648904800415 - sq_loss: 9.354174608233734e-07 - tot_loss: 0.18329016041908996 - acc: 0.970348204570185 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 5.206284999847412 - sq_loss: 9.330286161457479e-07 - tot_loss: 0.1686685099113876 - acc: 0.970348204570185 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 5.244670152664185 - sq_loss: 9.312195174970839e-07 - tot_loss: 0.17999190112608643 - acc: 0.970892274211099 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 5.267510890960693 - sq_loss: 9.28804297473107e-07 - tot_loss: 0.15238816814849887 - acc: 0.9707562568008705 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 5.226340293884277 - sq_loss: 9.255699637833459e-07 - tot_loss: 0.1726320221500086 - acc: 0.970892274211099 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 5.2099597454071045 - sq_loss: 9.227912300957541e-07 - tot_loss: 0.16383549499049366 - acc: 0.9707562568008705 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 5.186010360717773 - sq_loss: 9.225178132510337e-07 - tot_loss: 0.15475456184253344 - acc: 0.9707562568008705 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 5.320871353149414 - sq_loss: 9.217223464474955e-07 - tot_loss: 0.15843087354595697 - acc: 0.9710282916213275 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 5.252213954925537 - sq_loss: 9.189714660351456e-07 - tot_loss: 0.16912571100443552 - acc: 0.970892274211099 - val_acc: 0.9555480149304377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 5.263864994049072 - sq_loss: 9.166729455500899e-07 - tot_loss: 0.167252171435452 - acc: 0.970892274211099 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 5.247008562088013 - sq_loss: 9.147104265139205e-07 - tot_loss: 0.16791938951045893 - acc: 0.970892274211099 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 5.026521444320679 - sq_loss: 9.137548317994515e-07 - tot_loss: 0.1664187764132916 - acc: 0.9710282916213275 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 5.131076812744141 - sq_loss: 9.114557428802073e-07 - tot_loss: 0.16682159610895697 - acc: 0.971164309031556 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 5.078932523727417 - sq_loss: 9.098445730160165e-07 - tot_loss: 0.15990818809534657 - acc: 0.971164309031556 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 5.440105438232422 - sq_loss: 9.0811244035649e-07 - tot_loss: 0.1796168558951119 - acc: 0.971164309031556 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 5.1667351722717285 - sq_loss: 9.055863756657345e-07 - tot_loss: 0.1904060306269999 - acc: 0.971164309031556 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 5.07260274887085 - sq_loss: 9.034851586875448e-07 - tot_loss: 0.15999507751340292 - acc: 0.9713003264417845 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 5.043759822845459 - sq_loss: 9.030405863086344e-07 - tot_loss: 0.16576420303250927 - acc: 0.9715723612622416 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 5.24923849105835 - sq_loss: 9.012307486955251e-07 - tot_loss: 0.18819017093023827 - acc: 0.9713003264417845 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 5.2096168994903564 - sq_loss: 8.979185963653435e-07 - tot_loss: 0.17268901326147978 - acc: 0.9715723612622416 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 5.372737169265747 - sq_loss: 8.960050195128133e-07 - tot_loss: 0.16625268566616924 - acc: 0.9717083786724701 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 5.261276483535767 - sq_loss: 8.948013601184357e-07 - tot_loss: 0.18299915337620098 - acc: 0.9718443960826986 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 5.198213577270508 - sq_loss: 8.931278330237546e-07 - tot_loss: 0.16985488672290172 - acc: 0.9719804134929271 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 5.168909072875977 - sq_loss: 8.910340625334356e-07 - tot_loss: 0.16118250518129873 - acc: 0.9719804134929271 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 5.2400288581848145 - sq_loss: 8.89519242264214e-07 - tot_loss: 0.186054529530425 - acc: 0.9721164309031556 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 5.073858022689819 - sq_loss: 8.885507440936635e-07 - tot_loss: 0.1487468713273643 - acc: 0.9722524483133841 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 5.475119352340698 - sq_loss: 8.863157177074754e-07 - tot_loss: 0.1886394093014523 - acc: 0.9722524483133841 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 5.203726768493652 - sq_loss: 8.847948151924356e-07 - tot_loss: 0.15551658760699238 - acc: 0.9723884657236126 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 5.190183401107788 - sq_loss: 8.831481181914569e-07 - tot_loss: 0.1710375225665821 - acc: 0.9727965179542981 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 5.00402045249939 - sq_loss: 8.815799787953438e-07 - tot_loss: 0.18452392377285065 - acc: 0.9730685527747551 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 5.1918628215789795 - sq_loss: 8.791468530944258e-07 - tot_loss: 0.16340647901492722 - acc: 0.9730685527747551 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 5.096764802932739 - sq_loss: 8.783293878877885e-07 - tot_loss: 0.16449795833066516 - acc: 0.9733405875952121 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 5.053940057754517 - sq_loss: 8.757008913562458e-07 - tot_loss: 0.1833366874521758 - acc: 0.9734766050054406 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 5.06553840637207 - sq_loss: 8.734350558370352e-07 - tot_loss: 0.1673278769053539 - acc: 0.9736126224156693 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 5.040008306503296 - sq_loss: 8.709138796803018e-07 - tot_loss: 0.15949495532699176 - acc: 0.9736126224156693 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 5.222968578338623 - sq_loss: 8.688062962391996e-07 - tot_loss: 0.18015849995665678 - acc: 0.9736126224156693 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 5.0680224895477295 - sq_loss: 8.673587217344902e-07 - tot_loss: 0.16163117463334253 - acc: 0.9736126224156693 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 5.175570011138916 - sq_loss: 8.657165722070204e-07 - tot_loss: 0.16455102295802915 - acc: 0.9733405875952121 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 5.102921485900879 - sq_loss: 8.63795264649525e-07 - tot_loss: 0.17896557041883443 - acc: 0.9737486398258978 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 5.125815153121948 - sq_loss: 8.618212063993269e-07 - tot_loss: 0.1538268429219194 - acc: 0.9733405875952121 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 5.07591438293457 - sq_loss: 8.596812790528929e-07 - tot_loss: 0.16244520321537292 - acc: 0.9734766050054406 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 5.127596616744995 - sq_loss: 8.578820143156918e-07 - tot_loss: 0.17006264252063352 - acc: 0.9736126224156693 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 5.001880884170532 - sq_loss: 8.562269613321405e-07 - tot_loss: 0.17940170987545967 - acc: 0.9736126224156693 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 5.201540946960449 - sq_loss: 8.541472311662801e-07 - tot_loss: 0.1648812888459663 - acc: 0.9738846572361263 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 5.1469886302948 - sq_loss: 8.523258543391421e-07 - tot_loss: 0.17432900059137135 - acc: 0.9740206746463548 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 5.193711280822754 - sq_loss: 8.503986919095041e-07 - tot_loss: 0.16753212483658442 - acc: 0.9742927094668118 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 4.988830327987671 - sq_loss: 8.496328973706113e-07 - tot_loss: 0.18734064025895436 - acc: 0.9741566920565833 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 5.083541393280029 - sq_loss: 8.468661008009803e-07 - tot_loss: 0.18395336904430737 - acc: 0.9741566920565833 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 5.122108459472656 - sq_loss: 8.464522238682548e-07 - tot_loss: 0.1767600727672627 - acc: 0.9744287268770403 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 5.231935977935791 - sq_loss: 8.460855269731837e-07 - tot_loss: 0.17011231324395037 - acc: 0.9745647442872688 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 4.99357795715332 - sq_loss: 8.450061272924358e-07 - tot_loss: 0.17157700348864702 - acc: 0.9745647442872688 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 5.0812599658966064 - sq_loss: 8.442096373073582e-07 - tot_loss: 0.16637742112876253 - acc: 0.9744287268770403 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 5.1072609424591064 - sq_loss: 8.421616257692222e-07 - tot_loss: 0.15837805879056766 - acc: 0.9745647442872688 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 5.019804239273071 - sq_loss: 8.407686777900381e-07 - tot_loss: 0.16698594497610442 - acc: 0.9745647442872688 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 5.149840593338013 - sq_loss: 8.395551276407787e-07 - tot_loss: 0.167537572900877 - acc: 0.9745647442872688 - val_acc: 0.9572446555819477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 5.113956451416016 - sq_loss: 8.37725451674487e-07 - tot_loss: 0.16857618684724307 - acc: 0.9749727965179543 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 5.288428544998169 - sq_loss: 8.362300718545157e-07 - tot_loss: 0.16341633833931635 - acc: 0.9747007616974973 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 5.105812311172485 - sq_loss: 8.341810371348402e-07 - tot_loss: 0.1642130994766724 - acc: 0.9749727965179543 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 5.209012746810913 - sq_loss: 8.330495120389969e-07 - tot_loss: 0.17089215823184922 - acc: 0.9749727965179543 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 5.090527296066284 - sq_loss: 8.317161928061978e-07 - tot_loss: 0.18074776977764961 - acc: 0.9751088139281828 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 5.128396272659302 - sq_loss: 8.307885650538083e-07 - tot_loss: 0.14903097883732497 - acc: 0.9752448313384113 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 5.151601552963257 - sq_loss: 8.29328712370625e-07 - tot_loss: 0.18249824473802279 - acc: 0.9755168661588683 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 5.1258673667907715 - sq_loss: 8.271074420918012e-07 - tot_loss: 0.17456877328322418 - acc: 0.9751088139281828 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 5.147262811660767 - sq_loss: 8.259441983682336e-07 - tot_loss: 0.17196436617259026 - acc: 0.9755168661588683 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 5.117078542709351 - sq_loss: 8.241455020652211e-07 - tot_loss: 0.16730865329889122 - acc: 0.9755168661588683 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 5.059837818145752 - sq_loss: 8.219996061598067e-07 - tot_loss: 0.15612970834190576 - acc: 0.9755168661588683 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 5.030528545379639 - sq_loss: 8.197744136850815e-07 - tot_loss: 0.14167384107140601 - acc: 0.9755168661588683 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 5.216561555862427 - sq_loss: 8.187776643353573e-07 - tot_loss: 0.18557736091514054 - acc: 0.9755168661588683 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 5.102534770965576 - sq_loss: 8.174558843165869e-07 - tot_loss: 0.15970057360805012 - acc: 0.9755168661588683 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 5.02229905128479 - sq_loss: 8.15969315226539e-07 - tot_loss: 0.1633224852972277 - acc: 0.9757889009793254 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 5.0396013259887695 - sq_loss: 8.149939390023064e-07 - tot_loss: 0.15839525206219984 - acc: 0.9759249183895539 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 5.033925771713257 - sq_loss: 8.142848741954367e-07 - tot_loss: 0.16274529969556073 - acc: 0.9759249183895539 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 5.034037828445435 - sq_loss: 8.141460057231598e-07 - tot_loss: 0.18515524798606542 - acc: 0.9759249183895539 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 5.149667501449585 - sq_loss: 8.126057196022884e-07 - tot_loss: 0.1808340961236894 - acc: 0.9763329706202394 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 5.191220760345459 - sq_loss: 8.109745408546587e-07 - tot_loss: 0.18106451448203642 - acc: 0.9766050054406964 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 5.022217273712158 - sq_loss: 8.099789283733116e-07 - tot_loss: 0.15246885186899317 - acc: 0.9763329706202394 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 5.085314512252808 - sq_loss: 8.097979957710777e-07 - tot_loss: 0.17426426659392846 - acc: 0.9764689880304679 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 5.030083417892456 - sq_loss: 8.081964324446744e-07 - tot_loss: 0.1628724031764175 - acc: 0.9761969532100109 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 5.043874740600586 - sq_loss: 8.064347980507591e-07 - tot_loss: 0.16584027788546774 - acc: 0.9761969532100109 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 5.052126407623291 - sq_loss: 8.044445962696045e-07 - tot_loss: 0.17622767199698242 - acc: 0.9766050054406964 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 5.075152635574341 - sq_loss: 8.018174639801146e-07 - tot_loss: 0.17246330042221336 - acc: 0.9768770402611534 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 5.200307369232178 - sq_loss: 7.995421356099541e-07 - tot_loss: 0.17636608576367419 - acc: 0.9770130576713819 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 5.092103958129883 - sq_loss: 7.976491929184704e-07 - tot_loss: 0.1591460654496546 - acc: 0.9770130576713819 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 4.981179714202881 - sq_loss: 7.953104272928613e-07 - tot_loss: 0.16119494715440208 - acc: 0.9767410228509249 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 4.990303993225098 - sq_loss: 7.932213179628889e-07 - tot_loss: 0.15439935935600113 - acc: 0.9768770402611534 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 5.102869510650635 - sq_loss: 7.920310167719435e-07 - tot_loss: 0.1738150643208103 - acc: 0.9768770402611534 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 5.096055269241333 - sq_loss: 7.916693220977322e-07 - tot_loss: 0.15090322006513568 - acc: 0.9768770402611534 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 4.3545215129852295 - sq_loss: 7.908352586127876e-07 - tot_loss: 0.16779107996507503 - acc: 0.9772850924918389 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 3.2436509132385254 - sq_loss: 7.898939884398715e-07 - tot_loss: 0.17785644261310707 - acc: 0.9772850924918389 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 3.210636615753174 - sq_loss: 7.888468189776177e-07 - tot_loss: 0.1893476962942 - acc: 0.9772850924918389 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 3.2802846431732178 - sq_loss: 7.871377647461486e-07 - tot_loss: 0.17487610047874602 - acc: 0.9772850924918389 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 3.212306022644043 - sq_loss: 7.856342563172802e-07 - tot_loss: 0.17429219826719589 - acc: 0.9772850924918389 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 3.241196393966675 - sq_loss: 7.842440368222015e-07 - tot_loss: 0.15959910695349966 - acc: 0.9772850924918389 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 3.174656629562378 - sq_loss: 7.832381925254595e-07 - tot_loss: 0.16671467358661474 - acc: 0.9775571273122959 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 3.2354519367218018 - sq_loss: 7.824402246114914e-07 - tot_loss: 0.1777246942279458 - acc: 0.9775571273122959 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 3.2264842987060547 - sq_loss: 7.807858537489665e-07 - tot_loss: 0.16154865776160632 - acc: 0.9774211099020674 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 3.1945958137512207 - sq_loss: 7.788177072143299e-07 - tot_loss: 0.1572555368054982 - acc: 0.9775571273122959 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 3.209266185760498 - sq_loss: 7.776637858114555e-07 - tot_loss: 0.16163661539090435 - acc: 0.9775571273122959 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 3.1585824489593506 - sq_loss: 7.752419151074719e-07 - tot_loss: 0.16441623639133618 - acc: 0.977829162132753 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 3.2969040870666504 - sq_loss: 7.741764989077637e-07 - tot_loss: 0.16925209445495515 - acc: 0.9775571273122959 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 3.136085033416748 - sq_loss: 7.726568469479389e-07 - tot_loss: 0.1666213203365552 - acc: 0.9774211099020674 - val_acc: 0.9575839837122497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 3.291700601577759 - sq_loss: 7.717801508988487e-07 - tot_loss: 0.17616846225405491 - acc: 0.9774211099020674 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 3.157927989959717 - sq_loss: 7.703470714659488e-07 - tot_loss: 0.16468562000442089 - acc: 0.9775571273122959 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 3.11499285697937 - sq_loss: 7.685841865168186e-07 - tot_loss: 0.15309146422807407 - acc: 0.9774211099020674 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 3.2452609539031982 - sq_loss: 7.66191703860386e-07 - tot_loss: 0.1459701050178177 - acc: 0.9774211099020674 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 3.263324022293091 - sq_loss: 7.653923148609465e-07 - tot_loss: 0.1794693317551932 - acc: 0.977829162132753 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 3.20737624168396 - sq_loss: 7.637536327820271e-07 - tot_loss: 0.1719583380838925 - acc: 0.977829162132753 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 3.2715952396392822 - sq_loss: 7.62424406275386e-07 - tot_loss: 0.17403248751164324 - acc: 0.977829162132753 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 3.1734230518341064 - sq_loss: 7.606666372339532e-07 - tot_loss: 0.1934487495548738 - acc: 0.977829162132753 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 3.211134433746338 - sq_loss: 7.591301027787267e-07 - tot_loss: 0.16805117434545802 - acc: 0.977829162132753 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 3.133647918701172 - sq_loss: 7.586731385345047e-07 - tot_loss: 0.16590446958463634 - acc: 0.977829162132753 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 3.1587607860565186 - sq_loss: 7.581467684758536e-07 - tot_loss: 0.17257046389781916 - acc: 0.9779651795429815 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 3.15412974357605 - sq_loss: 7.574040523650183e-07 - tot_loss: 0.16980154447106166 - acc: 0.977829162132753 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 3.205003261566162 - sq_loss: 7.564158295281231e-07 - tot_loss: 0.17665937301249168 - acc: 0.97810119695321 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 3.294999837875366 - sq_loss: 7.560396397821023e-07 - tot_loss: 0.17233633775084334 - acc: 0.97810119695321 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 3.148244857788086 - sq_loss: 7.550634677500057e-07 - tot_loss: 0.18221615853388595 - acc: 0.97810119695321 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 3.1678719520568848 - sq_loss: 7.534537758147053e-07 - tot_loss: 0.17972587147065244 - acc: 0.97810119695321 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 3.268247127532959 - sq_loss: 7.529660592808796e-07 - tot_loss: 0.17770795559133212 - acc: 0.9783732317736671 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 3.1868786811828613 - sq_loss: 7.527283969466225e-07 - tot_loss: 0.16392381226830444 - acc: 0.9782372143634385 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 3.172927141189575 - sq_loss: 7.52514608848287e-07 - tot_loss: 0.16154027867793008 - acc: 0.9785092491838956 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 3.1933226585388184 - sq_loss: 7.52015182570176e-07 - tot_loss: 0.1724337868772785 - acc: 0.9785092491838956 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 3.180983543395996 - sq_loss: 7.505145731556695e-07 - tot_loss: 0.17352863492534776 - acc: 0.9786452665941241 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 3.110441207885742 - sq_loss: 7.48482648305071e-07 - tot_loss: 0.16429177617516766 - acc: 0.9786452665941241 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 3.197720527648926 - sq_loss: 7.47048829907726e-07 - tot_loss: 0.16739822232088564 - acc: 0.9785092491838956 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 3.2010529041290283 - sq_loss: 7.455988679794245e-07 - tot_loss: 0.16815782195641082 - acc: 0.9785092491838956 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 3.1836891174316406 - sq_loss: 7.4489952339718e-07 - tot_loss: 0.16361456811624087 - acc: 0.9786452665941241 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 3.191324472427368 - sq_loss: 7.442484388775483e-07 - tot_loss: 0.18023783243300207 - acc: 0.9786452665941241 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 3.141397714614868 - sq_loss: 7.433190489791741e-07 - tot_loss: 0.18860441744141587 - acc: 0.9787812840043526 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 3.2050840854644775 - sq_loss: 7.430913342432177e-07 - tot_loss: 0.18656271497600319 - acc: 0.9789173014145811 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 3.177356719970703 - sq_loss: 7.413797220578999e-07 - tot_loss: 0.17213854221981983 - acc: 0.9789173014145811 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 3.0842630863189697 - sq_loss: 7.402265964628896e-07 - tot_loss: 0.17529054481201278 - acc: 0.9789173014145811 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 3.119762659072876 - sq_loss: 7.384031164292537e-07 - tot_loss: 0.17594783498482425 - acc: 0.9791893362350381 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 3.204967737197876 - sq_loss: 7.366953127529996e-07 - tot_loss: 0.1531620091594359 - acc: 0.9791893362350381 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 3.0838098526000977 - sq_loss: 7.348066333179304e-07 - tot_loss: 0.16259681206649867 - acc: 0.9793253536452666 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 3.1775388717651367 - sq_loss: 7.337609986279858e-07 - tot_loss: 0.16205213606661828 - acc: 0.9793253536452666 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 3.155024766921997 - sq_loss: 7.337097258641734e-07 - tot_loss: 0.17029226420058063 - acc: 0.9793253536452666 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 3.1743075847625732 - sq_loss: 7.331204301408434e-07 - tot_loss: 0.1718503328595209 - acc: 0.9790533188248096 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 3.112765073776245 - sq_loss: 7.329271625167166e-07 - tot_loss: 0.16826090291242313 - acc: 0.9793253536452666 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 3.133420705795288 - sq_loss: 7.319416113205079e-07 - tot_loss: 0.2007136433884964 - acc: 0.9794613710554951 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 3.298866033554077 - sq_loss: 7.309691341106372e-07 - tot_loss: 0.19531870157766917 - acc: 0.9793253536452666 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 3.153709650039673 - sq_loss: 7.303413553927385e-07 - tot_loss: 0.18478088800857084 - acc: 0.9793253536452666 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 3.0690290927886963 - sq_loss: 7.277539566530322e-07 - tot_loss: 0.18441511064307536 - acc: 0.9793253536452666 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 3.118377447128296 - sq_loss: 7.258812502186629e-07 - tot_loss: 0.18182790148747974 - acc: 0.9794613710554951 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 3.153003692626953 - sq_loss: 7.241242769850942e-07 - tot_loss: 0.1765765014511591 - acc: 0.9794613710554951 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 3.1319942474365234 - sq_loss: 7.236042733893555e-07 - tot_loss: 0.176224773581102 - acc: 0.9794613710554951 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 3.2256832122802734 - sq_loss: 7.226071829791181e-07 - tot_loss: 0.16460185813513206 - acc: 0.9795973884657236 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 3.266357660293579 - sq_loss: 7.218168889266963e-07 - tot_loss: 0.1806272265086708 - acc: 0.9795973884657236 - val_acc: 0.9569053274516457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 3.237839698791504 - sq_loss: 7.203234986263851e-07 - tot_loss: 0.17510379877539806 - acc: 0.9795973884657236 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 3.2346651554107666 - sq_loss: 7.194009867816931e-07 - tot_loss: 0.16665092495099754 - acc: 0.9797334058759521 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 3.1749985218048096 - sq_loss: 7.181292858149391e-07 - tot_loss: 0.17754608253861992 - acc: 0.9795973884657236 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 3.1216328144073486 - sq_loss: 7.173279072958394e-07 - tot_loss: 0.18008419872700188 - acc: 0.9797334058759521 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 3.1592862606048584 - sq_loss: 7.15594069333747e-07 - tot_loss: 0.17246394114743246 - acc: 0.9797334058759521 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 3.1741292476654053 - sq_loss: 7.148009331103822e-07 - tot_loss: 0.17720333291113977 - acc: 0.9797334058759521 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 3.152935266494751 - sq_loss: 7.126119498934713e-07 - tot_loss: 0.18237143549805102 - acc: 0.9795973884657236 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 3.2129571437835693 - sq_loss: 7.107358896973892e-07 - tot_loss: 0.19183837095798761 - acc: 0.9800054406964092 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 3.200007438659668 - sq_loss: 7.098782361936173e-07 - tot_loss: 0.186386557479149 - acc: 0.9797334058759521 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 3.2543654441833496 - sq_loss: 7.094072316249367e-07 - tot_loss: 0.18124189302352112 - acc: 0.9798694232861807 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 3.2051854133605957 - sq_loss: 7.087580797815463e-07 - tot_loss: 0.15402075120217695 - acc: 0.9798694232861807 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 3.3225226402282715 - sq_loss: 7.085109245963395e-07 - tot_loss: 0.17611355495474812 - acc: 0.9800054406964092 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 3.242389678955078 - sq_loss: 7.076436077113613e-07 - tot_loss: 0.1607822604545177 - acc: 0.9800054406964092 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 3.264449119567871 - sq_loss: 7.065250997584371e-07 - tot_loss: 0.16126413107038862 - acc: 0.9800054406964092 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 3.1953017711639404 - sq_loss: 7.056187882881204e-07 - tot_loss: 0.17635465571304798 - acc: 0.9801414581066377 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 3.290585517883301 - sq_loss: 7.037100431261933e-07 - tot_loss: 0.18334667410379524 - acc: 0.9801414581066377 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 3.1897940635681152 - sq_loss: 7.026619641692378e-07 - tot_loss: 0.1620101400443772 - acc: 0.9801414581066377 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 3.1937787532806396 - sq_loss: 7.025275863270508e-07 - tot_loss: 0.1758553425842171 - acc: 0.9801414581066377 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 3.2351746559143066 - sq_loss: 7.019652912276797e-07 - tot_loss: 0.1762581877489775 - acc: 0.9801414581066377 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 3.239258050918579 - sq_loss: 7.005880320321012e-07 - tot_loss: 0.19028698367166563 - acc: 0.9801414581066377 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 3.288295030593872 - sq_loss: 6.988482255110284e-07 - tot_loss: 0.20373410018872384 - acc: 0.9801414581066377 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 3.258118152618408 - sq_loss: 6.979295790188189e-07 - tot_loss: 0.15198381617899237 - acc: 0.9801414581066377 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 3.2339816093444824 - sq_loss: 6.97069879151968e-07 - tot_loss: 0.16888908252587997 - acc: 0.9801414581066377 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 3.2677791118621826 - sq_loss: 6.96242523190449e-07 - tot_loss: 0.1798149942475955 - acc: 0.9802774755168662 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 3.160149097442627 - sq_loss: 6.9494711851803e-07 - tot_loss: 0.17788730807341668 - acc: 0.9801414581066377 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 3.2458486557006836 - sq_loss: 6.936631393728021e-07 - tot_loss: 0.2030048201122876 - acc: 0.9802774755168662 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 3.213111639022827 - sq_loss: 6.932265250725322e-07 - tot_loss: 0.16423200627642598 - acc: 0.9802774755168662 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 3.2137842178344727 - sq_loss: 6.924802846697276e-07 - tot_loss: 0.18107740135117623 - acc: 0.9804134929270947 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 3.275665521621704 - sq_loss: 6.913211905157368e-07 - tot_loss: 0.1781233831019331 - acc: 0.9804134929270947 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 3.2749545574188232 - sq_loss: 6.902523068674782e-07 - tot_loss: 0.1618360006091002 - acc: 0.9804134929270947 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 3.2696871757507324 - sq_loss: 6.896310082993296e-07 - tot_loss: 0.1716447871907847 - acc: 0.9805495103373232 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 3.236677408218384 - sq_loss: 6.886849064358103e-07 - tot_loss: 0.17950055078945537 - acc: 0.9804134929270947 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 3.2172741889953613 - sq_loss: 6.874445830362674e-07 - tot_loss: 0.1751988724047333 - acc: 0.9804134929270947 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 3.268584966659546 - sq_loss: 6.866856665510568e-07 - tot_loss: 0.17952443698954235 - acc: 0.9804134929270947 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 3.1547272205352783 - sq_loss: 6.862603072477214e-07 - tot_loss: 0.17043626488679253 - acc: 0.9804134929270947 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 3.219082832336426 - sq_loss: 6.85598877225857e-07 - tot_loss: 0.18303103375215235 - acc: 0.9805495103373232 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 3.220900297164917 - sq_loss: 6.840840569566353e-07 - tot_loss: 0.18399660813183916 - acc: 0.9806855277475517 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 3.2182836532592773 - sq_loss: 6.826966796324996e-07 - tot_loss: 0.16683935844098619 - acc: 0.9809575625680087 - val_acc: 0.9565659993213438\n",
      "CR_1 = 0.17665842270710058   CR_2 = 0.17592699696476163\n",
      "/home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 3\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "alpha = 1\n",
    "\n",
    "\n",
    "\n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "    d0 = 561 #561 =3*11*17\n",
    "\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 512\n",
    "    d6 = 6 \n",
    "\n",
    "\n",
    "    std_W1 = torch.sqrt(torch.tensor(1. / d0))\n",
    "    W1 =0.2* torch.empty(d1, d0, device=device).normal_(0, std_W1)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    std_W2 = torch.sqrt(torch.tensor(1. / d1))\n",
    "    W2 =0.2* torch.empty(d2, d1, device=device).normal_(0, std_W2)\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles factors, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    std_W3 = torch.sqrt(torch.tensor(1. / d2))\n",
    "    W3 =0.2* torch.empty(d3, d2, device=device).normal_(0, std_W3)\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    std_W4 = torch.sqrt(torch.tensor(1. / d3))\n",
    "    W4 =0.2* torch.empty(d4, d3, device=device).normal_(0, std_W4)\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    std_W5 = torch.sqrt(torch.tensor(1. / d4))\n",
    "    W5 =0.2* torch.empty(d5, d4, device=device).normal_(0, std_W5)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "    W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())\n",
    "    factors5 = tensor_train(W5_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "\n",
    "    std_W6 = torch.sqrt(torch.tensor(1. / d5))\n",
    "    W6 =0.2* torch.empty(d6, d5, device=device).normal_(0, std_W6)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "    b6 = 0*torch.ones(d6, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = nn.ReLU()(U5)\n",
    "    U6 = torch.addmm(b6.repeat(1, N), W6, V5)\n",
    "    V6 = U6 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V6 = (y_one_hot + gamma*U6 + alpha*V6)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U6 = (gamma*V6 + rho*(torch.mm(W6,V5) + b6.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W6, b6 = updateWb_org(U6,V5,W6,b6,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "        # update for 5th layer\n",
    "        # update V3\n",
    "        V5 = updateV(U5,U6,W6,b6,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U5 = relu_prox(V5,(rho*torch.addmm(b5.repeat(1,N), W5, V4) + alpha*U5)/(rho + alpha),(rho + alpha)/gamma,d5,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W5, b5 = updateWb(U5,V4,W5,b5,W5_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4))\n",
    "        W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors5 = tensor_train(W5_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        a5_train = nn.ReLU()(torch.addmm(b5.repeat(1, N), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b6.repeat(1, N), W6, a5_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        a5_test = nn.ReLU()(torch.addmm(b5.repeat(1, N_test), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b6.repeat(1, N_test), W6, a5_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V6,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b6.repeat(1,N), W6, V5),U6,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,nn.ReLU()(U5),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V6,U6,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W5.reshape((4,4,4,4,4,4,4,4,4)),torch.as_tensor(W5_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "    factors5_shape=[f.shape for f in factors5]\n",
    "    Sum_of_variables_factors5=sum(list(x*y*z for x,y,z in factors5_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4+Sum_of_variables_factors5\n",
    "\n",
    "    CR_1=((total_variabels)+(d5*d6))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5+d5*d6)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#     #this postion to add new row into existing table\n",
    "#         df=pd.read_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "#         new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "#                    'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "#                    'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1],'seed':seed} \n",
    "#         df=df.append(new_row,ignore_index=True)\n",
    "#         df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"LecunNormal_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e5c2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133d333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
