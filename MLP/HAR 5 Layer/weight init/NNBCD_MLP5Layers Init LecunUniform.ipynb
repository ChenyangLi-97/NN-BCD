{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4cb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a157bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a5c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "087d0e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 3 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 7.644079685211182 - sq_loss: 661.6734619140625 - tot_loss: 967.5735862401853 - acc: 0.17464635473340587 - val_acc: 0.166949440108585\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 6.727517366409302 - sq_loss: 294.07708740234375 - tot_loss: 493.1037290778477 - acc: 0.19028835690968443 - val_acc: 0.17950458092975907\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 6.609018087387085 - sq_loss: 164.3173065185547 - tot_loss: 269.73275418765843 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 6.653204679489136 - sq_loss: 89.59823608398438 - tot_loss: 152.41527014551684 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 6.505345582962036 - sq_loss: 48.27982711791992 - tot_loss: 89.25749735720456 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 6.712855577468872 - sq_loss: 25.91097068786621 - tot_loss: 54.93390953773633 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 6.6382362842559814 - sq_loss: 13.911141395568848 - tot_loss: 36.05545508349314 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 6.710372686386108 - sq_loss: 7.492652893066406 - tot_loss: 25.47270383895375 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 6.860838413238525 - sq_loss: 4.057625770568848 - tot_loss: 19.396208464400843 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 6.70759391784668 - sq_loss: 2.214118242263794 - tot_loss: 15.75444181181956 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 6.766276121139526 - sq_loss: 1.2202616930007935 - tot_loss: 13.430051687988453 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 6.840559959411621 - sq_loss: 0.6812044978141785 - tot_loss: 11.828732716967352 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 6.816365480422974 - sq_loss: 0.38650020956993103 - tot_loss: 10.608114574919455 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 7.09950065612793 - sq_loss: 0.2237655520439148 - tot_loss: 9.631528177764267 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 6.526844024658203 - sq_loss: 0.13276046514511108 - tot_loss: 8.794923142530024 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 6.209411382675171 - sq_loss: 0.08106858283281326 - tot_loss: 8.060823712847196 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 5.6070661544799805 - sq_loss: 0.05114704743027687 - tot_loss: 7.397798316087574 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 5.30979323387146 - sq_loss: 0.03343503549695015 - tot_loss: 6.854585390887223 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 5.309136867523193 - sq_loss: 0.022681038826704025 - tot_loss: 6.345868400938343 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 5.32392430305481 - sq_loss: 0.015964556485414505 - tot_loss: 5.907128595135873 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 5.593928813934326 - sq_loss: 0.011644210666418076 - tot_loss: 5.494445028656628 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 5.701855659484863 - sq_loss: 0.008778955787420273 - tot_loss: 5.1422982815420255 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 5.165061712265015 - sq_loss: 0.006820248905569315 - tot_loss: 4.816590666421689 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 6.106729507446289 - sq_loss: 0.0054413690231740475 - tot_loss: 4.543510491697816 - acc: 0.19464091403699674 - val_acc: 0.1856124872751951\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 6.075941562652588 - sq_loss: 0.004442128352820873 - tot_loss: 4.265674163252697 - acc: 0.2218443960826986 - val_acc: 0.20393620631150322\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 5.04345178604126 - sq_loss: 0.0036993250250816345 - tot_loss: 4.035110964730848 - acc: 0.27448313384113165 - val_acc: 0.25110281642348153\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 5.070375442504883 - sq_loss: 0.0031331016216427088 - tot_loss: 3.8281769035820616 - acc: 0.3205930359085963 - val_acc: 0.29453681710213775\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 5.134223699569702 - sq_loss: 0.0026917399372905493 - tot_loss: 3.6259132768173004 - acc: 0.33854733405875953 - val_acc: 0.33050559891415\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 4.995465278625488 - sq_loss: 0.002340856706723571 - tot_loss: 3.440155752992723 - acc: 0.34670837867247006 - val_acc: 0.3474720054292501\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 5.141133069992065 - sq_loss: 0.0020563036669045687 - tot_loss: 3.2775760635122424 - acc: 0.35310119695321 - val_acc: 0.3501866304716661\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 5.182931423187256 - sq_loss: 0.001821782672777772 - tot_loss: 3.114054766112531 - acc: 0.3570457018498368 - val_acc: 0.35086528673227013\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 5.070021390914917 - sq_loss: 0.001626055222004652 - tot_loss: 2.983980539131153 - acc: 0.3634385201305767 - val_acc: 0.35527655242619616\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 4.998081207275391 - sq_loss: 0.0014604913303628564 - tot_loss: 2.8533523562800838 - acc: 0.3986670293797606 - val_acc: 0.3803868340685443\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 5.149367570877075 - sq_loss: 0.0013188751181587577 - tot_loss: 2.7052010804618476 - acc: 0.45661044613710555 - val_acc: 0.4326433661350526\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 5.056993722915649 - sq_loss: 0.0011964979348704219 - tot_loss: 2.6013517717874493 - acc: 0.5025843307943417 - val_acc: 0.4865965388530709\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 5.1221232414245605 - sq_loss: 0.001090128323994577 - tot_loss: 2.4995130917304778 - acc: 0.5270674646354734 - val_acc: 0.511706820495419\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 5.1707940101623535 - sq_loss: 0.0009968318045139313 - tot_loss: 2.403299867073656 - acc: 0.5393090315560392 - val_acc: 0.5239226331862912\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 5.039039850234985 - sq_loss: 0.0009146815282292664 - tot_loss: 2.3095853522318066 - acc: 0.5427094668117519 - val_acc: 0.5276552426196132\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 5.125668525695801 - sq_loss: 0.0008415352203883231 - tot_loss: 2.228392165769037 - acc: 0.544069640914037 - val_acc: 0.5293518832711231\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 4.946375846862793 - sq_loss: 0.000776169472374022 - tot_loss: 2.12604603339787 - acc: 0.5452937976060935 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 5.051981210708618 - sq_loss: 0.0007177249062806368 - tot_loss: 2.047700692604849 - acc: 0.5461099020674647 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 5.129087924957275 - sq_loss: 0.0006651231669820845 - tot_loss: 1.9549420095427195 - acc: 0.5470620239390642 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 5.102441310882568 - sq_loss: 0.0006176454480737448 - tot_loss: 1.8961621351991198 - acc: 0.5480141458106638 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 5.183646202087402 - sq_loss: 0.0005745661910623312 - tot_loss: 1.8281353422535176 - acc: 0.5499183895538629 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 5.043094158172607 - sq_loss: 0.0005353246815502644 - tot_loss: 1.7795812936565198 - acc: 0.5537268770402611 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 4.957741022109985 - sq_loss: 0.0004995888448320329 - tot_loss: 1.712728250058717 - acc: 0.5602557127312296 - val_acc: 0.5313878520529352\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 4.996456146240234 - sq_loss: 0.00046702264808118343 - tot_loss: 1.6407868063579372 - acc: 0.5692328618063112 - val_acc: 0.5337631489650492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 5.129729986190796 - sq_loss: 0.00043711168109439313 - tot_loss: 1.5988660375296604 - acc: 0.580930359085963 - val_acc: 0.5385137427892772\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 5.1277031898498535 - sq_loss: 0.00040948056266643107 - tot_loss: 1.5485789094345819 - acc: 0.5943960826985855 - val_acc: 0.5429250084832032\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 5.041826963424683 - sq_loss: 0.0003840109275188297 - tot_loss: 1.5017026915247698 - acc: 0.6071817192600653 - val_acc: 0.5514082117407533\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 4.992061614990234 - sq_loss: 0.000360411882866174 - tot_loss: 1.4399022844081628 - acc: 0.6179270946681176 - val_acc: 0.5612487275195114\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 5.047180891036987 - sq_loss: 0.00033868217724375427 - tot_loss: 1.3982214765692333 - acc: 0.6297606093579978 - val_acc: 0.5714285714285714\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 5.028551816940308 - sq_loss: 0.00031864718766883016 - tot_loss: 1.3403052492794814 - acc: 0.6426822633297062 - val_acc: 0.5873769935527655\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 5.1137168407440186 - sq_loss: 0.0003000523429363966 - tot_loss: 1.2961651235345926 - acc: 0.654107725788901 - val_acc: 0.6006107906345436\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 5.144214868545532 - sq_loss: 0.00028268544701859355 - tot_loss: 1.2563921973251126 - acc: 0.6694776931447225 - val_acc: 0.6145232439769257\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 5.018900156021118 - sq_loss: 0.00026657935814000666 - tot_loss: 1.208654764754101 - acc: 0.6803590859630033 - val_acc: 0.6280963691890058\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 4.990664958953857 - sq_loss: 0.0002514287189114839 - tot_loss: 1.1953901872020651 - acc: 0.6885201305767138 - val_acc: 0.6392941974889719\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 5.143596649169922 - sq_loss: 0.00023737868468742818 - tot_loss: 1.1448191021172534 - acc: 0.6969532100108814 - val_acc: 0.6511706820495419\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 5.0799641609191895 - sq_loss: 0.0002241757174488157 - tot_loss: 1.1002632550535054 - acc: 0.706474428726877 - val_acc: 0.6576179165252799\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 5.1185338497161865 - sq_loss: 0.00021181927877478302 - tot_loss: 1.0797030496451043 - acc: 0.7169477693144722 - val_acc: 0.663725822870716\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 5.183120489120483 - sq_loss: 0.00020024854165967554 - tot_loss: 1.054028516937251 - acc: 0.7253808487486398 - val_acc: 0.6728876823888701\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 5.082888603210449 - sq_loss: 0.00018936842388939112 - tot_loss: 1.0158576599114895 - acc: 0.7315016322089227 - val_acc: 0.6803529012555141\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 4.9851086139678955 - sq_loss: 0.00017919408855959773 - tot_loss: 0.9872205874025894 - acc: 0.736126224156692 - val_acc: 0.6901934170342722\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 4.9973790645599365 - sq_loss: 0.00016957226034719497 - tot_loss: 0.9742349461166668 - acc: 0.7425190424374319 - val_acc: 0.6946046827281982\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 5.1179728507995605 - sq_loss: 0.00016059425252024084 - tot_loss: 0.9469046998119666 - acc: 0.7471436343852013 - val_acc: 0.7007125890736342\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 5.108907699584961 - sq_loss: 0.00015203928342089057 - tot_loss: 0.8922474548917307 - acc: 0.751088139281828 - val_acc: 0.7041058703766542\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 5.087892293930054 - sq_loss: 0.00014402582019101828 - tot_loss: 0.8776087565956914 - acc: 0.7555767138193689 - val_acc: 0.7108924329826942\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 5.045757293701172 - sq_loss: 0.00013645757280755788 - tot_loss: 0.8372811919571177 - acc: 0.7596572361262242 - val_acc: 0.7156430268069223\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 6.222527742385864 - sq_loss: 0.0001293898094445467 - tot_loss: 0.8242544115391865 - acc: 0.7626496191512514 - val_acc: 0.7200542925008483\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 5.239159107208252 - sq_loss: 0.00012267161218915135 - tot_loss: 0.8012875057374913 - acc: 0.764417845484222 - val_acc: 0.7234475738038684\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 5.046642541885376 - sq_loss: 0.00011627220374066383 - tot_loss: 0.784652139283935 - acc: 0.7670021762785637 - val_acc: 0.7268408551068883\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 5.064662218093872 - sq_loss: 0.00011023120168829337 - tot_loss: 0.7612350126473757 - acc: 0.7687704026115343 - val_acc: 0.7305734645402104\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 4.977230548858643 - sq_loss: 0.00010444521467434242 - tot_loss: 0.7465962154601584 - acc: 0.7706746463547334 - val_acc: 0.7343060739735324\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 5.078741073608398 - sq_loss: 9.908110951073468e-05 - tot_loss: 0.719260469609253 - acc: 0.7723068552774756 - val_acc: 0.7376993552765524\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 4.9446752071380615 - sq_loss: 9.400781709700823e-05 - tot_loss: 0.7005901535067096 - acc: 0.7738030467899891 - val_acc: 0.7393959959280625\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 4.929978847503662 - sq_loss: 8.916263323044404e-05 - tot_loss: 0.6799773217840084 - acc: 0.7765233949945594 - val_acc: 0.7431286053613845\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 5.103152513504028 - sq_loss: 8.461742254439741e-05 - tot_loss: 0.6567752304736132 - acc: 0.7786996735582155 - val_acc: 0.7441465897522904\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 4.977404832839966 - sq_loss: 8.029462333070114e-05 - tot_loss: 0.6483296743676874 - acc: 0.7808759521218716 - val_acc: 0.7468612147947065\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 5.044851064682007 - sq_loss: 7.616490620421246e-05 - tot_loss: 0.6416286839380518 - acc: 0.7837323177366703 - val_acc: 0.7485578554462164\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 4.935878038406372 - sq_loss: 7.22748227417469e-05 - tot_loss: 0.6026712187754129 - acc: 0.7853645266594124 - val_acc: 0.7502544960977265\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 5.014941692352295 - sq_loss: 6.85954000800848e-05 - tot_loss: 0.6052629544306001 - acc: 0.786588683351469 - val_acc: 0.7519511367492365\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 5.060921907424927 - sq_loss: 6.519599264720455e-05 - tot_loss: 0.6039014348862111 - acc: 0.7886289445048966 - val_acc: 0.7546657617916526\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 5.082473039627075 - sq_loss: 6.196303729666397e-05 - tot_loss: 0.5699387759391357 - acc: 0.7903971708378672 - val_acc: 0.7567017305734646\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 4.960016250610352 - sq_loss: 5.881876859348267e-05 - tot_loss: 0.5651742085560727 - acc: 0.7927094668117519 - val_acc: 0.7607736681370886\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 5.021651029586792 - sq_loss: 5.5849151976872236e-05 - tot_loss: 0.5443867455119289 - acc: 0.794885745375408 - val_acc: 0.7621309806582965\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 5.0842649936676025 - sq_loss: 5.301179044181481e-05 - tot_loss: 0.5364133790935739 - acc: 0.7978781284004353 - val_acc: 0.7641669494401085\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 4.949384689331055 - sq_loss: 5.0405807996867225e-05 - tot_loss: 0.533999435874648 - acc: 0.7999183895538629 - val_acc: 0.7665422463522226\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 5.039258241653442 - sq_loss: 4.785217242897488e-05 - tot_loss: 0.5159990558399841 - acc: 0.8025027203482046 - val_acc: 0.7699355276552426\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 5.01636815071106 - sq_loss: 4.5449800381902605e-05 - tot_loss: 0.5168173614233638 - acc: 0.8052230685527747 - val_acc: 0.7716321683067526\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 4.986279726028442 - sq_loss: 4.323333632783033e-05 - tot_loss: 0.49624536240412453 - acc: 0.8079434167573449 - val_acc: 0.7733288089582626\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 4.939284086227417 - sq_loss: 4.108741268282756e-05 - tot_loss: 0.4909324963207382 - acc: 0.8109357997823722 - val_acc: 0.7753647777400746\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 5.042638301849365 - sq_loss: 3.906759593519382e-05 - tot_loss: 0.4884065281389667 - acc: 0.8129760609357998 - val_acc: 0.7787580590430947\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 4.970871210098267 - sq_loss: 3.713630576385185e-05 - tot_loss: 0.4654929650394024 - acc: 0.8158324265505985 - val_acc: 0.7794367153036986\n",
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 4.905091762542725 - sq_loss: 3.530216417857446e-05 - tot_loss: 0.4647735895034657 - acc: 0.8186887921653971 - val_acc: 0.7818120122158126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 4.982845067977905 - sq_loss: 3.354251748532988e-05 - tot_loss: 0.4283623342728333 - acc: 0.8204570184983678 - val_acc: 0.7838479809976246\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 5.012707710266113 - sq_loss: 3.187010224792175e-05 - tot_loss: 0.4503126346232875 - acc: 0.8235854189336235 - val_acc: 0.7872412623006447\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 5.030372619628906 - sq_loss: 3.0290555514511652e-05 - tot_loss: 0.4301670407214715 - acc: 0.8260337323177367 - val_acc: 0.7889379029521547\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 4.905877351760864 - sq_loss: 2.881004911614582e-05 - tot_loss: 0.4310126974855848 - acc: 0.8280739934711643 - val_acc: 0.7896165592127588\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 5.037894248962402 - sq_loss: 2.7424614017945714e-05 - tot_loss: 0.40450943405198814 - acc: 0.8310663764961915 - val_acc: 0.7923311842551748\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 4.967034816741943 - sq_loss: 2.6093364795087837e-05 - tot_loss: 0.3978940718652666 - acc: 0.8341947769314473 - val_acc: 0.7960637936884968\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 4.966382026672363 - sq_loss: 2.484682590875309e-05 - tot_loss: 0.39947284620234313 - acc: 0.8380032644178455 - val_acc: 0.7980997624703088\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 5.04687237739563 - sq_loss: 2.3661425075260922e-05 - tot_loss: 0.3880426700729913 - acc: 0.8404515778019587 - val_acc: 0.7997964031218188\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 4.952924966812134 - sq_loss: 2.254979517601896e-05 - tot_loss: 0.37456774216866506 - acc: 0.8434439608269858 - val_acc: 0.8018323719036308\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 6.10026216506958 - sq_loss: 2.1477433620020747e-05 - tot_loss: 0.3825153551335916 - acc: 0.846436343852013 - val_acc: 0.8021717000339328\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 5.775103807449341 - sq_loss: 2.04724619834451e-05 - tot_loss: 0.38296641675503906 - acc: 0.8488846572361263 - val_acc: 0.8042076688157448\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 4.945463180541992 - sq_loss: 1.9492872525006533e-05 - tot_loss: 0.3639262751619299 - acc: 0.8520130576713819 - val_acc: 0.8069222938581608\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 4.944383382797241 - sq_loss: 1.8573184206616133e-05 - tot_loss: 0.3620251145268867 - acc: 0.8550054406964092 - val_acc: 0.8103155751611809\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 4.887216329574585 - sq_loss: 1.768134461599402e-05 - tot_loss: 0.37509462860248277 - acc: 0.8570457018498367 - val_acc: 0.8130302002035968\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 4.943258762359619 - sq_loss: 1.6850801330292597e-05 - tot_loss: 0.35595012725218567 - acc: 0.8604461371055495 - val_acc: 0.8181201221581269\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 4.899610280990601 - sq_loss: 1.604451608727686e-05 - tot_loss: 0.34570407167427675 - acc: 0.8631664853101197 - val_acc: 0.8204954190702409\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 4.919896364212036 - sq_loss: 1.5275305486284196e-05 - tot_loss: 0.33480661320561467 - acc: 0.8649347116430903 - val_acc: 0.8221920597217509\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 4.946075439453125 - sq_loss: 1.4556335372617468e-05 - tot_loss: 0.3258150117006835 - acc: 0.8668389553862894 - val_acc: 0.825246012894469\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 4.914965391159058 - sq_loss: 1.3899978512199596e-05 - tot_loss: 0.34000151276620727 - acc: 0.8683351468988031 - val_acc: 0.826942653545979\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 4.842848539352417 - sq_loss: 1.3267157555674203e-05 - tot_loss: 0.32746275946738024 - acc: 0.8713275299238302 - val_acc: 0.827621309806583\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 4.887649297714233 - sq_loss: 1.2675379366555717e-05 - tot_loss: 0.33199761147284335 - acc: 0.8736398258977149 - val_acc: 0.830335934848999\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 5.0380539894104 - sq_loss: 1.2117466212657746e-05 - tot_loss: 0.33274958522702036 - acc: 0.8754080522306855 - val_acc: 0.832371903630811\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 4.799006938934326 - sq_loss: 1.1567263754841406e-05 - tot_loss: 0.30787034108539046 - acc: 0.8777203482045702 - val_acc: 0.833389888021717\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 4.879625082015991 - sq_loss: 1.1072617780882865e-05 - tot_loss: 0.3225263620524288 - acc: 0.8788084874863983 - val_acc: 0.835765184933831\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 4.809709310531616 - sq_loss: 1.061087823472917e-05 - tot_loss: 0.3077470577887311 - acc: 0.8807127312295974 - val_acc: 0.8388191381065491\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 4.906612396240234 - sq_loss: 1.0128946087206714e-05 - tot_loss: 0.3199543779384726 - acc: 0.8819368879216539 - val_acc: 0.842551747539871\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 4.745390892028809 - sq_loss: 9.676426998339593e-06 - tot_loss: 0.28936454217449636 - acc: 0.8852013057671382 - val_acc: 0.8449270444519851\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 4.916459560394287 - sq_loss: 9.25013046071399e-06 - tot_loss: 0.2955560699015223 - acc: 0.8857453754080522 - val_acc: 0.8456057007125891\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 4.948393821716309 - sq_loss: 8.867741598805878e-06 - tot_loss: 0.2898441403835932 - acc: 0.8868335146898803 - val_acc: 0.8479809976247031\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 4.92282509803772 - sq_loss: 8.520860319549683e-06 - tot_loss: 0.29361412078429794 - acc: 0.8883297062023939 - val_acc: 0.850356294536817\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 4.9332616329193115 - sq_loss: 8.162684935086872e-06 - tot_loss: 0.29317942120309226 - acc: 0.8895538628944505 - val_acc: 0.8534102477095351\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 4.91621994972229 - sq_loss: 7.84757958172122e-06 - tot_loss: 0.28940152646089246 - acc: 0.8911860718171926 - val_acc: 0.8544282321004412\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 4.917283535003662 - sq_loss: 7.522363830503309e-06 - tot_loss: 0.2850209383300353 - acc: 0.8924102285092492 - val_acc: 0.8554462164913471\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 4.948209524154663 - sq_loss: 7.186692073446466e-06 - tot_loss: 0.275377964113261 - acc: 0.8937704026115343 - val_acc: 0.8581608415337632\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 4.886725425720215 - sq_loss: 6.873777692817384e-06 - tot_loss: 0.27696608208503903 - acc: 0.8947225244831338 - val_acc: 0.8601968103155752\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 4.887492656707764 - sq_loss: 6.606737315451028e-06 - tot_loss: 0.2640529860510128 - acc: 0.8955386289445049 - val_acc: 0.8618934509670851\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 4.994893550872803 - sq_loss: 6.352704076562077e-06 - tot_loss: 0.2694227602559067 - acc: 0.8979869423286181 - val_acc: 0.8632507634882932\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 5.000473737716675 - sq_loss: 6.098478934291052e-06 - tot_loss: 0.25581053911514573 - acc: 0.8993471164309031 - val_acc: 0.8642687478791992\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 4.953242540359497 - sq_loss: 5.854046321474016e-06 - tot_loss: 0.27402093993802623 - acc: 0.9005712731229597 - val_acc: 0.8649474041398032\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 4.956347703933716 - sq_loss: 5.6311032494704705e-06 - tot_loss: 0.25967899289020124 - acc: 0.9012513601741022 - val_acc: 0.8652867322701052\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 4.966314315795898 - sq_loss: 5.409010100265732e-06 - tot_loss: 0.25647667254517614 - acc: 0.9022034820457019 - val_acc: 0.8666440447913132\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 5.846554756164551 - sq_loss: 5.212446012592409e-06 - tot_loss: 0.2523009385301407 - acc: 0.9026115342763874 - val_acc: 0.8683406854428232\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 6.765096664428711 - sq_loss: 5.029034582548775e-06 - tot_loss: 0.2515752129814075 - acc: 0.9030195865070729 - val_acc: 0.8700373260943333\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 6.205826044082642 - sq_loss: 4.857556632487103e-06 - tot_loss: 0.24974769323546298 - acc: 0.903563656147987 - val_acc: 0.8707159823549372\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 6.211501836776733 - sq_loss: 4.687657110480359e-06 - tot_loss: 0.2558699068800365 - acc: 0.9045157780195865 - val_acc: 0.8724126230064473\n",
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 6.131887674331665 - sq_loss: 4.536029791779583e-06 - tot_loss: 0.24492485957574672 - acc: 0.9053318824809575 - val_acc: 0.8730912792670512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 6.032577991485596 - sq_loss: 4.3825375541928224e-06 - tot_loss: 0.2456061164961909 - acc: 0.9068280739934712 - val_acc: 0.8737699355276553\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 6.096586465835571 - sq_loss: 4.22602306571207e-06 - tot_loss: 0.22825243793209893 - acc: 0.9073721436343852 - val_acc: 0.8754665761791652\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 6.081078290939331 - sq_loss: 4.076812274433905e-06 - tot_loss: 0.2406947679124869 - acc: 0.9081882480957563 - val_acc: 0.8768238887003733\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 6.2123143672943115 - sq_loss: 3.9593032852280885e-06 - tot_loss: 0.23184564766961557 - acc: 0.9087323177366703 - val_acc: 0.8781812012215813\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 6.190211772918701 - sq_loss: 3.8349903661583085e-06 - tot_loss: 0.24156170604901206 - acc: 0.9100924918389554 - val_acc: 0.8795385137427892\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 6.216466665267944 - sq_loss: 3.7052479910926195e-06 - tot_loss: 0.23543573098191928 - acc: 0.9110446137105549 - val_acc: 0.8791991856124872\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 6.16260552406311 - sq_loss: 3.5925972952099983e-06 - tot_loss: 0.22885905144070762 - acc: 0.9124047878128401 - val_acc: 0.8802171700033933\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 6.068302392959595 - sq_loss: 3.488398533590953e-06 - tot_loss: 0.2295861105394721 - acc: 0.9126768226332971 - val_acc: 0.8819138106549033\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 6.189146518707275 - sq_loss: 3.382848262845073e-06 - tot_loss: 0.23463093336420116 - acc: 0.9136289445048966 - val_acc: 0.8825924669155073\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 6.056853294372559 - sq_loss: 3.291002485639183e-06 - tot_loss: 0.23349900834874404 - acc: 0.9141730141458106 - val_acc: 0.8832711231761113\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 6.148761749267578 - sq_loss: 3.196731995558366e-06 - tot_loss: 0.23724530364003726 - acc: 0.9148531011969532 - val_acc: 0.8846284356973193\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 6.199244737625122 - sq_loss: 3.1142833449848695e-06 - tot_loss: 0.23284464509032432 - acc: 0.9160772578890098 - val_acc: 0.8856464200882254\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 6.380634069442749 - sq_loss: 3.028460923815146e-06 - tot_loss: 0.24317300637721928 - acc: 0.9173014145810664 - val_acc: 0.8866644044791313\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 6.148911237716675 - sq_loss: 2.9532388907682616e-06 - tot_loss: 0.21326823786850468 - acc: 0.9181175190424374 - val_acc: 0.8870037326094333\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 6.103263854980469 - sq_loss: 2.877563701986219e-06 - tot_loss: 0.19699027423567372 - acc: 0.9186615886833515 - val_acc: 0.8876823888700374\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 6.2485363483428955 - sq_loss: 2.797620936689782e-06 - tot_loss: 0.2154207685872791 - acc: 0.918525571273123 - val_acc: 0.8887003732609433\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 6.174195289611816 - sq_loss: 2.7181301902601263e-06 - tot_loss: 0.22708054094751162 - acc: 0.919069640914037 - val_acc: 0.8897183576518494\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 6.075197219848633 - sq_loss: 2.64465916188783e-06 - tot_loss: 0.22864177732176927 - acc: 0.919341675734494 - val_acc: 0.8917543264336614\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 6.11214017868042 - sq_loss: 2.5731233108672313e-06 - tot_loss: 0.20977637349248113 - acc: 0.9194776931447225 - val_acc: 0.8927723108245673\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 6.020668983459473 - sq_loss: 2.501318476788583e-06 - tot_loss: 0.2094642968232563 - acc: 0.920157780195865 - val_acc: 0.8937902952154734\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 6.088432312011719 - sq_loss: 2.4422433853033e-06 - tot_loss: 0.21119324866690192 - acc: 0.9208378672470077 - val_acc: 0.8941296233457754\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 6.095934629440308 - sq_loss: 2.3916895770526025e-06 - tot_loss: 0.21744787717507563 - acc: 0.9215179542981502 - val_acc: 0.8951476077366813\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 6.001789808273315 - sq_loss: 2.341749677725602e-06 - tot_loss: 0.21838503950949928 - acc: 0.9217899891186072 - val_acc: 0.8961655921275874\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 6.049440622329712 - sq_loss: 2.30097612075042e-06 - tot_loss: 0.2123935667966137 - acc: 0.9221980413492927 - val_acc: 0.8965049202578894\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 6.024791717529297 - sq_loss: 2.2557189822691726e-06 - tot_loss: 0.21797875368773134 - acc: 0.9227421109902068 - val_acc: 0.8965049202578894\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 6.0561745166778564 - sq_loss: 2.207016450483934e-06 - tot_loss: 0.19310677163726098 - acc: 0.9230141458106638 - val_acc: 0.8975229046487954\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 6.0297629833221436 - sq_loss: 2.158054030587664e-06 - tot_loss: 0.18921292526313493 - acc: 0.9232861806311208 - val_acc: 0.8982015609093994\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 6.154693126678467 - sq_loss: 2.1152418412384577e-06 - tot_loss: 0.1994666701410921 - acc: 0.9235582154515778 - val_acc: 0.8988802171700034\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 5.9406139850616455 - sq_loss: 2.0785946617252193e-06 - tot_loss: 0.2008020329643685 - acc: 0.9239662676822633 - val_acc: 0.9002375296912114\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 5.999101400375366 - sq_loss: 2.0380132355057867e-06 - tot_loss: 0.19795135864416125 - acc: 0.9242383025027203 - val_acc: 0.9002375296912114\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 6.07687520980835 - sq_loss: 2.0004533780593192e-06 - tot_loss: 0.19416895483234242 - acc: 0.9245103373231773 - val_acc: 0.9012555140821175\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 6.053598165512085 - sq_loss: 1.964163857337553e-06 - tot_loss: 0.20608527374010066 - acc: 0.9249183895538629 - val_acc: 0.9015948422124194\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 6.0950376987457275 - sq_loss: 1.932730356202228e-06 - tot_loss: 0.20563722539517926 - acc: 0.9251904243743199 - val_acc: 0.9026128266033254\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 6.074418306350708 - sq_loss: 1.9012477423530072e-06 - tot_loss: 0.19801324737901638 - acc: 0.925734494015234 - val_acc: 0.9032914828639295\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 6.118027687072754 - sq_loss: 1.8755300743578118e-06 - tot_loss: 0.20709971872607724 - acc: 0.9255984766050055 - val_acc: 0.9032914828639295\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 6.07534384727478 - sq_loss: 1.849538534770545e-06 - tot_loss: 0.1939806519550764 - acc: 0.9255984766050055 - val_acc: 0.9039701391245334\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 6.22836446762085 - sq_loss: 1.8148873550671851e-06 - tot_loss: 0.1941866431318573 - acc: 0.926006528835691 - val_acc: 0.9039701391245334\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 6.14387321472168 - sq_loss: 1.7824830820245552e-06 - tot_loss: 0.1921272778015819 - acc: 0.926006528835691 - val_acc: 0.9046487953851374\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 6.12377142906189 - sq_loss: 1.75585876149853e-06 - tot_loss: 0.20639724122890257 - acc: 0.9264145810663765 - val_acc: 0.9060061079063454\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 6.122901916503906 - sq_loss: 1.735677756187215e-06 - tot_loss: 0.19951138404735858 - acc: 0.9269586507072906 - val_acc: 0.9066847641669494\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 6.236725091934204 - sq_loss: 1.7111138959080563e-06 - tot_loss: 0.19250422031332448 - acc: 0.9270946681175191 - val_acc: 0.9073634204275535\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 6.15287709236145 - sq_loss: 1.686719315330265e-06 - tot_loss: 0.19658326138368665 - acc: 0.9281828073993471 - val_acc: 0.9080420766881574\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 6.37425971031189 - sq_loss: 1.6613269053777913e-06 - tot_loss: 0.19936470754917224 - acc: 0.9287268770402611 - val_acc: 0.9093993892093655\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 6.077183246612549 - sq_loss: 1.6407572047683061e-06 - tot_loss: 0.18044981530994875 - acc: 0.9295429815016322 - val_acc: 0.9093993892093655\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 6.1472039222717285 - sq_loss: 1.6225469607888954e-06 - tot_loss: 0.19768924276567645 - acc: 0.9299510337323177 - val_acc: 0.9097387173396675\n",
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 6.184416770935059 - sq_loss: 1.5999689821910579e-06 - tot_loss: 0.18716876360918278 - acc: 0.9306311207834603 - val_acc: 0.9107567017305734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 6.265456438064575 - sq_loss: 1.5789031522217556e-06 - tot_loss: 0.18594287649230168 - acc: 0.9315832426550599 - val_acc: 0.9104173736002714\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 6.226737022399902 - sq_loss: 1.555799258312618e-06 - tot_loss: 0.20571352578768654 - acc: 0.9315832426550599 - val_acc: 0.9104173736002714\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 6.261124849319458 - sq_loss: 1.5378976740976213e-06 - tot_loss: 0.1834360699415747 - acc: 0.9319912948857454 - val_acc: 0.9104173736002714\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 6.100969076156616 - sq_loss: 1.5257131735779694e-06 - tot_loss: 0.18447294953096005 - acc: 0.9325353645266594 - val_acc: 0.9104173736002714\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 6.304095268249512 - sq_loss: 1.507446881987562e-06 - tot_loss: 0.18140315423261733 - acc: 0.9323993471164309 - val_acc: 0.9107567017305734\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 6.252147912979126 - sq_loss: 1.4957605571908061e-06 - tot_loss: 0.19083271781047273 - acc: 0.9329434167573449 - val_acc: 0.9121140142517815\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 6.142287731170654 - sq_loss: 1.4812710560363485e-06 - tot_loss: 0.17793821884088956 - acc: 0.9330794341675734 - val_acc: 0.9121140142517815\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 6.127275228500366 - sq_loss: 1.4633535556640709e-06 - tot_loss: 0.18428035602336124 - acc: 0.933487486398259 - val_acc: 0.9117746861214795\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 6.1235949993133545 - sq_loss: 1.4454462871071883e-06 - tot_loss: 0.17477443792643044 - acc: 0.93430359085963 - val_acc: 0.9117746861214795\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 6.1216442584991455 - sq_loss: 1.4285840279626427e-06 - tot_loss: 0.1873387510353588 - acc: 0.934575625680087 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 6.236814022064209 - sq_loss: 1.4154652490105946e-06 - tot_loss: 0.17976646499902316 - acc: 0.934847660500544 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 6.143025159835815 - sq_loss: 1.406116780344746e-06 - tot_loss: 0.1653012471538986 - acc: 0.9353917301414582 - val_acc: 0.9127926705123854\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 6.17030143737793 - sq_loss: 1.3911568430557963e-06 - tot_loss: 0.18595531073186677 - acc: 0.9360718171926007 - val_acc: 0.9138106549032915\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 6.153221130371094 - sq_loss: 1.3737230801780242e-06 - tot_loss: 0.18470103128405313 - acc: 0.9363438520130577 - val_acc: 0.9138106549032915\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 6.16543436050415 - sq_loss: 1.3660326203535078e-06 - tot_loss: 0.1688214588853274 - acc: 0.9367519042437432 - val_acc: 0.9138106549032915\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 6.1555421352386475 - sq_loss: 1.3581556004282902e-06 - tot_loss: 0.16747041205809055 - acc: 0.9374319912948857 - val_acc: 0.9138106549032915\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 6.3922717571258545 - sq_loss: 1.3498495263775112e-06 - tot_loss: 0.1690292471177255 - acc: 0.9378400435255713 - val_acc: 0.9144893111638955\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 6.190459966659546 - sq_loss: 1.3411063264356926e-06 - tot_loss: 0.17096091254435208 - acc: 0.9382480957562568 - val_acc: 0.9151679674244995\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 6.27230429649353 - sq_loss: 1.3330768524610903e-06 - tot_loss: 0.1821513296946371 - acc: 0.9390642002176278 - val_acc: 0.9161859518154055\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 6.302334547042847 - sq_loss: 1.3233457138994709e-06 - tot_loss: 0.1683519680401968 - acc: 0.9392002176278563 - val_acc: 0.9168646080760094\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 6.253418684005737 - sq_loss: 1.3130979823472444e-06 - tot_loss: 0.17652911243169989 - acc: 0.9396082698585418 - val_acc: 0.9175432643366135\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 6.342498064041138 - sq_loss: 1.3025349971940159e-06 - tot_loss: 0.17295257540374642 - acc: 0.9402883569096845 - val_acc: 0.9178825924669155\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 6.410171985626221 - sq_loss: 1.2908235476061236e-06 - tot_loss: 0.17603262328547764 - acc: 0.94069640914037 - val_acc: 0.9189005768578216\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 6.480544328689575 - sq_loss: 1.2845863466282026e-06 - tot_loss: 0.16772076189657525 - acc: 0.940968443960827 - val_acc: 0.9192399049881235\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 6.405949115753174 - sq_loss: 1.2756026990246028e-06 - tot_loss: 0.18124727527513151 - acc: 0.941240478781284 - val_acc: 0.9195792331184255\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 6.313398599624634 - sq_loss: 1.265685455109633e-06 - tot_loss: 0.18332520902670169 - acc: 0.9420565832426551 - val_acc: 0.9199185612487275\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 6.179066181182861 - sq_loss: 1.2606187738128938e-06 - tot_loss: 0.18201970494994235 - acc: 0.9428726877040261 - val_acc: 0.9202578893790295\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 6.27998685836792 - sq_loss: 1.2531137372207013e-06 - tot_loss: 0.16472159197038394 - acc: 0.9435527747551686 - val_acc: 0.9212758737699356\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 6.135498762130737 - sq_loss: 1.2437894838512875e-06 - tot_loss: 0.1792346585271689 - acc: 0.9440968443960827 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 6.242238759994507 - sq_loss: 1.2353716556390282e-06 - tot_loss: 0.18160415705797384 - acc: 0.9446409140369967 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 6.463407039642334 - sq_loss: 1.23299741972005e-06 - tot_loss: 0.17030047755184707 - acc: 0.9450489662676823 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 6.26025915145874 - sq_loss: 1.226753624905541e-06 - tot_loss: 0.1834475925057122 - acc: 0.9453210010881393 - val_acc: 0.9222938581608415\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 6.153807640075684 - sq_loss: 1.2198649983474752e-06 - tot_loss: 0.17312630419033326 - acc: 0.9455930359085963 - val_acc: 0.9222938581608415\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 6.317873239517212 - sq_loss: 1.2134087228332646e-06 - tot_loss: 0.17118369235612185 - acc: 0.9460010881392819 - val_acc: 0.9229725144214456\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 6.18282675743103 - sq_loss: 1.2106239637432736e-06 - tot_loss: 0.1765200301992893 - acc: 0.9462731229597389 - val_acc: 0.9229725144214456\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 6.21529483795166 - sq_loss: 1.200412270918605e-06 - tot_loss: 0.1639396838236955 - acc: 0.9466811751904244 - val_acc: 0.9229725144214456\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 6.151994705200195 - sq_loss: 1.1928493677260121e-06 - tot_loss: 0.15867823919301038 - acc: 0.9472252448313384 - val_acc: 0.9236511706820495\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 6.1958534717559814 - sq_loss: 1.1852961279146257e-06 - tot_loss: 0.1563890707556661 - acc: 0.9476332970620239 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 6.133935928344727 - sq_loss: 1.177770741378481e-06 - tot_loss: 0.16205490886906926 - acc: 0.9473612622415669 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 6.166161298751831 - sq_loss: 1.1726211823770427e-06 - tot_loss: 0.17028507830962702 - acc: 0.9477693144722524 - val_acc: 0.9246691550729556\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 5.47547721862793 - sq_loss: 1.1656449032670935e-06 - tot_loss: 0.1522911967949021 - acc: 0.948177366702938 - val_acc: 0.9250084832032576\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 5.171283721923828 - sq_loss: 1.1624473472693353e-06 - tot_loss: 0.1741408544423111 - acc: 0.948993471164309 - val_acc: 0.9253478113335596\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 5.07464861869812 - sq_loss: 1.156275970970455e-06 - tot_loss: 0.16982171576601246 - acc: 0.949265505984766 - val_acc: 0.9263657957244655\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 5.08458685874939 - sq_loss: 1.148859837485361e-06 - tot_loss: 0.1752582943246157 - acc: 0.9494015233949945 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 5.093794822692871 - sq_loss: 1.1432989595050458e-06 - tot_loss: 0.17143705337347193 - acc: 0.9496735582154516 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 5.041727066040039 - sq_loss: 1.1359310292391456e-06 - tot_loss: 0.15784694865259397 - acc: 0.9498095756256801 - val_acc: 0.9277231082456736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 5.054236650466919 - sq_loss: 1.1310759191474062e-06 - tot_loss: 0.1793222095171796 - acc: 0.9508977149075082 - val_acc: 0.9284017645062775\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 5.168098211288452 - sq_loss: 1.1289984058748814e-06 - tot_loss: 0.1618524489758677 - acc: 0.9514417845484222 - val_acc: 0.9284017645062775\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 5.221175193786621 - sq_loss: 1.1235329111514147e-06 - tot_loss: 0.17224240582429928 - acc: 0.9517138193688792 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 5.056553602218628 - sq_loss: 1.1206591352674877e-06 - tot_loss: 0.18014940236504629 - acc: 0.9515778019586507 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 5.087006568908691 - sq_loss: 1.115945110541361e-06 - tot_loss: 0.16869282506800953 - acc: 0.9517138193688792 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 5.179643630981445 - sq_loss: 1.111250298890809e-06 - tot_loss: 0.16410299072751577 - acc: 0.9521218715995647 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 5.05695652961731 - sq_loss: 1.1057062465624767e-06 - tot_loss: 0.18077537980180214 - acc: 0.9522578890097932 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 5.0290162563323975 - sq_loss: 1.1005179203493753e-06 - tot_loss: 0.1623114224097435 - acc: 0.9526659412404788 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 5.0502028465271 - sq_loss: 1.094753770303214e-06 - tot_loss: 0.17715421457485547 - acc: 0.9526659412404788 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 5.15853214263916 - sq_loss: 1.0891403690038715e-06 - tot_loss: 0.15327944304293606 - acc: 0.9533460282916213 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 5.12860369682312 - sq_loss: 1.080232550521032e-06 - tot_loss: 0.17656775399364655 - acc: 0.9540261153427638 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 5.06042742729187 - sq_loss: 1.0762144029285992e-06 - tot_loss: 0.16588121896267882 - acc: 0.9544341675734495 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 5.05950927734375 - sq_loss: 1.0708353102018009e-06 - tot_loss: 0.16323701415803615 - acc: 0.9549782372143635 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 5.199328422546387 - sq_loss: 1.0673628594304319e-06 - tot_loss: 0.17906861340177915 - acc: 0.9552502720348205 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 5.0208516120910645 - sq_loss: 1.0645933343766956e-06 - tot_loss: 0.1637968458953445 - acc: 0.955386289445049 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 4.934342622756958 - sq_loss: 1.0636528031682246e-06 - tot_loss: 0.16781539293357906 - acc: 0.955386289445049 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 5.059542655944824 - sq_loss: 1.0613827043925994e-06 - tot_loss: 0.15936387130468432 - acc: 0.9557943416757345 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 5.038349866867065 - sq_loss: 1.0551401601333055e-06 - tot_loss: 0.16964766175636026 - acc: 0.95620239390642 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 5.088106393814087 - sq_loss: 1.051263552653836e-06 - tot_loss: 0.17069940891685942 - acc: 0.956474428726877 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 5.037719488143921 - sq_loss: 1.0475059752934612e-06 - tot_loss: 0.16557554640787764 - acc: 0.9568824809575626 - val_acc: 0.9345096708517137\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 5.011096000671387 - sq_loss: 1.044291707330558e-06 - tot_loss: 0.17293081143611566 - acc: 0.9572905331882481 - val_acc: 0.9345096708517137\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 5.163926124572754 - sq_loss: 1.0391306659585098e-06 - tot_loss: 0.16903555498390777 - acc: 0.9575625680087051 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 4.976707696914673 - sq_loss: 1.036820776789682e-06 - tot_loss: 0.1605669186549754 - acc: 0.9575625680087051 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 5.122724533081055 - sq_loss: 1.0325293260393664e-06 - tot_loss: 0.16272593292052306 - acc: 0.9581066376496191 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 5.225829124450684 - sq_loss: 1.0288254088663962e-06 - tot_loss: 0.16783254645850265 - acc: 0.9582426550598476 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 5.136121511459351 - sq_loss: 1.0243825272482354e-06 - tot_loss: 0.15909661203385284 - acc: 0.9583786724700761 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 5.119838714599609 - sq_loss: 1.0202805924564018e-06 - tot_loss: 0.15214742911586 - acc: 0.9582426550598476 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 5.1219987869262695 - sq_loss: 1.0133841215065331e-06 - tot_loss: 0.16176328473889878 - acc: 0.9589227421109902 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 5.044299364089966 - sq_loss: 1.0088207318403875e-06 - tot_loss: 0.1621192726606684 - acc: 0.9590587595212187 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 5.136575937271118 - sq_loss: 1.007987407319888e-06 - tot_loss: 0.16324852907067688 - acc: 0.9590587595212187 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 5.196040868759155 - sq_loss: 1.0071504448205815e-06 - tot_loss: 0.16334719999157254 - acc: 0.9590587595212187 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 5.069492816925049 - sq_loss: 1.0044278724308242e-06 - tot_loss: 0.15406326898155864 - acc: 0.9597388465723613 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 5.125603675842285 - sq_loss: 1.0007317996496568e-06 - tot_loss: 0.16547556410593423 - acc: 0.9598748639825898 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 4.981469392776489 - sq_loss: 9.96480480353057e-07 - tot_loss: 0.1641057878640595 - acc: 0.9600108813928183 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 5.13158392906189 - sq_loss: 9.944252497007255e-07 - tot_loss: 0.16072655096983368 - acc: 0.9606909684439608 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 4.9680914878845215 - sq_loss: 9.91826141216734e-07 - tot_loss: 0.16531559547770813 - acc: 0.9609630032644179 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 5.019374370574951 - sq_loss: 9.892011121337418e-07 - tot_loss: 0.16357150957102018 - acc: 0.9615070729053319 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 5.065738916397095 - sq_loss: 9.863255172604113e-07 - tot_loss: 0.16049905086151872 - acc: 0.9617791077257889 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 4.980987787246704 - sq_loss: 9.825581628319924e-07 - tot_loss: 0.17000524108599402 - acc: 0.9619151251360174 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 5.207764148712158 - sq_loss: 9.801842679735273e-07 - tot_loss: 0.16791240562672227 - acc: 0.9621871599564744 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 5.219730377197266 - sq_loss: 9.784820349523216e-07 - tot_loss: 0.17057396590741414 - acc: 0.9621871599564744 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 5.132540464401245 - sq_loss: 9.750681329023791e-07 - tot_loss: 0.16617825906659212 - acc: 0.9624591947769314 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 5.210897207260132 - sq_loss: 9.704576768854167e-07 - tot_loss: 0.1493002615553709 - acc: 0.9623231773667029 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 4.3455421924591064 - sq_loss: 9.682318022896652e-07 - tot_loss: 0.16025762236650465 - acc: 0.9625952121871599 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 3.270998001098633 - sq_loss: 9.66612674346834e-07 - tot_loss: 0.15366655754434388 - acc: 0.9630032644178455 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 3.1655359268188477 - sq_loss: 9.641646556701744e-07 - tot_loss: 0.16173470158577397 - acc: 0.9628672470076169 - val_acc: 0.9392602646759416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 3.2423088550567627 - sq_loss: 9.608518212189665e-07 - tot_loss: 0.16628539017309096 - acc: 0.9628672470076169 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 3.2040963172912598 - sq_loss: 9.582397524354747e-07 - tot_loss: 0.16945469109342204 - acc: 0.963411316648531 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 3.216423273086548 - sq_loss: 9.544411341266823e-07 - tot_loss: 0.16455096230503852 - acc: 0.9632752992383025 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 3.164005756378174 - sq_loss: 9.502323905508092e-07 - tot_loss: 0.17592927863622743 - acc: 0.963411316648531 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 3.260082960128784 - sq_loss: 9.472611282035359e-07 - tot_loss: 0.1780817493348188 - acc: 0.9635473340587595 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 3.1269092559814453 - sq_loss: 9.442240980206407e-07 - tot_loss: 0.16172081403432692 - acc: 0.9638193688792165 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 3.1980459690093994 - sq_loss: 9.409776566826622e-07 - tot_loss: 0.16856908456331166 - acc: 0.9639553862894451 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 3.2209184169769287 - sq_loss: 9.387937893734488e-07 - tot_loss: 0.14910717992065692 - acc: 0.9643634385201306 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 3.3019521236419678 - sq_loss: 9.387065915689163e-07 - tot_loss: 0.16268976326783458 - acc: 0.9650435255712732 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 3.24271297454834 - sq_loss: 9.354536132377689e-07 - tot_loss: 0.16712541817076154 - acc: 0.9654515778019587 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 3.1961658000946045 - sq_loss: 9.342550697510887e-07 - tot_loss: 0.1756707346298767 - acc: 0.9653155603917302 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 3.2471656799316406 - sq_loss: 9.325503356194531e-07 - tot_loss: 0.14861087509884463 - acc: 0.9653155603917302 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 3.264204978942871 - sq_loss: 9.303412298322655e-07 - tot_loss: 0.16410061456456582 - acc: 0.9654515778019587 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 3.2163493633270264 - sq_loss: 9.283048711949959e-07 - tot_loss: 0.16662064870609683 - acc: 0.9658596300326442 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 3.1737704277038574 - sq_loss: 9.251327810488874e-07 - tot_loss: 0.15896691694985066 - acc: 0.9658596300326442 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 3.22837233543396 - sq_loss: 9.235348557012912e-07 - tot_loss: 0.15755092567949447 - acc: 0.9661316648531012 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 3.24971866607666 - sq_loss: 9.209270501742139e-07 - tot_loss: 0.17144587924646615 - acc: 0.9662676822633297 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 3.2344014644622803 - sq_loss: 9.175940931527293e-07 - tot_loss: 0.1594257198689144 - acc: 0.9665397170837867 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 3.1880671977996826 - sq_loss: 9.144804380412097e-07 - tot_loss: 0.17254168300163908 - acc: 0.9669477693144722 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 3.253222703933716 - sq_loss: 9.109973575505137e-07 - tot_loss: 0.15387851570960365 - acc: 0.9670837867247007 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 3.1516058444976807 - sq_loss: 9.086438126360008e-07 - tot_loss: 0.15577117880089997 - acc: 0.9673558215451578 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 3.167027473449707 - sq_loss: 9.065167319022294e-07 - tot_loss: 0.14177650721963042 - acc: 0.9676278563656148 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 3.167996406555176 - sq_loss: 9.050966696122487e-07 - tot_loss: 0.17372337164485963 - acc: 0.9677638737758433 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 3.1293575763702393 - sq_loss: 9.036168080456264e-07 - tot_loss: 0.1535626431247885 - acc: 0.9681719260065288 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 3.138273000717163 - sq_loss: 9.015320188154874e-07 - tot_loss: 0.17036055121603066 - acc: 0.9681719260065288 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 3.2156364917755127 - sq_loss: 8.982058830042661e-07 - tot_loss: 0.1734373479923894 - acc: 0.9683079434167573 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 3.1980724334716797 - sq_loss: 8.957526915764902e-07 - tot_loss: 0.16195793997111085 - acc: 0.9681719260065288 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 3.18397855758667 - sq_loss: 8.933291724133596e-07 - tot_loss: 0.1516067053861172 - acc: 0.9684439608269858 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 3.2064075469970703 - sq_loss: 8.912847420106118e-07 - tot_loss: 0.1614177528217713 - acc: 0.9684439608269858 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 3.274226188659668 - sq_loss: 8.886641467142908e-07 - tot_loss: 0.1542396074072263 - acc: 0.9687159956474428 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 3.195319890975952 - sq_loss: 8.870105148162111e-07 - tot_loss: 0.16499444642907157 - acc: 0.9684439608269858 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 3.2435085773468018 - sq_loss: 8.851228017192625e-07 - tot_loss: 0.15779109903218158 - acc: 0.9688520130576714 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 3.1917812824249268 - sq_loss: 8.839956535666715e-07 - tot_loss: 0.1623524566789425 - acc: 0.9688520130576714 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 3.1294000148773193 - sq_loss: 8.821781989354349e-07 - tot_loss: 0.15845656934472307 - acc: 0.9688520130576714 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 3.2325127124786377 - sq_loss: 8.794795007815992e-07 - tot_loss: 0.18449844462732612 - acc: 0.9689880304678999 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 3.202364683151245 - sq_loss: 8.783183602645295e-07 - tot_loss: 0.16587184607577665 - acc: 0.9691240478781284 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 3.150341510772705 - sq_loss: 8.748743312025908e-07 - tot_loss: 0.16710553812722484 - acc: 0.969532100108814 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 3.1432602405548096 - sq_loss: 8.722880693312618e-07 - tot_loss: 0.15798962680296214 - acc: 0.9696681175190425 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 3.2340073585510254 - sq_loss: 8.695831752447702e-07 - tot_loss: 0.17114735871884745 - acc: 0.9696681175190425 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 3.151594400405884 - sq_loss: 8.663136554787343e-07 - tot_loss: 0.15354245486973683 - acc: 0.9699401523394995 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 3.295949697494507 - sq_loss: 8.658777801429096e-07 - tot_loss: 0.14407295897619887 - acc: 0.9699401523394995 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 3.235473871231079 - sq_loss: 8.642590501040104e-07 - tot_loss: 0.18368692765556993 - acc: 0.9699401523394995 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 3.201782703399658 - sq_loss: 8.616711397735344e-07 - tot_loss: 0.15031274388183347 - acc: 0.9702121871599565 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 3.2233190536499023 - sq_loss: 8.59593853874685e-07 - tot_loss: 0.16037835863171912 - acc: 0.970620239390642 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 3.1724278926849365 - sq_loss: 8.553833481528272e-07 - tot_loss: 0.1629866289155908 - acc: 0.970620239390642 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 3.2618021965026855 - sq_loss: 8.522428629476053e-07 - tot_loss: 0.15797696565104014 - acc: 0.9710282916213275 - val_acc: 0.9457074991516796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 3.117217779159546 - sq_loss: 8.501664865434577e-07 - tot_loss: 0.1564373897600433 - acc: 0.9715723612622416 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 3.1792988777160645 - sq_loss: 8.485967555316165e-07 - tot_loss: 0.15867999860029647 - acc: 0.9715723612622416 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 3.1569385528564453 - sq_loss: 8.447638606412511e-07 - tot_loss: 0.17082467853125882 - acc: 0.9718443960826986 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 3.306798219680786 - sq_loss: 8.433882499048195e-07 - tot_loss: 0.17277056093184484 - acc: 0.9719804134929271 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 3.2134835720062256 - sq_loss: 8.423354529440985e-07 - tot_loss: 0.16466232254087654 - acc: 0.9719804134929271 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 3.2141895294189453 - sq_loss: 8.40738493934623e-07 - tot_loss: 0.15814270497644234 - acc: 0.9721164309031556 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 3.190652847290039 - sq_loss: 8.406976803598809e-07 - tot_loss: 0.1448085019605192 - acc: 0.9721164309031556 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 3.2286245822906494 - sq_loss: 8.392636345888604e-07 - tot_loss: 0.14995458654608962 - acc: 0.9722524483133841 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 3.2919821739196777 - sq_loss: 8.376056257475284e-07 - tot_loss: 0.16447458023744765 - acc: 0.9725244831338411 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 3.217733860015869 - sq_loss: 8.347312814294128e-07 - tot_loss: 0.15678095187596286 - acc: 0.9726605005440696 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 3.1534364223480225 - sq_loss: 8.32366652048222e-07 - tot_loss: 0.15449982035824927 - acc: 0.9726605005440696 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 3.179560422897339 - sq_loss: 8.298905527226452e-07 - tot_loss: 0.16775068974659968 - acc: 0.9727965179542981 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 3.2516212463378906 - sq_loss: 8.290072059935483e-07 - tot_loss: 0.16813550452334036 - acc: 0.9727965179542981 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 3.1610987186431885 - sq_loss: 8.26791449526354e-07 - tot_loss: 0.1671922820206655 - acc: 0.9727965179542981 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 3.1944966316223145 - sq_loss: 8.251836902672949e-07 - tot_loss: 0.1575194670582638 - acc: 0.9727965179542981 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 3.227236747741699 - sq_loss: 8.238723694375949e-07 - tot_loss: 0.1519200143188142 - acc: 0.9727965179542981 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 3.1082565784454346 - sq_loss: 8.226249974541133e-07 - tot_loss: 0.15358100079120662 - acc: 0.9727965179542981 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 3.1894125938415527 - sq_loss: 8.203228958336695e-07 - tot_loss: 0.16224706789584675 - acc: 0.9729325353645266 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 3.237071990966797 - sq_loss: 8.196309408958768e-07 - tot_loss: 0.14924134570489245 - acc: 0.9730685527747551 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 3.1825220584869385 - sq_loss: 8.180487043318863e-07 - tot_loss: 0.15557264462099418 - acc: 0.9732045701849836 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 3.1583361625671387 - sq_loss: 8.160812967616948e-07 - tot_loss: 0.17294766303692755 - acc: 0.9733405875952121 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 3.1301751136779785 - sq_loss: 8.137474196701078e-07 - tot_loss: 0.1480409650394503 - acc: 0.9736126224156693 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 3.195460081100464 - sq_loss: 8.110089311230695e-07 - tot_loss: 0.1729612573606658 - acc: 0.9737486398258978 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 3.221445322036743 - sq_loss: 8.102559263534204e-07 - tot_loss: 0.16317213877144043 - acc: 0.9738846572361263 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 3.2002923488616943 - sq_loss: 8.077573738773935e-07 - tot_loss: 0.15563535563131214 - acc: 0.9738846572361263 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 3.1556670665740967 - sq_loss: 8.052845146266918e-07 - tot_loss: 0.16371568288952876 - acc: 0.9738846572361263 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 3.2622225284576416 - sq_loss: 8.040285592869623e-07 - tot_loss: 0.16089887906354416 - acc: 0.9742927094668118 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 3.1712050437927246 - sq_loss: 8.034406278056849e-07 - tot_loss: 0.135759859022752 - acc: 0.9742927094668118 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 3.231475591659546 - sq_loss: 8.005464451343869e-07 - tot_loss: 0.15591800495469554 - acc: 0.9742927094668118 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 3.161010503768921 - sq_loss: 7.978110261319671e-07 - tot_loss: 0.15933429977162383 - acc: 0.9741566920565833 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 3.201216220855713 - sq_loss: 7.964634392010339e-07 - tot_loss: 0.14622285417386216 - acc: 0.9741566920565833 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 3.275031805038452 - sq_loss: 7.968105819600169e-07 - tot_loss: 0.16744738050129748 - acc: 0.9742927094668118 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 3.190763473510742 - sq_loss: 7.965734880599484e-07 - tot_loss: 0.1559865061807344 - acc: 0.9741566920565833 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 3.220651388168335 - sq_loss: 7.960335892676085e-07 - tot_loss: 0.16596444316767944 - acc: 0.9742927094668118 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 3.242661237716675 - sq_loss: 7.943778541630309e-07 - tot_loss: 0.15581942068142252 - acc: 0.9744287268770403 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 3.2425198554992676 - sq_loss: 7.92631567492208e-07 - tot_loss: 0.1699600667606871 - acc: 0.9747007616974973 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 3.2706737518310547 - sq_loss: 7.919643394416198e-07 - tot_loss: 0.16977781467177766 - acc: 0.9749727965179543 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 3.229755401611328 - sq_loss: 7.905769621174841e-07 - tot_loss: 0.15057149225289712 - acc: 0.9752448313384113 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 3.24678111076355 - sq_loss: 7.888559139246354e-07 - tot_loss: 0.16373756936100015 - acc: 0.9751088139281828 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 3.236327648162842 - sq_loss: 7.850281917853863e-07 - tot_loss: 0.15799858974150416 - acc: 0.9752448313384113 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 3.2764718532562256 - sq_loss: 7.833141921764764e-07 - tot_loss: 0.16124873360472614 - acc: 0.9753808487486398 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 3.1779062747955322 - sq_loss: 7.813220577190805e-07 - tot_loss: 0.1675092174358681 - acc: 0.9755168661588683 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 3.201338768005371 - sq_loss: 7.787267009007337e-07 - tot_loss: 0.18542100573117537 - acc: 0.9755168661588683 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 3.3029465675354004 - sq_loss: 7.794614020895096e-07 - tot_loss: 0.16272287136361174 - acc: 0.9757889009793254 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 3.1728904247283936 - sq_loss: 7.775497010698018e-07 - tot_loss: 0.1734369567631322 - acc: 0.9757889009793254 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 3.2439467906951904 - sq_loss: 7.768625778226124e-07 - tot_loss: 0.15675417709189143 - acc: 0.9756528835690969 - val_acc: 0.9507974211062097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 3.2279200553894043 - sq_loss: 7.762483846818213e-07 - tot_loss: 0.16437227180869285 - acc: 0.9759249183895539 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 3.2224624156951904 - sq_loss: 7.745174457340909e-07 - tot_loss: 0.18267774586230945 - acc: 0.9760609357997824 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 3.01023530960083 - sq_loss: 7.719679047113459e-07 - tot_loss: 0.16358278429962603 - acc: 0.9760609357997824 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 1.5449066162109375 - sq_loss: 7.691417067690054e-07 - tot_loss: 0.18231415784642113 - acc: 0.9760609357997824 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 1.5467078685760498 - sq_loss: 7.663351766495907e-07 - tot_loss: 0.1501851885969303 - acc: 0.9764689880304679 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 1.5598742961883545 - sq_loss: 7.646114568160556e-07 - tot_loss: 0.16064280166491174 - acc: 0.9764689880304679 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 1.5296499729156494 - sq_loss: 7.628792104696913e-07 - tot_loss: 0.14531390792779897 - acc: 0.9764689880304679 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 1.5471282005310059 - sq_loss: 7.610454986206605e-07 - tot_loss: 0.16277744850423903 - acc: 0.9764689880304679 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 1.5365221500396729 - sq_loss: 7.599119271617383e-07 - tot_loss: 0.1451921917208907 - acc: 0.9764689880304679 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 1.555480718612671 - sq_loss: 7.600972367072245e-07 - tot_loss: 0.14345369275190123 - acc: 0.9764689880304679 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 1.5443751811981201 - sq_loss: 7.587324830637954e-07 - tot_loss: 0.17179769458254457 - acc: 0.9764689880304679 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 1.5781195163726807 - sq_loss: 7.572958224955073e-07 - tot_loss: 0.15073660874543493 - acc: 0.9764689880304679 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 1.548708200454712 - sq_loss: 7.550214604634675e-07 - tot_loss: 0.1572219895485043 - acc: 0.9764689880304679 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 1.5568418502807617 - sq_loss: 7.5348248174123e-07 - tot_loss: 0.17118860707821137 - acc: 0.9764689880304679 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 1.5537381172180176 - sq_loss: 7.512526849495771e-07 - tot_loss: 0.15804660442526264 - acc: 0.9764689880304679 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 1.571603536605835 - sq_loss: 7.497654905819218e-07 - tot_loss: 0.15617800750097488 - acc: 0.9766050054406964 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 1.558314323425293 - sq_loss: 7.481753527827095e-07 - tot_loss: 0.1582008968885804 - acc: 0.9767410228509249 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 1.5617165565490723 - sq_loss: 7.458691015926888e-07 - tot_loss: 0.15414912248407053 - acc: 0.9768770402611534 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 1.5510752201080322 - sq_loss: 7.443852609867463e-07 - tot_loss: 0.16832967154277845 - acc: 0.9767410228509249 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 1.5379748344421387 - sq_loss: 7.429763400068623e-07 - tot_loss: 0.1816277952808838 - acc: 0.9770130576713819 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 1.5765235424041748 - sq_loss: 7.426506840602087e-07 - tot_loss: 0.17146548851149968 - acc: 0.9770130576713819 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 1.5587458610534668 - sq_loss: 7.424459340654721e-07 - tot_loss: 0.1621115617476896 - acc: 0.9772850924918389 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 1.5631237030029297 - sq_loss: 7.417373808493721e-07 - tot_loss: 0.1597414128486052 - acc: 0.9775571273122959 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 1.5914795398712158 - sq_loss: 7.40035716262355e-07 - tot_loss: 0.15948794084574658 - acc: 0.9774211099020674 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 1.5818848609924316 - sq_loss: 7.383296178886667e-07 - tot_loss: 0.15737803677014317 - acc: 0.9775571273122959 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 1.5585639476776123 - sq_loss: 7.363073564192746e-07 - tot_loss: 0.16996802482807416 - acc: 0.9776931447225244 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 1.5756092071533203 - sq_loss: 7.353563660217333e-07 - tot_loss: 0.15999658763356495 - acc: 0.9779651795429815 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 1.5680255889892578 - sq_loss: 7.355300795097719e-07 - tot_loss: 0.15967349542467102 - acc: 0.97810119695321 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 1.562990665435791 - sq_loss: 7.344275445575477e-07 - tot_loss: 0.16924509324209613 - acc: 0.97810119695321 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 1.5581209659576416 - sq_loss: 7.329772984121519e-07 - tot_loss: 0.1710551598611172 - acc: 0.97810119695321 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 1.55460786819458 - sq_loss: 7.303876259356912e-07 - tot_loss: 0.16282560472142427 - acc: 0.9783732317736671 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 1.5467360019683838 - sq_loss: 7.282580440914899e-07 - tot_loss: 0.15100351676641788 - acc: 0.9782372143634385 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 1.5249886512756348 - sq_loss: 7.280335125869897e-07 - tot_loss: 0.1479678995009952 - acc: 0.9785092491838956 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 1.5671098232269287 - sq_loss: 7.265259682753822e-07 - tot_loss: 0.15612661702275754 - acc: 0.9785092491838956 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 1.5619220733642578 - sq_loss: 7.25165307358111e-07 - tot_loss: 0.1579550828388807 - acc: 0.9786452665941241 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 1.5318422317504883 - sq_loss: 7.242040283017559e-07 - tot_loss: 0.18485369941314378 - acc: 0.9786452665941241 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 1.543137550354004 - sq_loss: 7.233617793644953e-07 - tot_loss: 0.15557252683548284 - acc: 0.9786452665941241 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 1.542823076248169 - sq_loss: 7.240724357870931e-07 - tot_loss: 0.16185015470894237 - acc: 0.9786452665941241 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 1.5603373050689697 - sq_loss: 7.231245717775892e-07 - tot_loss: 0.16205135574907148 - acc: 0.9789173014145811 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 1.5434248447418213 - sq_loss: 7.209235945992987e-07 - tot_loss: 0.1650463087591969 - acc: 0.9789173014145811 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 1.552119493484497 - sq_loss: 7.18862338544568e-07 - tot_loss: 0.15886950560773205 - acc: 0.9790533188248096 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 1.552180290222168 - sq_loss: 7.172298523983045e-07 - tot_loss: 0.17406158615089629 - acc: 0.9790533188248096 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 1.5468997955322266 - sq_loss: 7.160790573834674e-07 - tot_loss: 0.18782507430183748 - acc: 0.9790533188248096 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 1.563286542892456 - sq_loss: 7.1538784141012e-07 - tot_loss: 0.17022620984492143 - acc: 0.9794613710554951 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 1.5323011875152588 - sq_loss: 7.146135203583981e-07 - tot_loss: 0.1615504873594127 - acc: 0.9793253536452666 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 1.5317211151123047 - sq_loss: 7.131665142878774e-07 - tot_loss: 0.1610729553700525 - acc: 0.9794613710554951 - val_acc: 0.9535120461486257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 1.5436627864837646 - sq_loss: 7.109979378583375e-07 - tot_loss: 0.16535616168847045 - acc: 0.9795973884657236 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 1.5520658493041992 - sq_loss: 7.091869065334322e-07 - tot_loss: 0.1758541185534026 - acc: 0.9797334058759521 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 1.5567665100097656 - sq_loss: 7.085906190695823e-07 - tot_loss: 0.17569619305857853 - acc: 0.9798694232861807 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 1.5527708530426025 - sq_loss: 7.070043466228526e-07 - tot_loss: 0.15799502095114182 - acc: 0.9798694232861807 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 1.532303810119629 - sq_loss: 7.061863698254456e-07 - tot_loss: 0.16684545455362643 - acc: 0.9798694232861807 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 1.5200815200805664 - sq_loss: 7.047611347843485e-07 - tot_loss: 0.16890061968549297 - acc: 0.9800054406964092 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 1.5576369762420654 - sq_loss: 7.040248988232634e-07 - tot_loss: 0.16911614707045963 - acc: 0.9802774755168662 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 1.5523109436035156 - sq_loss: 7.027738888609747e-07 - tot_loss: 0.1656634623761699 - acc: 0.9801414581066377 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 1.5702698230743408 - sq_loss: 7.004198891991109e-07 - tot_loss: 0.15348128192631805 - acc: 0.9804134929270947 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 1.5572946071624756 - sq_loss: 6.999439960964082e-07 - tot_loss: 0.1713737236607895 - acc: 0.9802774755168662 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 1.5440645217895508 - sq_loss: 6.982894547036267e-07 - tot_loss: 0.15297624171768986 - acc: 0.9805495103373232 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 1.5586204528808594 - sq_loss: 6.967698595872207e-07 - tot_loss: 0.16437893979260898 - acc: 0.9805495103373232 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 1.5793542861938477 - sq_loss: 6.954692253202666e-07 - tot_loss: 0.153901756587433 - acc: 0.9806855277475517 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 1.5547804832458496 - sq_loss: 6.956919378353632e-07 - tot_loss: 0.1508198398505265 - acc: 0.9808215451577802 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 1.5392053127288818 - sq_loss: 6.943971584405517e-07 - tot_loss: 0.16201605083563808 - acc: 0.9808215451577802 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 1.5216310024261475 - sq_loss: 6.924853437340062e-07 - tot_loss: 0.15907349459850773 - acc: 0.9809575625680087 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 1.535895824432373 - sq_loss: 6.912408139214676e-07 - tot_loss: 0.1555285323725344 - acc: 0.9808215451577802 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 1.593005657196045 - sq_loss: 6.904906513227616e-07 - tot_loss: 0.16175601130597483 - acc: 0.9809575625680087 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 1.5390024185180664 - sq_loss: 6.890225563438435e-07 - tot_loss: 0.1725247418415714 - acc: 0.9810935799782372 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 1.5110580921173096 - sq_loss: 6.878360636619618e-07 - tot_loss: 0.17959451953714245 - acc: 0.9810935799782372 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 1.5601041316986084 - sq_loss: 6.867886668260326e-07 - tot_loss: 0.14576037407740805 - acc: 0.9810935799782372 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 1.555769443511963 - sq_loss: 6.859563654870726e-07 - tot_loss: 0.15108372980214368 - acc: 0.9812295973884657 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 1.552870512008667 - sq_loss: 6.845718871772988e-07 - tot_loss: 0.16131003213724293 - acc: 0.9810935799782372 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 1.5762240886688232 - sq_loss: 6.838558306299092e-07 - tot_loss: 0.1567228042133142 - acc: 0.9810935799782372 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 1.5525486469268799 - sq_loss: 6.816470659032348e-07 - tot_loss: 0.16355632119254926 - acc: 0.9815016322089227 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 1.5569894313812256 - sq_loss: 6.808488137721724e-07 - tot_loss: 0.1575251436794629 - acc: 0.9815016322089227 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 1.5628492832183838 - sq_loss: 6.793393936277425e-07 - tot_loss: 0.1776345784925546 - acc: 0.9815016322089227 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 1.5384576320648193 - sq_loss: 6.787675488340028e-07 - tot_loss: 0.17568826945492 - acc: 0.9816376496191512 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 1.5384440422058105 - sq_loss: 6.779638397347298e-07 - tot_loss: 0.1571354421197817 - acc: 0.9816376496191512 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 1.5426111221313477 - sq_loss: 6.768673301849049e-07 - tot_loss: 0.15365694029474852 - acc: 0.9816376496191512 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 1.5337514877319336 - sq_loss: 6.758800168427115e-07 - tot_loss: 0.15812671462691075 - acc: 0.9819096844396082 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 1.527557611465454 - sq_loss: 6.751233172508364e-07 - tot_loss: 0.16569507603852607 - acc: 0.9819096844396082 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 1.5450823307037354 - sq_loss: 6.741664151377336e-07 - tot_loss: 0.1543232415890725 - acc: 0.9815016322089227 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 1.5562620162963867 - sq_loss: 6.731290795869427e-07 - tot_loss: 0.1802635860904056 - acc: 0.9817736670293797 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 1.5152950286865234 - sq_loss: 6.727075287926709e-07 - tot_loss: 0.15830369735202998 - acc: 0.9819096844396082 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 1.5225980281829834 - sq_loss: 6.726340302520839e-07 - tot_loss: 0.17827446069235786 - acc: 0.9816376496191512 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 1.5414955615997314 - sq_loss: 6.718014446960296e-07 - tot_loss: 0.15984399485677026 - acc: 0.9819096844396082 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 1.5449750423431396 - sq_loss: 6.7034090989182e-07 - tot_loss: 0.16968174360086086 - acc: 0.9819096844396082 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 1.5614466667175293 - sq_loss: 6.696905074932147e-07 - tot_loss: 0.1666380089631132 - acc: 0.9819096844396082 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 1.5436112880706787 - sq_loss: 6.684642244181305e-07 - tot_loss: 0.16093376105024082 - acc: 0.9820457018498367 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 1.5417964458465576 - sq_loss: 6.685945663775783e-07 - tot_loss: 0.15414348024144497 - acc: 0.9821817192600653 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 1.542494773864746 - sq_loss: 6.68825407501572e-07 - tot_loss: 0.1607789143545444 - acc: 0.9820457018498367 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 1.5456185340881348 - sq_loss: 6.672416361652722e-07 - tot_loss: 0.15260577849489976 - acc: 0.9823177366702938 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 1.5269854068756104 - sq_loss: 6.657585913671937e-07 - tot_loss: 0.15908640785069061 - acc: 0.9823177366702938 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 1.5146949291229248 - sq_loss: 6.643260803684825e-07 - tot_loss: 0.15897216155929317 - acc: 0.9823177366702938 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 1.512162208557129 - sq_loss: 6.626274853260838e-07 - tot_loss: 0.15272245432298037 - acc: 0.9823177366702938 - val_acc: 0.9541907024092298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 1.5218446254730225 - sq_loss: 6.618114412049181e-07 - tot_loss: 0.17833529414497584 - acc: 0.9823177366702938 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 1.5465373992919922 - sq_loss: 6.609977845073445e-07 - tot_loss: 0.15509233221579533 - acc: 0.9823177366702938 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 1.5188405513763428 - sq_loss: 6.609541856050782e-07 - tot_loss: 0.16959787801775517 - acc: 0.9821817192600653 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 1.5645525455474854 - sq_loss: 6.59040608752548e-07 - tot_loss: 0.16899065098689192 - acc: 0.9824537540805223 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 1.5319688320159912 - sq_loss: 6.575300517397409e-07 - tot_loss: 0.17205564606094637 - acc: 0.9823177366702938 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 1.5541071891784668 - sq_loss: 6.565289254467643e-07 - tot_loss: 0.17195714129198247 - acc: 0.9824537540805223 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 1.5352783203125 - sq_loss: 6.550485522893723e-07 - tot_loss: 0.15144874382344975 - acc: 0.9824537540805223 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 1.5323610305786133 - sq_loss: 6.544142934217234e-07 - tot_loss: 0.16547462652829337 - acc: 0.9824537540805223 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 1.5509686470031738 - sq_loss: 6.530593736897572e-07 - tot_loss: 0.14287542890582539 - acc: 0.9824537540805223 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 1.5667576789855957 - sq_loss: 6.51075936275447e-07 - tot_loss: 0.16739304426282686 - acc: 0.9823177366702938 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 1.5084152221679688 - sq_loss: 6.502212954728748e-07 - tot_loss: 0.1588667932582608 - acc: 0.9824537540805223 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 1.5514590740203857 - sq_loss: 6.504859584310907e-07 - tot_loss: 0.16216973942421586 - acc: 0.9823177366702938 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 1.5155754089355469 - sq_loss: 6.504629368464521e-07 - tot_loss: 0.19346294170912026 - acc: 0.9823177366702938 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 1.53422212600708 - sq_loss: 6.489335078185832e-07 - tot_loss: 0.14840223259550211 - acc: 0.9823177366702938 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 1.5511925220489502 - sq_loss: 6.481831178462016e-07 - tot_loss: 0.17356327957686757 - acc: 0.9823177366702938 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 1.5300400257110596 - sq_loss: 6.4727555582067e-07 - tot_loss: 0.1726973394777187 - acc: 0.9823177366702938 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 1.5470502376556396 - sq_loss: 6.468023343586538e-07 - tot_loss: 0.173228330893892 - acc: 0.9823177366702938 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 1.5549311637878418 - sq_loss: 6.46513910851354e-07 - tot_loss: 0.16869151867612886 - acc: 0.9820457018498367 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 1.5562677383422852 - sq_loss: 6.454188223870005e-07 - tot_loss: 0.16743115466635983 - acc: 0.9821817192600653 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 1.5488193035125732 - sq_loss: 6.436454782487999e-07 - tot_loss: 0.16841468797634684 - acc: 0.9820457018498367 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 1.538128137588501 - sq_loss: 6.425160563594545e-07 - tot_loss: 0.1618905467104672 - acc: 0.9819096844396082 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 1.5662732124328613 - sq_loss: 6.410452328964311e-07 - tot_loss: 0.16112096472125415 - acc: 0.9820457018498367 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 1.580172061920166 - sq_loss: 6.392064619831217e-07 - tot_loss: 0.16884351189664315 - acc: 0.9819096844396082 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 1.5576908588409424 - sq_loss: 6.384086077559914e-07 - tot_loss: 0.16643823831627547 - acc: 0.9820457018498367 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 1.5373098850250244 - sq_loss: 6.373574592544173e-07 - tot_loss: 0.1604080630267415 - acc: 0.9820457018498367 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 1.5372743606567383 - sq_loss: 6.369322704813385e-07 - tot_loss: 0.16972176898682223 - acc: 0.9823177366702938 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 1.5525617599487305 - sq_loss: 6.36664992725855e-07 - tot_loss: 0.15079968636627417 - acc: 0.9823177366702938 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 1.533407211303711 - sq_loss: 6.362490125866316e-07 - tot_loss: 0.17333140865710028 - acc: 0.9825897714907508 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 1.5399351119995117 - sq_loss: 6.35708943264035e-07 - tot_loss: 0.16168400071943223 - acc: 0.9824537540805223 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 1.5328316688537598 - sq_loss: 6.337767786135373e-07 - tot_loss: 0.16295321506772542 - acc: 0.9821817192600653 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 1.5735011100769043 - sq_loss: 6.333257260848768e-07 - tot_loss: 0.1513412465455387 - acc: 0.9824537540805223 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 1.5635244846343994 - sq_loss: 6.323963930299215e-07 - tot_loss: 0.13526461820359503 - acc: 0.9823177366702938 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 1.5423226356506348 - sq_loss: 6.308536057986203e-07 - tot_loss: 0.17933846311758972 - acc: 0.9823177366702938 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 1.5482161045074463 - sq_loss: 6.302181532191753e-07 - tot_loss: 0.16001149854995722 - acc: 0.9824537540805223 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 1.5355026721954346 - sq_loss: 6.289054681474227e-07 - tot_loss: 0.16914006905082568 - acc: 0.9823177366702938 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 1.522634506225586 - sq_loss: 6.286867915150651e-07 - tot_loss: 0.17987103369600677 - acc: 0.9823177366702938 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 1.5430359840393066 - sq_loss: 6.27541339781601e-07 - tot_loss: 0.17444575722241806 - acc: 0.9821817192600653 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 1.5257987976074219 - sq_loss: 6.269967229854956e-07 - tot_loss: 0.15609792373249154 - acc: 0.9823177366702938 - val_acc: 0.9552086868001357\n",
      "CR_1 = 0.17665842270710058   CR_2 = 0.17592699696476163\n",
      "/home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 3\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "alpha = 1\n",
    "\n",
    "\n",
    "\n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "    d0 = 561 #561 =3*11*17\n",
    "\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 512\n",
    "    d6 = 6 \n",
    "\n",
    "\n",
    "    limit = torch.sqrt(torch.tensor(3. / d0))\n",
    "    W1 = 0.2* torch.empty(d1, d0, device=device).uniform_(-limit, limit)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    limit = torch.sqrt(torch.tensor(3. / d1))\n",
    "    W2 = 0.2* torch.empty(d2, d1, device=device).uniform_(-limit, limit)\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles factors, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    limit = torch.sqrt(torch.tensor(3. / d2))\n",
    "    W3 = 0.2* torch.empty(d3, d2, device=device).uniform_(-limit, limit)\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    limit = torch.sqrt(torch.tensor(3. / d3))\n",
    "    W4 = 0.2* torch.empty(d4, d3, device=device).uniform_(-limit, limit)\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    limit = torch.sqrt(torch.tensor(3. / d4))\n",
    "    W5 = 0.2* torch.empty(d5, d4, device=device).uniform_(-limit, limit)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "    W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())\n",
    "    factors5 = tensor_train(W5_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "\n",
    "    limit = torch.sqrt(torch.tensor(3. / d5))\n",
    "    W6 = 0.2* torch.empty(d6, d5, device=device).uniform_(-limit, limit)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "    b6 = 0*torch.ones(d6, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = nn.ReLU()(U5)\n",
    "    U6 = torch.addmm(b6.repeat(1, N), W6, V5)\n",
    "    V6 = U6 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V6 = (y_one_hot + gamma*U6 + alpha*V6)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U6 = (gamma*V6 + rho*(torch.mm(W6,V5) + b6.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W6, b6 = updateWb_org(U6,V5,W6,b6,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "        # update for 5th layer\n",
    "        # update V3\n",
    "        V5 = updateV(U5,U6,W6,b6,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U5 = relu_prox(V5,(rho*torch.addmm(b5.repeat(1,N), W5, V4) + alpha*U5)/(rho + alpha),(rho + alpha)/gamma,d5,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W5, b5 = updateWb(U5,V4,W5,b5,W5_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4))\n",
    "        W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors5 = tensor_train(W5_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        a5_train = nn.ReLU()(torch.addmm(b5.repeat(1, N), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b6.repeat(1, N), W6, a5_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        a5_test = nn.ReLU()(torch.addmm(b5.repeat(1, N_test), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b6.repeat(1, N_test), W6, a5_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V6,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b6.repeat(1,N), W6, V5),U6,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,nn.ReLU()(U5),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V6,U6,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W5.reshape((4,4,4,4,4,4,4,4,4)),torch.as_tensor(W5_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "    factors5_shape=[f.shape for f in factors5]\n",
    "    Sum_of_variables_factors5=sum(list(x*y*z for x,y,z in factors5_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4+Sum_of_variables_factors5\n",
    "\n",
    "    CR_1=((total_variabels)+(d5*d6))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5+d5*d6)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#     #this postion to add new row into existing table\n",
    "#         df=pd.read_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "#         new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "#                    'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "#                    'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1],'seed':seed} \n",
    "#         df=df.append(new_row,ignore_index=True)\n",
    "#         df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"LecunUniform_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133d333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
