{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4cb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a157bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a5c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087d0e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 3 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 1.5286130905151367 - sq_loss: 661.6843872070312 - tot_loss: 922.2364956646816 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 1.4654662609100342 - sq_loss: 294.0819396972656 - tot_loss: 482.30420965049416 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 1.4816415309906006 - sq_loss: 164.40667724609375 - tot_loss: 262.13626398239285 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 1.4714395999908447 - sq_loss: 89.64942169189453 - tot_loss: 146.10560800880194 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 1.5000660419464111 - sq_loss: 48.30636215209961 - tot_loss: 83.86332913918886 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 1.4661533832550049 - sq_loss: 25.925268173217773 - tot_loss: 50.23375971743371 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 1.4478199481964111 - sq_loss: 13.919182777404785 - tot_loss: 31.911546374089085 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 1.4496955871582031 - sq_loss: 7.497280597686768 - tot_loss: 21.785973492776975 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 1.4704482555389404 - sq_loss: 4.0603742599487305 - tot_loss: 16.053173587541096 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 1.4402093887329102 - sq_loss: 2.2158493995666504 - tot_loss: 12.671211569628213 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 1.4804236888885498 - sq_loss: 1.221468210220337 - tot_loss: 10.551158203044906 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 1.4649217128753662 - sq_loss: 0.6820798516273499 - tot_loss: 9.119180296955165 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 1.4408893585205078 - sq_loss: 0.387130469083786 - tot_loss: 8.04763311627903 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 1.4661273956298828 - sq_loss: 0.2241830974817276 - tot_loss: 7.200282262725523 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 1.4742915630340576 - sq_loss: 0.13298939168453217 - tot_loss: 6.507444195027347 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 1.4804482460021973 - sq_loss: 0.08113127201795578 - tot_loss: 5.91807118748693 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 1.4593505859375 - sq_loss: 0.05107306316494942 - tot_loss: 5.422262654203223 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 1.4621944427490234 - sq_loss: 0.03325873613357544 - tot_loss: 4.983599038852844 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 1.465745449066162 - sq_loss: 0.02244020625948906 - tot_loss: 4.591332613956183 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 1.4463448524475098 - sq_loss: 0.01568986102938652 - tot_loss: 4.252472143096384 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 1.456176996231079 - sq_loss: 0.011358845978975296 - tot_loss: 3.9664640314149437 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 1.449173927307129 - sq_loss: 0.008497951552271843 - tot_loss: 3.683614262343326 - acc: 0.18797606093579977 - val_acc: 0.1825585341024771\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 1.457136631011963 - sq_loss: 0.0065522813238203526 - tot_loss: 3.4534950903762365 - acc: 0.20321001088139282 - val_acc: 0.19545300305395316\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 1.4368431568145752 - sq_loss: 0.005190536379814148 - tot_loss: 3.2416643313190434 - acc: 0.2411588683351469 - val_acc: 0.2297251442144554\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 1.466341257095337 - sq_loss: 0.004211809486150742 - tot_loss: 3.0561458871816285 - acc: 0.28618063112078346 - val_acc: 0.2670512385476756\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 1.4722118377685547 - sq_loss: 0.003489434253424406 - tot_loss: 2.883737987242057 - acc: 0.3254896626768226 - val_acc: 0.30641330166270786\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 1.4441888332366943 - sq_loss: 0.0029429011046886444 - tot_loss: 2.7290697704993363 - acc: 0.3397714907508161 - val_acc: 0.334916864608076\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 1.4427995681762695 - sq_loss: 0.002519909990951419 - tot_loss: 2.586224675284029 - acc: 0.367791077257889 - val_acc: 0.35799117746861214\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 1.4557559490203857 - sq_loss: 0.0021849193144589663 - tot_loss: 2.455944008055667 - acc: 0.44885745375408054 - val_acc: 0.44248388191381066\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 1.4602160453796387 - sq_loss: 0.001914981403388083 - tot_loss: 2.3379582631132507 - acc: 0.52189880304679 - val_acc: 0.504580929759077\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 1.4601762294769287 - sq_loss: 0.0016939111519604921 - tot_loss: 2.225888810426113 - acc: 0.5401251360174102 - val_acc: 0.5167967424499491\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 1.4677879810333252 - sq_loss: 0.0015095649287104607 - tot_loss: 2.1296921507673687 - acc: 0.5432535364526659 - val_acc: 0.5252799457074991\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 1.4645252227783203 - sq_loss: 0.0013543530367314816 - tot_loss: 2.042774000812642 - acc: 0.5442056583242655 - val_acc: 0.5303698676620292\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 1.4490294456481934 - sq_loss: 0.0012219683267176151 - tot_loss: 1.9473965154174948 - acc: 0.544613710554951 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 1.4496943950653076 - sq_loss: 0.0011076831724494696 - tot_loss: 1.8584288337551698 - acc: 0.544613710554951 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 1.4759647846221924 - sq_loss: 0.0010085412068292499 - tot_loss: 1.7839413956317003 - acc: 0.544613710554951 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 1.4630775451660156 - sq_loss: 0.0009219382773153484 - tot_loss: 1.7155958589682996 - acc: 0.544613710554951 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 1.4656190872192383 - sq_loss: 0.0008454188937321305 - tot_loss: 1.6569226890478603 - acc: 0.5444776931447225 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 1.4691309928894043 - sq_loss: 0.0007777543505653739 - tot_loss: 1.5894331219460582 - acc: 0.5444776931447225 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 1.4450039863586426 - sq_loss: 0.0007173343328759074 - tot_loss: 1.5319496265874477 - acc: 0.5444776931447225 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 1.4638028144836426 - sq_loss: 0.0006631986470893025 - tot_loss: 1.4782746016644523 - acc: 0.544613710554951 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 1.4641151428222656 - sq_loss: 0.0006145364604890347 - tot_loss: 1.4245313965911919 - acc: 0.544613710554951 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 1.4442849159240723 - sq_loss: 0.0005703965434804559 - tot_loss: 1.3581755274935858 - acc: 0.544613710554951 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 1.4610397815704346 - sq_loss: 0.0005307429819367826 - tot_loss: 1.323781070552286 - acc: 0.544885745375408 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 1.4713757038116455 - sq_loss: 0.0004946325207129121 - tot_loss: 1.2791609206178691 - acc: 0.5457018498367792 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 1.4197936058044434 - sq_loss: 0.0004615062498487532 - tot_loss: 1.2258856949738401 - acc: 0.5466539717083787 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 1.4427533149719238 - sq_loss: 0.00043139036279171705 - tot_loss: 1.1856311856172397 - acc: 0.5481501632208923 - val_acc: 0.5307091957923312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 1.477961778640747 - sq_loss: 0.0004037957696709782 - tot_loss: 1.1406581981791533 - acc: 0.5496463547334058 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 1.4511003494262695 - sq_loss: 0.00037843812606297433 - tot_loss: 1.098040443370337 - acc: 0.5531828073993471 - val_acc: 0.5317271801832372\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 1.443232774734497 - sq_loss: 0.00035502167884260416 - tot_loss: 1.0696935787736948 - acc: 0.5602557127312296 - val_acc: 0.5334238208347472\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 1.4591917991638184 - sq_loss: 0.000333524018060416 - tot_loss: 1.0321283058065092 - acc: 0.5710010881392819 - val_acc: 0.5395317271801833\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 1.465620756149292 - sq_loss: 0.00031350846984423697 - tot_loss: 0.9979093781967094 - acc: 0.5888193688792165 - val_acc: 0.5493722429589413\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 1.455549716949463 - sq_loss: 0.0002950486377812922 - tot_loss: 0.9729377162875608 - acc: 0.6093579978237215 - val_acc: 0.5656599932134374\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 1.438380479812622 - sq_loss: 0.00027785764541476965 - tot_loss: 0.9356449294627964 - acc: 0.6322089227421109 - val_acc: 0.5853410247709535\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 1.479245662689209 - sq_loss: 0.00026175487437285483 - tot_loss: 0.8965807252770901 - acc: 0.6580522306855278 - val_acc: 0.6019681031557517\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 1.449709177017212 - sq_loss: 0.0002469955070409924 - tot_loss: 0.8756962778079469 - acc: 0.6791349292709467 - val_acc: 0.6152019002375297\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 1.4578006267547607 - sq_loss: 0.00023325566144194454 - tot_loss: 0.8514230762602892 - acc: 0.6962731229597389 - val_acc: 0.6321683067526298\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 1.4543163776397705 - sq_loss: 0.0002203766198363155 - tot_loss: 0.8149287830192407 - acc: 0.713683351468988 - val_acc: 0.6457414319647099\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 1.4431867599487305 - sq_loss: 0.00020824195235036314 - tot_loss: 0.7970569737499318 - acc: 0.7260609357997824 - val_acc: 0.656939260264676\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 1.4699954986572266 - sq_loss: 0.000196893306565471 - tot_loss: 0.7608728205432271 - acc: 0.7354461371055495 - val_acc: 0.66949440108585\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 1.4487013816833496 - sq_loss: 0.0001863113429863006 - tot_loss: 0.7413767672451286 - acc: 0.7421109902067464 - val_acc: 0.6837461825585341\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 1.4223005771636963 - sq_loss: 0.00017627586203161627 - tot_loss: 0.7090652486485851 - acc: 0.750272034820457 - val_acc: 0.6986766202918222\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 1.4709868431091309 - sq_loss: 0.00016686387243680656 - tot_loss: 0.6911383045462571 - acc: 0.7568008705114254 - val_acc: 0.7074991516796743\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 1.4711432456970215 - sq_loss: 0.0001580316456966102 - tot_loss: 0.6614521976816832 - acc: 0.7612894450489662 - val_acc: 0.7186969799796403\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 1.4495484828948975 - sq_loss: 0.00014963638386689126 - tot_loss: 0.6578889457714467 - acc: 0.766050054406964 - val_acc: 0.7281981676280964\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 1.9369864463806152 - sq_loss: 0.00014173061936162412 - tot_loss: 0.6275763230428311 - acc: 0.7694504896626768 - val_acc: 0.7387173396674585\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 2.1526260375976562 - sq_loss: 0.0001341997558483854 - tot_loss: 0.6123907796718413 - acc: 0.7717627856365615 - val_acc: 0.7478791991856125\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 1.617891550064087 - sq_loss: 0.0001271113578695804 - tot_loss: 0.5867609257866206 - acc: 0.7754352557127312 - val_acc: 0.7550050899219545\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 1.4725258350372314 - sq_loss: 0.0001204463405883871 - tot_loss: 0.5641787340023257 - acc: 0.7797878128400435 - val_acc: 0.7628096369189006\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 1.4742629528045654 - sq_loss: 0.00011422164971008897 - tot_loss: 0.5503725751650563 - acc: 0.7829162132752993 - val_acc: 0.7675602307431286\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 1.4609556198120117 - sq_loss: 0.00010830265819095075 - tot_loss: 0.5376651811270676 - acc: 0.7853645266594124 - val_acc: 0.7733288089582626\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 1.4635467529296875 - sq_loss: 0.00010265775927109644 - tot_loss: 0.5161116959739047 - acc: 0.7894450489662677 - val_acc: 0.7777400746521886\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 1.4618990421295166 - sq_loss: 9.728786972118542e-05 - tot_loss: 0.5018745742499959 - acc: 0.7925734494015234 - val_acc: 0.7807940278249067\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 1.4711408615112305 - sq_loss: 9.228302224073559e-05 - tot_loss: 0.4914598708205631 - acc: 0.7959738846572362 - val_acc: 0.7858839497794368\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 1.450995922088623 - sq_loss: 8.749717380851507e-05 - tot_loss: 0.47776984525648913 - acc: 0.7995103373231773 - val_acc: 0.7896165592127588\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 1.4464750289916992 - sq_loss: 8.297535532619804e-05 - tot_loss: 0.4551271300274493 - acc: 0.8046789989118607 - val_acc: 0.7950458092975907\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 1.469071865081787 - sq_loss: 7.867324893595651e-05 - tot_loss: 0.4435095615890532 - acc: 0.809575625680087 - val_acc: 0.8014930437733289\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 1.4617838859558105 - sq_loss: 7.4578303610906e-05 - tot_loss: 0.4464214051720319 - acc: 0.81569640914037 - val_acc: 0.8045469969460468\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 1.4705100059509277 - sq_loss: 7.076966721797362e-05 - tot_loss: 0.42677318246637697 - acc: 0.8227693144722524 - val_acc: 0.8092975907702749\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 1.4782166481018066 - sq_loss: 6.70978770358488e-05 - tot_loss: 0.4169576346264421 - acc: 0.8272578890097932 - val_acc: 0.8143875127248049\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 1.4521770477294922 - sq_loss: 6.35946707916446e-05 - tot_loss: 0.39927382850237336 - acc: 0.8322905331882481 - val_acc: 0.8204954190702409\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 1.4405303001403809 - sq_loss: 6.0278980527073145e-05 - tot_loss: 0.38943736280634766 - acc: 0.838411316648531 - val_acc: 0.823210044112657\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 1.434391736984253 - sq_loss: 5.7151464716298506e-05 - tot_loss: 0.3804850835438174 - acc: 0.8430359085963003 - val_acc: 0.827281981676281\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 1.4585378170013428 - sq_loss: 5.417075954028405e-05 - tot_loss: 0.36308066792275895 - acc: 0.8480685527747551 - val_acc: 0.832032575500509\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 1.4434330463409424 - sq_loss: 5.135799801792018e-05 - tot_loss: 0.3555456133315147 - acc: 0.8540533188248096 - val_acc: 0.835086528673227\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 1.4480373859405518 - sq_loss: 4.869719487032853e-05 - tot_loss: 0.34571935965755074 - acc: 0.8593579978237215 - val_acc: 0.838479809976247\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 1.4557499885559082 - sq_loss: 4.613290730048902e-05 - tot_loss: 0.3388559856543907 - acc: 0.8637105549510338 - val_acc: 0.8432304038004751\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 1.4586119651794434 - sq_loss: 4.374677882879041e-05 - tot_loss: 0.33515677070431593 - acc: 0.8667029379760609 - val_acc: 0.8476416694944011\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 1.460296392440796 - sq_loss: 4.153966438025236e-05 - tot_loss: 0.3177952930441279 - acc: 0.8688792165397171 - val_acc: 0.8496776382762131\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 1.4401283264160156 - sq_loss: 3.9392114558722824e-05 - tot_loss: 0.3180726940704517 - acc: 0.8706474428726877 - val_acc: 0.8540889039701391\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 1.4619724750518799 - sq_loss: 3.73599432350602e-05 - tot_loss: 0.3071907976359398 - acc: 0.8717355821545157 - val_acc: 0.8591788259246692\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 1.4397523403167725 - sq_loss: 3.54489020537585e-05 - tot_loss: 0.302497974672292 - acc: 0.8717355821545157 - val_acc: 0.8625721072276892\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 1.4436287879943848 - sq_loss: 3.363528958288953e-05 - tot_loss: 0.28941815506868807 - acc: 0.8736398258977149 - val_acc: 0.8622327790973872\n",
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 1.446103811264038 - sq_loss: 3.189189374097623e-05 - tot_loss: 0.29187131010303347 - acc: 0.875816104461371 - val_acc: 0.8656260604004072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 1.4356205463409424 - sq_loss: 3.0232244171202183e-05 - tot_loss: 0.28654047358133994 - acc: 0.876088139281828 - val_acc: 0.8673227010519172\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 1.4465663433074951 - sq_loss: 2.868156116164755e-05 - tot_loss: 0.28569222350961354 - acc: 0.8774483133841132 - val_acc: 0.8683406854428232\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 1.432927131652832 - sq_loss: 2.7204438083572313e-05 - tot_loss: 0.280415955688909 - acc: 0.8782644178454843 - val_acc: 0.8693586698337292\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 1.4243364334106445 - sq_loss: 2.5811974410316907e-05 - tot_loss: 0.2697822927032121 - acc: 0.8792165397170838 - val_acc: 0.8741092636579573\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 1.4573888778686523 - sq_loss: 2.4491311705787666e-05 - tot_loss: 0.2640446807145054 - acc: 0.8797606093579978 - val_acc: 0.8754665761791652\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 1.4093577861785889 - sq_loss: 2.3258626242750324e-05 - tot_loss: 0.25522787811701164 - acc: 0.8812568008705114 - val_acc: 0.8761452324397693\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 1.4273221492767334 - sq_loss: 2.205947930633556e-05 - tot_loss: 0.25475736741611854 - acc: 0.8807127312295974 - val_acc: 0.8768238887003733\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 1.4310529232025146 - sq_loss: 2.0942059563822113e-05 - tot_loss: 0.2509815602600156 - acc: 0.8816648531011969 - val_acc: 0.8758059043094673\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 1.4445223808288574 - sq_loss: 1.9883156710420735e-05 - tot_loss: 0.24230441514339418 - acc: 0.8823449401523396 - val_acc: 0.8768238887003733\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 1.429309606552124 - sq_loss: 1.8886761608882807e-05 - tot_loss: 0.23837766587132592 - acc: 0.8834330794341676 - val_acc: 0.8768238887003733\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 1.4696495532989502 - sq_loss: 1.7909884263644926e-05 - tot_loss: 0.23796780415875673 - acc: 0.8841131664853101 - val_acc: 0.8768238887003733\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 1.4383800029754639 - sq_loss: 1.7013331671478227e-05 - tot_loss: 0.23412712894781862 - acc: 0.8843852013057671 - val_acc: 0.8781812012215813\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 1.437734603881836 - sq_loss: 1.6175501514226198e-05 - tot_loss: 0.22625623047912313 - acc: 0.8846572361262242 - val_acc: 0.8795385137427892\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 1.452303409576416 - sq_loss: 1.5375682778540067e-05 - tot_loss: 0.21918374012801678 - acc: 0.8858813928182807 - val_acc: 0.8822531387852053\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 1.4490268230438232 - sq_loss: 1.4609479876526166e-05 - tot_loss: 0.21723598691886536 - acc: 0.8862894450489662 - val_acc: 0.8825924669155073\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 1.4560420513153076 - sq_loss: 1.390539273415925e-05 - tot_loss: 0.210043846434246 - acc: 0.8881936887921654 - val_acc: 0.8832711231761113\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 1.439786434173584 - sq_loss: 1.3226620467321482e-05 - tot_loss: 0.2100911474438476 - acc: 0.888873775843308 - val_acc: 0.8842891075670173\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 1.457019567489624 - sq_loss: 1.260753288079286e-05 - tot_loss: 0.2002067270073553 - acc: 0.8898258977149075 - val_acc: 0.8856464200882254\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 1.456045150756836 - sq_loss: 1.2001051800325513e-05 - tot_loss: 0.19591725917968006 - acc: 0.8909140369967355 - val_acc: 0.8870037326094333\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 2.1437056064605713 - sq_loss: 1.1424630429246463e-05 - tot_loss: 0.20803739360690088 - acc: 0.8921381936887922 - val_acc: 0.8897183576518494\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 2.558666467666626 - sq_loss: 1.0855937034648377e-05 - tot_loss: 0.2007333862352425 - acc: 0.8930903155603918 - val_acc: 0.8900576857821514\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 2.511507987976074 - sq_loss: 1.032552700053202e-05 - tot_loss: 0.19666204976533663 - acc: 0.8943144722524483 - val_acc: 0.8914149983033594\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 2.763237714767456 - sq_loss: 9.853624760580715e-06 - tot_loss: 0.1999054543098282 - acc: 0.8955386289445049 - val_acc: 0.8924329826942654\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 2.9377806186676025 - sq_loss: 9.390961167810019e-06 - tot_loss: 0.1928736593921201 - acc: 0.8962187159956474 - val_acc: 0.8937902952154734\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 3.186927080154419 - sq_loss: 8.94671211426612e-06 - tot_loss: 0.1842119240361626 - acc: 0.8966267682263329 - val_acc: 0.8937902952154734\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 3.8109493255615234 - sq_loss: 8.520516530552413e-06 - tot_loss: 0.18532694747730716 - acc: 0.8973068552774756 - val_acc: 0.8941296233457754\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 3.5424745082855225 - sq_loss: 8.13400765764527e-06 - tot_loss: 0.18384047837321305 - acc: 0.8981229597388466 - val_acc: 0.8944689514760774\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 3.174954414367676 - sq_loss: 7.768531759211328e-06 - tot_loss: 0.17448734042596925 - acc: 0.8988030467899891 - val_acc: 0.8948082796063793\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 3.061614513397217 - sq_loss: 7.4216804932802916e-06 - tot_loss: 0.17476097154496983 - acc: 0.8997551686615887 - val_acc: 0.8954869358669834\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 3.037013053894043 - sq_loss: 7.079503575369017e-06 - tot_loss: 0.16886186877380283 - acc: 0.9000272034820457 - val_acc: 0.8961655921275874\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 3.012373685836792 - sq_loss: 6.761966233170824e-06 - tot_loss: 0.15933488242319527 - acc: 0.9004352557127312 - val_acc: 0.8982015609093994\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 3.076101779937744 - sq_loss: 6.467874754889635e-06 - tot_loss: 0.16299625467900114 - acc: 0.9016594124047879 - val_acc: 0.9002375296912114\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 3.018282890319824 - sq_loss: 6.195321020641131e-06 - tot_loss: 0.17224068583993812 - acc: 0.9020674646354734 - val_acc: 0.9012555140821175\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 3.0266690254211426 - sq_loss: 5.932056410529185e-06 - tot_loss: 0.17095823534040733 - acc: 0.9027475516866159 - val_acc: 0.9032914828639295\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 2.95930552482605 - sq_loss: 5.6749531722743995e-06 - tot_loss: 0.16611000890580385 - acc: 0.9030195865070729 - val_acc: 0.9049881235154394\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 3.0637125968933105 - sq_loss: 5.425889867183287e-06 - tot_loss: 0.17093423621528814 - acc: 0.904107725788901 - val_acc: 0.9049881235154394\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 3.082962989807129 - sq_loss: 5.204287390370155e-06 - tot_loss: 0.1686731900303471 - acc: 0.904651795429815 - val_acc: 0.9066847641669494\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 3.152353286743164 - sq_loss: 4.995274139218964e-06 - tot_loss: 0.1590309950265123 - acc: 0.9058759521218716 - val_acc: 0.9070240922972514\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 3.0500450134277344 - sq_loss: 4.800604983756784e-06 - tot_loss: 0.16705640328487448 - acc: 0.9066920565832427 - val_acc: 0.9077027485578555\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 3.019465923309326 - sq_loss: 4.60836463389569e-06 - tot_loss: 0.158727658668937 - acc: 0.9072361262241567 - val_acc: 0.9077027485578555\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 3.054020643234253 - sq_loss: 4.435859409568366e-06 - tot_loss: 0.15625274217167373 - acc: 0.9079162132752993 - val_acc: 0.9080420766881574\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 3.0668675899505615 - sq_loss: 4.266936684871325e-06 - tot_loss: 0.16148479176784747 - acc: 0.9084602829162133 - val_acc: 0.9080420766881574\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 3.122842311859131 - sq_loss: 4.105192147108028e-06 - tot_loss: 0.15757895455755033 - acc: 0.9098204570184983 - val_acc: 0.9077027485578555\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 3.0268752574920654 - sq_loss: 3.953099621867295e-06 - tot_loss: 0.14781970890102514 - acc: 0.9107725788900979 - val_acc: 0.9087207329487614\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 2.981306791305542 - sq_loss: 3.802539822572726e-06 - tot_loss: 0.15450457684045205 - acc: 0.9119967355821545 - val_acc: 0.9090600610790635\n",
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 3.0394303798675537 - sq_loss: 3.6661274407379096e-06 - tot_loss: 0.14432741768942492 - acc: 0.9125408052230686 - val_acc: 0.9093993892093655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 3.029378890991211 - sq_loss: 3.5430805382929975e-06 - tot_loss: 0.1467586909085412 - acc: 0.9129488574537541 - val_acc: 0.9104173736002714\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 3.008884906768799 - sq_loss: 3.420994744374184e-06 - tot_loss: 0.15331415332251197 - acc: 0.9139009793253536 - val_acc: 0.9100780454699695\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 3.017299175262451 - sq_loss: 3.3134845125459833e-06 - tot_loss: 0.1385817355958352 - acc: 0.9147170837867247 - val_acc: 0.9104173736002714\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 3.0847885608673096 - sq_loss: 3.2006889796321047e-06 - tot_loss: 0.1522245694003459 - acc: 0.9151251360174102 - val_acc: 0.9110960298608755\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 2.996100664138794 - sq_loss: 3.09304573420377e-06 - tot_loss: 0.15530893896542608 - acc: 0.9152611534276387 - val_acc: 0.9114353579911775\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 2.9594171047210693 - sq_loss: 2.991633891724632e-06 - tot_loss: 0.14625690635148914 - acc: 0.9158052230685527 - val_acc: 0.9134713267729895\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 3.020033359527588 - sq_loss: 2.9014297524554422e-06 - tot_loss: 0.14355119842924324 - acc: 0.9164853101196954 - val_acc: 0.9138106549032915\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 3.0381011962890625 - sq_loss: 2.8182162168377545e-06 - tot_loss: 0.14501144035396152 - acc: 0.9173014145810664 - val_acc: 0.9141499830335935\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 3.0240859985351562 - sq_loss: 2.7352862161933444e-06 - tot_loss: 0.1411684866307681 - acc: 0.9175734494015234 - val_acc: 0.9138106549032915\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 3.034886360168457 - sq_loss: 2.6545144464762416e-06 - tot_loss: 0.13803618600380219 - acc: 0.9182535364526659 - val_acc: 0.9148286392941974\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 3.112292528152466 - sq_loss: 2.575871121734963e-06 - tot_loss: 0.13651018992246122 - acc: 0.9194776931447225 - val_acc: 0.9151679674244995\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 3.0297892093658447 - sq_loss: 2.5066315174626652e-06 - tot_loss: 0.13366484734310546 - acc: 0.9202937976060935 - val_acc: 0.9161859518154055\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 2.999506950378418 - sq_loss: 2.4390797079831827e-06 - tot_loss: 0.13347214174398658 - acc: 0.9205658324265505 - val_acc: 0.9172039362063115\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 3.082629442214966 - sq_loss: 2.3702989437879296e-06 - tot_loss: 0.1341594967874471 - acc: 0.9213819368879217 - val_acc: 0.9175432643366135\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 3.071455240249634 - sq_loss: 2.3124791823647683e-06 - tot_loss: 0.13559459067201374 - acc: 0.9220620239390642 - val_acc: 0.9175432643366135\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 3.073759078979492 - sq_loss: 2.254670107504353e-06 - tot_loss: 0.13632620589685018 - acc: 0.9226060935799782 - val_acc: 0.9189005768578216\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 3.0595011711120605 - sq_loss: 2.196753484895453e-06 - tot_loss: 0.1405653272543077 - acc: 0.9230141458106638 - val_acc: 0.9199185612487275\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 3.045745372772217 - sq_loss: 2.1351700070226798e-06 - tot_loss: 0.12690403419216167 - acc: 0.9235582154515778 - val_acc: 0.9205972175093315\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 3.0254955291748047 - sq_loss: 2.0863988083874574e-06 - tot_loss: 0.1275934245798247 - acc: 0.9236942328618063 - val_acc: 0.9212758737699356\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 2.996093988418579 - sq_loss: 2.0423160549398744e-06 - tot_loss: 0.12643476194469727 - acc: 0.9239662676822633 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 2.9398529529571533 - sq_loss: 1.9971369056293042e-06 - tot_loss: 0.11619071661209901 - acc: 0.9246463547334058 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 3.0239641666412354 - sq_loss: 1.9512963262968697e-06 - tot_loss: 0.13013466837952947 - acc: 0.9247823721436343 - val_acc: 0.9236511706820495\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 3.0441033840179443 - sq_loss: 1.9098276879958576e-06 - tot_loss: 0.1357563720284709 - acc: 0.9261425462459195 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 3.0191991329193115 - sq_loss: 1.8694597656576661e-06 - tot_loss: 0.131995250152805 - acc: 0.926822633297062 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 3.0558009147644043 - sq_loss: 1.8337824485570309e-06 - tot_loss: 0.12342025221877861 - acc: 0.9275027203482046 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 3.0069286823272705 - sq_loss: 1.7963237723961356e-06 - tot_loss: 0.13005377820374875 - acc: 0.9279107725788901 - val_acc: 0.9246691550729556\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 2.9692862033843994 - sq_loss: 1.763074465088721e-06 - tot_loss: 0.12745202582778248 - acc: 0.9291349292709467 - val_acc: 0.9250084832032576\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 3.0320286750793457 - sq_loss: 1.7321801806247095e-06 - tot_loss: 0.12026695114599661 - acc: 0.9300870511425462 - val_acc: 0.9263657957244655\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 3.0122764110565186 - sq_loss: 1.7043856814780156e-06 - tot_loss: 0.120970390596014 - acc: 0.9303590859630033 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 3.0986862182617188 - sq_loss: 1.6731761434130021e-06 - tot_loss: 0.12580199158392702 - acc: 0.9307671381936888 - val_acc: 0.9277231082456736\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 3.0388684272766113 - sq_loss: 1.6486096683365759e-06 - tot_loss: 0.12724635382828708 - acc: 0.9315832426550599 - val_acc: 0.9280624363759755\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 3.0171549320220947 - sq_loss: 1.6232517054959317e-06 - tot_loss: 0.12588672715419236 - acc: 0.9318552774755169 - val_acc: 0.9280624363759755\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 3.1040005683898926 - sq_loss: 1.601134840711893e-06 - tot_loss: 0.11480958258355933 - acc: 0.9322633297062024 - val_acc: 0.9290804207668816\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 3.078143835067749 - sq_loss: 1.5760750784465927e-06 - tot_loss: 0.12321929940432419 - acc: 0.9326713819368879 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 3.0301647186279297 - sq_loss: 1.5480545698665082e-06 - tot_loss: 0.11639035034281697 - acc: 0.933215451577802 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 3.0400984287261963 - sq_loss: 1.5267863773260615e-06 - tot_loss: 0.11592533388842163 - acc: 0.934031556039173 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 3.1332733631134033 - sq_loss: 1.5079726836120244e-06 - tot_loss: 0.11512009563074699 - acc: 0.934847660500544 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 3.083634853363037 - sq_loss: 1.4853751508780988e-06 - tot_loss: 0.12120182405725544 - acc: 0.9357997823721437 - val_acc: 0.9311163895486936\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 3.0558388233184814 - sq_loss: 1.464655042582308e-06 - tot_loss: 0.12194694005682827 - acc: 0.9364798694232862 - val_acc: 0.9311163895486936\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 3.1096582412719727 - sq_loss: 1.4455577002081554e-06 - tot_loss: 0.11830249538716764 - acc: 0.9372959738846572 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 3.0698201656341553 - sq_loss: 1.4277072750701336e-06 - tot_loss: 0.11984151361338036 - acc: 0.9379760609357998 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 3.080695390701294 - sq_loss: 1.4117823639026028e-06 - tot_loss: 0.1097991575972248 - acc: 0.9385201305767138 - val_acc: 0.9321343739395996\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 3.0817575454711914 - sq_loss: 1.3969295196147868e-06 - tot_loss: 0.10966442952667244 - acc: 0.9389281828073993 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 3.0632598400115967 - sq_loss: 1.3810843029204989e-06 - tot_loss: 0.1118431561350377 - acc: 0.9393362350380848 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 3.0391769409179688 - sq_loss: 1.3695014331460698e-06 - tot_loss: 0.12081488539549134 - acc: 0.9396082698585418 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 3.028163194656372 - sq_loss: 1.3524016821975238e-06 - tot_loss: 0.11176998626465817 - acc: 0.9411044613710555 - val_acc: 0.9341703427214116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 3.0255179405212402 - sq_loss: 1.3407886854110984e-06 - tot_loss: 0.11346356542452618 - acc: 0.941512513601741 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 3.111921548843384 - sq_loss: 1.3279453696668497e-06 - tot_loss: 0.10311707004420612 - acc: 0.9426006528835691 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 3.1706066131591797 - sq_loss: 1.3158942238078453e-06 - tot_loss: 0.10925614103391812 - acc: 0.9431447225244831 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 3.0684165954589844 - sq_loss: 1.3033854884270113e-06 - tot_loss: 0.11712574793010333 - acc: 0.9432807399347116 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 3.0556585788726807 - sq_loss: 1.2916873401991324e-06 - tot_loss: 0.11474114994690598 - acc: 0.9440968443960827 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 3.0410678386688232 - sq_loss: 1.2827632644984988e-06 - tot_loss: 0.11147086483625479 - acc: 0.9449129488574538 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 3.0431060791015625 - sq_loss: 1.2730731668852968e-06 - tot_loss: 0.12557334355595184 - acc: 0.9453210010881393 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 3.0306901931762695 - sq_loss: 1.2649387599594775e-06 - tot_loss: 0.10886855753706115 - acc: 0.9457290533188248 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 3.0870769023895264 - sq_loss: 1.253295977221569e-06 - tot_loss: 0.10510752660290468 - acc: 0.9462731229597389 - val_acc: 0.9382422802850356\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 3.0547597408294678 - sq_loss: 1.2421828614606056e-06 - tot_loss: 0.11108966963772815 - acc: 0.9469532100108814 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 3.1151926517486572 - sq_loss: 1.2330234540058882e-06 - tot_loss: 0.10851155995442596 - acc: 0.9472252448313384 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 3.1026618480682373 - sq_loss: 1.2247669474163558e-06 - tot_loss: 0.10311166464565691 - acc: 0.9479053318824809 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 3.0784108638763428 - sq_loss: 1.2130313962188666e-06 - tot_loss: 0.10205610540004972 - acc: 0.9485854189336235 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 3.027466058731079 - sq_loss: 1.203707483909966e-06 - tot_loss: 0.10838625302069271 - acc: 0.9491294885745375 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 3.307645559310913 - sq_loss: 1.1934400845348136e-06 - tot_loss: 0.1104195977922684 - acc: 0.949265505984766 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 3.0811526775360107 - sq_loss: 1.184739744530816e-06 - tot_loss: 0.11429274846976156 - acc: 0.9499455930359086 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 2.99383282661438 - sq_loss: 1.1765804401875357e-06 - tot_loss: 0.11189278081033294 - acc: 0.9502176278563657 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 3.118105888366699 - sq_loss: 1.1717547749867663e-06 - tot_loss: 0.10844184030026494 - acc: 0.9504896626768227 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 3.0600085258483887 - sq_loss: 1.1641359378700145e-06 - tot_loss: 0.10212944625283615 - acc: 0.9506256800870512 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 2.959350347518921 - sq_loss: 1.156245389211108e-06 - tot_loss: 0.09491554862678253 - acc: 0.9510337323177367 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 3.1169376373291016 - sq_loss: 1.1469340961411945e-06 - tot_loss: 0.10925421854570683 - acc: 0.9514417845484222 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 3.126781940460205 - sq_loss: 1.1393181011953857e-06 - tot_loss: 0.11453970380199952 - acc: 0.9517138193688792 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 3.067228078842163 - sq_loss: 1.1324087836328545e-06 - tot_loss: 0.10148778113790158 - acc: 0.9522578890097932 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 3.015073776245117 - sq_loss: 1.1260686960667954e-06 - tot_loss: 0.10822735701045705 - acc: 0.9525299238302503 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 3.1037473678588867 - sq_loss: 1.1211408263989142e-06 - tot_loss: 0.10894977574748044 - acc: 0.9522578890097932 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 3.0998806953430176 - sq_loss: 1.1170538982696598e-06 - tot_loss: 0.11187513676648297 - acc: 0.9525299238302503 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 3.1720595359802246 - sq_loss: 1.109937784349313e-06 - tot_loss: 0.10189427106331683 - acc: 0.9526659412404788 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 3.2080702781677246 - sq_loss: 1.101513703360979e-06 - tot_loss: 0.1005480161952872 - acc: 0.9528019586507073 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 2.994347333908081 - sq_loss: 1.093226387638424e-06 - tot_loss: 0.10141140541542804 - acc: 0.9529379760609358 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 3.059257745742798 - sq_loss: 1.0879019782805699e-06 - tot_loss: 0.10316497336821717 - acc: 0.9536180631120783 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 3.024315357208252 - sq_loss: 1.0812617574629257e-06 - tot_loss: 0.11021675332007197 - acc: 0.9537540805223068 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 3.08174204826355 - sq_loss: 1.0754730510598165e-06 - tot_loss: 0.09927989492318634 - acc: 0.9541621327529923 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 3.0458168983459473 - sq_loss: 1.070089524546347e-06 - tot_loss: 0.10312615131386238 - acc: 0.954570184983678 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 3.0664777755737305 - sq_loss: 1.0649142723195837e-06 - tot_loss: 0.09928640378774656 - acc: 0.9552502720348205 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 3.0005686283111572 - sq_loss: 1.0617751513564144e-06 - tot_loss: 0.10719349700383729 - acc: 0.9555223068552775 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 3.0789568424224854 - sq_loss: 1.0563044270384125e-06 - tot_loss: 0.10772494051463521 - acc: 0.955658324265506 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 2.995704174041748 - sq_loss: 1.0528234497542144e-06 - tot_loss: 0.10255856552083698 - acc: 0.9560663764961915 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 3.129852533340454 - sq_loss: 1.0493889703866444e-06 - tot_loss: 0.10208155265278407 - acc: 0.9560663764961915 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 3.004734754562378 - sq_loss: 1.0444863391967374e-06 - tot_loss: 0.10413924965382382 - acc: 0.95620239390642 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 3.054452896118164 - sq_loss: 1.0413508562123752e-06 - tot_loss: 0.09797101393325747 - acc: 0.9567464635473341 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 3.073169708251953 - sq_loss: 1.0357812243455555e-06 - tot_loss: 0.1053233057672851 - acc: 0.9570184983677911 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 3.113182306289673 - sq_loss: 1.0313191296518198e-06 - tot_loss: 0.1005402783818381 - acc: 0.9575625680087051 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 3.0647740364074707 - sq_loss: 1.0277225328536588e-06 - tot_loss: 0.10176095419074427 - acc: 0.9578346028291621 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 3.0065789222717285 - sq_loss: 1.0240761412205757e-06 - tot_loss: 0.09275522649337153 - acc: 0.9585146898803046 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 3.0983827114105225 - sq_loss: 1.0204880709352437e-06 - tot_loss: 0.10172671756636831 - acc: 0.9591947769314473 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 2.993886709213257 - sq_loss: 1.01623345472035e-06 - tot_loss: 0.0990397393171909 - acc: 0.9593307943416758 - val_acc: 0.9477434679334917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 3.007251739501953 - sq_loss: 1.013138330563379e-06 - tot_loss: 0.0934672994296295 - acc: 0.9597388465723613 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 3.0269222259521484 - sq_loss: 1.0081020036523114e-06 - tot_loss: 0.1047786237936772 - acc: 0.9601468988030468 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 3.0509324073791504 - sq_loss: 1.004574187390972e-06 - tot_loss: 0.09710528727135115 - acc: 0.9605549510337323 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 3.0525472164154053 - sq_loss: 1.0018985676651937e-06 - tot_loss: 0.10168571319836373 - acc: 0.9605549510337323 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 3.0520598888397217 - sq_loss: 9.999728263210272e-07 - tot_loss: 0.10036364671323783 - acc: 0.9610990206746464 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 3.061448574066162 - sq_loss: 9.96466951619368e-07 - tot_loss: 0.10131133285026506 - acc: 0.9616430903155604 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 3.0952131748199463 - sq_loss: 9.934383342624642e-07 - tot_loss: 0.10450389098949575 - acc: 0.9616430903155604 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 2.962416410446167 - sq_loss: 9.89408135865233e-07 - tot_loss: 0.0953170810282784 - acc: 0.9619151251360174 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 3.029529094696045 - sq_loss: 9.836134040597244e-07 - tot_loss: 0.09974264496702556 - acc: 0.9623231773667029 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 3.0504276752471924 - sq_loss: 9.784212124941405e-07 - tot_loss: 0.09418557474848832 - acc: 0.963139281828074 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 3.0080411434173584 - sq_loss: 9.739069355418906e-07 - tot_loss: 0.09625624230812635 - acc: 0.963683351468988 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 2.9788849353790283 - sq_loss: 9.700047485239338e-07 - tot_loss: 0.10007794039868312 - acc: 0.9640914036996736 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 3.0348105430603027 - sq_loss: 9.659512443249696e-07 - tot_loss: 0.10158235968792839 - acc: 0.9640914036996736 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 2.984830141067505 - sq_loss: 9.616297802494955e-07 - tot_loss: 0.10431669208438654 - acc: 0.9644994559303591 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 3.013087272644043 - sq_loss: 9.583477549313102e-07 - tot_loss: 0.101318850111765 - acc: 0.9650435255712732 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 2.953669309616089 - sq_loss: 9.557600151310908e-07 - tot_loss: 0.09294710290142083 - acc: 0.9650435255712732 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 3.0361275672912598 - sq_loss: 9.525160749035422e-07 - tot_loss: 0.10351272864944949 - acc: 0.9651795429815017 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 3.0348143577575684 - sq_loss: 9.494036703472375e-07 - tot_loss: 0.10106173803254803 - acc: 0.9653155603917302 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 3.0901172161102295 - sq_loss: 9.469029009778751e-07 - tot_loss: 0.10112761897661438 - acc: 0.9661316648531012 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 3.0135669708251953 - sq_loss: 9.435771630705858e-07 - tot_loss: 0.09670841413548814 - acc: 0.9664036996735582 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 3.064321994781494 - sq_loss: 9.4237441317091e-07 - tot_loss: 0.09235299338242164 - acc: 0.9665397170837867 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 3.0687079429626465 - sq_loss: 9.396819677931489e-07 - tot_loss: 0.10038115378424317 - acc: 0.9665397170837867 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 3.054502487182617 - sq_loss: 9.357927979181113e-07 - tot_loss: 0.09670940828217756 - acc: 0.9668117519042437 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 3.0557448863983154 - sq_loss: 9.344730642624199e-07 - tot_loss: 0.09433041879592441 - acc: 0.9670837867247007 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 3.0883262157440186 - sq_loss: 9.311396524935844e-07 - tot_loss: 0.09909562821549711 - acc: 0.9672198041349293 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 3.000570297241211 - sq_loss: 9.28467784433451e-07 - tot_loss: 0.11081554420325768 - acc: 0.9672198041349293 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 3.0444648265838623 - sq_loss: 9.249033610103652e-07 - tot_loss: 0.09525837784433833 - acc: 0.9673558215451578 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 3.033473014831543 - sq_loss: 9.225191774930863e-07 - tot_loss: 0.09807591009054129 - acc: 0.9680359085963003 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 3.0221140384674072 - sq_loss: 9.196422183777031e-07 - tot_loss: 0.09539829644550224 - acc: 0.9683079434167573 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 2.9976859092712402 - sq_loss: 9.166211611955077e-07 - tot_loss: 0.09017992999763846 - acc: 0.9685799782372143 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 3.069256067276001 - sq_loss: 9.127671205533261e-07 - tot_loss: 0.09143304668556018 - acc: 0.9688520130576714 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 3.146641492843628 - sq_loss: 9.105578442358819e-07 - tot_loss: 0.08945637063599365 - acc: 0.9689880304678999 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 3.0275161266326904 - sq_loss: 9.095033419725951e-07 - tot_loss: 0.10564115774979177 - acc: 0.9691240478781284 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 3.0772430896759033 - sq_loss: 9.072640523299924e-07 - tot_loss: 0.09722728355080612 - acc: 0.9693960826985855 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 3.097536325454712 - sq_loss: 9.039962378665223e-07 - tot_loss: 0.0877408460935043 - acc: 0.9693960826985855 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 3.029831647872925 - sq_loss: 9.022040785566787e-07 - tot_loss: 0.09631051254749368 - acc: 0.9696681175190425 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 2.945795774459839 - sq_loss: 8.986951911538199e-07 - tot_loss: 0.09556506184839275 - acc: 0.970076169749728 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 3.044276714324951 - sq_loss: 8.960125228441029e-07 - tot_loss: 0.08829056596906693 - acc: 0.9704842219804135 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 3.0686843395233154 - sq_loss: 8.92492266757472e-07 - tot_loss: 0.08665015925625497 - acc: 0.9704842219804135 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 3.068453073501587 - sq_loss: 8.902937906896113e-07 - tot_loss: 0.0941768168618009 - acc: 0.970620239390642 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 3.098426580429077 - sq_loss: 8.873873866832582e-07 - tot_loss: 0.103474819393929 - acc: 0.9710282916213275 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 3.106886386871338 - sq_loss: 8.836811957735335e-07 - tot_loss: 0.09354860118693442 - acc: 0.971436343852013 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 3.048096179962158 - sq_loss: 8.810099529910076e-07 - tot_loss: 0.10186787322830271 - acc: 0.971436343852013 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 3.044039249420166 - sq_loss: 8.805482138996013e-07 - tot_loss: 0.10098470575001728 - acc: 0.9717083786724701 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 3.03362774848938 - sq_loss: 8.780168627708917e-07 - tot_loss: 0.09400224552696113 - acc: 0.9717083786724701 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 3.066370964050293 - sq_loss: 8.754459486226551e-07 - tot_loss: 0.09376573054075954 - acc: 0.9717083786724701 - val_acc: 0.9524940617577197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 3.0946178436279297 - sq_loss: 8.748576760808646e-07 - tot_loss: 0.09718687451675767 - acc: 0.9717083786724701 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 3.069347620010376 - sq_loss: 8.736712970858207e-07 - tot_loss: 0.10086669649781999 - acc: 0.9718443960826986 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 2.9804999828338623 - sq_loss: 8.708981908966962e-07 - tot_loss: 0.08650402528795875 - acc: 0.9723884657236126 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 3.1008715629577637 - sq_loss: 8.69393772973126e-07 - tot_loss: 0.09675531680911642 - acc: 0.9721164309031556 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 3.089242458343506 - sq_loss: 8.687250101502286e-07 - tot_loss: 0.10582303118390213 - acc: 0.9723884657236126 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 2.9937307834625244 - sq_loss: 8.65926210735779e-07 - tot_loss: 0.10038253659510876 - acc: 0.9730685527747551 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 3.066204071044922 - sq_loss: 8.629962735540175e-07 - tot_loss: 0.08852889060666747 - acc: 0.9730685527747551 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 3.005265235900879 - sq_loss: 8.606192523075151e-07 - tot_loss: 0.10138359326933077 - acc: 0.9730685527747551 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 2.9984145164489746 - sq_loss: 8.582139798818389e-07 - tot_loss: 0.09745869648078664 - acc: 0.9732045701849836 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 2.9716567993164062 - sq_loss: 8.568501357331115e-07 - tot_loss: 0.0889095995169622 - acc: 0.9732045701849836 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 3.0220799446105957 - sq_loss: 8.541841225451208e-07 - tot_loss: 0.09618725291280894 - acc: 0.9736126224156693 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 3.046851634979248 - sq_loss: 8.518687764080823e-07 - tot_loss: 0.10046158598449062 - acc: 0.9736126224156693 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 2.9360458850860596 - sq_loss: 8.494047847307229e-07 - tot_loss: 0.0961125753844363 - acc: 0.9740206746463548 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 3.073796033859253 - sq_loss: 8.471316164104792e-07 - tot_loss: 0.0959154791682788 - acc: 0.9742927094668118 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 2.9672582149505615 - sq_loss: 8.449958954770409e-07 - tot_loss: 0.10001937024552232 - acc: 0.9744287268770403 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 3.1122725009918213 - sq_loss: 8.416539571953763e-07 - tot_loss: 0.08318732193109546 - acc: 0.9747007616974973 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 3.148287773132324 - sq_loss: 8.394454766857962e-07 - tot_loss: 0.10298213059157058 - acc: 0.9745647442872688 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 3.19478440284729 - sq_loss: 8.388070114051516e-07 - tot_loss: 0.0962544749764549 - acc: 0.9748367791077258 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 3.039916753768921 - sq_loss: 8.381121006095782e-07 - tot_loss: 0.09398984121951814 - acc: 0.9748367791077258 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 3.1017911434173584 - sq_loss: 8.356180387636414e-07 - tot_loss: 0.08999445952756169 - acc: 0.9749727965179543 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 3.0412044525146484 - sq_loss: 8.33310025427636e-07 - tot_loss: 0.10068547175497722 - acc: 0.9752448313384113 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 3.1215860843658447 - sq_loss: 8.320577080667135e-07 - tot_loss: 0.09631401755694102 - acc: 0.9753808487486398 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 3.1568169593811035 - sq_loss: 8.305977985401114e-07 - tot_loss: 0.10660584785925109 - acc: 0.9760609357997824 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 2.9791877269744873 - sq_loss: 8.276525704786764e-07 - tot_loss: 0.0955559595192581 - acc: 0.9761969532100109 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 3.1214985847473145 - sq_loss: 8.267247721960302e-07 - tot_loss: 0.10414389786612621 - acc: 0.9763329706202394 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 3.099642038345337 - sq_loss: 8.250038945334381e-07 - tot_loss: 0.09467485165488809 - acc: 0.9766050054406964 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 3.1071829795837402 - sq_loss: 8.235820132540539e-07 - tot_loss: 0.09344222849082628 - acc: 0.9766050054406964 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 3.089992046356201 - sq_loss: 8.213962132685992e-07 - tot_loss: 0.09520143847501261 - acc: 0.9766050054406964 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 3.061368465423584 - sq_loss: 8.184973125935358e-07 - tot_loss: 0.1017479685341971 - acc: 0.9764689880304679 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 3.008591651916504 - sq_loss: 8.158696118698572e-07 - tot_loss: 0.10096590995905474 - acc: 0.9766050054406964 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 3.013620615005493 - sq_loss: 8.135683060572774e-07 - tot_loss: 0.08664550918826386 - acc: 0.9768770402611534 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 3.047008991241455 - sq_loss: 8.118594223560649e-07 - tot_loss: 0.09023880846193655 - acc: 0.9768770402611534 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 3.0913965702056885 - sq_loss: 8.093023211586114e-07 - tot_loss: 0.0972914312827522 - acc: 0.9775571273122959 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 3.0636818408966064 - sq_loss: 8.075377877503342e-07 - tot_loss: 0.09094426372952635 - acc: 0.9775571273122959 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 3.0352795124053955 - sq_loss: 8.055827720454545e-07 - tot_loss: 0.09048311744562287 - acc: 0.9776931447225244 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 3.024538993835449 - sq_loss: 8.045323625083256e-07 - tot_loss: 0.09907865628561807 - acc: 0.977829162132753 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 3.071681499481201 - sq_loss: 8.024094881875499e-07 - tot_loss: 0.09699072108443896 - acc: 0.977829162132753 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 3.0504560470581055 - sq_loss: 8.003042921700398e-07 - tot_loss: 0.09525532123233571 - acc: 0.977829162132753 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 3.0515832901000977 - sq_loss: 7.988345487319748e-07 - tot_loss: 0.09286031167656539 - acc: 0.97810119695321 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 3.023388147354126 - sq_loss: 7.963360530993668e-07 - tot_loss: 0.09112205896555237 - acc: 0.9782372143634385 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 3.034433603286743 - sq_loss: 7.935991561680567e-07 - tot_loss: 0.09516968034803486 - acc: 0.97810119695321 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 3.068728446960449 - sq_loss: 7.90803255767969e-07 - tot_loss: 0.09572973957153508 - acc: 0.97810119695321 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 2.981938123703003 - sq_loss: 7.890740221228043e-07 - tot_loss: 0.09591447340093628 - acc: 0.9785092491838956 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 2.996005058288574 - sq_loss: 7.878338692535181e-07 - tot_loss: 0.09803274735286704 - acc: 0.9786452665941241 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 3.016469717025757 - sq_loss: 7.852040653233416e-07 - tot_loss: 0.09856976794938177 - acc: 0.9786452665941241 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 3.0436129570007324 - sq_loss: 7.823757641745033e-07 - tot_loss: 0.08152661685981433 - acc: 0.9791893362350381 - val_acc: 0.9528333898880217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 3.0187320709228516 - sq_loss: 7.805278983141761e-07 - tot_loss: 0.09399055722500793 - acc: 0.9793253536452666 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 2.981391429901123 - sq_loss: 7.79130459704902e-07 - tot_loss: 0.09394713738740479 - acc: 0.9793253536452666 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 3.0765180587768555 - sq_loss: 7.771963055347442e-07 - tot_loss: 0.0839058379986577 - acc: 0.9794613710554951 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 3.0391862392425537 - sq_loss: 7.745898642497195e-07 - tot_loss: 0.09219471149305547 - acc: 0.9795973884657236 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 3.026585817337036 - sq_loss: 7.729501589892607e-07 - tot_loss: 0.09522512110330883 - acc: 0.9797334058759521 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 3.080198049545288 - sq_loss: 7.708844691478589e-07 - tot_loss: 0.08933728377801109 - acc: 0.9797334058759521 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 3.0415256023406982 - sq_loss: 7.696925194977666e-07 - tot_loss: 0.09597508671777666 - acc: 0.9800054406964092 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 3.0755693912506104 - sq_loss: 7.684048455303127e-07 - tot_loss: 0.08841645628166406 - acc: 0.9797334058759521 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 2.986218214035034 - sq_loss: 7.674216249142773e-07 - tot_loss: 0.0982484885091377 - acc: 0.9800054406964092 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 3.0405561923980713 - sq_loss: 7.661438985451241e-07 - tot_loss: 0.09024315372020686 - acc: 0.9800054406964092 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 3.102858543395996 - sq_loss: 7.654981573068653e-07 - tot_loss: 0.09423719263000918 - acc: 0.9797334058759521 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 3.017043113708496 - sq_loss: 7.644769652870309e-07 - tot_loss: 0.08709168630777331 - acc: 0.9804134929270947 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 3.0566444396972656 - sq_loss: 7.625542934874829e-07 - tot_loss: 0.0889401305330757 - acc: 0.9800054406964092 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 3.0735833644866943 - sq_loss: 7.608418286508822e-07 - tot_loss: 0.08920150968555385 - acc: 0.9804134929270947 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 3.0086026191711426 - sq_loss: 7.584812919958495e-07 - tot_loss: 0.09677019022862199 - acc: 0.9805495103373232 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 3.013134479522705 - sq_loss: 7.57175087073847e-07 - tot_loss: 0.09849912034006691 - acc: 0.9805495103373232 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 3.0554592609405518 - sq_loss: 7.560115022897662e-07 - tot_loss: 0.08746584040883776 - acc: 0.9805495103373232 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 3.0292606353759766 - sq_loss: 7.540309638898179e-07 - tot_loss: 0.10066236870403178 - acc: 0.9805495103373232 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 3.0659799575805664 - sq_loss: 7.52215271404566e-07 - tot_loss: 0.08509572706575952 - acc: 0.9808215451577802 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 3.046903133392334 - sq_loss: 7.516144364672073e-07 - tot_loss: 0.09226805320335729 - acc: 0.9812295973884657 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 3.043100357055664 - sq_loss: 7.505873895752302e-07 - tot_loss: 0.08414371003346455 - acc: 0.9812295973884657 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 2.9871954917907715 - sq_loss: 7.489034601348976e-07 - tot_loss: 0.0896486859962633 - acc: 0.9813656147986942 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 3.0905349254608154 - sq_loss: 7.464201416951255e-07 - tot_loss: 0.09323999708170438 - acc: 0.9812295973884657 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 3.062891721725464 - sq_loss: 7.448498422490957e-07 - tot_loss: 0.0940806889921435 - acc: 0.9816376496191512 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 3.027949333190918 - sq_loss: 7.436153737216955e-07 - tot_loss: 0.09613529225797124 - acc: 0.9816376496191512 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 3.0547683238983154 - sq_loss: 7.424321779581078e-07 - tot_loss: 0.0954521596893887 - acc: 0.9817736670293797 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 2.999711751937866 - sq_loss: 7.417856977554038e-07 - tot_loss: 0.09380173929248747 - acc: 0.9817736670293797 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 3.028278112411499 - sq_loss: 7.394246495096013e-07 - tot_loss: 0.09118212275175863 - acc: 0.9819096844396082 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 3.163226366043091 - sq_loss: 7.378710620287166e-07 - tot_loss: 0.08810131216803807 - acc: 0.9817736670293797 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 3.04441499710083 - sq_loss: 7.365323426711257e-07 - tot_loss: 0.10086354508562367 - acc: 0.9817736670293797 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 2.9796524047851562 - sq_loss: 7.362630185525632e-07 - tot_loss: 0.09945251029448965 - acc: 0.9819096844396082 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 3.1153666973114014 - sq_loss: 7.347271093749441e-07 - tot_loss: 0.09591723626808513 - acc: 0.9817736670293797 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 3.0429558753967285 - sq_loss: 7.3371887765461e-07 - tot_loss: 0.0890310965701786 - acc: 0.9817736670293797 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 2.9699506759643555 - sq_loss: 7.323853878915543e-07 - tot_loss: 0.09297945238651573 - acc: 0.9819096844396082 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 3.1576790809631348 - sq_loss: 7.305688995984383e-07 - tot_loss: 0.10023619099578274 - acc: 0.9819096844396082 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 3.088707447052002 - sq_loss: 7.284674552465731e-07 - tot_loss: 0.09789741357043491 - acc: 0.9821817192600653 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 3.045219898223877 - sq_loss: 7.2709042342467e-07 - tot_loss: 0.09921084337908903 - acc: 0.9821817192600653 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 3.142559051513672 - sq_loss: 7.265336989803473e-07 - tot_loss: 0.09590965833328835 - acc: 0.9821817192600653 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 3.209970235824585 - sq_loss: 7.256703042912704e-07 - tot_loss: 0.08967178996171721 - acc: 0.9821817192600653 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 2.9953811168670654 - sq_loss: 7.244460675792652e-07 - tot_loss: 0.0940278163032442 - acc: 0.9824537540805223 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 3.1049044132232666 - sq_loss: 7.234471013362054e-07 - tot_loss: 0.08859103686832981 - acc: 0.9823177366702938 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 3.0393142700195312 - sq_loss: 7.232727625705593e-07 - tot_loss: 0.08352589079455286 - acc: 0.9824537540805223 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 2.998495101928711 - sq_loss: 7.221668738566223e-07 - tot_loss: 0.09406823170506362 - acc: 0.9824537540805223 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 3.0649490356445312 - sq_loss: 7.194881845862255e-07 - tot_loss: 0.0960056403543521 - acc: 0.9825897714907508 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 3.132032871246338 - sq_loss: 7.173160270212975e-07 - tot_loss: 0.08780420357867658 - acc: 0.9824537540805223 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 3.0535757541656494 - sq_loss: 7.154484933380445e-07 - tot_loss: 0.08960322013601951 - acc: 0.9824537540805223 - val_acc: 0.9558873430607397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 3.077850103378296 - sq_loss: 7.14149621217075e-07 - tot_loss: 0.08656328819278714 - acc: 0.9823177366702938 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 2.994126081466675 - sq_loss: 7.126209879970702e-07 - tot_loss: 0.09263888093543793 - acc: 0.9823177366702938 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 3.12716007232666 - sq_loss: 7.107223609637003e-07 - tot_loss: 0.0958466877071138 - acc: 0.9823177366702938 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 3.095583915710449 - sq_loss: 7.090894769135048e-07 - tot_loss: 0.09352330656194541 - acc: 0.9824537540805223 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 3.0900466442108154 - sq_loss: 7.073867323015293e-07 - tot_loss: 0.09442487869392258 - acc: 0.9824537540805223 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 3.1329264640808105 - sq_loss: 7.058570190565661e-07 - tot_loss: 0.09243900708896291 - acc: 0.9825897714907508 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 3.0220346450805664 - sq_loss: 7.045638881209015e-07 - tot_loss: 0.09544813930578888 - acc: 0.9825897714907508 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 3.0084898471832275 - sq_loss: 7.0285096853695e-07 - tot_loss: 0.1007772591262397 - acc: 0.9827257889009793 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 3.0457825660705566 - sq_loss: 7.020174734861939e-07 - tot_loss: 0.09819329441580882 - acc: 0.9825897714907508 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 3.1147611141204834 - sq_loss: 7.016778340585006e-07 - tot_loss: 0.10597581337268092 - acc: 0.9828618063112078 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 3.060805559158325 - sq_loss: 7.003116593295999e-07 - tot_loss: 0.09242718190880628 - acc: 0.9829978237214363 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 3.0002198219299316 - sq_loss: 6.989865255491168e-07 - tot_loss: 0.10313010578956905 - acc: 0.9829978237214363 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 3.1732587814331055 - sq_loss: 6.981693445595738e-07 - tot_loss: 0.09480075483105321 - acc: 0.9831338411316648 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 3.0417916774749756 - sq_loss: 6.965465786379355e-07 - tot_loss: 0.08834912060698774 - acc: 0.9831338411316648 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 3.1050195693969727 - sq_loss: 6.953529236852773e-07 - tot_loss: 0.09731036206115085 - acc: 0.9831338411316648 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 3.090136766433716 - sq_loss: 6.936780891919625e-07 - tot_loss: 0.10962201940576421 - acc: 0.9832698585418934 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 3.1298248767852783 - sq_loss: 6.923381761225755e-07 - tot_loss: 0.08891353366764476 - acc: 0.9835418933623504 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 3.041924476623535 - sq_loss: 6.912356411703513e-07 - tot_loss: 0.0890169213347527 - acc: 0.9835418933623504 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 3.0189576148986816 - sq_loss: 6.894152306813339e-07 - tot_loss: 0.09250097718544992 - acc: 0.9835418933623504 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 3.080751657485962 - sq_loss: 6.878979661451012e-07 - tot_loss: 0.08866647034363506 - acc: 0.9835418933623504 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 3.040431022644043 - sq_loss: 6.864287911412248e-07 - tot_loss: 0.09731135042935435 - acc: 0.9835418933623504 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 3.102490186691284 - sq_loss: 6.85792429067078e-07 - tot_loss: 0.09454602925132027 - acc: 0.9835418933623504 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 3.0799646377563477 - sq_loss: 6.842416837571363e-07 - tot_loss: 0.08292198982374599 - acc: 0.9835418933623504 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 3.1287336349487305 - sq_loss: 6.82754091485549e-07 - tot_loss: 0.09105007946422106 - acc: 0.9835418933623504 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 3.0110886096954346 - sq_loss: 6.820050657552201e-07 - tot_loss: 0.09223935432989294 - acc: 0.9835418933623504 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 3.0528368949890137 - sq_loss: 6.812571200498496e-07 - tot_loss: 0.09054568515345374 - acc: 0.9838139281828074 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 3.065760374069214 - sq_loss: 6.795749527555017e-07 - tot_loss: 0.09082852964109966 - acc: 0.9835418933623504 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 2.9289772510528564 - sq_loss: 6.779293357794813e-07 - tot_loss: 0.09446874051737697 - acc: 0.9835418933623504 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 3.0202739238739014 - sq_loss: 6.774544090148993e-07 - tot_loss: 0.09915643952581532 - acc: 0.9838139281828074 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 2.9991602897644043 - sq_loss: 6.759779580534087e-07 - tot_loss: 0.09314625127670728 - acc: 0.9838139281828074 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 3.0565385818481445 - sq_loss: 6.741850597791199e-07 - tot_loss: 0.09595487517490653 - acc: 0.9835418933623504 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 3.027134895324707 - sq_loss: 6.717326073157892e-07 - tot_loss: 0.09702569927344384 - acc: 0.9838139281828074 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 2.9577486515045166 - sq_loss: 6.701596930724918e-07 - tot_loss: 0.09810968850712687 - acc: 0.9838139281828074 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 3.0968892574310303 - sq_loss: 6.692434340038744e-07 - tot_loss: 0.09239895211269622 - acc: 0.9835418933623504 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 3.000598907470703 - sq_loss: 6.684969093839754e-07 - tot_loss: 0.1050116466346438 - acc: 0.9835418933623504 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 3.0716159343719482 - sq_loss: 6.670258585472766e-07 - tot_loss: 0.09722542291639247 - acc: 0.9835418933623504 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 3.0383570194244385 - sq_loss: 6.65357845264225e-07 - tot_loss: 0.09379056724017543 - acc: 0.9834058759521219 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 2.9954493045806885 - sq_loss: 6.634426199525478e-07 - tot_loss: 0.0964745281609386 - acc: 0.9835418933623504 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 3.070146083831787 - sq_loss: 6.621128250117181e-07 - tot_loss: 0.09554131146889389 - acc: 0.9834058759521219 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 2.983668088912964 - sq_loss: 6.603656288461934e-07 - tot_loss: 0.09745158619423999 - acc: 0.9835418933623504 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 3.0378870964050293 - sq_loss: 6.58725355151546e-07 - tot_loss: 0.09355827523794558 - acc: 0.9836779107725789 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 3.0483386516571045 - sq_loss: 6.576639179911581e-07 - tot_loss: 0.09470081174353495 - acc: 0.9836779107725789 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 3.121164083480835 - sq_loss: 6.568109256477328e-07 - tot_loss: 0.08894944660331994 - acc: 0.9835418933623504 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 3.019958257675171 - sq_loss: 6.565846888406668e-07 - tot_loss: 0.09428467454962364 - acc: 0.9836779107725789 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 3.03118634223938 - sq_loss: 6.558346967722173e-07 - tot_loss: 0.09427823900422938 - acc: 0.9836779107725789 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 3.0099236965179443 - sq_loss: 6.557476694979414e-07 - tot_loss: 0.09817327429209755 - acc: 0.9836779107725789 - val_acc: 0.9599592806243638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 2.9461450576782227 - sq_loss: 6.551978231073008e-07 - tot_loss: 0.09957708519156816 - acc: 0.9836779107725789 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 3.0539186000823975 - sq_loss: 6.544232746819034e-07 - tot_loss: 0.09449368177096562 - acc: 0.9838139281828074 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 3.0305769443511963 - sq_loss: 6.534215231113194e-07 - tot_loss: 0.0901773841821617 - acc: 0.9838139281828074 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 3.0203170776367188 - sq_loss: 6.52615938179224e-07 - tot_loss: 0.08665400547942859 - acc: 0.983949945593036 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 2.9622740745544434 - sq_loss: 6.518433792734868e-07 - tot_loss: 0.1018832309620139 - acc: 0.983949945593036 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 3.0637423992156982 - sq_loss: 6.493563660114887e-07 - tot_loss: 0.09401228964474218 - acc: 0.983949945593036 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 3.0690529346466064 - sq_loss: 6.475382861026446e-07 - tot_loss: 0.09568641634102193 - acc: 0.9840859630032645 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 3.0156054496765137 - sq_loss: 6.452695515690721e-07 - tot_loss: 0.09835253558435919 - acc: 0.9840859630032645 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 3.0615687370300293 - sq_loss: 6.44635349544842e-07 - tot_loss: 0.0928053498864132 - acc: 0.9840859630032645 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 3.043529748916626 - sq_loss: 6.442195399358752e-07 - tot_loss: 0.08944042943376274 - acc: 0.9840859630032645 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 3.1188061237335205 - sq_loss: 6.436478088289732e-07 - tot_loss: 0.0904981944557951 - acc: 0.9840859630032645 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 3.0172226428985596 - sq_loss: 6.423204013117356e-07 - tot_loss: 0.10057776710717448 - acc: 0.9840859630032645 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 3.068305492401123 - sq_loss: 6.416616997739766e-07 - tot_loss: 0.08892921979435886 - acc: 0.9840859630032645 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 3.0025596618652344 - sq_loss: 6.409026696019282e-07 - tot_loss: 0.0931469811378195 - acc: 0.9843579978237215 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 3.085592746734619 - sq_loss: 6.396431331268104e-07 - tot_loss: 0.09273540235792066 - acc: 0.9846300326441785 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 3.082335948944092 - sq_loss: 6.400885581570037e-07 - tot_loss: 0.09529636056028012 - acc: 0.98449401523395 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 3.038956642150879 - sq_loss: 6.392934892573976e-07 - tot_loss: 0.09008603800279147 - acc: 0.9846300326441785 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 3.017106533050537 - sq_loss: 6.383035042745178e-07 - tot_loss: 0.09121636563001423 - acc: 0.98449401523395 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 3.0718331336975098 - sq_loss: 6.367803280227236e-07 - tot_loss: 0.09494520684824126 - acc: 0.9846300326441785 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 3.022435188293457 - sq_loss: 6.357971074066882e-07 - tot_loss: 0.09433501742861117 - acc: 0.9846300326441785 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 3.0005741119384766 - sq_loss: 6.351822889882897e-07 - tot_loss: 0.09226408692711086 - acc: 0.984766050054407 - val_acc: 0.9599592806243638\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 3.012787103652954 - sq_loss: 6.336757678582217e-07 - tot_loss: 0.09972319252687112 - acc: 0.984766050054407 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 3.0145492553710938 - sq_loss: 6.318668397398142e-07 - tot_loss: 0.0874901337230568 - acc: 0.9846300326441785 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 3.0067851543426514 - sq_loss: 6.31082798463467e-07 - tot_loss: 0.0947605606600016 - acc: 0.984766050054407 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 3.0329294204711914 - sq_loss: 6.297469781202381e-07 - tot_loss: 0.08952115073231848 - acc: 0.984766050054407 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 3.114917516708374 - sq_loss: 6.287540941229963e-07 - tot_loss: 0.1005111113220325 - acc: 0.984766050054407 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 3.0638768672943115 - sq_loss: 6.27536451247579e-07 - tot_loss: 0.09506082512038538 - acc: 0.9849020674646355 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 3.004977226257324 - sq_loss: 6.27021051968768e-07 - tot_loss: 0.09162893655506044 - acc: 0.9849020674646355 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 3.0274899005889893 - sq_loss: 6.255275479816191e-07 - tot_loss: 0.09503018972909927 - acc: 0.985038084874864 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 3.0603814125061035 - sq_loss: 6.249879334063735e-07 - tot_loss: 0.10276118507539778 - acc: 0.985038084874864 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 3.027149200439453 - sq_loss: 6.229118980627391e-07 - tot_loss: 0.09959620941509262 - acc: 0.984766050054407 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 3.0034210681915283 - sq_loss: 6.2130413880368e-07 - tot_loss: 0.09936406407891818 - acc: 0.984766050054407 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 3.085602045059204 - sq_loss: 6.203118232406268e-07 - tot_loss: 0.10670357906871741 - acc: 0.984766050054407 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 3.0361554622650146 - sq_loss: 6.197481070557842e-07 - tot_loss: 0.09386038221487292 - acc: 0.984766050054407 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 3.0532686710357666 - sq_loss: 6.187281087477459e-07 - tot_loss: 0.10007543217458414 - acc: 0.98449401523395 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 3.188920497894287 - sq_loss: 6.175882845127489e-07 - tot_loss: 0.10364795042222719 - acc: 0.9846300326441785 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 3.119370222091675 - sq_loss: 6.170066626509652e-07 - tot_loss: 0.09845169091684891 - acc: 0.9849020674646355 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 3.0819718837738037 - sq_loss: 6.169584594317712e-07 - tot_loss: 0.08948932121791708 - acc: 0.9849020674646355 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 3.0619444847106934 - sq_loss: 6.166384878270037e-07 - tot_loss: 0.0811115153298183 - acc: 0.9849020674646355 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 3.0053813457489014 - sq_loss: 6.163677994663885e-07 - tot_loss: 0.10504196934715981 - acc: 0.9849020674646355 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 3.0424087047576904 - sq_loss: 6.154802463242959e-07 - tot_loss: 0.09607278974900058 - acc: 0.9849020674646355 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 2.9580812454223633 - sq_loss: 6.146347573121602e-07 - tot_loss: 0.08734880845713211 - acc: 0.98449401523395 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 3.105804681777954 - sq_loss: 6.131452892077505e-07 - tot_loss: 0.10968938021300989 - acc: 0.984766050054407 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 3.0216336250305176 - sq_loss: 6.122500053606927e-07 - tot_loss: 0.08829008138074035 - acc: 0.9849020674646355 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 3.0381340980529785 - sq_loss: 6.11233019753854e-07 - tot_loss: 0.09154039215305887 - acc: 0.984766050054407 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 3.050262451171875 - sq_loss: 6.099588176766702e-07 - tot_loss: 0.0929112425702826 - acc: 0.984766050054407 - val_acc: 0.9606379368849678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 2.9866292476654053 - sq_loss: 6.085755330786924e-07 - tot_loss: 0.09352543483394693 - acc: 0.984766050054407 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 3.058588981628418 - sq_loss: 6.07278650477383e-07 - tot_loss: 0.11136916922445661 - acc: 0.984766050054407 - val_acc: 0.9602986087546658\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 3.1504311561584473 - sq_loss: 6.057525752112269e-07 - tot_loss: 0.09146111830224235 - acc: 0.984766050054407 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 3.1356041431427 - sq_loss: 6.051200784895627e-07 - tot_loss: 0.09467607740453288 - acc: 0.984766050054407 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 3.052912712097168 - sq_loss: 6.048713316886278e-07 - tot_loss: 0.09890168631193053 - acc: 0.984766050054407 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 3.0914626121520996 - sq_loss: 6.040992275302415e-07 - tot_loss: 0.09702758794745792 - acc: 0.984766050054407 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 3.0951833724975586 - sq_loss: 6.033557156115421e-07 - tot_loss: 0.0920194562327239 - acc: 0.9849020674646355 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 3.039273977279663 - sq_loss: 6.027325412105711e-07 - tot_loss: 0.09898819082172028 - acc: 0.985038084874864 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 3.0708179473876953 - sq_loss: 6.022577281328267e-07 - tot_loss: 0.09372470677900024 - acc: 0.985038084874864 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 3.0738868713378906 - sq_loss: 6.015582130203256e-07 - tot_loss: 0.0943474361281893 - acc: 0.9851741022850925 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 3.047621011734009 - sq_loss: 6.007794013385137e-07 - tot_loss: 0.0930932272934697 - acc: 0.985038084874864 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 3.1428496837615967 - sq_loss: 6.002382519909588e-07 - tot_loss: 0.0863011213861622 - acc: 0.9851741022850925 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 3.0802500247955322 - sq_loss: 5.991979605823872e-07 - tot_loss: 0.09701312067195456 - acc: 0.9851741022850925 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 3.059901714324951 - sq_loss: 5.979157435831439e-07 - tot_loss: 0.09479640021617253 - acc: 0.985310119695321 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 3.083798885345459 - sq_loss: 5.958312385700992e-07 - tot_loss: 0.1005518420110969 - acc: 0.9851741022850925 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 3.0162246227264404 - sq_loss: 5.954084372206125e-07 - tot_loss: 0.10204855338751795 - acc: 0.985310119695321 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 3.0605781078338623 - sq_loss: 5.941820973021095e-07 - tot_loss: 0.09610046350944423 - acc: 0.985310119695321 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 3.0453224182128906 - sq_loss: 5.927051347498491e-07 - tot_loss: 0.10624653082088087 - acc: 0.985310119695321 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 3.082202196121216 - sq_loss: 5.917261205468094e-07 - tot_loss: 0.09842955042408252 - acc: 0.9851741022850925 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 2.9799461364746094 - sq_loss: 5.911383595957886e-07 - tot_loss: 0.08952176993518779 - acc: 0.985310119695321 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 3.1460256576538086 - sq_loss: 5.904869340156438e-07 - tot_loss: 0.09223488013811809 - acc: 0.985310119695321 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 3.0863194465637207 - sq_loss: 5.899075290471956e-07 - tot_loss: 0.09159583906267776 - acc: 0.985310119695321 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 3.0007810592651367 - sq_loss: 5.893133447898435e-07 - tot_loss: 0.09159909491933527 - acc: 0.9854461371055495 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 3.0363643169403076 - sq_loss: 5.882931191081298e-07 - tot_loss: 0.08645254009904102 - acc: 0.9854461371055495 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 3.034966468811035 - sq_loss: 5.869895858268137e-07 - tot_loss: 0.1054266111220028 - acc: 0.9854461371055495 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 3.081573009490967 - sq_loss: 5.860389933332044e-07 - tot_loss: 0.10492177875482667 - acc: 0.9854461371055495 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 3.1483306884765625 - sq_loss: 5.848314117429254e-07 - tot_loss: 0.09765227655801778 - acc: 0.985582154515778 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 3.032013416290283 - sq_loss: 5.84591873575846e-07 - tot_loss: 0.09827485364561506 - acc: 0.985310119695321 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 3.088336706161499 - sq_loss: 5.839319783262908e-07 - tot_loss: 0.09262459494298192 - acc: 0.9854461371055495 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 3.1158559322357178 - sq_loss: 5.837168828293215e-07 - tot_loss: 0.09218811727361842 - acc: 0.9851741022850925 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 3.0616376399993896 - sq_loss: 5.828260896123538e-07 - tot_loss: 0.09362332910223803 - acc: 0.9857181719260065 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 3.111016035079956 - sq_loss: 5.817277610731253e-07 - tot_loss: 0.08935506331931065 - acc: 0.985582154515778 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 3.0859720706939697 - sq_loss: 5.799516316074005e-07 - tot_loss: 0.0959423109084303 - acc: 0.9857181719260065 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 3.0912914276123047 - sq_loss: 5.796513278255588e-07 - tot_loss: 0.0877457493628343 - acc: 0.985310119695321 - val_acc: 0.9613165931455717\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 3.131134510040283 - sq_loss: 5.785843200101226e-07 - tot_loss: 0.09684888828088678 - acc: 0.985854189336235 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 3.034363269805908 - sq_loss: 5.775717113465362e-07 - tot_loss: 0.09887287487833263 - acc: 0.985582154515778 - val_acc: 0.9606379368849678\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 3.0215299129486084 - sq_loss: 5.765262471868482e-07 - tot_loss: 0.09172234684841585 - acc: 0.9857181719260065 - val_acc: 0.9609772650152698\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 2.990544319152832 - sq_loss: 5.756051564276277e-07 - tot_loss: 0.09686935635859728 - acc: 0.985854189336235 - val_acc: 0.9609772650152698\n",
      "CR_1 = 0.17665842270710058   CR_2 = 0.17592699696476163\n",
      "/home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 3\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "alpha = 1\n",
    "\n",
    "\n",
    "\n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "    d0 = 561 #561 =3*11*17\n",
    "\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 512\n",
    "    d6 = 6 \n",
    "\n",
    "\n",
    "    W1 = 0.2*init.orthogonal_(torch.empty(d1, d0, device=device), gain=1.0)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    W2 = 0.2*init.orthogonal_(torch.empty(d2, d1, device=device), gain=1.0)\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles factors, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    W3 = 0.2*init.orthogonal_(torch.empty(d3, d2, device=device), gain=1.0)\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    W4 = 0.2*init.orthogonal_(torch.empty(d4, d3, device=device), gain=1.0)\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    W5 = 0.2*init.orthogonal_(torch.empty(d5, d4, device=device), gain=1.0)\n",
    "    W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())\n",
    "    factors5 = tensor_train(W5_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "\n",
    "    W6 = 0.2*init.orthogonal_(torch.empty(d6, d5, device=device), gain=1.0)\n",
    "    b6 = 0*torch.ones(d6, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = nn.ReLU()(U5)\n",
    "    U6 = torch.addmm(b6.repeat(1, N), W6, V5)\n",
    "    V6 = U6 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V6 = (y_one_hot + gamma*U6 + alpha*V6)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U6 = (gamma*V6 + rho*(torch.mm(W6,V5) + b6.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W6, b6 = updateWb_org(U6,V5,W6,b6,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "        # update for 5th layer\n",
    "        # update V3\n",
    "        V5 = updateV(U5,U6,W6,b6,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U5 = relu_prox(V5,(rho*torch.addmm(b5.repeat(1,N), W5, V4) + alpha*U5)/(rho + alpha),(rho + alpha)/gamma,d5,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W5, b5 = updateWb(U5,V4,W5,b5,W5_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4))\n",
    "        W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors5 = tensor_train(W5_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        a5_train = nn.ReLU()(torch.addmm(b5.repeat(1, N), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b6.repeat(1, N), W6, a5_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        a5_test = nn.ReLU()(torch.addmm(b5.repeat(1, N_test), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b6.repeat(1, N_test), W6, a5_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V6,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b6.repeat(1,N), W6, V5),U6,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,nn.ReLU()(U5),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V6,U6,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W5.reshape((4,4,4,4,4,4,4,4,4)),torch.as_tensor(W5_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "    factors5_shape=[f.shape for f in factors5]\n",
    "    Sum_of_variables_factors5=sum(list(x*y*z for x,y,z in factors5_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4+Sum_of_variables_factors5\n",
    "\n",
    "    CR_1=((total_variabels)+(d5*d6))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5+d5*d6)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#     #this postion to add new row into existing table\n",
    "#         df=pd.read_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "#         new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "#                    'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "#                    'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1],'seed':seed} \n",
    "#         df=df.append(new_row,ignore_index=True)\n",
    "#         df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"Orthogonal_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e5c2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133d333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
