{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4cb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a157bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a5c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087d0e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 3 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 3.813204526901245 - sq_loss: 661.678466796875 - tot_loss: 924.9924528305496 - acc: 0.17859085963003266 - val_acc: 0.168985408890397\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 3.1159539222717285 - sq_loss: 294.0793151855469 - tot_loss: 484.89320694527123 - acc: 0.20797062023939064 - val_acc: 0.19239904988123516\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 3.0232977867126465 - sq_loss: 165.0137481689453 - tot_loss: 264.86316735250875 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 3.1198904514312744 - sq_loss: 90.42965698242188 - tot_loss: 148.2673159246333 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 3.0823814868927 - sq_loss: 48.922645568847656 - tot_loss: 85.64182902732864 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 3.082014560699463 - sq_loss: 26.344892501831055 - tot_loss: 51.717684238334186 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 3.06447696685791 - sq_loss: 14.190069198608398 - tot_loss: 33.11105320858769 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 3.1185452938079834 - sq_loss: 7.670068264007568 - tot_loss: 22.80154768365901 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 3.0728330612182617 - sq_loss: 4.171710968017578 - tot_loss: 16.965477681951597 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 3.213334560394287 - sq_loss: 2.288911819458008 - tot_loss: 13.550093784113415 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 3.12750244140625 - sq_loss: 1.2702614068984985 - tot_loss: 11.447092700516805 - acc: 0.1749183895538629 - val_acc: 0.166610111978283\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 3.208810806274414 - sq_loss: 0.7151975631713867 - tot_loss: 10.037563751684502 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 3.0250582695007324 - sq_loss: 0.41001176834106445 - tot_loss: 8.98236981232185 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 2.9775354862213135 - sq_loss: 0.24033299088478088 - tot_loss: 8.122083423717413 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 3.127963066101074 - sq_loss: 0.14469408988952637 - tot_loss: 7.3639434892102145 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 3.1042397022247314 - sq_loss: 0.0898732915520668 - tot_loss: 6.684311712742783 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 3.015875816345215 - sq_loss: 0.05780169740319252 - tot_loss: 6.071991071046796 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 3.0770537853240967 - sq_loss: 0.03857740759849548 - tot_loss: 5.538230277161347 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 3.0456745624542236 - sq_loss: 0.026729656383395195 - tot_loss: 5.069337621258455 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 3.0695223808288574 - sq_loss: 0.01920027658343315 - tot_loss: 4.657039754878497 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 3.072486639022827 - sq_loss: 0.014257022179663181 - tot_loss: 4.302872809901601 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 3.1046648025512695 - sq_loss: 0.010904761962592602 - tot_loss: 3.9831458017361 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 3.1226212978363037 - sq_loss: 0.008559389971196651 - tot_loss: 3.703618640676723 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 2.969787120819092 - sq_loss: 0.006869570817798376 - tot_loss: 3.4659529777782154 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 3.011988639831543 - sq_loss: 0.0056183962151408195 - tot_loss: 3.2379440155200427 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 3.0421884059906006 - sq_loss: 0.004670414142310619 - tot_loss: 3.0500698507530615 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 3.0445566177368164 - sq_loss: 0.003936660010367632 - tot_loss: 2.8697278444305994 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 3.0576937198638916 - sq_loss: 0.003357863752171397 - tot_loss: 2.712918610726774 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 3.0842318534851074 - sq_loss: 0.0028938292525708675 - tot_loss: 2.5625804772607808 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 3.0426344871520996 - sq_loss: 0.002517152577638626 - tot_loss: 2.42865358785275 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 3.039410352706909 - sq_loss: 0.002207010518759489 - tot_loss: 2.30359301279168 - acc: 0.1968171926006529 - val_acc: 0.18866644044791314\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 3.0593512058258057 - sq_loss: 0.001948694814927876 - tot_loss: 2.191640879780607 - acc: 0.23707834602829161 - val_acc: 0.21920597217509333\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 3.096325635910034 - sq_loss: 0.0017315075965598226 - tot_loss: 2.0924052355367166 - acc: 0.2867247007616975 - val_acc: 0.2639972853749576\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 3.0172078609466553 - sq_loss: 0.0015470867510885 - tot_loss: 1.9986463322129566 - acc: 0.3294341675734494 - val_acc: 0.3077706141839158\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 3.0475332736968994 - sq_loss: 0.0013892136048525572 - tot_loss: 1.9105460324026353 - acc: 0.34194776931447224 - val_acc: 0.33932813030200204\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 3.032416820526123 - sq_loss: 0.0012530673993751407 - tot_loss: 1.8203042477143754 - acc: 0.3499727965179543 - val_acc: 0.3501866304716661\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 3.0211384296417236 - sq_loss: 0.0011346214450895786 - tot_loss: 1.7483970730972942 - acc: 0.35527747551686617 - val_acc: 0.3505259586019681\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 3.0778815746307373 - sq_loss: 0.0010314183309674263 - tot_loss: 1.6800491072317527 - acc: 0.35758977149075083 - val_acc: 0.3505259586019681\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 3.0968618392944336 - sq_loss: 0.0009404578013345599 - tot_loss: 1.6062426593271084 - acc: 0.35799782372143635 - val_acc: 0.3505259586019681\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 3.084303855895996 - sq_loss: 0.0008601135341450572 - tot_loss: 1.5480716241982009 - acc: 0.35772578890097934 - val_acc: 0.3505259586019681\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 3.0872490406036377 - sq_loss: 0.0007886651437729597 - tot_loss: 1.487037325216079 - acc: 0.35786180631120784 - val_acc: 0.3505259586019681\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 3.0682358741760254 - sq_loss: 0.000724850979167968 - tot_loss: 1.4344155425060308 - acc: 0.3586779107725789 - val_acc: 0.3522225992534781\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 3.107733726501465 - sq_loss: 0.0006679418147541583 - tot_loss: 1.3863070916431752 - acc: 0.37744831338411317 - val_acc: 0.3647777400746522\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 3.048201322555542 - sq_loss: 0.0006166979437693954 - tot_loss: 1.32547206549134 - acc: 0.4164853101196953 - val_acc: 0.4021038344078724\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 3.092721700668335 - sq_loss: 0.0005705764633603394 - tot_loss: 1.2824315154175565 - acc: 0.4666757344940152 - val_acc: 0.45062775704105873\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 3.0661685466766357 - sq_loss: 0.0005287107778713107 - tot_loss: 1.2388010876602493 - acc: 0.5044885745375408 - val_acc: 0.49032914828639296\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 3.084178924560547 - sq_loss: 0.0004905798705294728 - tot_loss: 1.204674800439534 - acc: 0.5228509249183896 - val_acc: 0.5123854767560231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 3.1245858669281006 - sq_loss: 0.00045608493383042514 - tot_loss: 1.1575935223700071 - acc: 0.5346844396082698 - val_acc: 0.5212080081438751\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 3.071181535720825 - sq_loss: 0.0004245070740580559 - tot_loss: 1.1134993216082876 - acc: 0.5412132752992383 - val_acc: 0.5269765863590091\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 3.098316192626953 - sq_loss: 0.0003957573208026588 - tot_loss: 1.0791120416115518 - acc: 0.5432535364526659 - val_acc: 0.5279945707499152\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 3.044724702835083 - sq_loss: 0.00036944885505363345 - tot_loss: 1.0419405997072317 - acc: 0.5457018498367792 - val_acc: 0.5293518832711231\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 3.0877580642700195 - sq_loss: 0.00034519191831350327 - tot_loss: 1.0074506321043373 - acc: 0.5471980413492927 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 3.1394636631011963 - sq_loss: 0.0003228900895919651 - tot_loss: 0.9777805321955384 - acc: 0.5488302502720348 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 3.064645767211914 - sq_loss: 0.0003023941535502672 - tot_loss: 0.9495492248242954 - acc: 0.5511425462459195 - val_acc: 0.5313878520529352\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 3.030357837677002 - sq_loss: 0.00028340599965304136 - tot_loss: 0.9087973721552771 - acc: 0.5549510337323177 - val_acc: 0.5327451645741432\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 3.0863242149353027 - sq_loss: 0.0002657989680301398 - tot_loss: 0.8857176572973913 - acc: 0.5640642002176278 - val_acc: 0.5364777740074652\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 3.0506670475006104 - sq_loss: 0.0002495452354196459 - tot_loss: 0.8608690918836146 - acc: 0.5750816104461371 - val_acc: 0.5419070240922973\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 3.021608829498291 - sq_loss: 0.00023457634961232543 - tot_loss: 0.8312994616026117 - acc: 0.5893634385201306 - val_acc: 0.5524261961316593\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 3.1250011920928955 - sq_loss: 0.00022060881019569933 - tot_loss: 0.7992368726208952 - acc: 0.60310119695321 - val_acc: 0.5632846963013234\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 3.113715887069702 - sq_loss: 0.0002076653909171 - tot_loss: 0.7811843714757742 - acc: 0.6187431991294886 - val_acc: 0.5721072276891754\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 3.0531604290008545 - sq_loss: 0.00019553923630155623 - tot_loss: 0.7525627382642597 - acc: 0.6345212187159956 - val_acc: 0.5843230403800475\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 3.0684759616851807 - sq_loss: 0.000184236399945803 - tot_loss: 0.7328628532814037 - acc: 0.6517954298150164 - val_acc: 0.5928062436375976\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 3.0740694999694824 - sq_loss: 0.0001736418198561296 - tot_loss: 0.7043924800545938 - acc: 0.6624047878128401 - val_acc: 0.6016287750254496\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 3.121272563934326 - sq_loss: 0.00016365054761990905 - tot_loss: 0.6875063677603066 - acc: 0.6735582154515778 - val_acc: 0.6050220563284696\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 3.1080732345581055 - sq_loss: 0.0001543759717606008 - tot_loss: 0.6583213951994367 - acc: 0.684031556039173 - val_acc: 0.6145232439769257\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 3.042647123336792 - sq_loss: 0.0001457312610000372 - tot_loss: 0.644634903714632 - acc: 0.6916485310119695 - val_acc: 0.6277570410587038\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 3.0211009979248047 - sq_loss: 0.0001376667496515438 - tot_loss: 0.6272062518000894 - acc: 0.6999455930359086 - val_acc: 0.6386155412283678\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 3.0397138595581055 - sq_loss: 0.00012998745660297573 - tot_loss: 0.605637328812918 - acc: 0.7042981501632208 - val_acc: 0.6481167288768239\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 3.0830228328704834 - sq_loss: 0.00012279079237487167 - tot_loss: 0.5883160602024873 - acc: 0.7089227421109902 - val_acc: 0.656939260264676\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 3.0697896480560303 - sq_loss: 0.00011600835568970069 - tot_loss: 0.5734380359676834 - acc: 0.7121871599564744 - val_acc: 0.66610111978283\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 3.085831880569458 - sq_loss: 0.00010965581168420613 - tot_loss: 0.5538014627836674 - acc: 0.7162676822633297 - val_acc: 0.671869697997964\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 3.107923746109009 - sq_loss: 0.00010367742652306333 - tot_loss: 0.5345770371518483 - acc: 0.7215723612622416 - val_acc: 0.6766202918221921\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 3.124645471572876 - sq_loss: 9.799285180633888e-05 - tot_loss: 0.5222838731008324 - acc: 0.7285092491838956 - val_acc: 0.6844248388191381\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 3.020951271057129 - sq_loss: 9.269743168260902e-05 - tot_loss: 0.5120547364804224 - acc: 0.7334058759521219 - val_acc: 0.6922293858160842\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 3.040451765060425 - sq_loss: 8.771059947321191e-05 - tot_loss: 0.49647752343548746 - acc: 0.7365342763873776 - val_acc: 0.6959619952494062\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 3.0441858768463135 - sq_loss: 8.297455497086048e-05 - tot_loss: 0.48400479128463303 - acc: 0.7408868335146899 - val_acc: 0.7007125890736342\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 3.0452470779418945 - sq_loss: 7.851242844481021e-05 - tot_loss: 0.463646323571993 - acc: 0.7442872687704026 - val_acc: 0.7064811672887682\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 3.1269969940185547 - sq_loss: 7.430330151692033e-05 - tot_loss: 0.46180835184782154 - acc: 0.7498639825897715 - val_acc: 0.7108924329826942\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 3.2444064617156982 - sq_loss: 7.028757681837305e-05 - tot_loss: 0.4460519053970984 - acc: 0.7534004352557128 - val_acc: 0.7146250424160163\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 3.044344425201416 - sq_loss: 6.651220610365272e-05 - tot_loss: 0.4228229135176207 - acc: 0.7559847660500544 - val_acc: 0.7190363081099423\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 3.0925087928771973 - sq_loss: 6.28680209047161e-05 - tot_loss: 0.42201191680646843 - acc: 0.7588411316648531 - val_acc: 0.7224295894129623\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 2.9939937591552734 - sq_loss: 5.949645128566772e-05 - tot_loss: 0.4117291416239368 - acc: 0.7596572361262242 - val_acc: 0.7268408551068883\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 3.052513360977173 - sq_loss: 5.634573244606145e-05 - tot_loss: 0.3972935728252196 - acc: 0.7625136017410229 - val_acc: 0.7309127926705123\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 3.1517701148986816 - sq_loss: 5.340179632185027e-05 - tot_loss: 0.38424115481348053 - acc: 0.764145810663765 - val_acc: 0.7363420427553444\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 3.109790086746216 - sq_loss: 5.05691823491361e-05 - tot_loss: 0.3833528369900705 - acc: 0.7661860718171926 - val_acc: 0.7387173396674585\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 3.1378390789031982 - sq_loss: 4.7879562771413475e-05 - tot_loss: 0.37476984741931574 - acc: 0.7680903155603918 - val_acc: 0.7400746521886664\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 3.088146209716797 - sq_loss: 4.5344837417360395e-05 - tot_loss: 0.3608510721114726 - acc: 0.7702665941240479 - val_acc: 0.7427892772310825\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 3.045184373855591 - sq_loss: 4.29858555435203e-05 - tot_loss: 0.3491361343404833 - acc: 0.7723068552774756 - val_acc: 0.7455039022734985\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 3.0815985202789307 - sq_loss: 4.074144453625195e-05 - tot_loss: 0.338244662539978 - acc: 0.7738030467899891 - val_acc: 0.7485578554462164\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 3.033600330352783 - sq_loss: 3.860762080876157e-05 - tot_loss: 0.3298181793833237 - acc: 0.7750272034820457 - val_acc: 0.7502544960977265\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 3.3706600666046143 - sq_loss: 3.660114816739224e-05 - tot_loss: 0.3281930021125845 - acc: 0.7770674646354734 - val_acc: 0.7519511367492365\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 3.0622801780700684 - sq_loss: 3.4691889595706016e-05 - tot_loss: 0.323524323206243 - acc: 0.7782916213275299 - val_acc: 0.7543264336613505\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 3.072388172149658 - sq_loss: 3.2904405088629574e-05 - tot_loss: 0.3090436304578361 - acc: 0.779379760609358 - val_acc: 0.7543264336613505\n",
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 3.0690767765045166 - sq_loss: 3.126333831460215e-05 - tot_loss: 0.30284550403098365 - acc: 0.7812840043525572 - val_acc: 0.7567017305734646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 3.086115837097168 - sq_loss: 2.961941390822176e-05 - tot_loss: 0.2988174970384989 - acc: 0.7825081610446137 - val_acc: 0.7573803868340685\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 3.0095508098602295 - sq_loss: 2.8071875931345858e-05 - tot_loss: 0.2869498829037411 - acc: 0.7834602829162133 - val_acc: 0.7587376993552766\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 3.0457394123077393 - sq_loss: 2.6609692213241942e-05 - tot_loss: 0.28079263228573836 - acc: 0.7842763873775843 - val_acc: 0.7607736681370886\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 3.079810380935669 - sq_loss: 2.525557101762388e-05 - tot_loss: 0.27110584829188156 - acc: 0.7864526659412405 - val_acc: 0.7628096369189006\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 3.060966730117798 - sq_loss: 2.4005514205782674e-05 - tot_loss: 0.2710176506905668 - acc: 0.7880848748639826 - val_acc: 0.7651849338310146\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 3.097782611846924 - sq_loss: 2.2823780454928055e-05 - tot_loss: 0.25997786108609944 - acc: 0.7899891186071817 - val_acc: 0.7668815744825246\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 3.058793067932129 - sq_loss: 2.1671126887667924e-05 - tot_loss: 0.2610445046089467 - acc: 0.7913492927094669 - val_acc: 0.7672209026128266\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 3.0600662231445312 - sq_loss: 2.0610903447959572e-05 - tot_loss: 0.26239282187611934 - acc: 0.7927094668117519 - val_acc: 0.7685782151340346\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 3.0870883464813232 - sq_loss: 1.9598426661104895e-05 - tot_loss: 0.24989646583770764 - acc: 0.7942056583242655 - val_acc: 0.7706141839158466\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 3.041372776031494 - sq_loss: 1.8616216038935818e-05 - tot_loss: 0.24226141876482643 - acc: 0.7959738846572362 - val_acc: 0.7729894808279606\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 3.041806697845459 - sq_loss: 1.7689824744593352e-05 - tot_loss: 0.23830205574927277 - acc: 0.7977421109902068 - val_acc: 0.7753647777400746\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 3.0798587799072266 - sq_loss: 1.683511982264463e-05 - tot_loss: 0.23814591659106554 - acc: 0.8000544069640914 - val_acc: 0.7757041058703766\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 3.040065050125122 - sq_loss: 1.6027117453631945e-05 - tot_loss: 0.23689449015449782 - acc: 0.8016866158868335 - val_acc: 0.7777400746521886\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 3.0595171451568604 - sq_loss: 1.5251826880557928e-05 - tot_loss: 0.2260097025440473 - acc: 0.8035908596300326 - val_acc: 0.7801153715643027\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 3.0578536987304688 - sq_loss: 1.4498325981548987e-05 - tot_loss: 0.22086575419569954 - acc: 0.8056311207834603 - val_acc: 0.7814726840855107\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 3.05557918548584 - sq_loss: 1.3803021829517093e-05 - tot_loss: 0.21606706742068127 - acc: 0.8080794341675734 - val_acc: 0.7835086528673227\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 3.112173557281494 - sq_loss: 1.3157565263099968e-05 - tot_loss: 0.2215333526212362 - acc: 0.8106637649619152 - val_acc: 0.7852052935188327\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 3.042628765106201 - sq_loss: 1.2516193237388507e-05 - tot_loss: 0.21434167105550728 - acc: 0.8128400435255713 - val_acc: 0.7885985748218527\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 3.1396710872650146 - sq_loss: 1.1937410818063654e-05 - tot_loss: 0.20106596272435695 - acc: 0.815424374319913 - val_acc: 0.7916525279945708\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 3.0350096225738525 - sq_loss: 1.1366190847184043e-05 - tot_loss: 0.2041184164749552 - acc: 0.8169205658324266 - val_acc: 0.7943671530369868\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 3.0721940994262695 - sq_loss: 1.0844650205399375e-05 - tot_loss: 0.1937899637700582 - acc: 0.8192328618063112 - val_acc: 0.7953851374278927\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 3.0434250831604004 - sq_loss: 1.0350999218644574e-05 - tot_loss: 0.19066126503008718 - acc: 0.8214091403699674 - val_acc: 0.7967424499491008\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 3.0446386337280273 - sq_loss: 9.876061994873453e-06 - tot_loss: 0.19824149539300606 - acc: 0.8238574537540805 - val_acc: 0.7980997624703088\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 3.163543939590454 - sq_loss: 9.41486723604612e-06 - tot_loss: 0.19767046004386657 - acc: 0.8256256800870512 - val_acc: 0.8001357312521208\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 3.013906955718994 - sq_loss: 8.980845450423658e-06 - tot_loss: 0.1912557689767027 - acc: 0.8278019586507073 - val_acc: 0.8038683406854428\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 3.0369136333465576 - sq_loss: 8.576349500799552e-06 - tot_loss: 0.18996845206885382 - acc: 0.83120239390642 - val_acc: 0.8062436375975568\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 3.026740312576294 - sq_loss: 8.202977369364817e-06 - tot_loss: 0.18911898308542163 - acc: 0.8335146898803046 - val_acc: 0.8082796063793688\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 3.0986762046813965 - sq_loss: 7.85256543167634e-06 - tot_loss: 0.18628130061102866 - acc: 0.8347388465723613 - val_acc: 0.8099762470308789\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 3.120878219604492 - sq_loss: 7.516289770137519e-06 - tot_loss: 0.18088440129395167 - acc: 0.8378672470076169 - val_acc: 0.8120122158126909\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 3.088900566101074 - sq_loss: 7.178964096965501e-06 - tot_loss: 0.17768374061398617 - acc: 0.8409956474428727 - val_acc: 0.8133695283338989\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 3.122284412384033 - sq_loss: 6.862715963507071e-06 - tot_loss: 0.16612007016681218 - acc: 0.844532100108814 - val_acc: 0.8147268408551069\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 3.009612560272217 - sq_loss: 6.569098786712857e-06 - tot_loss: 0.1763793951014634 - acc: 0.846436343852013 - val_acc: 0.8150661689854088\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 3.0924527645111084 - sq_loss: 6.28670932201203e-06 - tot_loss: 0.1738992571082889 - acc: 0.8491566920565833 - val_acc: 0.8184594502884289\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 3.095933437347412 - sq_loss: 6.017039140715497e-06 - tot_loss: 0.1673101169946989 - acc: 0.8521490750816104 - val_acc: 0.821174075330845\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 2.9865148067474365 - sq_loss: 5.752734068664722e-06 - tot_loss: 0.16512241527709648 - acc: 0.8554134929270947 - val_acc: 0.8238887003732609\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 3.0727715492248535 - sq_loss: 5.50282447875361e-06 - tot_loss: 0.16390937540629125 - acc: 0.8582698585418934 - val_acc: 0.825924669155073\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 3.0730395317077637 - sq_loss: 5.271665486361599e-06 - tot_loss: 0.16301499363430594 - acc: 0.8615342763873776 - val_acc: 0.8282999660671869\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 3.068654775619507 - sq_loss: 5.0776802709151525e-06 - tot_loss: 0.16424078066096115 - acc: 0.8637105549510338 - val_acc: 0.8286392941974889\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 3.0398104190826416 - sq_loss: 4.878290837950772e-06 - tot_loss: 0.15619889771254236 - acc: 0.8656147986942329 - val_acc: 0.832371903630811\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 3.0165672302246094 - sq_loss: 4.697079475590726e-06 - tot_loss: 0.1577174103926211 - acc: 0.8681991294885746 - val_acc: 0.835086528673227\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 3.0669236183166504 - sq_loss: 4.523015377344564e-06 - tot_loss: 0.154238002219671 - acc: 0.8698313384113167 - val_acc: 0.837122497455039\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 3.0198047161102295 - sq_loss: 4.359317244961858e-06 - tot_loss: 0.15295938212241822 - acc: 0.8717355821545157 - val_acc: 0.839837122497455\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 3.051736831665039 - sq_loss: 4.19461275669164e-06 - tot_loss: 0.14723260973394758 - acc: 0.8729597388465724 - val_acc: 0.841533763148965\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 3.0569815635681152 - sq_loss: 4.029613137390697e-06 - tot_loss: 0.14312721253202199 - acc: 0.875 - val_acc: 0.843909060061079\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 3.0708580017089844 - sq_loss: 3.8760645111324266e-06 - tot_loss: 0.13970864983476616 - acc: 0.8770402611534276 - val_acc: 0.8456057007125891\n",
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 3.0724563598632812 - sq_loss: 3.7369811707321787e-06 - tot_loss: 0.1427575321010437 - acc: 0.8779923830250272 - val_acc: 0.8479809976247031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 3.076361894607544 - sq_loss: 3.5918064895668067e-06 - tot_loss: 0.1502379266232623 - acc: 0.8807127312295974 - val_acc: 0.8520529351883271\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 3.013364315032959 - sq_loss: 3.4658328331715893e-06 - tot_loss: 0.14175761384976937 - acc: 0.8834330794341676 - val_acc: 0.8527315914489311\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 3.0745127201080322 - sq_loss: 3.3461462862760527e-06 - tot_loss: 0.13563772136882335 - acc: 0.8852013057671382 - val_acc: 0.8544282321004412\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 3.069274663925171 - sq_loss: 3.23351014230866e-06 - tot_loss: 0.1342105197650838 - acc: 0.8872415669205659 - val_acc: 0.8561248727519511\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 3.081641912460327 - sq_loss: 3.1260353807738284e-06 - tot_loss: 0.13725499896173687 - acc: 0.8883297062023939 - val_acc: 0.8588394977943672\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 3.0486550331115723 - sq_loss: 3.0223113753891084e-06 - tot_loss: 0.13785260199220062 - acc: 0.8895538628944505 - val_acc: 0.8595181540549711\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 3.0488860607147217 - sq_loss: 2.927332616309286e-06 - tot_loss: 0.13343823391760168 - acc: 0.891050054406964 - val_acc: 0.8612147947064812\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 3.02823543548584 - sq_loss: 2.8369413485052064e-06 - tot_loss: 0.14008455057947344 - acc: 0.8915941240478781 - val_acc: 0.8625721072276892\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 3.051847457885742 - sq_loss: 2.7359762952983147e-06 - tot_loss: 0.12638070982465877 - acc: 0.8933623503808488 - val_acc: 0.8642687478791992\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 3.0791382789611816 - sq_loss: 2.6603358946886146e-06 - tot_loss: 0.13508251688044481 - acc: 0.8951305767138193 - val_acc: 0.8649474041398032\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 3.0399041175842285 - sq_loss: 2.585961738077458e-06 - tot_loss: 0.12804725784275206 - acc: 0.8960826985854189 - val_acc: 0.8659653885307091\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 3.002021551132202 - sq_loss: 2.5093977455981076e-06 - tot_loss: 0.13279062968512534 - acc: 0.8963547334058759 - val_acc: 0.8683406854428232\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 3.043736219406128 - sq_loss: 2.433262125123292e-06 - tot_loss: 0.13259240720658383 - acc: 0.8977149075081611 - val_acc: 0.8693586698337292\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 3.004925012588501 - sq_loss: 2.3641778170713224e-06 - tot_loss: 0.12568389192218277 - acc: 0.8988030467899891 - val_acc: 0.8713946386155412\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 3.0487465858459473 - sq_loss: 2.2942131181480363e-06 - tot_loss: 0.12087019458022752 - acc: 0.8997551686615887 - val_acc: 0.8747879199185612\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 3.055692195892334 - sq_loss: 2.230921836599009e-06 - tot_loss: 0.12452991059349472 - acc: 0.9002992383025027 - val_acc: 0.8771632168306752\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 3.0827581882476807 - sq_loss: 2.1675687094102614e-06 - tot_loss: 0.11898853673458376 - acc: 0.9013873775843307 - val_acc: 0.8785205293518833\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 3.039053201675415 - sq_loss: 2.107728732880787e-06 - tot_loss: 0.12731732742926027 - acc: 0.9022034820457019 - val_acc: 0.8798778418730913\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 3.062905788421631 - sq_loss: 2.054561491604545e-06 - tot_loss: 0.11513955879711801 - acc: 0.9039717083786725 - val_acc: 0.8805564981336953\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 3.1028225421905518 - sq_loss: 1.9970257199020125e-06 - tot_loss: 0.12199121945189262 - acc: 0.9050598476605005 - val_acc: 0.8825924669155073\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 3.039634943008423 - sq_loss: 1.952083948708605e-06 - tot_loss: 0.12389651423158199 - acc: 0.9060119695321001 - val_acc: 0.8839497794367153\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 3.0227348804473877 - sq_loss: 1.9001512328031822e-06 - tot_loss: 0.11701423221350993 - acc: 0.9069640914036997 - val_acc: 0.8856464200882254\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 3.076564311981201 - sq_loss: 1.8555432461653254e-06 - tot_loss: 0.1259645948182353 - acc: 0.9080522306855278 - val_acc: 0.8866644044791313\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 3.0859994888305664 - sq_loss: 1.8130763237422798e-06 - tot_loss: 0.11504680039859849 - acc: 0.9083242655059848 - val_acc: 0.8876823888700374\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 3.0158843994140625 - sq_loss: 1.7686677438177867e-06 - tot_loss: 0.12694229101532528 - acc: 0.9085963003264418 - val_acc: 0.8887003732609433\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 3.1016430854797363 - sq_loss: 1.7261004359170329e-06 - tot_loss: 0.1202934422093982 - acc: 0.9090043525571273 - val_acc: 0.8893790295215473\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 3.054729700088501 - sq_loss: 1.6809486851343536e-06 - tot_loss: 0.11699520011441322 - acc: 0.9096844396082698 - val_acc: 0.8907363420427553\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 3.028871536254883 - sq_loss: 1.6401525044784648e-06 - tot_loss: 0.11454759938844106 - acc: 0.9103645266594124 - val_acc: 0.8920936545639634\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 3.017578363418579 - sq_loss: 1.6093589465526748e-06 - tot_loss: 0.11390218701046173 - acc: 0.9111806311207835 - val_acc: 0.8931116389548693\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 3.1280624866485596 - sq_loss: 1.580080720486876e-06 - tot_loss: 0.11618983638062375 - acc: 0.911860718171926 - val_acc: 0.8934509670851714\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 3.045423746109009 - sq_loss: 1.5448048316102359e-06 - tot_loss: 0.11602720075579143 - acc: 0.9124047878128401 - val_acc: 0.8951476077366813\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 3.1050634384155273 - sq_loss: 1.5166770026553422e-06 - tot_loss: 0.1078246101712903 - acc: 0.9126768226332971 - val_acc: 0.8965049202578894\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 3.111539840698242 - sq_loss: 1.4802369605604326e-06 - tot_loss: 0.11376276358660675 - acc: 0.9137649619151251 - val_acc: 0.8968442483881914\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 3.0711710453033447 - sq_loss: 1.4482961887551937e-06 - tot_loss: 0.11408322296508899 - acc: 0.9143090315560392 - val_acc: 0.8971835765184933\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 3.114128589630127 - sq_loss: 1.4208143284122343e-06 - tot_loss: 0.11517276338162574 - acc: 0.9148531011969532 - val_acc: 0.8978622327790974\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 3.119952440261841 - sq_loss: 1.3944514876129688e-06 - tot_loss: 0.11141182509985548 - acc: 0.9152611534276387 - val_acc: 0.8988802171700034\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 3.101290464401245 - sq_loss: 1.3690511195818544e-06 - tot_loss: 0.10782020866994735 - acc: 0.9158052230685527 - val_acc: 0.8995588734306074\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 3.112178087234497 - sq_loss: 1.3428459624265088e-06 - tot_loss: 0.10060875641766032 - acc: 0.9162132752992383 - val_acc: 0.9012555140821175\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 3.0601820945739746 - sq_loss: 1.3200873354435316e-06 - tot_loss: 0.11007085866156174 - acc: 0.9170293797606094 - val_acc: 0.9015948422124194\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 3.0763187408447266 - sq_loss: 1.2954296835232526e-06 - tot_loss: 0.10276070923263525 - acc: 0.9174374319912949 - val_acc: 0.9026128266033254\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 3.124274253845215 - sq_loss: 1.2782357998730731e-06 - tot_loss: 0.10582184439071618 - acc: 0.9182535364526659 - val_acc: 0.9043094672548354\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 3.093519926071167 - sq_loss: 1.2568070815177634e-06 - tot_loss: 0.10059687771686043 - acc: 0.91879760609358 - val_acc: 0.9043094672548354\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 3.209768295288086 - sq_loss: 1.233523789778701e-06 - tot_loss: 0.10738577351275502 - acc: 0.9186615886833515 - val_acc: 0.9046487953851374\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 3.0954947471618652 - sq_loss: 1.2118762242607772e-06 - tot_loss: 0.11057215119625319 - acc: 0.919341675734494 - val_acc: 0.9063454360366474\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 3.120414972305298 - sq_loss: 1.194707124341221e-06 - tot_loss: 0.10968348303497777 - acc: 0.9197497279651795 - val_acc: 0.9066847641669494\n",
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 3.1080973148345947 - sq_loss: 1.1782900628531934e-06 - tot_loss: 0.1037942079656915 - acc: 0.919885745375408 - val_acc: 0.9073634204275535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 3.11938214302063 - sq_loss: 1.162442572422151e-06 - tot_loss: 0.10118722237482292 - acc: 0.920157780195865 - val_acc: 0.9080420766881574\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 3.0696451663970947 - sq_loss: 1.1500707159939338e-06 - tot_loss: 0.10362536070274153 - acc: 0.9207018498367792 - val_acc: 0.9083814048184594\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 3.044933795928955 - sq_loss: 1.1338103149682865e-06 - tot_loss: 0.10214828812875076 - acc: 0.9211099020674647 - val_acc: 0.9080420766881574\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 3.0620875358581543 - sq_loss: 1.1211524224563618e-06 - tot_loss: 0.10454497925352157 - acc: 0.9216539717083787 - val_acc: 0.9087207329487614\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 3.031355381011963 - sq_loss: 1.1069687388953753e-06 - tot_loss: 0.099649397682394 - acc: 0.9219260065288357 - val_acc: 0.9083814048184594\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 3.037149429321289 - sq_loss: 1.090589080376958e-06 - tot_loss: 0.10180048775902151 - acc: 0.9224700761697497 - val_acc: 0.9093993892093655\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 3.061121940612793 - sq_loss: 1.0760187478808803e-06 - tot_loss: 0.10175140624271428 - acc: 0.9231501632208923 - val_acc: 0.9100780454699695\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 3.0732781887054443 - sq_loss: 1.0627635447235662e-06 - tot_loss: 0.1050842493655404 - acc: 0.9234221980413493 - val_acc: 0.9104173736002714\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 3.0028367042541504 - sq_loss: 1.0481122671990306e-06 - tot_loss: 0.09799471798267767 - acc: 0.9241022850924918 - val_acc: 0.9100780454699695\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 3.1646764278411865 - sq_loss: 1.0360688520449912e-06 - tot_loss: 0.10457949014602441 - acc: 0.9245103373231773 - val_acc: 0.9107567017305734\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 3.068835735321045 - sq_loss: 1.0241305972158443e-06 - tot_loss: 0.0947362295410592 - acc: 0.9250544069640914 - val_acc: 0.9107567017305734\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 3.0044829845428467 - sq_loss: 1.0107607977261068e-06 - tot_loss: 0.10559087072172435 - acc: 0.9255984766050055 - val_acc: 0.9110960298608755\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 3.035222053527832 - sq_loss: 9.992593277274864e-07 - tot_loss: 0.10236054566663011 - acc: 0.926006528835691 - val_acc: 0.9114353579911775\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 3.0936779975891113 - sq_loss: 9.89041382126743e-07 - tot_loss: 0.09921380998269225 - acc: 0.926822633297062 - val_acc: 0.9117746861214795\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 3.049638032913208 - sq_loss: 9.823419304666459e-07 - tot_loss: 0.09433884633474232 - acc: 0.9269586507072906 - val_acc: 0.9117746861214795\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 2.997119903564453 - sq_loss: 9.711543498269748e-07 - tot_loss: 0.09218560352261829 - acc: 0.9275027203482046 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 3.0104281902313232 - sq_loss: 9.580124924468691e-07 - tot_loss: 0.09709385994316655 - acc: 0.9277747551686616 - val_acc: 0.9138106549032915\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 2.9920308589935303 - sq_loss: 9.487898751103785e-07 - tot_loss: 0.09924234764543449 - acc: 0.9284548422198041 - val_acc: 0.9138106549032915\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 3.040846109390259 - sq_loss: 9.418648119208228e-07 - tot_loss: 0.1017468052303947 - acc: 0.9284548422198041 - val_acc: 0.9141499830335935\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 3.049318313598633 - sq_loss: 9.360059607388393e-07 - tot_loss: 0.09472261673939908 - acc: 0.9287268770402611 - val_acc: 0.9148286392941974\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 3.052690267562866 - sq_loss: 9.234896651832969e-07 - tot_loss: 0.1038350631923235 - acc: 0.9291349292709467 - val_acc: 0.9155072955548015\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 3.052633285522461 - sq_loss: 9.167146686195338e-07 - tot_loss: 0.100970567257054 - acc: 0.9296789989118607 - val_acc: 0.9158466236851035\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 3.072425603866577 - sq_loss: 9.054730298885261e-07 - tot_loss: 0.09464039519245748 - acc: 0.9296789989118607 - val_acc: 0.9165252799457075\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 3.032506227493286 - sq_loss: 8.98184282505099e-07 - tot_loss: 0.09195100769425135 - acc: 0.9300870511425462 - val_acc: 0.9155072955548015\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 3.0448102951049805 - sq_loss: 8.881005442162859e-07 - tot_loss: 0.09577256624837371 - acc: 0.9306311207834603 - val_acc: 0.9165252799457075\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 3.0602831840515137 - sq_loss: 8.787927185949229e-07 - tot_loss: 0.09581655701337777 - acc: 0.9311751904243744 - val_acc: 0.9172039362063115\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 3.0194764137268066 - sq_loss: 8.715109629520157e-07 - tot_loss: 0.08917606349596019 - acc: 0.9313112078346029 - val_acc: 0.9175432643366135\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 2.9804627895355225 - sq_loss: 8.636931170258322e-07 - tot_loss: 0.09603482110182204 - acc: 0.9315832426550599 - val_acc: 0.9175432643366135\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 3.065272092819214 - sq_loss: 8.559268849239743e-07 - tot_loss: 0.08992709976304347 - acc: 0.9319912948857454 - val_acc: 0.9178825924669155\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 3.0441670417785645 - sq_loss: 8.494768621858384e-07 - tot_loss: 0.09306543866600991 - acc: 0.9323993471164309 - val_acc: 0.9168646080760094\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 2.9898672103881836 - sq_loss: 8.411693670495879e-07 - tot_loss: 0.09364679642061535 - acc: 0.9329434167573449 - val_acc: 0.9175432643366135\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 3.0715105533599854 - sq_loss: 8.39395738694293e-07 - tot_loss: 0.09338260052920777 - acc: 0.9330794341675734 - val_acc: 0.9175432643366135\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 3.047006607055664 - sq_loss: 8.31843919968378e-07 - tot_loss: 0.08498254718233378 - acc: 0.933215451577802 - val_acc: 0.9182219205972175\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 3.041002035140991 - sq_loss: 8.281094210360607e-07 - tot_loss: 0.09332578023683036 - acc: 0.933759521218716 - val_acc: 0.9189005768578216\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 3.0764827728271484 - sq_loss: 8.200004231184721e-07 - tot_loss: 0.0922612466725008 - acc: 0.9338955386289445 - val_acc: 0.9192399049881235\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 3.0355823040008545 - sq_loss: 8.103458526420582e-07 - tot_loss: 0.09348250728060226 - acc: 0.934847660500544 - val_acc: 0.9199185612487275\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 3.029242753982544 - sq_loss: 8.053581268541166e-07 - tot_loss: 0.09246554965590903 - acc: 0.9352557127312296 - val_acc: 0.9202578893790295\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 3.090294599533081 - sq_loss: 8.020310815481935e-07 - tot_loss: 0.09658735767368087 - acc: 0.9357997823721437 - val_acc: 0.9205972175093315\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 3.086477518081665 - sq_loss: 7.994095767571707e-07 - tot_loss: 0.09150565365858077 - acc: 0.9366158868335147 - val_acc: 0.9209365456396336\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 3.078240156173706 - sq_loss: 7.949070095492061e-07 - tot_loss: 0.09607673415020423 - acc: 0.9364798694232862 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 3.067112445831299 - sq_loss: 7.901001026766608e-07 - tot_loss: 0.09242139328466381 - acc: 0.9366158868335147 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 3.0747275352478027 - sq_loss: 7.866219675634056e-07 - tot_loss: 0.08985489681316494 - acc: 0.9371599564744287 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 3.1225178241729736 - sq_loss: 7.838891065148346e-07 - tot_loss: 0.08654971243969145 - acc: 0.9377040261153428 - val_acc: 0.9226331862911435\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 3.0739290714263916 - sq_loss: 7.791168172843754e-07 - tot_loss: 0.09511794126084139 - acc: 0.9382480957562568 - val_acc: 0.9222938581608415\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 3.0645482540130615 - sq_loss: 7.744424124211946e-07 - tot_loss: 0.09168928452129066 - acc: 0.9383841131664853 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 3.0045313835144043 - sq_loss: 7.696432930970332e-07 - tot_loss: 0.08936501095123717 - acc: 0.9386561479869423 - val_acc: 0.9236511706820495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 3.0225203037261963 - sq_loss: 7.658525191800436e-07 - tot_loss: 0.09021345096107192 - acc: 0.9385201305767138 - val_acc: 0.9236511706820495\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 3.1323444843292236 - sq_loss: 7.623054898431292e-07 - tot_loss: 0.08502392534151992 - acc: 0.9386561479869423 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 3.086653232574463 - sq_loss: 7.582974035358347e-07 - tot_loss: 0.08440301835871056 - acc: 0.9392002176278563 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 3.1489639282226562 - sq_loss: 7.558801371487789e-07 - tot_loss: 0.09967668597908963 - acc: 0.9396082698585418 - val_acc: 0.9246691550729556\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 2.977494478225708 - sq_loss: 7.527203251811443e-07 - tot_loss: 0.08389512814306332 - acc: 0.9394722524483133 - val_acc: 0.9253478113335596\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 3.1132006645202637 - sq_loss: 7.486986532967421e-07 - tot_loss: 0.09188136972127037 - acc: 0.9396082698585418 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 3.103696823120117 - sq_loss: 7.42811494092166e-07 - tot_loss: 0.08757588222106749 - acc: 0.9398803046789989 - val_acc: 0.9267051238547676\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 3.033360004425049 - sq_loss: 7.377818178611051e-07 - tot_loss: 0.0824627721645248 - acc: 0.9402883569096845 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 3.049345016479492 - sq_loss: 7.330302196351113e-07 - tot_loss: 0.09198541274385308 - acc: 0.9408324265505985 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 3.0524954795837402 - sq_loss: 7.295275281649083e-07 - tot_loss: 0.08795926301121426 - acc: 0.9411044613710555 - val_acc: 0.9277231082456736\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 3.0985777378082275 - sq_loss: 7.258626055772766e-07 - tot_loss: 0.08376083029955517 - acc: 0.941240478781284 - val_acc: 0.9284017645062775\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 3.0816617012023926 - sq_loss: 7.229543825815199e-07 - tot_loss: 0.08764341939129494 - acc: 0.9416485310119695 - val_acc: 0.9290804207668816\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 3.0248754024505615 - sq_loss: 7.176271310527227e-07 - tot_loss: 0.0900050774790091 - acc: 0.941784548422198 - val_acc: 0.9290804207668816\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 3.0317888259887695 - sq_loss: 7.130131507437909e-07 - tot_loss: 0.0867054711919586 - acc: 0.9423286180631121 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 3.034943103790283 - sq_loss: 7.09211917637731e-07 - tot_loss: 0.08928249894623153 - acc: 0.9426006528835691 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 3.004973888397217 - sq_loss: 7.070823926369485e-07 - tot_loss: 0.09035858254174323 - acc: 0.9427366702937976 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 3.1262762546539307 - sq_loss: 7.038274816295598e-07 - tot_loss: 0.08795828418825913 - acc: 0.9434167573449401 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 3.168056011199951 - sq_loss: 7.009475666563958e-07 - tot_loss: 0.09256234789134932 - acc: 0.9442328618063112 - val_acc: 0.9311163895486936\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 3.0903258323669434 - sq_loss: 6.976562758609361e-07 - tot_loss: 0.085862572740806 - acc: 0.9443688792165397 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 3.0204992294311523 - sq_loss: 6.94771131293237e-07 - tot_loss: 0.08188635482720774 - acc: 0.9449129488574538 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 3.0678675174713135 - sq_loss: 6.903778739797417e-07 - tot_loss: 0.08391782851124985 - acc: 0.9450489662676823 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 3.0586869716644287 - sq_loss: 6.856392360532482e-07 - tot_loss: 0.07794723478129884 - acc: 0.9458650707290533 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 3.1740169525146484 - sq_loss: 6.831015753050451e-07 - tot_loss: 0.08226044231149365 - acc: 0.9465451577801959 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 3.1065773963928223 - sq_loss: 6.789286999264732e-07 - tot_loss: 0.08735173090160453 - acc: 0.9465451577801959 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 3.0686967372894287 - sq_loss: 6.78526134834101e-07 - tot_loss: 0.082383663714092 - acc: 0.9470892274211099 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 3.011201858520508 - sq_loss: 6.786740414099768e-07 - tot_loss: 0.08673663903564832 - acc: 0.9472252448313384 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 3.122319459915161 - sq_loss: 6.775767360522877e-07 - tot_loss: 0.08261396282278155 - acc: 0.9473612622415669 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 3.1283202171325684 - sq_loss: 6.739828108948132e-07 - tot_loss: 0.08869296622030243 - acc: 0.9474972796517954 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 3.0686347484588623 - sq_loss: 6.699476102767221e-07 - tot_loss: 0.08338863508888839 - acc: 0.9483133841131665 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 3.1098148822784424 - sq_loss: 6.658218580923858e-07 - tot_loss: 0.08490236839744125 - acc: 0.948449401523395 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 3.051693916320801 - sq_loss: 6.630922371186898e-07 - tot_loss: 0.08519267412033482 - acc: 0.9485854189336235 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 3.0490152835845947 - sq_loss: 6.613682899114792e-07 - tot_loss: 0.08536413287271682 - acc: 0.9494015233949945 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 3.1043505668640137 - sq_loss: 6.585047458429472e-07 - tot_loss: 0.08529383289585524 - acc: 0.9498095756256801 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 3.108337640762329 - sq_loss: 6.536421892633371e-07 - tot_loss: 0.08482813238475129 - acc: 0.9498095756256801 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 3.0728917121887207 - sq_loss: 6.506382419502188e-07 - tot_loss: 0.07686906222576528 - acc: 0.9502176278563657 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 3.078252077102661 - sq_loss: 6.49742560199229e-07 - tot_loss: 0.08810042352285952 - acc: 0.9504896626768227 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 3.025608777999878 - sq_loss: 6.490931809821632e-07 - tot_loss: 0.08151401184707452 - acc: 0.9507616974972797 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 3.0953266620635986 - sq_loss: 6.476809630839853e-07 - tot_loss: 0.08124518101970701 - acc: 0.9508977149075082 - val_acc: 0.9345096708517137\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 3.0806362628936768 - sq_loss: 6.467500952567207e-07 - tot_loss: 0.08602828097119608 - acc: 0.9511697497279652 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 3.0350003242492676 - sq_loss: 6.43609098460729e-07 - tot_loss: 0.08929348715812657 - acc: 0.9511697497279652 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 3.0287816524505615 - sq_loss: 6.423470040317625e-07 - tot_loss: 0.0821183364070388 - acc: 0.9513057671381937 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 3.1866629123687744 - sq_loss: 6.409802608686732e-07 - tot_loss: 0.08650683748048094 - acc: 0.9517138193688792 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 3.042609453201294 - sq_loss: 6.381406478794815e-07 - tot_loss: 0.08041335370848723 - acc: 0.9518498367791077 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 3.0277090072631836 - sq_loss: 6.372573579938035e-07 - tot_loss: 0.08201666071474456 - acc: 0.9521218715995647 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 3.0551271438598633 - sq_loss: 6.381930006682524e-07 - tot_loss: 0.08812206939423395 - acc: 0.9523939064200218 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 3.069817543029785 - sq_loss: 6.360729685184197e-07 - tot_loss: 0.08612017271469607 - acc: 0.9528019586507073 - val_acc: 0.9375636240244316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 3.1050846576690674 - sq_loss: 6.346925829348038e-07 - tot_loss: 0.08266264709800386 - acc: 0.9530739934711643 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 3.0612995624542236 - sq_loss: 6.327299502117967e-07 - tot_loss: 0.08372870804388843 - acc: 0.9533460282916213 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 3.1342978477478027 - sq_loss: 6.302470865193754e-07 - tot_loss: 0.08520303514719219 - acc: 0.9537540805223068 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 3.0214083194732666 - sq_loss: 6.281211994974001e-07 - tot_loss: 0.07638260197495206 - acc: 0.9540261153427638 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 3.0236902236938477 - sq_loss: 6.263351224333746e-07 - tot_loss: 0.08145075991409478 - acc: 0.954842219804135 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 3.0457651615142822 - sq_loss: 6.245130634852103e-07 - tot_loss: 0.08699044852331506 - acc: 0.9555223068552775 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 3.048539876937866 - sq_loss: 6.232946248019289e-07 - tot_loss: 0.08481784874465137 - acc: 0.955658324265506 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 3.0109331607818604 - sq_loss: 6.20090418124164e-07 - tot_loss: 0.07823298895757014 - acc: 0.955930359085963 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 3.134351968765259 - sq_loss: 6.174717555040843e-07 - tot_loss: 0.0865177011711995 - acc: 0.956474428726877 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 2.9765374660491943 - sq_loss: 6.166697517073771e-07 - tot_loss: 0.08384044514328015 - acc: 0.956474428726877 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 3.072969436645508 - sq_loss: 6.152769174150308e-07 - tot_loss: 0.08328323332736343 - acc: 0.9566104461371056 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 3.0211422443389893 - sq_loss: 6.137544801276817e-07 - tot_loss: 0.08511846608317097 - acc: 0.9566104461371056 - val_acc: 0.9416355615880556\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 3.14928936958313 - sq_loss: 6.124047331468319e-07 - tot_loss: 0.08500174313338982 - acc: 0.9570184983677911 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 3.085411548614502 - sq_loss: 6.10578808846185e-07 - tot_loss: 0.07780246615195852 - acc: 0.9571545157780196 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 3.0694375038146973 - sq_loss: 6.09134360729513e-07 - tot_loss: 0.08275079594334311 - acc: 0.9571545157780196 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 3.021578073501587 - sq_loss: 6.060389523554477e-07 - tot_loss: 0.07580037018902352 - acc: 0.9574265505984766 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 3.0314977169036865 - sq_loss: 6.026658070368285e-07 - tot_loss: 0.07222806918863611 - acc: 0.9576985854189336 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 3.0549697875976562 - sq_loss: 5.990997351545957e-07 - tot_loss: 0.08615389696824538 - acc: 0.9578346028291621 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 3.092942953109741 - sq_loss: 5.961919100627711e-07 - tot_loss: 0.09261791135392405 - acc: 0.9579706202393906 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 3.050899028778076 - sq_loss: 5.956599693490716e-07 - tot_loss: 0.07985752025642467 - acc: 0.9583786724700761 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 3.071902275085449 - sq_loss: 5.949591468379367e-07 - tot_loss: 0.08403288448571922 - acc: 0.9587867247007617 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 3.0461485385894775 - sq_loss: 5.931228201916383e-07 - tot_loss: 0.09198876777161114 - acc: 0.9589227421109902 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 3.009258985519409 - sq_loss: 5.915417204960249e-07 - tot_loss: 0.0870024600318886 - acc: 0.9593307943416758 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 3.0524017810821533 - sq_loss: 5.913838094784296e-07 - tot_loss: 0.07642273950920186 - acc: 0.9596028291621328 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 3.046508312225342 - sq_loss: 5.899909751860832e-07 - tot_loss: 0.0912282927352488 - acc: 0.9596028291621328 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 3.0176281929016113 - sq_loss: 5.880597768737061e-07 - tot_loss: 0.08193239038356825 - acc: 0.9600108813928183 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 3.055812358856201 - sq_loss: 5.854688538420305e-07 - tot_loss: 0.07850118549365015 - acc: 0.9608269858541894 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 3.050856113433838 - sq_loss: 5.846652584295953e-07 - tot_loss: 0.08252687126073943 - acc: 0.9609630032644179 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 3.1361494064331055 - sq_loss: 5.826493634231156e-07 - tot_loss: 0.08945386507918607 - acc: 0.9606909684439608 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 3.152540922164917 - sq_loss: 5.820756427965534e-07 - tot_loss: 0.07766096152449276 - acc: 0.9609630032644179 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 3.1802468299865723 - sq_loss: 5.814916335111775e-07 - tot_loss: 0.08676839747896437 - acc: 0.9612350380848749 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 3.0976905822753906 - sq_loss: 5.793243644802715e-07 - tot_loss: 0.07438422210189821 - acc: 0.9610990206746464 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 3.0266106128692627 - sq_loss: 5.780362357654667e-07 - tot_loss: 0.08286634007887828 - acc: 0.9616430903155604 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 3.049492597579956 - sq_loss: 5.775318072664959e-07 - tot_loss: 0.08087893925958989 - acc: 0.9616430903155604 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 3.141277551651001 - sq_loss: 5.76967806864559e-07 - tot_loss: 0.0783186622690848 - acc: 0.9617791077257889 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 3.0618999004364014 - sq_loss: 5.763955641668872e-07 - tot_loss: 0.07887985975960987 - acc: 0.9620511425462459 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 3.0695841312408447 - sq_loss: 5.747544378209568e-07 - tot_loss: 0.08420802843883446 - acc: 0.9620511425462459 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 3.003570556640625 - sq_loss: 5.73205795717513e-07 - tot_loss: 0.07466618957949533 - acc: 0.9621871599564744 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 3.2115795612335205 - sq_loss: 5.718887905459269e-07 - tot_loss: 0.08986684468322226 - acc: 0.9623231773667029 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 3.012941837310791 - sq_loss: 5.703008127966314e-07 - tot_loss: 0.08556930108167293 - acc: 0.9627312295973884 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 3.125044584274292 - sq_loss: 5.686067083843227e-07 - tot_loss: 0.08320511943764441 - acc: 0.9625952121871599 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 3.029757022857666 - sq_loss: 5.668263725056022e-07 - tot_loss: 0.08498576164907834 - acc: 0.9627312295973884 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 3.05838942527771 - sq_loss: 5.65126356377732e-07 - tot_loss: 0.08693344559645233 - acc: 0.9630032644178455 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 3.0358667373657227 - sq_loss: 5.636780429085775e-07 - tot_loss: 0.08559358441394149 - acc: 0.963139281828074 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 3.0336201190948486 - sq_loss: 5.62076991172944e-07 - tot_loss: 0.08119999348229512 - acc: 0.9632752992383025 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 3.0727808475494385 - sq_loss: 5.620242404802411e-07 - tot_loss: 0.086799567804831 - acc: 0.9635473340587595 - val_acc: 0.9446895147607737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 3.125966787338257 - sq_loss: 5.602767032542033e-07 - tot_loss: 0.08493162353220973 - acc: 0.9639553862894451 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 3.12489652633667 - sq_loss: 5.59447812520375e-07 - tot_loss: 0.08157952811280378 - acc: 0.9644994559303591 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 3.0447003841400146 - sq_loss: 5.5665776699243e-07 - tot_loss: 0.07935407565858155 - acc: 0.9647714907508161 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 3.114706516265869 - sq_loss: 5.534506044568843e-07 - tot_loss: 0.08079540912051808 - acc: 0.9650435255712732 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 3.068784236907959 - sq_loss: 5.529192321773735e-07 - tot_loss: 0.08653556179563116 - acc: 0.9650435255712732 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 3.0340898036956787 - sq_loss: 5.52872450043651e-07 - tot_loss: 0.07739090676430616 - acc: 0.9651795429815017 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 3.068153142929077 - sq_loss: 5.523689878828009e-07 - tot_loss: 0.0789794746390391 - acc: 0.9650435255712732 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 3.0370030403137207 - sq_loss: 5.527355142476154e-07 - tot_loss: 0.08629262103510671 - acc: 0.9653155603917302 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 2.9986207485198975 - sq_loss: 5.501496502802183e-07 - tot_loss: 0.08279349655803714 - acc: 0.9657236126224157 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 3.1470539569854736 - sq_loss: 5.490068133440218e-07 - tot_loss: 0.0877953663982517 - acc: 0.9658596300326442 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 3.0375866889953613 - sq_loss: 5.481917924043955e-07 - tot_loss: 0.07611267996785942 - acc: 0.9659956474428727 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 3.0473108291625977 - sq_loss: 5.477797913044924e-07 - tot_loss: 0.07554833858754062 - acc: 0.9662676822633297 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 3.0858373641967773 - sq_loss: 5.463389243232086e-07 - tot_loss: 0.07492138764762923 - acc: 0.9668117519042437 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 3.0271575450897217 - sq_loss: 5.459267526930489e-07 - tot_loss: 0.08081139071926136 - acc: 0.9668117519042437 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 3.1002180576324463 - sq_loss: 5.439499091153266e-07 - tot_loss: 0.0843731725074216 - acc: 0.9672198041349293 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 3.113905668258667 - sq_loss: 5.433566343526763e-07 - tot_loss: 0.07805756667372077 - acc: 0.9670837867247007 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 3.0351407527923584 - sq_loss: 5.420113211584976e-07 - tot_loss: 0.07838098470441335 - acc: 0.9677638737758433 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 3.044740676879883 - sq_loss: 5.387909709497762e-07 - tot_loss: 0.08096962494938476 - acc: 0.9676278563656148 - val_acc: 0.9484221241940957\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 3.084426164627075 - sq_loss: 5.368585789256031e-07 - tot_loss: 0.07088169656975363 - acc: 0.9680359085963003 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 3.062182664871216 - sq_loss: 5.368879101297352e-07 - tot_loss: 0.08274051113756964 - acc: 0.9680359085963003 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 3.0121312141418457 - sq_loss: 5.3618560968971e-07 - tot_loss: 0.08874803822665855 - acc: 0.9683079434167573 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 3.056316614151001 - sq_loss: 5.353653591555485e-07 - tot_loss: 0.08083831649167172 - acc: 0.9683079434167573 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 3.041788339614868 - sq_loss: 5.341408950698678e-07 - tot_loss: 0.08127527815585345 - acc: 0.9684439608269858 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 3.058129072189331 - sq_loss: 5.327822805156757e-07 - tot_loss: 0.07536199596913873 - acc: 0.9687159956474428 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 3.018655776977539 - sq_loss: 5.311940185492858e-07 - tot_loss: 0.07521786823191712 - acc: 0.969260065288357 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 3.0031886100769043 - sq_loss: 5.300932457430463e-07 - tot_loss: 0.0819520936134076 - acc: 0.9696681175190425 - val_acc: 0.9480827960637936\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 3.0617923736572266 - sq_loss: 5.279869697005779e-07 - tot_loss: 0.08275957709512982 - acc: 0.9696681175190425 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 3.0555524826049805 - sq_loss: 5.267231131256267e-07 - tot_loss: 0.0721578123884068 - acc: 0.969804134929271 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 3.0373358726501465 - sq_loss: 5.25544407992129e-07 - tot_loss: 0.07529498308269478 - acc: 0.969804134929271 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 3.0511672496795654 - sq_loss: 5.252869073046895e-07 - tot_loss: 0.08125461636980968 - acc: 0.969804134929271 - val_acc: 0.9491007804546997\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 3.1081926822662354 - sq_loss: 5.247808303465717e-07 - tot_loss: 0.08193096759820984 - acc: 0.970076169749728 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 3.1040658950805664 - sq_loss: 5.235411890680552e-07 - tot_loss: 0.0724775130981763 - acc: 0.970076169749728 - val_acc: 0.9494401085850017\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 3.0676000118255615 - sq_loss: 5.227397537055367e-07 - tot_loss: 0.07978649502025836 - acc: 0.970076169749728 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 3.039191484451294 - sq_loss: 5.215439387029619e-07 - tot_loss: 0.07692879244686779 - acc: 0.970076169749728 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 3.1103992462158203 - sq_loss: 5.199119641474681e-07 - tot_loss: 0.07824338674624576 - acc: 0.970348204570185 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 3.073838710784912 - sq_loss: 5.191400873627572e-07 - tot_loss: 0.08639524844921254 - acc: 0.970348204570185 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 3.103827714920044 - sq_loss: 5.18373212798906e-07 - tot_loss: 0.07993097907436442 - acc: 0.970348204570185 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 3.03560209274292 - sq_loss: 5.179190338822082e-07 - tot_loss: 0.08667362214064656 - acc: 0.9704842219804135 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 3.0609657764434814 - sq_loss: 5.173623662813043e-07 - tot_loss: 0.08121448809204701 - acc: 0.9704842219804135 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 2.952397108078003 - sq_loss: 5.160601972420409e-07 - tot_loss: 0.07408339574257405 - acc: 0.9704842219804135 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 3.0469918251037598 - sq_loss: 5.148597210791195e-07 - tot_loss: 0.07721970252977228 - acc: 0.9704842219804135 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 3.1412525177001953 - sq_loss: 5.128232487550122e-07 - tot_loss: 0.08184693798307763 - acc: 0.970348204570185 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 3.0846400260925293 - sq_loss: 5.115583121551026e-07 - tot_loss: 0.07768371768292504 - acc: 0.9704842219804135 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 3.056429386138916 - sq_loss: 5.104076308271033e-07 - tot_loss: 0.07391807142028028 - acc: 0.9713003264417845 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 3.0324838161468506 - sq_loss: 5.091550292490865e-07 - tot_loss: 0.0789808312573208 - acc: 0.9713003264417845 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 3.037787437438965 - sq_loss: 5.076572051621042e-07 - tot_loss: 0.08089584188691235 - acc: 0.971436343852013 - val_acc: 0.9511367492365117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 3.111637830734253 - sq_loss: 5.065745654064813e-07 - tot_loss: 0.07879996079536744 - acc: 0.9717083786724701 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 3.0563652515411377 - sq_loss: 5.064172228230746e-07 - tot_loss: 0.08537849981479984 - acc: 0.9718443960826986 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 3.0907142162323 - sq_loss: 5.064362653683929e-07 - tot_loss: 0.08280633392143844 - acc: 0.9719804134929271 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 3.1219077110290527 - sq_loss: 5.05834691466589e-07 - tot_loss: 0.08532945124816238 - acc: 0.9722524483133841 - val_acc: 0.9511367492365117\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 2.949526071548462 - sq_loss: 5.054558869233006e-07 - tot_loss: 0.08262117308356032 - acc: 0.9723884657236126 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 3.0555124282836914 - sq_loss: 5.03486489833449e-07 - tot_loss: 0.0746078946031139 - acc: 0.9722524483133841 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 2.093414068222046 - sq_loss: 5.024370466344408e-07 - tot_loss: 0.07558858716425765 - acc: 0.9723884657236126 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 1.423206090927124 - sq_loss: 5.025070208830584e-07 - tot_loss: 0.08541823855372066 - acc: 0.9725244831338411 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 1.4607784748077393 - sq_loss: 5.023533731218777e-07 - tot_loss: 0.07828536218427273 - acc: 0.9726605005440696 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 1.4476814270019531 - sq_loss: 5.011715984437615e-07 - tot_loss: 0.08182745181350248 - acc: 0.9726605005440696 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 1.4412410259246826 - sq_loss: 5.004462764190976e-07 - tot_loss: 0.07946220999712961 - acc: 0.9725244831338411 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 1.4712059497833252 - sq_loss: 4.997393148187257e-07 - tot_loss: 0.08271911855535108 - acc: 0.9732045701849836 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 1.4439828395843506 - sq_loss: 4.989142325939611e-07 - tot_loss: 0.07430970802095649 - acc: 0.9730685527747551 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 1.4720113277435303 - sq_loss: 4.98161625728244e-07 - tot_loss: 0.08002468090387149 - acc: 0.9733405875952121 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 1.4426729679107666 - sq_loss: 4.973238674210734e-07 - tot_loss: 0.0715948547210824 - acc: 0.9736126224156693 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 1.455204725265503 - sq_loss: 4.95567178404599e-07 - tot_loss: 0.08048821886830404 - acc: 0.9736126224156693 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 1.4543864727020264 - sq_loss: 4.94388984861871e-07 - tot_loss: 0.07965735844482857 - acc: 0.9738846572361263 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 1.451416015625 - sq_loss: 4.933555146635626e-07 - tot_loss: 0.07097968995100568 - acc: 0.9737486398258978 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 1.4650609493255615 - sq_loss: 4.920349283565884e-07 - tot_loss: 0.07328579915036504 - acc: 0.9744287268770403 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 1.4569828510284424 - sq_loss: 4.903858439320175e-07 - tot_loss: 0.08388056920273412 - acc: 0.9745647442872688 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 1.457756757736206 - sq_loss: 4.907549282506807e-07 - tot_loss: 0.08032850478083997 - acc: 0.9742927094668118 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 1.4539401531219482 - sq_loss: 4.898054726254486e-07 - tot_loss: 0.07413743322209587 - acc: 0.9745647442872688 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 1.4527320861816406 - sq_loss: 4.877967967331642e-07 - tot_loss: 0.08147027240208204 - acc: 0.9744287268770403 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 1.455073595046997 - sq_loss: 4.870389034294931e-07 - tot_loss: 0.07677640387648754 - acc: 0.9745647442872688 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 1.4685609340667725 - sq_loss: 4.879778430222359e-07 - tot_loss: 0.07701121449742454 - acc: 0.9748367791077258 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 1.4609026908874512 - sq_loss: 4.870018983638147e-07 - tot_loss: 0.08159999085392611 - acc: 0.9748367791077258 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 1.4676823616027832 - sq_loss: 4.852983011005563e-07 - tot_loss: 0.07799590569144199 - acc: 0.9751088139281828 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 1.434507131576538 - sq_loss: 4.83818439533934e-07 - tot_loss: 0.07725909137207687 - acc: 0.9752448313384113 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 1.4680252075195312 - sq_loss: 4.830526449950412e-07 - tot_loss: 0.07695051006788811 - acc: 0.9753808487486398 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 1.4489572048187256 - sq_loss: 4.821589527637116e-07 - tot_loss: 0.0784368289615125 - acc: 0.9753808487486398 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 1.4775352478027344 - sq_loss: 4.80990820506122e-07 - tot_loss: 0.07592766345279267 - acc: 0.9753808487486398 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 1.4490299224853516 - sq_loss: 4.802174089491018e-07 - tot_loss: 0.07993626731198655 - acc: 0.9756528835690969 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 1.4554905891418457 - sq_loss: 4.799836119673273e-07 - tot_loss: 0.08159840692329656 - acc: 0.9753808487486398 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 1.4436123371124268 - sq_loss: 4.793747621079092e-07 - tot_loss: 0.07056175091549743 - acc: 0.9755168661588683 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 1.458068609237671 - sq_loss: 4.790254024555907e-07 - tot_loss: 0.0852350381966065 - acc: 0.9755168661588683 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 1.4567911624908447 - sq_loss: 4.7857236040727e-07 - tot_loss: 0.07814439272828577 - acc: 0.9755168661588683 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 1.4490516185760498 - sq_loss: 4.779697064805077e-07 - tot_loss: 0.07975675058826859 - acc: 0.9755168661588683 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 1.4212749004364014 - sq_loss: 4.776259743266564e-07 - tot_loss: 0.0822508046549425 - acc: 0.9756528835690969 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 1.4472370147705078 - sq_loss: 4.7658966195740504e-07 - tot_loss: 0.08168557924305808 - acc: 0.9756528835690969 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 1.4446468353271484 - sq_loss: 4.758244642744103e-07 - tot_loss: 0.08214777087578151 - acc: 0.9757889009793254 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 1.4578218460083008 - sq_loss: 4.749967388306686e-07 - tot_loss: 0.0815005331362535 - acc: 0.9757889009793254 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 1.4531493186950684 - sq_loss: 4.738434427054017e-07 - tot_loss: 0.08194178184683298 - acc: 0.9757889009793254 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 1.4448692798614502 - sq_loss: 4.733715570637287e-07 - tot_loss: 0.0798122428043615 - acc: 0.9759249183895539 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 1.458036184310913 - sq_loss: 4.7230167865564e-07 - tot_loss: 0.08502582332171704 - acc: 0.9763329706202394 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 1.446873664855957 - sq_loss: 4.713126884325902e-07 - tot_loss: 0.08549326570017324 - acc: 0.9761969532100109 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 1.452418327331543 - sq_loss: 4.703218507984275e-07 - tot_loss: 0.07718670041412734 - acc: 0.9763329706202394 - val_acc: 0.9552086868001357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 1.4489727020263672 - sq_loss: 4.6987273094600823e-07 - tot_loss: 0.08250571192417422 - acc: 0.9764689880304679 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 1.4527034759521484 - sq_loss: 4.6851607748976676e-07 - tot_loss: 0.08045929234570726 - acc: 0.9764689880304679 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 1.4435968399047852 - sq_loss: 4.6708458967259503e-07 - tot_loss: 0.09128972269772728 - acc: 0.9766050054406964 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 1.4488928318023682 - sq_loss: 4.674058402542869e-07 - tot_loss: 0.07568320114624949 - acc: 0.9768770402611534 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 1.4439127445220947 - sq_loss: 4.671597935157479e-07 - tot_loss: 0.07971107785566922 - acc: 0.9770130576713819 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 1.4413845539093018 - sq_loss: 4.672446038966882e-07 - tot_loss: 0.08775726000631279 - acc: 0.9770130576713819 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 1.460444450378418 - sq_loss: 4.667034261274239e-07 - tot_loss: 0.07318621347912624 - acc: 0.9770130576713819 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 1.4440019130706787 - sq_loss: 4.664041171054123e-07 - tot_loss: 0.08345049446578057 - acc: 0.9768770402611534 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 1.45127272605896 - sq_loss: 4.6664663955198193e-07 - tot_loss: 0.0822891878699995 - acc: 0.9768770402611534 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 1.44854736328125 - sq_loss: 4.664444190893846e-07 - tot_loss: 0.08304713867470337 - acc: 0.9770130576713819 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 1.4676196575164795 - sq_loss: 4.6476546344820235e-07 - tot_loss: 0.08266460273373277 - acc: 0.9771490750816104 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 1.458320140838623 - sq_loss: 4.6334099579325994e-07 - tot_loss: 0.07995531447258963 - acc: 0.9774211099020674 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 1.4687590599060059 - sq_loss: 4.613757198512758e-07 - tot_loss: 0.07877989674539487 - acc: 0.9774211099020674 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 1.4689297676086426 - sq_loss: 4.601339185228426e-07 - tot_loss: 0.08943772273354966 - acc: 0.9775571273122959 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 1.4736363887786865 - sq_loss: 4.5882862309554184e-07 - tot_loss: 0.0704446624417373 - acc: 0.9775571273122959 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 1.4776830673217773 - sq_loss: 4.5806837078998797e-07 - tot_loss: 0.08168826640509486 - acc: 0.9776931447225244 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 1.4601409435272217 - sq_loss: 4.568409224248171e-07 - tot_loss: 0.08022747533194574 - acc: 0.9776931447225244 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 1.4683949947357178 - sq_loss: 4.563502216115012e-07 - tot_loss: 0.08186585356345533 - acc: 0.9776931447225244 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 1.4788193702697754 - sq_loss: 4.55150683364991e-07 - tot_loss: 0.07870399764066205 - acc: 0.977829162132753 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 1.4587223529815674 - sq_loss: 4.5475289311980305e-07 - tot_loss: 0.08377897088073938 - acc: 0.977829162132753 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 1.4587218761444092 - sq_loss: 4.539384406143654e-07 - tot_loss: 0.07460322206315206 - acc: 0.977829162132753 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 1.4614126682281494 - sq_loss: 4.5288692263056873e-07 - tot_loss: 0.07923596787674603 - acc: 0.9779651795429815 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 1.509467363357544 - sq_loss: 4.5277138838173414e-07 - tot_loss: 0.08295361425916736 - acc: 0.97810119695321 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 1.459310531616211 - sq_loss: 4.5278540028448333e-07 - tot_loss: 0.08382228919782209 - acc: 0.97810119695321 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 1.4487402439117432 - sq_loss: 4.5238786583468027e-07 - tot_loss: 0.0820260581732799 - acc: 0.9782372143634385 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 1.448854923248291 - sq_loss: 4.5131648107599176e-07 - tot_loss: 0.08307769360160999 - acc: 0.9782372143634385 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 1.4636220932006836 - sq_loss: 4.512650093602133e-07 - tot_loss: 0.07262803863667833 - acc: 0.9782372143634385 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 1.4468426704406738 - sq_loss: 4.508250697199401e-07 - tot_loss: 0.07900003319973559 - acc: 0.9782372143634385 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 1.4536957740783691 - sq_loss: 4.5042114038551517e-07 - tot_loss: 0.0699547330045468 - acc: 0.9782372143634385 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 1.4467196464538574 - sq_loss: 4.503243360431952e-07 - tot_loss: 0.08411386259252152 - acc: 0.97810119695321 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 1.466139316558838 - sq_loss: 4.4975789137424727e-07 - tot_loss: 0.07296376106434266 - acc: 0.97810119695321 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 1.4532134532928467 - sq_loss: 4.4860323100692767e-07 - tot_loss: 0.07991337698344125 - acc: 0.9783732317736671 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 1.4546518325805664 - sq_loss: 4.474411809951562e-07 - tot_loss: 0.08419400640166452 - acc: 0.9783732317736671 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 1.445352554321289 - sq_loss: 4.4673313936982595e-07 - tot_loss: 0.07470234754869598 - acc: 0.97810119695321 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 1.4488487243652344 - sq_loss: 4.456402109553892e-07 - tot_loss: 0.07361996837332474 - acc: 0.9782372143634385 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 1.4544851779937744 - sq_loss: 4.4518435515783494e-07 - tot_loss: 0.07986659316508493 - acc: 0.9783732317736671 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 1.4495794773101807 - sq_loss: 4.437863196926628e-07 - tot_loss: 0.08642594658266689 - acc: 0.9785092491838956 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 1.440455675125122 - sq_loss: 4.432673961218825e-07 - tot_loss: 0.08562685608766951 - acc: 0.9786452665941241 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 1.4301707744598389 - sq_loss: 4.4292681877777795e-07 - tot_loss: 0.07660846924404285 - acc: 0.9786452665941241 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 1.4447014331817627 - sq_loss: 4.427309079346742e-07 - tot_loss: 0.07569790029200008 - acc: 0.9786452665941241 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 1.4567761421203613 - sq_loss: 4.426764519394055e-07 - tot_loss: 0.08047613384701713 - acc: 0.9787812840043526 - val_acc: 0.9538513742789277\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 1.4541466236114502 - sq_loss: 4.423515065354877e-07 - tot_loss: 0.08078255438039583 - acc: 0.9789173014145811 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 1.4586031436920166 - sq_loss: 4.41722079358442e-07 - tot_loss: 0.07802910254605833 - acc: 0.9789173014145811 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 1.4482698440551758 - sq_loss: 4.4044753622074495e-07 - tot_loss: 0.08464140736083603 - acc: 0.9789173014145811 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 1.4940297603607178 - sq_loss: 4.400083355449169e-07 - tot_loss: 0.08614484387145482 - acc: 0.9789173014145811 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 1.4697608947753906 - sq_loss: 4.396094368530612e-07 - tot_loss: 0.07985200722998265 - acc: 0.9790533188248096 - val_acc: 0.9548693586698337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 1.4622740745544434 - sq_loss: 4.3893999190913746e-07 - tot_loss: 0.07905424248258697 - acc: 0.9791893362350381 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 1.4548029899597168 - sq_loss: 4.388172953895264e-07 - tot_loss: 0.08533859474464878 - acc: 0.9793253536452666 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 1.4559552669525146 - sq_loss: 4.384486089747952e-07 - tot_loss: 0.0755424268390239 - acc: 0.9794613710554951 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 1.4613797664642334 - sq_loss: 4.367579151676182e-07 - tot_loss: 0.08403651878910312 - acc: 0.9794613710554951 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 1.4735782146453857 - sq_loss: 4.350875428826839e-07 - tot_loss: 0.08711554178535197 - acc: 0.9795973884657236 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 1.4670209884643555 - sq_loss: 4.333104755005479e-07 - tot_loss: 0.07735500591268984 - acc: 0.9795973884657236 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 1.449434518814087 - sq_loss: 4.3307016994731384e-07 - tot_loss: 0.08676759857533878 - acc: 0.9795973884657236 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 1.4519460201263428 - sq_loss: 4.3297174556755635e-07 - tot_loss: 0.07627235250607844 - acc: 0.9797334058759521 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 1.472548484802246 - sq_loss: 4.325476936628547e-07 - tot_loss: 0.08358050898522551 - acc: 0.9797334058759521 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 1.4437189102172852 - sq_loss: 4.323948132878286e-07 - tot_loss: 0.07822615882312378 - acc: 0.9797334058759521 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 1.4458026885986328 - sq_loss: 4.321097151205322e-07 - tot_loss: 0.07201471337111198 - acc: 0.9801414581066377 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 1.4532456398010254 - sq_loss: 4.3144288497387606e-07 - tot_loss: 0.09110501857650521 - acc: 0.9800054406964092 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 1.4534633159637451 - sq_loss: 4.3103520397380635e-07 - tot_loss: 0.08358508526015418 - acc: 0.9798694232861807 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 1.454350233078003 - sq_loss: 4.3010706463064707e-07 - tot_loss: 0.08502622517530123 - acc: 0.9802774755168662 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 1.448807954788208 - sq_loss: 4.2880768091890786e-07 - tot_loss: 0.08083157430624466 - acc: 0.9802774755168662 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 1.4475717544555664 - sq_loss: 4.279488905467588e-07 - tot_loss: 0.0847026370052939 - acc: 0.9802774755168662 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 1.4654107093811035 - sq_loss: 4.272463343113486e-07 - tot_loss: 0.0710114076035071 - acc: 0.9804134929270947 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 1.446443796157837 - sq_loss: 4.272337150723615e-07 - tot_loss: 0.07658120243698796 - acc: 0.9804134929270947 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 1.45469069480896 - sq_loss: 4.276344327536208e-07 - tot_loss: 0.07605593861661308 - acc: 0.9805495103373232 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 1.4515130519866943 - sq_loss: 4.276132017366763e-07 - tot_loss: 0.07645408868586279 - acc: 0.9804134929270947 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 1.4507811069488525 - sq_loss: 4.273237266261276e-07 - tot_loss: 0.07277550478509553 - acc: 0.9805495103373232 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 1.452484369277954 - sq_loss: 4.265137931724894e-07 - tot_loss: 0.08591557816520545 - acc: 0.9806855277475517 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 1.4535777568817139 - sq_loss: 4.2644796849344857e-07 - tot_loss: 0.08020140867078662 - acc: 0.9806855277475517 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 1.4534642696380615 - sq_loss: 4.2586688664414396e-07 - tot_loss: 0.08025522061640938 - acc: 0.9805495103373232 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 1.4518136978149414 - sq_loss: 4.247119989031489e-07 - tot_loss: 0.07870464190344911 - acc: 0.9806855277475517 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 1.445401668548584 - sq_loss: 4.2381995513096626e-07 - tot_loss: 0.0837747743333494 - acc: 0.9806855277475517 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 1.4651892185211182 - sq_loss: 4.2327317828494415e-07 - tot_loss: 0.07633298031294328 - acc: 0.9806855277475517 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 1.4664697647094727 - sq_loss: 4.228878935919056e-07 - tot_loss: 0.08082997442028433 - acc: 0.9808215451577802 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 1.4655709266662598 - sq_loss: 4.225231577947852e-07 - tot_loss: 0.0859038528007921 - acc: 0.9809575625680087 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 1.4687590599060059 - sq_loss: 4.2214972495457914e-07 - tot_loss: 0.08502854635318058 - acc: 0.9810935799782372 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 1.450913429260254 - sq_loss: 4.216765887576912e-07 - tot_loss: 0.08354380202850736 - acc: 0.9809575625680087 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 1.4500620365142822 - sq_loss: 4.210671136206656e-07 - tot_loss: 0.08246873164780272 - acc: 0.9809575625680087 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 1.4234402179718018 - sq_loss: 4.20802535927578e-07 - tot_loss: 0.07763365150560875 - acc: 0.9810935799782372 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 1.4383783340454102 - sq_loss: 4.1990722365881084e-07 - tot_loss: 0.08335397658346344 - acc: 0.9812295973884657 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 1.4389536380767822 - sq_loss: 4.195497353975952e-07 - tot_loss: 0.07921760105345721 - acc: 0.9810935799782372 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 1.47170090675354 - sq_loss: 4.186454987120669e-07 - tot_loss: 0.07570832078385797 - acc: 0.9809575625680087 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 1.423809289932251 - sq_loss: 4.1791255966927565e-07 - tot_loss: 0.07796927718006519 - acc: 0.9810935799782372 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 1.4683504104614258 - sq_loss: 4.175047365606588e-07 - tot_loss: 0.08234582148828862 - acc: 0.9812295973884657 - val_acc: 0.9558873430607397\n",
      "CR_1 = 0.17665842270710058   CR_2 = 0.17592699696476163\n",
      "/home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 3\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "alpha = 1\n",
    "\n",
    "\n",
    "\n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "    d0 = 561 #561 =3*11*17\n",
    "\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 512\n",
    "    d6 = 6 \n",
    "\n",
    "\n",
    "    W1 = init.uniform_(torch.empty(d1, d0, device=device), a=-0.01, b=0.01)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    W2 = init.uniform_(torch.empty(d2, d1, device=device), a=-0.01, b=0.01)\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles ‘factors’, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    W3 = init.uniform_(torch.empty(d3, d2, device=device), a=-0.01, b=0.01)\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    W4 = init.uniform_(torch.empty(d4, d3, device=device), a=-0.01, b=0.01)\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    W5 = init.uniform_(torch.empty(d5, d4, device=device), a=-0.01, b=0.01)\n",
    "    W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())\n",
    "    factors5 = tensor_train(W5_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "\n",
    "    W6 = init.uniform_(torch.empty(d6, d5, device=device), a=-0.01, b=0.01)\n",
    "    b6 = 0*torch.ones(d6, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = nn.ReLU()(U5)\n",
    "    U6 = torch.addmm(b6.repeat(1, N), W6, V5)\n",
    "    V6 = U6 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V6 = (y_one_hot + gamma*U6 + alpha*V6)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U6 = (gamma*V6 + rho*(torch.mm(W6,V5) + b6.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W6, b6 = updateWb_org(U6,V5,W6,b6,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "        # update for 5th layer\n",
    "        # update V3\n",
    "        V5 = updateV(U5,U6,W6,b6,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U5 = relu_prox(V5,(rho*torch.addmm(b5.repeat(1,N), W5, V4) + alpha*U5)/(rho + alpha),(rho + alpha)/gamma,d5,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W5, b5 = updateWb(U5,V4,W5,b5,W5_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4))\n",
    "        W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors5 = tensor_train(W5_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        a5_train = nn.ReLU()(torch.addmm(b5.repeat(1, N), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b6.repeat(1, N), W6, a5_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        a5_test = nn.ReLU()(torch.addmm(b5.repeat(1, N_test), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b6.repeat(1, N_test), W6, a5_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V6,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b6.repeat(1,N), W6, V5),U6,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,nn.ReLU()(U5),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V6,U6,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W5.reshape((4,4,4,4,4,4,4,4,4)),torch.as_tensor(W5_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "    factors5_shape=[f.shape for f in factors5]\n",
    "    Sum_of_variables_factors5=sum(list(x*y*z for x,y,z in factors5_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4+Sum_of_variables_factors5\n",
    "\n",
    "    CR_1=((total_variabels)+(d5*d6))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5+d5*d6)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#     #this postion to add new row into existing table\n",
    "#         df=pd.read_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "#         new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "#                    'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "#                    'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1],'seed':seed} \n",
    "#         df=df.append(new_row,ignore_index=True)\n",
    "#         df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"UniformScaled_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e5c2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133d333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
