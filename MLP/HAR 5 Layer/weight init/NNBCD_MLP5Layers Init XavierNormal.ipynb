{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4cb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a157bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a5c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087d0e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 3 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 1.7864327430725098 - sq_loss: 661.6837768554688 - tot_loss: 962.8837831819328 - acc: 0.15832426550598477 - val_acc: 0.15575161180861893\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 1.4745683670043945 - sq_loss: 294.0816650390625 - tot_loss: 484.6620297046611 - acc: 0.17519042437431992 - val_acc: 0.167288768238887\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 1.4563641548156738 - sq_loss: 163.61614990234375 - tot_loss: 264.0111472378485 - acc: 0.17437431991294886 - val_acc: 0.16389548693586697\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 1.475423812866211 - sq_loss: 89.1167984008789 - tot_loss: 148.24794450122863 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 1.4267325401306152 - sq_loss: 48.02313232421875 - tot_loss: 85.99057460390031 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 1.4480578899383545 - sq_loss: 25.787328720092773 - tot_loss: 52.24007048876956 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 1.5474143028259277 - sq_loss: 13.855937004089355 - tot_loss: 33.772872308734804 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 2.1222047805786133 - sq_loss: 7.47028112411499 - tot_loss: 23.514487427659333 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 1.699526071548462 - sq_loss: 4.05014705657959 - tot_loss: 17.623764889198355 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 1.4271917343139648 - sq_loss: 2.2129859924316406 - tot_loss: 14.136736232205294 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 1.4274163246154785 - sq_loss: 1.2216044664382935 - tot_loss: 11.92685223033186 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 1.4302880764007568 - sq_loss: 0.6832810640335083 - tot_loss: 10.42417817702517 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 1.4110257625579834 - sq_loss: 0.38859230279922485 - tot_loss: 9.261817879858427 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 1.444139003753662 - sq_loss: 0.22558589279651642 - tot_loss: 8.354574809665792 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 1.4302988052368164 - sq_loss: 0.13424214720726013 - tot_loss: 7.578408841276541 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 1.4184257984161377 - sq_loss: 0.08222716301679611 - tot_loss: 6.910831130226143 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 1.4370050430297852 - sq_loss: 0.05202481150627136 - tot_loss: 6.324841906432994 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 1.4146127700805664 - sq_loss: 0.03408491611480713 - tot_loss: 5.822411282337271 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 1.447746992111206 - sq_loss: 0.023155251517891884 - tot_loss: 5.366635525540914 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 1.414337158203125 - sq_loss: 0.016307275742292404 - tot_loss: 4.975771267228993 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 1.4396498203277588 - sq_loss: 0.011889450252056122 - tot_loss: 4.631145217339508 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 1.4383275508880615 - sq_loss: 0.008952249772846699 - tot_loss: 4.305658188313828 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 1.4259603023529053 - sq_loss: 0.006940360181033611 - tot_loss: 4.026189553085715 - acc: 0.1868879216539717 - val_acc: 0.18052256532066507\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 1.464036464691162 - sq_loss: 0.005521581508219242 - tot_loss: 3.772374989828677 - acc: 0.2529923830250272 - val_acc: 0.2514421445537835\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 1.4403719902038574 - sq_loss: 0.00449324632063508 - tot_loss: 3.5567866143246647 - acc: 0.37309575625680086 - val_acc: 0.35934848998982016\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 1.4161477088928223 - sq_loss: 0.0037277331575751305 - tot_loss: 3.3600183678790927 - acc: 0.4207018498367791 - val_acc: 0.40685442823210044\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 1.4308159351348877 - sq_loss: 0.0031437876168638468 - tot_loss: 3.175126999980421 - acc: 0.4649075081610446 - val_acc: 0.4387512724804886\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 1.4266304969787598 - sq_loss: 0.002689039334654808 - tot_loss: 2.9984893496875884 - acc: 0.4910228509249184 - val_acc: 0.46521886664404477\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 1.4348127841949463 - sq_loss: 0.002327767899259925 - tot_loss: 2.843861571091111 - acc: 0.48272578890097934 - val_acc: 0.48829317950458095\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 1.4232206344604492 - sq_loss: 0.0020351028069853783 - tot_loss: 2.706102756965265 - acc: 0.47565288356909685 - val_acc: 0.4916864608076009\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 1.432312250137329 - sq_loss: 0.0017948077293112874 - tot_loss: 2.565199642886 - acc: 0.4661316648531012 - val_acc: 0.4825246012894469\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 1.436178207397461 - sq_loss: 0.0015944665065035224 - tot_loss: 2.4472235128851025 - acc: 0.4623231773667029 - val_acc: 0.47641669494401084\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 1.4290752410888672 - sq_loss: 0.0014257242437452078 - tot_loss: 2.3468929968148586 - acc: 0.46055495103373234 - val_acc: 0.47370206990159486\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 1.397155523300171 - sq_loss: 0.0012813492212444544 - tot_loss: 2.2390212253667414 - acc: 0.462867247007617 - val_acc: 0.4750593824228028\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 1.4423017501831055 - sq_loss: 0.001157434657216072 - tot_loss: 2.153415706987289 - acc: 0.4698041349292709 - val_acc: 0.4791313199864269\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 1.410404920578003 - sq_loss: 0.0010501265060156584 - tot_loss: 2.0625018943792384 - acc: 0.47864526659412404 - val_acc: 0.48489989820156093\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 1.4112555980682373 - sq_loss: 0.0009563566418364644 - tot_loss: 1.980119038536941 - acc: 0.49047878128400435 - val_acc: 0.49440108585001696\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 1.431807041168213 - sq_loss: 0.0008740928024053574 - tot_loss: 1.8854315114476776 - acc: 0.5013601741022851 - val_acc: 0.501526976586359\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 1.4085783958435059 - sq_loss: 0.0008011054014787078 - tot_loss: 1.8162835537041246 - acc: 0.5137377584330794 - val_acc: 0.5100101798439091\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 1.4336836338043213 - sq_loss: 0.0007361364550888538 - tot_loss: 1.743745017600304 - acc: 0.5236670293797606 - val_acc: 0.5164574143196471\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 1.4594199657440186 - sq_loss: 0.000678188051097095 - tot_loss: 1.6845591334458732 - acc: 0.529923830250272 - val_acc: 0.5198506956226672\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 1.4355580806732178 - sq_loss: 0.0006263006362132728 - tot_loss: 1.6272558527962246 - acc: 0.5349564744287268 - val_acc: 0.5229046487953851\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 1.4272639751434326 - sq_loss: 0.0005797030171379447 - tot_loss: 1.5710041950187588 - acc: 0.5383569096844396 - val_acc: 0.5242619613165932\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 1.4324893951416016 - sq_loss: 0.0005374841275624931 - tot_loss: 1.5139984891648055 - acc: 0.5408052230685527 - val_acc: 0.5269765863590091\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 1.4182281494140625 - sq_loss: 0.000499140820465982 - tot_loss: 1.4443204910367058 - acc: 0.5427094668117519 - val_acc: 0.5276552426196132\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 1.4269473552703857 - sq_loss: 0.0004643161955755204 - tot_loss: 1.4063805277473875 - acc: 0.5433895538628944 - val_acc: 0.5283338988802172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 1.4306671619415283 - sq_loss: 0.0004327986389398575 - tot_loss: 1.3466166389644059 - acc: 0.5442056583242655 - val_acc: 0.5296912114014252\n",
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 1.4392459392547607 - sq_loss: 0.0004039535124320537 - tot_loss: 1.3157404584544565 - acc: 0.5458378672470077 - val_acc: 0.5310485239226331\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 1.4307119846343994 - sq_loss: 0.00037736172089353204 - tot_loss: 1.2506423972372431 - acc: 0.5485582154515778 - val_acc: 0.5351204614862572\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 1.435593605041504 - sq_loss: 0.0003530910180415958 - tot_loss: 1.2224871171983978 - acc: 0.5572633297062024 - val_acc: 0.5391923990498813\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 1.436711072921753 - sq_loss: 0.00033075339160859585 - tot_loss: 1.1783856397687487 - acc: 0.5663764961915125 - val_acc: 0.5449609772650152\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 1.435814619064331 - sq_loss: 0.0003101137699559331 - tot_loss: 1.1470595799110015 - acc: 0.5768498367791077 - val_acc: 0.5520868680013573\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 1.4516496658325195 - sq_loss: 0.0002910923503804952 - tot_loss: 1.1070656731681083 - acc: 0.5893634385201306 - val_acc: 0.5581947743467933\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 1.424370288848877 - sq_loss: 0.0002735218731686473 - tot_loss: 1.0607365741652757 - acc: 0.6033732317736671 - val_acc: 0.5639633525619274\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 1.4217286109924316 - sq_loss: 0.00025720635312609375 - tot_loss: 1.0202324994634182 - acc: 0.6157508161044614 - val_acc: 0.5717678995588734\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 1.4539539813995361 - sq_loss: 0.00024195332662202418 - tot_loss: 0.9910752185278398 - acc: 0.6319368879216539 - val_acc: 0.5809297590770275\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 1.4199399948120117 - sq_loss: 0.0002278087049489841 - tot_loss: 0.9572190947101262 - acc: 0.6483949945593036 - val_acc: 0.5938242280285035\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 1.4216151237487793 - sq_loss: 0.00021455339447129518 - tot_loss: 0.9301428942162602 - acc: 0.6663492927094669 - val_acc: 0.6084153376314897\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 1.423645257949829 - sq_loss: 0.00020218231657054275 - tot_loss: 0.9004466286742172 - acc: 0.6863438520130577 - val_acc: 0.6223277909738717\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 1.4483716487884521 - sq_loss: 0.00019069216796196997 - tot_loss: 0.8735883102935986 - acc: 0.7010337323177367 - val_acc: 0.6382762130980658\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 1.42409348487854 - sq_loss: 0.00017983210273087025 - tot_loss: 0.8512112633061406 - acc: 0.7144994559303591 - val_acc: 0.6511706820495419\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 1.4302849769592285 - sq_loss: 0.00016970737488009036 - tot_loss: 0.8100282409041029 - acc: 0.7302774755168662 - val_acc: 0.66610111978283\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 1.4257712364196777 - sq_loss: 0.00016023962234612554 - tot_loss: 0.7950297747065633 - acc: 0.7429270946681176 - val_acc: 0.6786562606040041\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 1.4410099983215332 - sq_loss: 0.00015134156274143606 - tot_loss: 0.7723135678506878 - acc: 0.7536724700761698 - val_acc: 0.6878181201221581\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 1.4407105445861816 - sq_loss: 0.00014296361769083887 - tot_loss: 0.7482096808334973 - acc: 0.7623775843307944 - val_acc: 0.7013912453342382\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 1.440826416015625 - sq_loss: 0.00013501226203516126 - tot_loss: 0.7195452812293297 - acc: 0.7701305767138193 - val_acc: 0.7112317611129962\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 1.4460077285766602 - sq_loss: 0.00012760242680087686 - tot_loss: 0.705968531333383 - acc: 0.7758433079434167 - val_acc: 0.7234475738038684\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 1.443779706954956 - sq_loss: 0.00012057871936121956 - tot_loss: 0.6748104290963965 - acc: 0.7838683351468988 - val_acc: 0.7295554801493044\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 1.4623265266418457 - sq_loss: 0.00011397046182537451 - tot_loss: 0.6561742992366817 - acc: 0.7895810663764962 - val_acc: 0.7376993552765524\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 1.460602045059204 - sq_loss: 0.00010776069393614307 - tot_loss: 0.6446247088733799 - acc: 0.794613710554951 - val_acc: 0.7427892772310825\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 2.401522397994995 - sq_loss: 0.00010183981066802517 - tot_loss: 0.6279159466666897 - acc: 0.7986942328618063 - val_acc: 0.7495758398371225\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 2.6880040168762207 - sq_loss: 9.628156112739816e-05 - tot_loss: 0.6143579774802674 - acc: 0.8030467899891186 - val_acc: 0.7590770274855786\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 2.732870101928711 - sq_loss: 9.113199485000223e-05 - tot_loss: 0.5848215739724765 - acc: 0.8068552774755169 - val_acc: 0.7634882931795046\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 3.0794968605041504 - sq_loss: 8.622098539490253e-05 - tot_loss: 0.5786539763275869 - acc: 0.8101196953210011 - val_acc: 0.7682388870037327\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 2.975548267364502 - sq_loss: 8.156472176779062e-05 - tot_loss: 0.5527232026142883 - acc: 0.8143362350380848 - val_acc: 0.7750254496097726\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 2.823051929473877 - sq_loss: 7.724315219093114e-05 - tot_loss: 0.5511622502908722 - acc: 0.8185527747551686 - val_acc: 0.7794367153036986\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 2.8418920040130615 - sq_loss: 7.310854562092572e-05 - tot_loss: 0.5239097823373413 - acc: 0.8233133841131665 - val_acc: 0.7858839497794368\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 2.8071281909942627 - sq_loss: 6.918338476680219e-05 - tot_loss: 0.5279614026089803 - acc: 0.8272578890097932 - val_acc: 0.7909738717339667\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 2.857679605484009 - sq_loss: 6.551162368850783e-05 - tot_loss: 0.4934989504117766 - acc: 0.8313384113166485 - val_acc: 0.7960637936884968\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 2.825303077697754 - sq_loss: 6.200858479132876e-05 - tot_loss: 0.4935156501687743 - acc: 0.8348748639825898 - val_acc: 0.8001357312521208\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 2.8499386310577393 - sq_loss: 5.866556602995843e-05 - tot_loss: 0.47376832045119954 - acc: 0.8373231773667029 - val_acc: 0.8055649813369529\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 2.824080228805542 - sq_loss: 5.552349102799781e-05 - tot_loss: 0.4597932696715361 - acc: 0.8407236126224157 - val_acc: 0.8092975907702749\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 2.8625502586364746 - sq_loss: 5.258752207737416e-05 - tot_loss: 0.4718811056634422 - acc: 0.8433079434167573 - val_acc: 0.8126908720732948\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 2.86982798576355 - sq_loss: 4.980740777682513e-05 - tot_loss: 0.4405060395781675 - acc: 0.8468443960826986 - val_acc: 0.8150661689854088\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 2.821460485458374 - sq_loss: 4.717650153907016e-05 - tot_loss: 0.4383979516119325 - acc: 0.8498367791077258 - val_acc: 0.8184594502884289\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 2.86750864982605 - sq_loss: 4.47096026618965e-05 - tot_loss: 0.42379765265241076 - acc: 0.8522850924918389 - val_acc: 0.8215134034611469\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 2.8470606803894043 - sq_loss: 4.232255378155969e-05 - tot_loss: 0.40812527071875593 - acc: 0.8559575625680087 - val_acc: 0.825246012894469\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 2.7897958755493164 - sq_loss: 4.015223021269776e-05 - tot_loss: 0.39855907370656496 - acc: 0.8581338411316648 - val_acc: 0.8306752629793009\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 2.8095953464508057 - sq_loss: 3.808457768172957e-05 - tot_loss: 0.39405067506868363 - acc: 0.8588139281828074 - val_acc: 0.832032575500509\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 2.9031383991241455 - sq_loss: 3.608819315559231e-05 - tot_loss: 0.3946882260456732 - acc: 0.860854189336235 - val_acc: 0.833050559891415\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 2.792860984802246 - sq_loss: 3.4235286875627935e-05 - tot_loss: 0.3744404061365003 - acc: 0.8631664853101197 - val_acc: 0.8347472005429251\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 2.847900629043579 - sq_loss: 3.2453554013045505e-05 - tot_loss: 0.3744096402390369 - acc: 0.8652067464635473 - val_acc: 0.837801153715643\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 2.8214962482452393 - sq_loss: 3.078537338296883e-05 - tot_loss: 0.35597159009944335 - acc: 0.8668389553862894 - val_acc: 0.8411944350186631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 2.825350761413574 - sq_loss: 2.9215418180683628e-05 - tot_loss: 0.3554635995232047 - acc: 0.8669749727965179 - val_acc: 0.844248388191381\n",
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 2.837512254714966 - sq_loss: 2.7683208827511407e-05 - tot_loss: 0.3382630403662006 - acc: 0.8683351468988031 - val_acc: 0.8469630132337971\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 2.7913858890533447 - sq_loss: 2.6269110094290227e-05 - tot_loss: 0.3336273159920893 - acc: 0.8710554951033732 - val_acc: 0.8506956226671191\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 2.8108878135681152 - sq_loss: 2.4928738639573567e-05 - tot_loss: 0.3192149814467484 - acc: 0.8730957562568009 - val_acc: 0.8530709195792331\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 2.860074281692505 - sq_loss: 2.3664451873628423e-05 - tot_loss: 0.33846469994830386 - acc: 0.874727965179543 - val_acc: 0.8557855446216491\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 2.8017325401306152 - sq_loss: 2.244572533527389e-05 - tot_loss: 0.3246047986376652 - acc: 0.8767682263329706 - val_acc: 0.8591788259246692\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 2.84185528755188 - sq_loss: 2.1328520233510062e-05 - tot_loss: 0.3094658705884967 - acc: 0.8775843307943417 - val_acc: 0.8601968103155752\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 2.841428756713867 - sq_loss: 2.0250074157956988e-05 - tot_loss: 0.315296787982561 - acc: 0.8789445048966268 - val_acc: 0.8625721072276892\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 2.7940521240234375 - sq_loss: 1.9247032469138503e-05 - tot_loss: 0.3089855879525203 - acc: 0.8793525571273123 - val_acc: 0.8635900916185952\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 2.8024516105651855 - sq_loss: 1.8320892195333727e-05 - tot_loss: 0.2935379712895383 - acc: 0.8803046789989118 - val_acc: 0.8656260604004072\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 2.8215184211730957 - sq_loss: 1.7431375454179943e-05 - tot_loss: 0.29153532509167235 - acc: 0.8818008705114254 - val_acc: 0.8669833729216152\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 2.747164011001587 - sq_loss: 1.658383735048119e-05 - tot_loss: 0.27953266671897836 - acc: 0.8831610446137106 - val_acc: 0.8686800135731252\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 2.8204402923583984 - sq_loss: 1.5749199519632384e-05 - tot_loss: 0.28695167467731153 - acc: 0.8838411316648531 - val_acc: 0.8707159823549372\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 2.847393751144409 - sq_loss: 1.4966262824600562e-05 - tot_loss: 0.27980591899302 - acc: 0.8847932535364527 - val_acc: 0.8717339667458432\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 2.7901313304901123 - sq_loss: 1.4229699445422739e-05 - tot_loss: 0.2698435780153545 - acc: 0.8852013057671382 - val_acc: 0.8717339667458432\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 2.786932945251465 - sq_loss: 1.352704748569522e-05 - tot_loss: 0.2815542632707775 - acc: 0.8853373231773667 - val_acc: 0.8730912792670512\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 2.8225302696228027 - sq_loss: 1.2887279808637686e-05 - tot_loss: 0.2579489660231502 - acc: 0.8866974972796517 - val_acc: 0.8754665761791652\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 2.780933380126953 - sq_loss: 1.2285514458199032e-05 - tot_loss: 0.2674550262289017 - acc: 0.8877856365614799 - val_acc: 0.8768238887003733\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 2.855161428451538 - sq_loss: 1.1701060429913923e-05 - tot_loss: 0.2480798128904098 - acc: 0.8890097932535365 - val_acc: 0.8788598574821853\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 2.8717708587646484 - sq_loss: 1.1144790732942056e-05 - tot_loss: 0.2589454686656154 - acc: 0.889961915125136 - val_acc: 0.8802171700033933\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 2.813608169555664 - sq_loss: 1.0628308700688649e-05 - tot_loss: 0.2446117090874509 - acc: 0.891050054406964 - val_acc: 0.8815744825246012\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 2.8422844409942627 - sq_loss: 1.0138442121387925e-05 - tot_loss: 0.24932048056598433 - acc: 0.8914581066376496 - val_acc: 0.8829317950458093\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 2.890103578567505 - sq_loss: 9.673725799075328e-06 - tot_loss: 0.2408625579014938 - acc: 0.8920021762785637 - val_acc: 0.8815744825246012\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 2.7892611026763916 - sq_loss: 9.234555363946129e-06 - tot_loss: 0.24887329711629036 - acc: 0.8928182807399347 - val_acc: 0.8822531387852053\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 2.7513656616210938 - sq_loss: 8.83068878465565e-06 - tot_loss: 0.23866091662387134 - acc: 0.8932263329706203 - val_acc: 0.8839497794367153\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 2.7924716472625732 - sq_loss: 8.438692020718008e-06 - tot_loss: 0.24932170233148554 - acc: 0.8934983677910773 - val_acc: 0.8839497794367153\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 2.807812452316284 - sq_loss: 8.066393093031365e-06 - tot_loss: 0.23181473904020322 - acc: 0.8945865070729053 - val_acc: 0.8856464200882254\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 2.834137439727783 - sq_loss: 7.725388059043325e-06 - tot_loss: 0.23094650815852447 - acc: 0.8955386289445049 - val_acc: 0.8863250763488293\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 2.830582857131958 - sq_loss: 7.384063792414963e-06 - tot_loss: 0.22210903503352597 - acc: 0.8958106637649619 - val_acc: 0.8866644044791313\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 2.8656017780303955 - sq_loss: 7.060574262141017e-06 - tot_loss: 0.2254908837891776 - acc: 0.8966267682263329 - val_acc: 0.8880217170003394\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 2.83933162689209 - sq_loss: 6.7503974605642725e-06 - tot_loss: 0.21456403134405377 - acc: 0.8967627856365615 - val_acc: 0.8897183576518494\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 2.800891876220703 - sq_loss: 6.457357812905684e-06 - tot_loss: 0.22692602109108861 - acc: 0.8973068552774756 - val_acc: 0.8900576857821514\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 2.783025026321411 - sq_loss: 6.178061994432937e-06 - tot_loss: 0.2210602123033425 - acc: 0.8981229597388466 - val_acc: 0.8907363420427553\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 2.757692337036133 - sq_loss: 5.922800482949242e-06 - tot_loss: 0.2271986453185093 - acc: 0.8993471164309031 - val_acc: 0.8910756701730573\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 2.867603302001953 - sq_loss: 5.682218215952162e-06 - tot_loss: 0.20742044509927382 - acc: 0.9005712731229597 - val_acc: 0.8924329826942654\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 2.857800006866455 - sq_loss: 5.451287051982945e-06 - tot_loss: 0.20694866068450324 - acc: 0.9008433079434167 - val_acc: 0.8927723108245673\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 2.7896225452423096 - sq_loss: 5.227336259849835e-06 - tot_loss: 0.20154392843858204 - acc: 0.9020674646354734 - val_acc: 0.8941296233457754\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 2.766033172607422 - sq_loss: 5.00629630550975e-06 - tot_loss: 0.20275839669255902 - acc: 0.9030195865070729 - val_acc: 0.8948082796063793\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 2.862316608428955 - sq_loss: 4.804454420082038e-06 - tot_loss: 0.21407028074236223 - acc: 0.9036996735582155 - val_acc: 0.8961655921275874\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 2.8670053482055664 - sq_loss: 4.621277184924111e-06 - tot_loss: 0.1953451964218118 - acc: 0.904651795429815 - val_acc: 0.8978622327790974\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 2.79117751121521 - sq_loss: 4.4421562961360905e-06 - tot_loss: 0.20373206243826303 - acc: 0.905195865070729 - val_acc: 0.8988802171700034\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 2.806762218475342 - sq_loss: 4.275230367056793e-06 - tot_loss: 0.1956241534778087 - acc: 0.9053318824809575 - val_acc: 0.8995588734306074\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 2.792567014694214 - sq_loss: 4.125738996663131e-06 - tot_loss: 0.19553048538297446 - acc: 0.9056039173014145 - val_acc: 0.8992195453003053\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 2.780799150466919 - sq_loss: 3.975819709012285e-06 - tot_loss: 0.18770820391411291 - acc: 0.9061479869423286 - val_acc: 0.8988802171700034\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 2.827665328979492 - sq_loss: 3.839904366031988e-06 - tot_loss: 0.19121889245595014 - acc: 0.9069640914036997 - val_acc: 0.8992195453003053\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 2.823964834213257 - sq_loss: 3.7051870549476007e-06 - tot_loss: 0.1902892956226907 - acc: 0.9073721436343852 - val_acc: 0.9005768578215134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 2.740168333053589 - sq_loss: 3.573416506696958e-06 - tot_loss: 0.1899405374170584 - acc: 0.9079162132752993 - val_acc: 0.9022734984730234\n",
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 2.788569927215576 - sq_loss: 3.4525526189099764e-06 - tot_loss: 0.18874734358691114 - acc: 0.9092763873775843 - val_acc: 0.9039701391245334\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 2.863085985183716 - sq_loss: 3.3375613384123426e-06 - tot_loss: 0.19209755232334658 - acc: 0.9095484221980413 - val_acc: 0.9043094672548354\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 2.790290594100952 - sq_loss: 3.2277910122502362e-06 - tot_loss: 0.18288974894292664 - acc: 0.9102285092491839 - val_acc: 0.9056667797760435\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 2.8723511695861816 - sq_loss: 3.129454853478819e-06 - tot_loss: 0.1793075008110634 - acc: 0.9111806311207835 - val_acc: 0.9060061079063454\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 2.792630195617676 - sq_loss: 3.032100948985317e-06 - tot_loss: 0.17318672262172186 - acc: 0.9124047878128401 - val_acc: 0.9077027485578555\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 2.7908310890197754 - sq_loss: 2.939555088232737e-06 - tot_loss: 0.17154653638746709 - acc: 0.9133569096844396 - val_acc: 0.9087207329487614\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 2.763439416885376 - sq_loss: 2.84786733573128e-06 - tot_loss: 0.18507565648840796 - acc: 0.9136289445048966 - val_acc: 0.9090600610790635\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 2.817723274230957 - sq_loss: 2.756515641522128e-06 - tot_loss: 0.17598638399407207 - acc: 0.9148531011969532 - val_acc: 0.9097387173396675\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 2.7887790203094482 - sq_loss: 2.676831172720995e-06 - tot_loss: 0.1683672379467822 - acc: 0.9151251360174102 - val_acc: 0.9107567017305734\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 2.7822821140289307 - sq_loss: 2.6059306037495844e-06 - tot_loss: 0.16706085770911727 - acc: 0.9153971708378672 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 2.723461151123047 - sq_loss: 2.5362610358570237e-06 - tot_loss: 0.17315114911678364 - acc: 0.9162132752992383 - val_acc: 0.9121140142517815\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 2.7573578357696533 - sq_loss: 2.465621946612373e-06 - tot_loss: 0.16489293844828978 - acc: 0.9163492927094669 - val_acc: 0.9127926705123854\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 2.785374402999878 - sq_loss: 2.391168663962162e-06 - tot_loss: 0.16629847182705504 - acc: 0.9170293797606094 - val_acc: 0.9134713267729895\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 2.850562810897827 - sq_loss: 2.332326175746857e-06 - tot_loss: 0.18838036639439792 - acc: 0.9173014145810664 - val_acc: 0.9148286392941974\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 2.802507162094116 - sq_loss: 2.2739332052879035e-06 - tot_loss: 0.17676300702183312 - acc: 0.9174374319912949 - val_acc: 0.9168646080760094\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 2.7806293964385986 - sq_loss: 2.2236770291783614e-06 - tot_loss: 0.17937910882223917 - acc: 0.9179815016322089 - val_acc: 0.9185612487275195\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 2.7711997032165527 - sq_loss: 2.1688485958293313e-06 - tot_loss: 0.16116361447645033 - acc: 0.918525571273123 - val_acc: 0.9182219205972175\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 2.8107776641845703 - sq_loss: 2.121014176736935e-06 - tot_loss: 0.157110549789941 - acc: 0.919341675734494 - val_acc: 0.9195792331184255\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 2.843320369720459 - sq_loss: 2.0686197785835247e-06 - tot_loss: 0.17531690958583823 - acc: 0.9200217627856365 - val_acc: 0.9195792331184255\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 2.80798077583313 - sq_loss: 2.0272809706511907e-06 - tot_loss: 0.16726463438771333 - acc: 0.9211099020674647 - val_acc: 0.9202578893790295\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 2.8392653465270996 - sq_loss: 1.9846052055072505e-06 - tot_loss: 0.16936256349875833 - acc: 0.9213819368879217 - val_acc: 0.9209365456396336\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 2.8310317993164062 - sq_loss: 1.9428523501119344e-06 - tot_loss: 0.15754668862823706 - acc: 0.9220620239390642 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 2.8305463790893555 - sq_loss: 1.8967352843901608e-06 - tot_loss: 0.1545293350460355 - acc: 0.9223340587595212 - val_acc: 0.9226331862911435\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 2.8171279430389404 - sq_loss: 1.8628243196872063e-06 - tot_loss: 0.16593162171506748 - acc: 0.9227421109902068 - val_acc: 0.9226331862911435\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 2.896181106567383 - sq_loss: 1.8308107883058256e-06 - tot_loss: 0.15516077145070994 - acc: 0.9234221980413493 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 2.8312478065490723 - sq_loss: 1.7953799442693708e-06 - tot_loss: 0.16029317189983772 - acc: 0.9238302502720348 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 2.81622576713562 - sq_loss: 1.758532448548067e-06 - tot_loss: 0.15753873762466952 - acc: 0.9243743199129488 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 2.855531930923462 - sq_loss: 1.7164909422717756e-06 - tot_loss: 0.15141286246617724 - acc: 0.9251904243743199 - val_acc: 0.9236511706820495\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 2.9018146991729736 - sq_loss: 1.6832210576467332e-06 - tot_loss: 0.16473563184168682 - acc: 0.9253264417845484 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 2.847757339477539 - sq_loss: 1.6567679494983167e-06 - tot_loss: 0.15900352684262842 - acc: 0.926006528835691 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 2.7779057025909424 - sq_loss: 1.6302712992910529e-06 - tot_loss: 0.15823292923851895 - acc: 0.9261425462459195 - val_acc: 0.9250084832032576\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 2.7496416568756104 - sq_loss: 1.603870600774826e-06 - tot_loss: 0.15044455038966476 - acc: 0.926278563656148 - val_acc: 0.9256871394638616\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 2.790581464767456 - sq_loss: 1.5785161622261512e-06 - tot_loss: 0.15418927257142911 - acc: 0.9264145810663765 - val_acc: 0.9253478113335596\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 2.7965426445007324 - sq_loss: 1.553191282255284e-06 - tot_loss: 0.14779443275024207 - acc: 0.926550598476605 - val_acc: 0.9253478113335596\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 2.7909915447235107 - sq_loss: 1.529277710687893e-06 - tot_loss: 0.1609215156294468 - acc: 0.9272306855277476 - val_acc: 0.9256871394638616\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 2.813753366470337 - sq_loss: 1.5108414572750917e-06 - tot_loss: 0.1544845782618367 - acc: 0.9281828073993471 - val_acc: 0.9256871394638616\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 2.785573959350586 - sq_loss: 1.4941100516807637e-06 - tot_loss: 0.15256937195527698 - acc: 0.9283188248095756 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 2.7975881099700928 - sq_loss: 1.472431790716655e-06 - tot_loss: 0.15635408706599563 - acc: 0.9285908596300326 - val_acc: 0.9260264675941635\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 2.8401734828948975 - sq_loss: 1.4526647191814845e-06 - tot_loss: 0.14571199049943218 - acc: 0.9288628944504896 - val_acc: 0.9263657957244655\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 2.7628321647644043 - sq_loss: 1.4371263432622072e-06 - tot_loss: 0.14960816027245016 - acc: 0.9302230685527747 - val_acc: 0.9267051238547676\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 2.7832205295562744 - sq_loss: 1.4223047628547647e-06 - tot_loss: 0.14523824200283997 - acc: 0.9309031556039173 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 2.814539670944214 - sq_loss: 1.4053447330297786e-06 - tot_loss: 0.14461636413585843 - acc: 0.9310391730141458 - val_acc: 0.9287410926365796\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 2.7626101970672607 - sq_loss: 1.3905511195844156e-06 - tot_loss: 0.1419226385441057 - acc: 0.9314472252448314 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 2.7566378116607666 - sq_loss: 1.3711774045077618e-06 - tot_loss: 0.142991061621089 - acc: 0.9317192600652884 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 2.880183696746826 - sq_loss: 1.358233703285805e-06 - tot_loss: 0.14314836753895754 - acc: 0.9323993471164309 - val_acc: 0.9297590770274856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 2.7990896701812744 - sq_loss: 1.3454001646096003e-06 - tot_loss: 0.14698265619294126 - acc: 0.9328073993471164 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 2.8376824855804443 - sq_loss: 1.3315476508068969e-06 - tot_loss: 0.14875257143788367 - acc: 0.9329434167573449 - val_acc: 0.9304377332880895\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 2.8071343898773193 - sq_loss: 1.3154244697943795e-06 - tot_loss: 0.141346858674245 - acc: 0.9336235038084875 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 2.8676962852478027 - sq_loss: 1.3017019000471919e-06 - tot_loss: 0.13641432772948825 - acc: 0.933759521218716 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 2.766308069229126 - sq_loss: 1.2915122624690412e-06 - tot_loss: 0.14909330098770113 - acc: 0.9341675734494015 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 2.801002264022827 - sq_loss: 1.2822350754504441e-06 - tot_loss: 0.14564615522912305 - acc: 0.934847660500544 - val_acc: 0.9321343739395996\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 2.752760410308838 - sq_loss: 1.2712097259282018e-06 - tot_loss: 0.13822949675077467 - acc: 0.9349836779107725 - val_acc: 0.9321343739395996\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 2.804882764816284 - sq_loss: 1.2579088206621236e-06 - tot_loss: 0.14162875613051007 - acc: 0.9356637649619152 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 2.8126509189605713 - sq_loss: 1.2444454569049412e-06 - tot_loss: 0.12977941457447173 - acc: 0.9359357997823722 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 2.781315326690674 - sq_loss: 1.2316774018472643e-06 - tot_loss: 0.14075380052251418 - acc: 0.9360718171926007 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 2.8151237964630127 - sq_loss: 1.2220199323564884e-06 - tot_loss: 0.15575126809710227 - acc: 0.9366158868335147 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 2.807697296142578 - sq_loss: 1.2158349136370816e-06 - tot_loss: 0.1442425338435891 - acc: 0.9374319912948857 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 2.8285624980926514 - sq_loss: 1.2093474879293353e-06 - tot_loss: 0.12792661743295586 - acc: 0.9379760609357998 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 2.739964008331299 - sq_loss: 1.2030769767079619e-06 - tot_loss: 0.14520848254559748 - acc: 0.9385201305767138 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 2.809600830078125 - sq_loss: 1.194491915157414e-06 - tot_loss: 0.1318841865522602 - acc: 0.9383841131664853 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 2.8065807819366455 - sq_loss: 1.1850557939396822e-06 - tot_loss: 0.13032816856111396 - acc: 0.9389281828073993 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 2.7732133865356445 - sq_loss: 1.1735287444025744e-06 - tot_loss: 0.12899208606734813 - acc: 0.9396082698585418 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 2.882983922958374 - sq_loss: 1.1638660453172633e-06 - tot_loss: 0.1368682884035719 - acc: 0.940152339499456 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 2.809892177581787 - sq_loss: 1.1564947044462315e-06 - tot_loss: 0.13749373234088313 - acc: 0.9405603917301415 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 2.8391315937042236 - sq_loss: 1.1481197361717932e-06 - tot_loss: 0.14360410903970333 - acc: 0.940968443960827 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 2.793055772781372 - sq_loss: 1.1388199254724896e-06 - tot_loss: 0.13090270969035078 - acc: 0.9411044613710555 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 2.7989110946655273 - sq_loss: 1.1324700608383864e-06 - tot_loss: 0.14121336232934212 - acc: 0.9411044613710555 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 2.79982590675354 - sq_loss: 1.1270117283856962e-06 - tot_loss: 0.12878313183105217 - acc: 0.941512513601741 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 2.879615068435669 - sq_loss: 1.1202384939679177e-06 - tot_loss: 0.13038704969536852 - acc: 0.9416485310119695 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 2.874713897705078 - sq_loss: 1.1168110631842865e-06 - tot_loss: 0.12523220684644 - acc: 0.9419205658324266 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 2.846191644668579 - sq_loss: 1.1100918300144258e-06 - tot_loss: 0.13033563069067444 - acc: 0.9424646354733406 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 2.850576877593994 - sq_loss: 1.1022889339074027e-06 - tot_loss: 0.136074038504451 - acc: 0.9430087051142546 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 2.8455679416656494 - sq_loss: 1.0953141327263438e-06 - tot_loss: 0.13576381678794913 - acc: 0.9430087051142546 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 2.8793938159942627 - sq_loss: 1.0921859256995958e-06 - tot_loss: 0.13643148540904182 - acc: 0.9436887921653971 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 2.86039662361145 - sq_loss: 1.0868053550439072e-06 - tot_loss: 0.13152340395271356 - acc: 0.9439608269858542 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 2.8876912593841553 - sq_loss: 1.0831156487256521e-06 - tot_loss: 0.13012193307792863 - acc: 0.9442328618063112 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 2.8546650409698486 - sq_loss: 1.077687102224445e-06 - tot_loss: 0.13693232098156738 - acc: 0.9449129488574538 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 2.8127715587615967 - sq_loss: 1.0710386959544849e-06 - tot_loss: 0.12688413855672476 - acc: 0.9449129488574538 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 2.8672144412994385 - sq_loss: 1.0643373116181465e-06 - tot_loss: 0.1352574276946994 - acc: 0.9454570184983678 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 2.820894241333008 - sq_loss: 1.062000364981941e-06 - tot_loss: 0.13400657393265725 - acc: 0.9460010881392819 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 2.793409585952759 - sq_loss: 1.057463236975309e-06 - tot_loss: 0.1285119962504364 - acc: 0.9468171926006529 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 2.8257105350494385 - sq_loss: 1.0539314416746492e-06 - tot_loss: 0.1282199919077449 - acc: 0.9470892274211099 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 2.832054615020752 - sq_loss: 1.0492744877410587e-06 - tot_loss: 0.13671289403789277 - acc: 0.9473612622415669 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 2.784402847290039 - sq_loss: 1.042943267748342e-06 - tot_loss: 0.13036161683566672 - acc: 0.9476332970620239 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 2.777559995651245 - sq_loss: 1.038619302562438e-06 - tot_loss: 0.1560593294771886 - acc: 0.948177366702938 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 2.848738431930542 - sq_loss: 1.034847514347348e-06 - tot_loss: 0.13119537381854895 - acc: 0.9485854189336235 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 2.859694242477417 - sq_loss: 1.0312103313481202e-06 - tot_loss: 0.1267785101006007 - acc: 0.9491294885745375 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 2.8194034099578857 - sq_loss: 1.0287833447364392e-06 - tot_loss: 0.13845408762293987 - acc: 0.9495375408052231 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 2.80513596534729 - sq_loss: 1.025007122734678e-06 - tot_loss: 0.1365308261831415 - acc: 0.9503536452665942 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 2.7973148822784424 - sq_loss: 1.020158833853202e-06 - tot_loss: 0.13057016682603617 - acc: 0.9504896626768227 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 2.79378342628479 - sq_loss: 1.0177194553762092e-06 - tot_loss: 0.12946863906872608 - acc: 0.9507616974972797 - val_acc: 0.9423142178486597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 2.7630138397216797 - sq_loss: 1.0135130423805094e-06 - tot_loss: 0.12645618061184072 - acc: 0.9514417845484222 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 2.859276056289673 - sq_loss: 1.0088247108797077e-06 - tot_loss: 0.12145856945596556 - acc: 0.9519858541893362 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 2.809105157852173 - sq_loss: 1.0063157560580294e-06 - tot_loss: 0.12564772548676517 - acc: 0.9522578890097932 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 2.7985994815826416 - sq_loss: 1.0007331638917094e-06 - tot_loss: 0.11952513049071811 - acc: 0.9525299238302503 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 2.8211817741394043 - sq_loss: 9.968121048586909e-07 - tot_loss: 0.12269249811971283 - acc: 0.9528019586507073 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 2.8519201278686523 - sq_loss: 9.92470177152427e-07 - tot_loss: 0.13023132423401806 - acc: 0.9529379760609358 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 2.7649741172790527 - sq_loss: 9.880660627459292e-07 - tot_loss: 0.13069606630062536 - acc: 0.9532100108813928 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 2.789595127105713 - sq_loss: 9.846730790741276e-07 - tot_loss: 0.13539283292506044 - acc: 0.9536180631120783 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 2.8287768363952637 - sq_loss: 9.806594789552037e-07 - tot_loss: 0.1381110157224894 - acc: 0.9538900979325353 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 2.8118624687194824 - sq_loss: 9.779101901585818e-07 - tot_loss: 0.12913937638490447 - acc: 0.9538900979325353 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 2.8126773834228516 - sq_loss: 9.747568583406974e-07 - tot_loss: 0.117017314523582 - acc: 0.9542981501632208 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 2.820615530014038 - sq_loss: 9.709655159895192e-07 - tot_loss: 0.1297098807667436 - acc: 0.9542981501632208 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 2.793896436691284 - sq_loss: 9.681834853836335e-07 - tot_loss: 0.12699961886947486 - acc: 0.9544341675734495 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 2.8208417892456055 - sq_loss: 9.641169071983313e-07 - tot_loss: 0.12498966787689181 - acc: 0.9547062023939065 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 2.7954959869384766 - sq_loss: 9.60337047217763e-07 - tot_loss: 0.1326794897742829 - acc: 0.955114254624592 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 2.7987377643585205 - sq_loss: 9.56641997618135e-07 - tot_loss: 0.12235802777090177 - acc: 0.955386289445049 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 2.848031997680664 - sq_loss: 9.54555162024917e-07 - tot_loss: 0.1292370851844611 - acc: 0.955658324265506 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 2.829763174057007 - sq_loss: 9.525321047476609e-07 - tot_loss: 0.12563443859070977 - acc: 0.955930359085963 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 2.8371646404266357 - sq_loss: 9.47690296015935e-07 - tot_loss: 0.1159068341634435 - acc: 0.9563384113166485 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 2.8769659996032715 - sq_loss: 9.455390568291477e-07 - tot_loss: 0.14060924229479665 - acc: 0.9566104461371056 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 2.8003716468811035 - sq_loss: 9.428763974028698e-07 - tot_loss: 0.11969420025782629 - acc: 0.9568824809575626 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 2.8318140506744385 - sq_loss: 9.399350915373361e-07 - tot_loss: 0.12668890548227685 - acc: 0.9568824809575626 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 2.809828758239746 - sq_loss: 9.357879093840893e-07 - tot_loss: 0.11156048152696574 - acc: 0.9568824809575626 - val_acc: 0.9457074991516796\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 2.8660671710968018 - sq_loss: 9.327991392638069e-07 - tot_loss: 0.12811994062220444 - acc: 0.9572905331882481 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 2.832826614379883 - sq_loss: 9.284916586693726e-07 - tot_loss: 0.12257349525317096 - acc: 0.9574265505984766 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 2.8076565265655518 - sq_loss: 9.243528324986983e-07 - tot_loss: 0.1297593539009454 - acc: 0.9575625680087051 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 2.8198654651641846 - sq_loss: 9.211128713104699e-07 - tot_loss: 0.12147623197333068 - acc: 0.9575625680087051 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 2.768127679824829 - sq_loss: 9.17721649784653e-07 - tot_loss: 0.12642882109412845 - acc: 0.9579706202393906 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 2.834909200668335 - sq_loss: 9.14287966224947e-07 - tot_loss: 0.12315021356252354 - acc: 0.9581066376496191 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 2.799060583114624 - sq_loss: 9.109717780120263e-07 - tot_loss: 0.12740636633451752 - acc: 0.9582426550598476 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 2.8750429153442383 - sq_loss: 9.082700103135721e-07 - tot_loss: 0.13667406467853205 - acc: 0.9585146898803046 - val_acc: 0.9460468272819816\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 2.817160129547119 - sq_loss: 9.042575470630254e-07 - tot_loss: 0.13186131921983435 - acc: 0.9585146898803046 - val_acc: 0.9463861554122837\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 2.8464910984039307 - sq_loss: 9.008581400848925e-07 - tot_loss: 0.12379637455023795 - acc: 0.9586507072905331 - val_acc: 0.9467254835425857\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 2.8334107398986816 - sq_loss: 8.982171380012005e-07 - tot_loss: 0.11891729569854403 - acc: 0.9594668117519043 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 2.8319194316864014 - sq_loss: 8.958666626313061e-07 - tot_loss: 0.1298363949075454 - acc: 0.9598748639825898 - val_acc: 0.9470648116728877\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 2.862794876098633 - sq_loss: 8.933149615586444e-07 - tot_loss: 0.13700215055637122 - acc: 0.9597388465723613 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 2.7686126232147217 - sq_loss: 8.921621201807284e-07 - tot_loss: 0.13015589286679585 - acc: 0.9600108813928183 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 2.7859456539154053 - sq_loss: 8.90345404513937e-07 - tot_loss: 0.12768800132489977 - acc: 0.9602829162132753 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 2.8853061199188232 - sq_loss: 8.874808372638654e-07 - tot_loss: 0.120261650738124 - acc: 0.9605549510337323 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 2.851217746734619 - sq_loss: 8.860312163960771e-07 - tot_loss: 0.12159552283073394 - acc: 0.9608269858541894 - val_acc: 0.9474041398031897\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 2.8284859657287598 - sq_loss: 8.840254963615735e-07 - tot_loss: 0.13071229040357446 - acc: 0.9615070729053319 - val_acc: 0.9477434679334917\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 2.8238775730133057 - sq_loss: 8.823631105769891e-07 - tot_loss: 0.12319729423771486 - acc: 0.9619151251360174 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 2.7817444801330566 - sq_loss: 8.786870466792607e-07 - tot_loss: 0.13301881411714822 - acc: 0.9621871599564744 - val_acc: 0.9487614523243977\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 2.804049253463745 - sq_loss: 8.77858326475689e-07 - tot_loss: 0.12043222647140484 - acc: 0.9624591947769314 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 2.803335428237915 - sq_loss: 8.773491799729527e-07 - tot_loss: 0.12563588230686307 - acc: 0.9624591947769314 - val_acc: 0.9497794367153037\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 2.876910924911499 - sq_loss: 8.743124340071518e-07 - tot_loss: 0.11401392880169414 - acc: 0.9625952121871599 - val_acc: 0.9501187648456056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 2.881479501724243 - sq_loss: 8.720475648260617e-07 - tot_loss: 0.11893827639409782 - acc: 0.9624591947769314 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 2.7947535514831543 - sq_loss: 8.689273727213731e-07 - tot_loss: 0.11861059223789194 - acc: 0.9624591947769314 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 2.861276865005493 - sq_loss: 8.658500405545055e-07 - tot_loss: 0.13427761827259221 - acc: 0.9630032644178455 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 2.8675460815429688 - sq_loss: 8.625997338640445e-07 - tot_loss: 0.13140704116164148 - acc: 0.9630032644178455 - val_acc: 0.9504580929759077\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 2.8486738204956055 - sq_loss: 8.598208864896151e-07 - tot_loss: 0.12381409030583201 - acc: 0.9630032644178455 - val_acc: 0.9501187648456056\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 2.8561203479766846 - sq_loss: 8.591239861743816e-07 - tot_loss: 0.12526087482327908 - acc: 0.963411316648531 - val_acc: 0.9507974211062097\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 2.805516481399536 - sq_loss: 8.581183124078962e-07 - tot_loss: 0.12274639633030571 - acc: 0.9638193688792165 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 2.8345701694488525 - sq_loss: 8.563361006963532e-07 - tot_loss: 0.13079098975484005 - acc: 0.9639553862894451 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 2.8260629177093506 - sq_loss: 8.546942353859777e-07 - tot_loss: 0.1325171082353953 - acc: 0.9642274211099021 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 2.840615749359131 - sq_loss: 8.532010156159231e-07 - tot_loss: 0.1306315569536043 - acc: 0.9642274211099021 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 2.8427093029022217 - sq_loss: 8.501376100866764e-07 - tot_loss: 0.12250707176933062 - acc: 0.9644994559303591 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 2.792607069015503 - sq_loss: 8.465224823339668e-07 - tot_loss: 0.12279075660498728 - acc: 0.9646354733405876 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 2.758056402206421 - sq_loss: 8.453251894025016e-07 - tot_loss: 0.14064885608415967 - acc: 0.9646354733405876 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 2.778137683868408 - sq_loss: 8.434765277343104e-07 - tot_loss: 0.11853499263624667 - acc: 0.9650435255712732 - val_acc: 0.9521547336274178\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 2.8007895946502686 - sq_loss: 8.406069582633791e-07 - tot_loss: 0.11577062039746222 - acc: 0.9650435255712732 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 2.8473379611968994 - sq_loss: 8.376342748306342e-07 - tot_loss: 0.11799708096522998 - acc: 0.9650435255712732 - val_acc: 0.9514760773668137\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 2.822252035140991 - sq_loss: 8.354821261491452e-07 - tot_loss: 0.12138641357575186 - acc: 0.9654515778019587 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 2.831650495529175 - sq_loss: 8.334042149726884e-07 - tot_loss: 0.13026586734649626 - acc: 0.9657236126224157 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 2.79386043548584 - sq_loss: 8.307201255774999e-07 - tot_loss: 0.12789477393242077 - acc: 0.9657236126224157 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 2.7880613803863525 - sq_loss: 8.284319505946769e-07 - tot_loss: 0.10940032047709769 - acc: 0.9659956474428727 - val_acc: 0.9518154054971157\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 2.8430380821228027 - sq_loss: 8.25668394099921e-07 - tot_loss: 0.12366408017840747 - acc: 0.9666757344940152 - val_acc: 0.9524940617577197\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 2.8320605754852295 - sq_loss: 8.231771744249272e-07 - tot_loss: 0.13687355007089685 - acc: 0.9668117519042437 - val_acc: 0.9528333898880217\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 2.839970827102661 - sq_loss: 8.222444876082591e-07 - tot_loss: 0.12230472152256477 - acc: 0.9669477693144722 - val_acc: 0.9531727180183237\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 2.8143579959869385 - sq_loss: 8.199149874599243e-07 - tot_loss: 0.12133800517011273 - acc: 0.9672198041349293 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 2.788316249847412 - sq_loss: 8.183437216757738e-07 - tot_loss: 0.12867336792368222 - acc: 0.9672198041349293 - val_acc: 0.9535120461486257\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 2.767160415649414 - sq_loss: 8.166167049239448e-07 - tot_loss: 0.12835284801931457 - acc: 0.9676278563656148 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 2.818857431411743 - sq_loss: 8.146352001858759e-07 - tot_loss: 0.12932451597949535 - acc: 0.9678998911860718 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 2.850550651550293 - sq_loss: 8.119662879835232e-07 - tot_loss: 0.1252525312620032 - acc: 0.9680359085963003 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 2.784236431121826 - sq_loss: 8.111010743050429e-07 - tot_loss: 0.12185237386514003 - acc: 0.9680359085963003 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 2.7882256507873535 - sq_loss: 8.097828754216607e-07 - tot_loss: 0.1234127647332468 - acc: 0.9683079434167573 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 2.7958180904388428 - sq_loss: 8.088970844255527e-07 - tot_loss: 0.12766387553587855 - acc: 0.9683079434167573 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 2.7873170375823975 - sq_loss: 8.076216886365728e-07 - tot_loss: 0.11945409448881339 - acc: 0.9685799782372143 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 2.8263185024261475 - sq_loss: 8.054402655943704e-07 - tot_loss: 0.129561409589388 - acc: 0.9685799782372143 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 2.811174154281616 - sq_loss: 8.031719858081487e-07 - tot_loss: 0.12631197823343698 - acc: 0.9684439608269858 - val_acc: 0.9545300305395318\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 2.812131643295288 - sq_loss: 8.012065109141986e-07 - tot_loss: 0.135759715026613 - acc: 0.9684439608269858 - val_acc: 0.9541907024092298\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 2.8328726291656494 - sq_loss: 7.995712394404109e-07 - tot_loss: 0.12360388075618034 - acc: 0.9688520130576714 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 2.803100347518921 - sq_loss: 7.981188332450984e-07 - tot_loss: 0.13419514245118203 - acc: 0.9688520130576714 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 2.829942226409912 - sq_loss: 7.967111628204293e-07 - tot_loss: 0.12175605404861822 - acc: 0.9691240478781284 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 2.8441152572631836 - sq_loss: 7.946766231725633e-07 - tot_loss: 0.12124705791545276 - acc: 0.969260065288357 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 2.825965166091919 - sq_loss: 7.936478709780204e-07 - tot_loss: 0.11624161780098419 - acc: 0.969260065288357 - val_acc: 0.9548693586698337\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 2.824009656906128 - sq_loss: 7.919613267404202e-07 - tot_loss: 0.11148888178185445 - acc: 0.969532100108814 - val_acc: 0.9552086868001357\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 2.7860524654388428 - sq_loss: 7.899349725448701e-07 - tot_loss: 0.10738938066248949 - acc: 0.9693960826985855 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 2.8519930839538574 - sq_loss: 7.877960683799756e-07 - tot_loss: 0.10482236195573447 - acc: 0.9696681175190425 - val_acc: 0.9555480149304377\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 2.781002998352051 - sq_loss: 7.871027492001303e-07 - tot_loss: 0.12230285548431286 - acc: 0.9699401523394995 - val_acc: 0.9558873430607397\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 2.774812698364258 - sq_loss: 7.858917570047197e-07 - tot_loss: 0.12437480631284359 - acc: 0.970348204570185 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 2.780646800994873 - sq_loss: 7.850533165765228e-07 - tot_loss: 0.11359198851627017 - acc: 0.970348204570185 - val_acc: 0.9565659993213438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 2.7957262992858887 - sq_loss: 7.830225285943015e-07 - tot_loss: 0.1201757734137181 - acc: 0.9704842219804135 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 2.802046775817871 - sq_loss: 7.81736332555738e-07 - tot_loss: 0.11006599333342337 - acc: 0.970620239390642 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 2.8201208114624023 - sq_loss: 7.802509003340674e-07 - tot_loss: 0.11485639354636912 - acc: 0.970620239390642 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 2.7785842418670654 - sq_loss: 7.787100457790075e-07 - tot_loss: 0.12439034431544749 - acc: 0.970620239390642 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 2.757631301879883 - sq_loss: 7.770178740429401e-07 - tot_loss: 0.13568859502462538 - acc: 0.970620239390642 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 2.8012609481811523 - sq_loss: 7.753201316518243e-07 - tot_loss: 0.12936126722772823 - acc: 0.970892274211099 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 2.8102853298187256 - sq_loss: 7.740390515209583e-07 - tot_loss: 0.1311016889664327 - acc: 0.9710282916213275 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 2.8049919605255127 - sq_loss: 7.722485406702617e-07 - tot_loss: 0.12967070051661844 - acc: 0.9710282916213275 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 2.7610719203948975 - sq_loss: 7.702312814217294e-07 - tot_loss: 0.12810475726918225 - acc: 0.971164309031556 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 2.8244521617889404 - sq_loss: 7.686780918447766e-07 - tot_loss: 0.13536175379942006 - acc: 0.9713003264417845 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 2.823951005935669 - sq_loss: 7.688867071919958e-07 - tot_loss: 0.11127208133891009 - acc: 0.971436343852013 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 2.7957701683044434 - sq_loss: 7.674917128497327e-07 - tot_loss: 0.12333681334893698 - acc: 0.971436343852013 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 2.7550508975982666 - sq_loss: 7.648238238289196e-07 - tot_loss: 0.1165554939572997 - acc: 0.9713003264417845 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 2.7842023372650146 - sq_loss: 7.6307986773827e-07 - tot_loss: 0.13008533353826235 - acc: 0.9713003264417845 - val_acc: 0.9562266711910418\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 2.8007161617279053 - sq_loss: 7.608114174217917e-07 - tot_loss: 0.13531618483411445 - acc: 0.9715723612622416 - val_acc: 0.9565659993213438\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 2.7792766094207764 - sq_loss: 7.575117706437595e-07 - tot_loss: 0.1083220758546597 - acc: 0.9717083786724701 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 2.772183656692505 - sq_loss: 7.550598866146174e-07 - tot_loss: 0.12908351546349106 - acc: 0.9718443960826986 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 2.8277103900909424 - sq_loss: 7.538683348684572e-07 - tot_loss: 0.12324490409671118 - acc: 0.9722524483133841 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 2.7594523429870605 - sq_loss: 7.521816769440193e-07 - tot_loss: 0.12564150942885677 - acc: 0.9723884657236126 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 2.7733724117279053 - sq_loss: 7.495291356462985e-07 - tot_loss: 0.11621137131785741 - acc: 0.9727965179542981 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 2.769695520401001 - sq_loss: 7.470392233699386e-07 - tot_loss: 0.11522799977440412 - acc: 0.9727965179542981 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 2.804764747619629 - sq_loss: 7.457263677679293e-07 - tot_loss: 0.11081934662429882 - acc: 0.9726605005440696 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 2.749227285385132 - sq_loss: 7.451352530551958e-07 - tot_loss: 0.12782430771124953 - acc: 0.9725244831338411 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 2.8300817012786865 - sq_loss: 7.449203849319019e-07 - tot_loss: 0.11644695876301725 - acc: 0.9727965179542981 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 2.8041493892669678 - sq_loss: 7.438964075845433e-07 - tot_loss: 0.12461913577103623 - acc: 0.9730685527747551 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 2.806859254837036 - sq_loss: 7.435207294292923e-07 - tot_loss: 0.12944319147111227 - acc: 0.9730685527747551 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 2.8886911869049072 - sq_loss: 7.430767823279893e-07 - tot_loss: 0.125926259351959 - acc: 0.9730685527747551 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 2.8436849117279053 - sq_loss: 7.417032179546368e-07 - tot_loss: 0.1250790324323321 - acc: 0.9730685527747551 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 2.80428147315979 - sq_loss: 7.397965191557887e-07 - tot_loss: 0.14569886188297 - acc: 0.9732045701849836 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 2.8137919902801514 - sq_loss: 7.385186790997977e-07 - tot_loss: 0.14179482291684598 - acc: 0.9733405875952121 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 2.785449743270874 - sq_loss: 7.372391905846598e-07 - tot_loss: 0.11810476798821079 - acc: 0.9732045701849836 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 2.8326969146728516 - sq_loss: 7.359313372035103e-07 - tot_loss: 0.10906210625034207 - acc: 0.9732045701849836 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 2.8223989009857178 - sq_loss: 7.333620146710018e-07 - tot_loss: 0.11340339446135328 - acc: 0.9733405875952121 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 2.7853732109069824 - sq_loss: 7.319674750760896e-07 - tot_loss: 0.12288838226349008 - acc: 0.9732045701849836 - val_acc: 0.9569053274516457\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 2.8094756603240967 - sq_loss: 7.304112727979373e-07 - tot_loss: 0.12814957431976026 - acc: 0.9732045701849836 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 2.8315188884735107 - sq_loss: 7.295109298866009e-07 - tot_loss: 0.1225914928967824 - acc: 0.9734766050054406 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 2.801218032836914 - sq_loss: 7.277551503648283e-07 - tot_loss: 0.12910155542802504 - acc: 0.9736126224156693 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 2.8237335681915283 - sq_loss: 7.26145003682177e-07 - tot_loss: 0.12183251342348478 - acc: 0.9736126224156693 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 2.8405301570892334 - sq_loss: 7.247979283420136e-07 - tot_loss: 0.13579706714536366 - acc: 0.9740206746463548 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 2.8306944370269775 - sq_loss: 7.23196933449799e-07 - tot_loss: 0.1393491061545138 - acc: 0.9738846572361263 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 2.805758237838745 - sq_loss: 7.220002657959412e-07 - tot_loss: 0.1270535524733183 - acc: 0.9738846572361263 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 2.797384738922119 - sq_loss: 7.205150041045272e-07 - tot_loss: 0.11894181323349073 - acc: 0.9741566920565833 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 2.7926857471466064 - sq_loss: 7.187747996795224e-07 - tot_loss: 0.1253325360509827 - acc: 0.9741566920565833 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 2.804290533065796 - sq_loss: 7.175725613706163e-07 - tot_loss: 0.1219784181896475 - acc: 0.9742927094668118 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 2.8640668392181396 - sq_loss: 7.164471185205912e-07 - tot_loss: 0.11540814817911893 - acc: 0.9749727965179543 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 2.8535332679748535 - sq_loss: 7.154171157708333e-07 - tot_loss: 0.13723600296052774 - acc: 0.9749727965179543 - val_acc: 0.9582626399728538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 2.8457400798797607 - sq_loss: 7.148644272092497e-07 - tot_loss: 0.12059567734834942 - acc: 0.9749727965179543 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 2.7930305004119873 - sq_loss: 7.142519962144434e-07 - tot_loss: 0.11505840302291404 - acc: 0.9752448313384113 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 2.7645721435546875 - sq_loss: 7.133117492230667e-07 - tot_loss: 0.10530058033119949 - acc: 0.9751088139281828 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 2.795748710632324 - sq_loss: 7.119061251614767e-07 - tot_loss: 0.12495668361345214 - acc: 0.9752448313384113 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 2.839797258377075 - sq_loss: 7.101843948476017e-07 - tot_loss: 0.12159652050619396 - acc: 0.9752448313384113 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 2.8371849060058594 - sq_loss: 7.092499458849488e-07 - tot_loss: 0.1284745119334605 - acc: 0.9752448313384113 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 2.802229404449463 - sq_loss: 7.083962145770784e-07 - tot_loss: 0.12541250958011996 - acc: 0.9752448313384113 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 2.812345027923584 - sq_loss: 7.061569249344757e-07 - tot_loss: 0.12733790382790078 - acc: 0.9755168661588683 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 2.793149709701538 - sq_loss: 7.055425612634281e-07 - tot_loss: 0.11884812972244108 - acc: 0.9751088139281828 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 2.820857048034668 - sq_loss: 7.051419288472971e-07 - tot_loss: 0.12350275956174461 - acc: 0.9752448313384113 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 2.8022572994232178 - sq_loss: 7.043024652375607e-07 - tot_loss: 0.1231137729609808 - acc: 0.9753808487486398 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 2.8050570487976074 - sq_loss: 7.036090323708777e-07 - tot_loss: 0.12912758553084625 - acc: 0.9753808487486398 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 2.8429737091064453 - sq_loss: 7.023216426205181e-07 - tot_loss: 0.11054703501589991 - acc: 0.9753808487486398 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 2.8737401962280273 - sq_loss: 7.007658950897167e-07 - tot_loss: 0.11931418708258068 - acc: 0.9752448313384113 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 2.813209295272827 - sq_loss: 6.992270868977357e-07 - tot_loss: 0.12580972017400915 - acc: 0.9756528835690969 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 2.786064863204956 - sq_loss: 6.98478004323988e-07 - tot_loss: 0.1226642650064711 - acc: 0.9761969532100109 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 2.75331974029541 - sq_loss: 6.977319344514399e-07 - tot_loss: 0.13134459252043662 - acc: 0.9757889009793254 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 2.8066046237945557 - sq_loss: 6.958883886909462e-07 - tot_loss: 0.13031585848965044 - acc: 0.9760609357997824 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 2.7920753955841064 - sq_loss: 6.935825922482763e-07 - tot_loss: 0.11821930246473333 - acc: 0.9763329706202394 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 2.7730162143707275 - sq_loss: 6.915376502547588e-07 - tot_loss: 0.11340913339059555 - acc: 0.9761969532100109 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 2.7708916664123535 - sq_loss: 6.901627216393535e-07 - tot_loss: 0.12737430447571851 - acc: 0.9763329706202394 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 2.7865118980407715 - sq_loss: 6.882091838633642e-07 - tot_loss: 0.12355679948566833 - acc: 0.9761969532100109 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 2.6980888843536377 - sq_loss: 6.869405524412286e-07 - tot_loss: 0.10824816347122024 - acc: 0.9763329706202394 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 2.7367539405822754 - sq_loss: 6.856195113869035e-07 - tot_loss: 0.14596969502629187 - acc: 0.9763329706202394 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 2.740621328353882 - sq_loss: 6.84017606999987e-07 - tot_loss: 0.1369072615571496 - acc: 0.9761969532100109 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 2.747272253036499 - sq_loss: 6.837282171545667e-07 - tot_loss: 0.1282418702550694 - acc: 0.9763329706202394 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 2.7000396251678467 - sq_loss: 6.834368377894862e-07 - tot_loss: 0.12689416343589976 - acc: 0.9763329706202394 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 2.746915817260742 - sq_loss: 6.826901994827494e-07 - tot_loss: 0.13279612315859057 - acc: 0.9764689880304679 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 2.7168772220611572 - sq_loss: 6.815537290094653e-07 - tot_loss: 0.12730454042538675 - acc: 0.9766050054406964 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 2.7904200553894043 - sq_loss: 6.802512189096888e-07 - tot_loss: 0.13647399835304141 - acc: 0.9764689880304679 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 2.7004899978637695 - sq_loss: 6.789626354475331e-07 - tot_loss: 0.11821311260751588 - acc: 0.9767410228509249 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 2.723684787750244 - sq_loss: 6.786655717405665e-07 - tot_loss: 0.11108355129591185 - acc: 0.9764689880304679 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 2.7150001525878906 - sq_loss: 6.781625643270672e-07 - tot_loss: 0.12169627889697066 - acc: 0.9767410228509249 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 2.7519240379333496 - sq_loss: 6.767879199287563e-07 - tot_loss: 0.12164554333203692 - acc: 0.9767410228509249 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 2.6644647121429443 - sq_loss: 6.755744834663346e-07 - tot_loss: 0.12725011245324258 - acc: 0.9767410228509249 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 2.6728830337524414 - sq_loss: 6.746836334059481e-07 - tot_loss: 0.1198305983582113 - acc: 0.9770130576713819 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 2.67756724357605 - sq_loss: 6.736429440934444e-07 - tot_loss: 0.13598164530967938 - acc: 0.9767410228509249 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 2.7388360500335693 - sq_loss: 6.716799703099241e-07 - tot_loss: 0.12407140246701132 - acc: 0.9767410228509249 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 2.748863458633423 - sq_loss: 6.709237823088188e-07 - tot_loss: 0.12647153235803765 - acc: 0.9768770402611534 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 2.6992177963256836 - sq_loss: 6.690841019008076e-07 - tot_loss: 0.10771995045360927 - acc: 0.9767410228509249 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 2.8064398765563965 - sq_loss: 6.683939659524185e-07 - tot_loss: 0.11614052900199168 - acc: 0.9770130576713819 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 2.747191905975342 - sq_loss: 6.66907681079465e-07 - tot_loss: 0.12325580860484342 - acc: 0.9771490750816104 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 2.721940755844116 - sq_loss: 6.656148912043136e-07 - tot_loss: 0.13190960752414083 - acc: 0.9771490750816104 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 2.7693252563476562 - sq_loss: 6.647396730841137e-07 - tot_loss: 0.1319456921997606 - acc: 0.9771490750816104 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 2.801675319671631 - sq_loss: 6.634426199525478e-07 - tot_loss: 0.12168093950933923 - acc: 0.9771490750816104 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 2.8001372814178467 - sq_loss: 6.628915230066923e-07 - tot_loss: 0.1305371936205867 - acc: 0.9771490750816104 - val_acc: 0.9586019681031558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 2.8026535511016846 - sq_loss: 6.617320877921884e-07 - tot_loss: 0.1323429784639628 - acc: 0.9775571273122959 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 2.806072235107422 - sq_loss: 6.606380225093744e-07 - tot_loss: 0.12497473651903401 - acc: 0.9774211099020674 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 2.7736334800720215 - sq_loss: 6.595542458853743e-07 - tot_loss: 0.1197325095325239 - acc: 0.9775571273122959 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 2.810361385345459 - sq_loss: 6.59085117149516e-07 - tot_loss: 0.11702912286139366 - acc: 0.9779651795429815 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 2.84899640083313 - sq_loss: 6.580361286978587e-07 - tot_loss: 0.131829891751846 - acc: 0.9782372143634385 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 2.778761386871338 - sq_loss: 6.569430865965842e-07 - tot_loss: 0.1296503379945002 - acc: 0.97810119695321 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 2.812009811401367 - sq_loss: 6.558945528922777e-07 - tot_loss: 0.12579629249063362 - acc: 0.9782372143634385 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 2.8300623893737793 - sq_loss: 6.547094812958676e-07 - tot_loss: 0.13130047432048764 - acc: 0.9776931447225244 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 2.8248257637023926 - sq_loss: 6.533102805406088e-07 - tot_loss: 0.13036074421073185 - acc: 0.9783732317736671 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 2.804048776626587 - sq_loss: 6.518724262605247e-07 - tot_loss: 0.12776410101720415 - acc: 0.97810119695321 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 2.8179984092712402 - sq_loss: 6.512377694889437e-07 - tot_loss: 0.1283985442043709 - acc: 0.9783732317736671 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 2.7931549549102783 - sq_loss: 6.509126819764788e-07 - tot_loss: 0.12607949345761638 - acc: 0.9786452665941241 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 2.8094239234924316 - sq_loss: 6.492089141829638e-07 - tot_loss: 0.13242844200113868 - acc: 0.9786452665941241 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 2.825657606124878 - sq_loss: 6.4802003407749e-07 - tot_loss: 0.12276849515462562 - acc: 0.9786452665941241 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 2.810612201690674 - sq_loss: 6.476674911937153e-07 - tot_loss: 0.12561314233376875 - acc: 0.9786452665941241 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 2.8009109497070312 - sq_loss: 6.462319106503855e-07 - tot_loss: 0.12964929383841128 - acc: 0.9786452665941241 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 2.8139822483062744 - sq_loss: 6.453902869907324e-07 - tot_loss: 0.11677896031857293 - acc: 0.9785092491838956 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 2.8013901710510254 - sq_loss: 6.447938858400448e-07 - tot_loss: 0.11462875681111362 - acc: 0.9786452665941241 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 2.803914785385132 - sq_loss: 6.436104058593628e-07 - tot_loss: 0.12660124172650356 - acc: 0.9786452665941241 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 2.8102662563323975 - sq_loss: 6.424523348869116e-07 - tot_loss: 0.12057804311292519 - acc: 0.9785092491838956 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 2.8031527996063232 - sq_loss: 6.421988700822112e-07 - tot_loss: 0.1321797439963408 - acc: 0.9786452665941241 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 2.813969373703003 - sq_loss: 6.417982945094991e-07 - tot_loss: 0.13521667526919234 - acc: 0.9789173014145811 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 2.7898685932159424 - sq_loss: 6.400180154741975e-07 - tot_loss: 0.1271138229854294 - acc: 0.9789173014145811 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 2.814931631088257 - sq_loss: 6.391302918018482e-07 - tot_loss: 0.1333149288645027 - acc: 0.9789173014145811 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 2.805042028427124 - sq_loss: 6.377412660185655e-07 - tot_loss: 0.11821689944180847 - acc: 0.9789173014145811 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 2.7478220462799072 - sq_loss: 6.366591946971312e-07 - tot_loss: 0.11798213485116449 - acc: 0.9790533188248096 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 2.869145393371582 - sq_loss: 6.353256480906566e-07 - tot_loss: 0.12185410605428304 - acc: 0.9789173014145811 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 2.8020646572113037 - sq_loss: 6.347431735775899e-07 - tot_loss: 0.12061948176648996 - acc: 0.9790533188248096 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 2.833850383758545 - sq_loss: 6.337933768918447e-07 - tot_loss: 0.12449735425200104 - acc: 0.9790533188248096 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 2.8850114345550537 - sq_loss: 6.334592512757808e-07 - tot_loss: 0.12174103485412047 - acc: 0.9791893362350381 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 2.8519678115844727 - sq_loss: 6.335948796731827e-07 - tot_loss: 0.11952403759323005 - acc: 0.9791893362350381 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 2.8008406162261963 - sq_loss: 6.329975121843745e-07 - tot_loss: 0.12204666817807097 - acc: 0.9791893362350381 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 2.7983739376068115 - sq_loss: 6.309559239525697e-07 - tot_loss: 0.11988641170642522 - acc: 0.9793253536452666 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 2.781728982925415 - sq_loss: 6.299873120951816e-07 - tot_loss: 0.11693302633673319 - acc: 0.9790533188248096 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 2.781012773513794 - sq_loss: 6.288078679972386e-07 - tot_loss: 0.11066305371054663 - acc: 0.9791893362350381 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 2.842458963394165 - sq_loss: 6.27554413767939e-07 - tot_loss: 0.1318266547266379 - acc: 0.9793253536452666 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 2.852381467819214 - sq_loss: 6.258596840780228e-07 - tot_loss: 0.12024486543205293 - acc: 0.9790533188248096 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 2.7950918674468994 - sq_loss: 6.246534098863776e-07 - tot_loss: 0.11405267689446286 - acc: 0.9793253536452666 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 2.8525173664093018 - sq_loss: 6.24160747975111e-07 - tot_loss: 0.11876336273428945 - acc: 0.9793253536452666 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 2.793002128601074 - sq_loss: 6.233169642655412e-07 - tot_loss: 0.11944754747208142 - acc: 0.9793253536452666 - val_acc: 0.9592806243637597\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 2.7971720695495605 - sq_loss: 6.220005843715626e-07 - tot_loss: 0.12108717397967761 - acc: 0.9794613710554951 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 2.801234722137451 - sq_loss: 6.208928198248032e-07 - tot_loss: 0.11815787247147302 - acc: 0.9794613710554951 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 2.858064651489258 - sq_loss: 6.205787599355972e-07 - tot_loss: 0.12655753777572643 - acc: 0.9795973884657236 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 2.802277088165283 - sq_loss: 6.194356956257252e-07 - tot_loss: 0.12618083318146334 - acc: 0.9795973884657236 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 2.7297146320343018 - sq_loss: 6.187962071635411e-07 - tot_loss: 0.12151988194054297 - acc: 0.9794613710554951 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 2.789989471435547 - sq_loss: 6.174311124595988e-07 - tot_loss: 0.11786987101539093 - acc: 0.9794613710554951 - val_acc: 0.9589412962334578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 2.8360228538513184 - sq_loss: 6.160705652291654e-07 - tot_loss: 0.11805322093093695 - acc: 0.9795973884657236 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 2.7658307552337646 - sq_loss: 6.154453444651153e-07 - tot_loss: 0.1126662752142239 - acc: 0.9795973884657236 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 2.774756908416748 - sq_loss: 6.141049198049586e-07 - tot_loss: 0.13053010326038195 - acc: 0.9795973884657236 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 2.849656820297241 - sq_loss: 6.130237579782261e-07 - tot_loss: 0.12258698658455447 - acc: 0.9795973884657236 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 2.821397066116333 - sq_loss: 6.119250315350655e-07 - tot_loss: 0.11319078028261942 - acc: 0.9793253536452666 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 2.839071035385132 - sq_loss: 6.112449568718148e-07 - tot_loss: 0.12485342593649928 - acc: 0.9797334058759521 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 2.8049356937408447 - sq_loss: 6.1061598444212e-07 - tot_loss: 0.1340703299637419 - acc: 0.9795973884657236 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 2.7925777435302734 - sq_loss: 6.102147835918004e-07 - tot_loss: 0.12504465611265314 - acc: 0.9798694232861807 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 2.788944721221924 - sq_loss: 6.094988407312485e-07 - tot_loss: 0.11720555245492992 - acc: 0.9797334058759521 - val_acc: 0.9596199524940617\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 2.8158116340637207 - sq_loss: 6.085556378820911e-07 - tot_loss: 0.11847114637329603 - acc: 0.9797334058759521 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 2.854132890701294 - sq_loss: 6.077767693568603e-07 - tot_loss: 0.11942157043240376 - acc: 0.9798694232861807 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 2.891146659851074 - sq_loss: 6.079244485590607e-07 - tot_loss: 0.12842973768848565 - acc: 0.9798694232861807 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 2.80755352973938 - sq_loss: 6.075599685573252e-07 - tot_loss: 0.11801905307788041 - acc: 0.9798694232861807 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 2.819749116897583 - sq_loss: 6.064751119083667e-07 - tot_loss: 0.13022415938732979 - acc: 0.9798694232861807 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 2.808077812194824 - sq_loss: 6.056742449800367e-07 - tot_loss: 0.12988822216097984 - acc: 0.9798694232861807 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 2.7921082973480225 - sq_loss: 6.051639616089233e-07 - tot_loss: 0.1442481968011008 - acc: 0.9798694232861807 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 2.7871830463409424 - sq_loss: 6.049276066733e-07 - tot_loss: 0.13834155162849027 - acc: 0.9798694232861807 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 2.8036301136016846 - sq_loss: 6.044114684300439e-07 - tot_loss: 0.12441530741464113 - acc: 0.9798694232861807 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 2.7927114963531494 - sq_loss: 6.035029400663916e-07 - tot_loss: 0.11814101226492846 - acc: 0.9800054406964092 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 2.776104211807251 - sq_loss: 6.033280328665569e-07 - tot_loss: 0.13503583820268006 - acc: 0.9800054406964092 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 2.7957825660705566 - sq_loss: 6.028899406373966e-07 - tot_loss: 0.1425376425971574 - acc: 0.9798694232861807 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 2.765099287033081 - sq_loss: 6.022874572408909e-07 - tot_loss: 0.11842563310432419 - acc: 0.9800054406964092 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 2.83016037940979 - sq_loss: 6.01525812271575e-07 - tot_loss: 0.12213672825896171 - acc: 0.9800054406964092 - val_acc: 0.9586019681031558\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 2.7734835147857666 - sq_loss: 6.006866328789329e-07 - tot_loss: 0.11912365028963456 - acc: 0.9802774755168662 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 2.8027706146240234 - sq_loss: 5.997326297801919e-07 - tot_loss: 0.13255320605395204 - acc: 0.9802774755168662 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 2.8255510330200195 - sq_loss: 5.982867605780484e-07 - tot_loss: 0.11630766612789567 - acc: 0.9801414581066377 - val_acc: 0.9589412962334578\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 2.878420114517212 - sq_loss: 5.97035636928922e-07 - tot_loss: 0.1316876267665158 - acc: 0.9804134929270947 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 2.8757972717285156 - sq_loss: 5.957543862677994e-07 - tot_loss: 0.12637380059951875 - acc: 0.9804134929270947 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 2.85739803314209 - sq_loss: 5.950687409495004e-07 - tot_loss: 0.13055168498560177 - acc: 0.9804134929270947 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 2.7945706844329834 - sq_loss: 5.93566028328496e-07 - tot_loss: 0.1339608044239905 - acc: 0.9805495103373232 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 2.824352979660034 - sq_loss: 5.929531994297577e-07 - tot_loss: 0.11821791205016807 - acc: 0.9804134929270947 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 2.8238985538482666 - sq_loss: 5.921770593886322e-07 - tot_loss: 0.1277762541610703 - acc: 0.9806855277475517 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 2.7832705974578857 - sq_loss: 5.917263479204848e-07 - tot_loss: 0.12315914714035203 - acc: 0.9806855277475517 - val_acc: 0.9572446555819477\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 2.7939767837524414 - sq_loss: 5.91196624100121e-07 - tot_loss: 0.1332924281202038 - acc: 0.9806855277475517 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 2.7822062969207764 - sq_loss: 5.910927711738623e-07 - tot_loss: 0.12861180501278524 - acc: 0.9806855277475517 - val_acc: 0.9575839837122497\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 2.7871274948120117 - sq_loss: 5.910439426770608e-07 - tot_loss: 0.12210965229454462 - acc: 0.9806855277475517 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 2.7771549224853516 - sq_loss: 5.900157589167065e-07 - tot_loss: 0.12301205895154488 - acc: 0.9808215451577802 - val_acc: 0.9579233118425518\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 2.775067090988159 - sq_loss: 5.88596435591171e-07 - tot_loss: 0.1369503475870565 - acc: 0.9808215451577802 - val_acc: 0.9582626399728538\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 2.8426427841186523 - sq_loss: 5.874200041944277e-07 - tot_loss: 0.1241978863625518 - acc: 0.9808215451577802 - val_acc: 0.9589412962334578\n",
      "CR_1 = 0.17665842270710058   CR_2 = 0.17592699696476163\n",
      "/home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 3\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "alpha = 1\n",
    "\n",
    "\n",
    "\n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "    d0 = 561 #561 =3*11*17\n",
    "\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 512\n",
    "    d6 = 6 \n",
    "\n",
    "\n",
    "    W1 = 0.2*init.xavier_normal_(torch.empty(d1, d0, device=device), gain=1.0)\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    W2 = 0.2*init.xavier_normal_(torch.empty(d2, d1, device=device), gain=1.0)\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles factors, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    W3 = 0.2*init.xavier_normal_(torch.empty(d3, d2, device=device), gain=1.0)\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    W4 = 0.2*init.xavier_normal_(torch.empty(d4, d3, device=device), gain=1.0)\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    W5 = 0.2*init.xavier_normal_(torch.empty(d5, d4, device=device), gain=1.0)\n",
    "    W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())\n",
    "    factors5 = tensor_train(W5_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "\n",
    "    W6 = 0.2*init.xavier_normal_(torch.empty(d6, d5, device=device), gain=1.0)\n",
    "    b6 = 0*torch.ones(d6, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = nn.ReLU()(U5)\n",
    "    U6 = torch.addmm(b6.repeat(1, N), W6, V5)\n",
    "    V6 = U6 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V6 = (y_one_hot + gamma*U6 + alpha*V6)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U6 = (gamma*V6 + rho*(torch.mm(W6,V5) + b6.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W6, b6 = updateWb_org(U6,V5,W6,b6,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "        # update for 5th layer\n",
    "        # update V3\n",
    "        V5 = updateV(U5,U6,W6,b6,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U5 = relu_prox(V5,(rho*torch.addmm(b5.repeat(1,N), W5, V4) + alpha*U5)/(rho + alpha),(rho + alpha)/gamma,d5,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W5, b5 = updateWb(U5,V4,W5,b5,W5_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4))\n",
    "        W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors5 = tensor_train(W5_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        a5_train = nn.ReLU()(torch.addmm(b5.repeat(1, N), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b6.repeat(1, N), W6, a5_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        a5_test = nn.ReLU()(torch.addmm(b5.repeat(1, N_test), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b6.repeat(1, N_test), W6, a5_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V6,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b6.repeat(1,N), W6, V5),U6,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,nn.ReLU()(U5),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V6,U6,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W5.reshape((4,4,4,4,4,4,4,4,4)),torch.as_tensor(W5_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "    factors5_shape=[f.shape for f in factors5]\n",
    "    Sum_of_variables_factors5=sum(list(x*y*z for x,y,z in factors5_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4+Sum_of_variables_factors5\n",
    "\n",
    "    CR_1=((total_variabels)+(d5*d6))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5+d5*d6)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#     #this postion to add new row into existing table\n",
    "#         df=pd.read_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "#         new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "#                    'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "#                    'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1],'seed':seed} \n",
    "#         df=df.append(new_row,ignore_index=True)\n",
    "#         df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"XavierNormal_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e5c2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133d333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
