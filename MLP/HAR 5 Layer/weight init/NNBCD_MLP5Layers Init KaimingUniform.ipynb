{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Torchvision Version: 0.14.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorly as tl\n",
    "# library for TTD   (Tensorly  (search))\n",
    "\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.decomposition import tensor_train\n",
    "# different forms of tensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorly import tt_to_tensor\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "# tensor operations\n",
    "\n",
    "\n",
    "#from math import ceil\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as Fun\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4369bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737fba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open(\"/home/c/cl237/TenBCD/UCI HAR/data/features.txt\") as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('# of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eacbd4",
   "metadata": {},
   "source": [
    "## get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6509a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_train.txt', delim_whitespace=True, header=None)\n",
    "pd_X_train.columns = features\n",
    "pd_y_train = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_train.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N = len(pd_X_train)\n",
    "\n",
    "K = 6\n",
    "\n",
    "x = pd_X_train.values\n",
    "y = pd_y_train.values\n",
    "\n",
    "X_train=torch.tensor(x,dtype = torch.float32,device=device)\n",
    "y_train=torch.tensor(y,dtype = int) #dtype=torch.int,device=device)\n",
    "\n",
    "y_train = torch.flatten(y_train)\n",
    "\n",
    "X_train = torch.t(X_train)\n",
    "\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train-1, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372bd68",
   "metadata": {},
   "source": [
    "## get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445500a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_X_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/X_test.txt', delim_whitespace=True, header=None)\n",
    "pd_X_test.columns = features\n",
    "pd_y_test = pd.read_csv('/home/c/cl237/TenBCD/UCI HAR/data/y_test.txt', delim_whitespace=True, names=['Activity'])\n",
    "\n",
    "N_test = len(pd_X_test)\n",
    "\n",
    "x = pd_X_test.values\n",
    "y = pd_y_test.values\n",
    "\n",
    "X_test=torch.tensor(x,dtype = torch.float32, device=device)\n",
    "y_test=torch.tensor(y,dtype = int)\n",
    "\n",
    "y_test = torch.flatten(y_test)\n",
    "\n",
    "X_test = torch.t(X_test)\n",
    "\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test-1, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device) #Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    # check how to get V* W*\n",
    "    # torch.mm*=(input,mat2) performs a matrix multiplication of the matrices input and mat2.\n",
    "    #   if input is a (n*m) tensor,mat2 is a (m*p) tensor, output will be (n*p) tensor\n",
    "    return Vstar\n",
    "\n",
    "def updateWb_org(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "def updateWb(U, V, W, b, W_tensor_rec, alpha, rho,tau): \n",
    "    W_tensor_rec = torch.as_tensor(W_tensor_rec,device=device).float()\n",
    "    W_tensor2matrix = W_tensor_rec.reshape(W.shape)\n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+tau*W_tensor2matrix+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse((alpha+tau)*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = 0*(alpha*b+rho*torch.sum(U-torch.mm(Wstar,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar\n",
    "\n",
    "# U update  E(1) in global convergent\n",
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4cb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a157bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a5c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "087d0e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 80 tau= 3 gamma= 0.5 rho= 0.5 alpha 1\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Repeatition 1 Epoch 1 / 500 \n",
      " - time: 1.578333854675293 - sq_loss: 661.652099609375 - tot_loss: 1062.3111628236802 - acc: 0.22755712731229596 - val_acc: 0.20597217509331522\n",
      "Repeatition 1 Epoch 2 / 500 \n",
      " - time: 1.5063374042510986 - sq_loss: 294.0675354003906 - tot_loss: 507.8709136461839 - acc: 0.27189880304679 - val_acc: 0.2653545978961656\n",
      "Repeatition 1 Epoch 3 / 500 \n",
      " - time: 1.519254207611084 - sq_loss: 162.49237060546875 - tot_loss: 280.48820755816996 - acc: 0.22986942328618062 - val_acc: 0.21954530030539532\n",
      "Repeatition 1 Epoch 4 / 500 \n",
      " - time: 1.5444300174713135 - sq_loss: 88.346923828125 - tot_loss: 161.71768063586205 - acc: 0.1894722524483134 - val_acc: 0.18018323719036308\n",
      "Repeatition 1 Epoch 5 / 500 \n",
      " - time: 1.5257132053375244 - sq_loss: 47.59058380126953 - tot_loss: 97.3372645676136 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 6 / 500 \n",
      " - time: 1.5610082149505615 - sq_loss: 25.55284881591797 - tot_loss: 62.037639673333615 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 7 / 500 \n",
      " - time: 1.5816318988800049 - sq_loss: 13.725837707519531 - tot_loss: 42.31311950460076 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 8 / 500 \n",
      " - time: 1.5670738220214844 - sq_loss: 7.394023418426514 - tot_loss: 31.04818341974169 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 9 / 500 \n",
      " - time: 1.580906867980957 - sq_loss: 4.0026373863220215 - tot_loss: 24.343198305461556 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 10 / 500 \n",
      " - time: 1.553227424621582 - sq_loss: 2.18192720413208 - tot_loss: 20.14524773717858 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 11 / 500 \n",
      " - time: 1.5701684951782227 - sq_loss: 1.2005789279937744 - tot_loss: 17.316642326069996 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 12 / 500 \n",
      " - time: 1.5662550926208496 - sq_loss: 0.6686733961105347 - tot_loss: 15.293127263896167 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 13 / 500 \n",
      " - time: 1.5770831108093262 - sq_loss: 0.3781987726688385 - tot_loss: 13.720385497668758 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 14 / 500 \n",
      " - time: 1.5276830196380615 - sq_loss: 0.2180166095495224 - tot_loss: 12.424445653799921 - acc: 0.1913764961915125 - val_acc: 0.18221920597217509\n",
      "Repeatition 1 Epoch 15 / 500 \n",
      " - time: 1.5733356475830078 - sq_loss: 0.12858232855796814 - tot_loss: 11.342092245118693 - acc: 0.19355277475516866 - val_acc: 0.1832371903630811\n",
      "Repeatition 1 Epoch 16 / 500 \n",
      " - time: 1.5428133010864258 - sq_loss: 0.077886663377285 - tot_loss: 10.442157253623009 - acc: 0.2290533188248096 - val_acc: 0.20868680013573127\n",
      "Repeatition 1 Epoch 17 / 500 \n",
      " - time: 1.5738637447357178 - sq_loss: 0.048623669892549515 - tot_loss: 9.633874426363036 - acc: 0.2969260065288357 - val_acc: 0.2714625042416016\n",
      "Repeatition 1 Epoch 18 / 500 \n",
      " - time: 1.5529534816741943 - sq_loss: 0.031374670565128326 - tot_loss: 8.923453472321853 - acc: 0.3472524483133841 - val_acc: 0.32575500508992195\n",
      "Repeatition 1 Epoch 19 / 500 \n",
      " - time: 1.5340142250061035 - sq_loss: 0.020966973155736923 - tot_loss: 8.288233720872086 - acc: 0.39934711643090315 - val_acc: 0.3888700373260943\n",
      "Repeatition 1 Epoch 20 / 500 \n",
      " - time: 1.5687453746795654 - sq_loss: 0.014524973928928375 - tot_loss: 7.75466940458864 - acc: 0.45987486398258975 - val_acc: 0.44350186630471666\n",
      "Repeatition 1 Epoch 21 / 500 \n",
      " - time: 1.5402781963348389 - sq_loss: 0.010428803972899914 - tot_loss: 7.281853912834777 - acc: 0.5062568008705114 - val_acc: 0.4872751951136749\n",
      "Repeatition 1 Epoch 22 / 500 \n",
      " - time: 1.5335922241210938 - sq_loss: 0.00774992024526 - tot_loss: 6.842235058546066 - acc: 0.5259793253536452 - val_acc: 0.509331523583305\n",
      "Repeatition 1 Epoch 23 / 500 \n",
      " - time: 1.554534673690796 - sq_loss: 0.005946355406194925 - tot_loss: 6.427450174611295 - acc: 0.5382208922742111 - val_acc: 0.5174753987105531\n",
      "Repeatition 1 Epoch 24 / 500 \n",
      " - time: 1.5452990531921387 - sq_loss: 0.004697189200669527 - tot_loss: 6.042352967779152 - acc: 0.545157780195865 - val_acc: 0.5266372582287071\n",
      "Repeatition 1 Epoch 25 / 500 \n",
      " - time: 1.527571678161621 - sq_loss: 0.003806290216743946 - tot_loss: 5.731333955875016 - acc: 0.5489662676822633 - val_acc: 0.5296912114014252\n",
      "Repeatition 1 Epoch 26 / 500 \n",
      " - time: 1.5533068180084229 - sq_loss: 0.003153903177008033 - tot_loss: 5.410670720084454 - acc: 0.5520946681175191 - val_acc: 0.5307091957923312\n",
      "Repeatition 1 Epoch 27 / 500 \n",
      " - time: 1.553215503692627 - sq_loss: 0.0026637862902134657 - tot_loss: 5.153618885044125 - acc: 0.5552230685527747 - val_acc: 0.5313878520529352\n",
      "Repeatition 1 Epoch 28 / 500 \n",
      " - time: 1.5242373943328857 - sq_loss: 0.002285712631419301 - tot_loss: 4.886705288794474 - acc: 0.5616158868335147 - val_acc: 0.5351204614862572\n",
      "Repeatition 1 Epoch 29 / 500 \n",
      " - time: 1.509291648864746 - sq_loss: 0.001987508498132229 - tot_loss: 4.645301659053075 - acc: 0.5746735582154516 - val_acc: 0.5395317271801833\n",
      "Repeatition 1 Epoch 30 / 500 \n",
      " - time: 1.5605945587158203 - sq_loss: 0.0017474533524364233 - tot_loss: 4.415058924554614 - acc: 0.5920837867247007 - val_acc: 0.5480149304377333\n",
      "Repeatition 1 Epoch 31 / 500 \n",
      " - time: 1.5447051525115967 - sq_loss: 0.001549954991787672 - tot_loss: 4.190354939943063 - acc: 0.609221980413493 - val_acc: 0.5558194774346793\n",
      "Repeatition 1 Epoch 32 / 500 \n",
      " - time: 1.5463323593139648 - sq_loss: 0.0013850778341293335 - tot_loss: 4.01922683432349 - acc: 0.6237758433079434 - val_acc: 0.5676959619952494\n",
      "Repeatition 1 Epoch 33 / 500 \n",
      " - time: 1.5545003414154053 - sq_loss: 0.0012451697839424014 - tot_loss: 3.8434795650755404 - acc: 0.6384657236126224 - val_acc: 0.5816084153376315\n",
      "Repeatition 1 Epoch 34 / 500 \n",
      " - time: 1.548236608505249 - sq_loss: 0.001125610084272921 - tot_loss: 3.6805857766303234 - acc: 0.6526115342763874 - val_acc: 0.5992534781133356\n",
      "Repeatition 1 Epoch 35 / 500 \n",
      " - time: 1.5192813873291016 - sq_loss: 0.001021954114548862 - tot_loss: 3.568579371945816 - acc: 0.6662132752992383 - val_acc: 0.6155412283678316\n",
      "Repeatition 1 Epoch 36 / 500 \n",
      " - time: 1.5005576610565186 - sq_loss: 0.0009313283953815699 - tot_loss: 3.3702408298340742 - acc: 0.6787268770402611 - val_acc: 0.6321683067526298\n",
      "Repeatition 1 Epoch 37 / 500 \n",
      " - time: 1.534480333328247 - sq_loss: 0.0008515992667526007 - tot_loss: 3.221815746779612 - acc: 0.6867519042437432 - val_acc: 0.6447234475738038\n",
      "Repeatition 1 Epoch 38 / 500 \n",
      " - time: 1.52284836769104 - sq_loss: 0.0007808876689523458 - tot_loss: 3.1020067309364094 - acc: 0.6970892274211099 - val_acc: 0.6562606040040719\n",
      "Repeatition 1 Epoch 39 / 500 \n",
      " - time: 1.5264642238616943 - sq_loss: 0.0007178768864832819 - tot_loss: 2.996078066302289 - acc: 0.7074265505984766 - val_acc: 0.667458432304038\n",
      "Repeatition 1 Epoch 40 / 500 \n",
      " - time: 1.525686502456665 - sq_loss: 0.0006613122532144189 - tot_loss: 2.883856211185048 - acc: 0.7187159956474428 - val_acc: 0.6779776043434\n",
      "Repeatition 1 Epoch 41 / 500 \n",
      " - time: 1.5484869480133057 - sq_loss: 0.000610299757681787 - tot_loss: 2.749508967572183 - acc: 0.7272850924918389 - val_acc: 0.6881574482524602\n",
      "Repeatition 1 Epoch 42 / 500 \n",
      " - time: 1.540198564529419 - sq_loss: 0.0005641552852466702 - tot_loss: 2.661511153659376 - acc: 0.7340859630032645 - val_acc: 0.6929080420766881\n",
      "Repeatition 1 Epoch 43 / 500 \n",
      " - time: 1.5569353103637695 - sq_loss: 0.0005222465260885656 - tot_loss: 2.566373496709275 - acc: 0.7410228509249184 - val_acc: 0.6996946046827281\n",
      "Repeatition 1 Epoch 44 / 500 \n",
      " - time: 1.5629470348358154 - sq_loss: 0.0004840349138248712 - tot_loss: 2.4554555604081543 - acc: 0.7468715995647442 - val_acc: 0.7068204954190702\n",
      "Repeatition 1 Epoch 45 / 500 \n",
      " - time: 1.551443338394165 - sq_loss: 0.0004492047301027924 - tot_loss: 2.383191708533559 - acc: 0.7513601741022851 - val_acc: 0.7098744485917883\n",
      "Repeatition 1 Epoch 46 / 500 \n",
      " - time: 1.556013822555542 - sq_loss: 0.0004175181093160063 - tot_loss: 2.28987232586951 - acc: 0.7565288356909684 - val_acc: 0.7153036986766202\n",
      "Repeatition 1 Epoch 47 / 500 \n",
      " - time: 1.5226032733917236 - sq_loss: 0.0003884958859998733 - tot_loss: 2.229768394590792 - acc: 0.7610174102285092 - val_acc: 0.7203936206311503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 48 / 500 \n",
      " - time: 1.5355300903320312 - sq_loss: 0.0003618234768509865 - tot_loss: 2.1230737952209893 - acc: 0.764689880304679 - val_acc: 0.7254835425856804\n",
      "Repeatition 1 Epoch 49 / 500 \n",
      " - time: 1.5146212577819824 - sq_loss: 0.0003373716026544571 - tot_loss: 2.080036603863846 - acc: 0.7676822633297062 - val_acc: 0.7295554801493044\n",
      "Repeatition 1 Epoch 50 / 500 \n",
      " - time: 1.5463201999664307 - sq_loss: 0.0003147937823086977 - tot_loss: 1.985768975224346 - acc: 0.7708106637649619 - val_acc: 0.7332880895826264\n",
      "Repeatition 1 Epoch 51 / 500 \n",
      " - time: 1.5298166275024414 - sq_loss: 0.0002940105623565614 - tot_loss: 1.924092289773398 - acc: 0.7742110990206746 - val_acc: 0.7343060739735324\n",
      "Repeatition 1 Epoch 52 / 500 \n",
      " - time: 1.5369107723236084 - sq_loss: 0.00027486670296639204 - tot_loss: 1.858865196334591 - acc: 0.7766594124047879 - val_acc: 0.7380386834068544\n",
      "Repeatition 1 Epoch 53 / 500 \n",
      " - time: 1.540961742401123 - sq_loss: 0.00025712253409437835 - tot_loss: 1.8147228079124034 - acc: 0.7792437431991295 - val_acc: 0.7410926365795725\n",
      "Repeatition 1 Epoch 54 / 500 \n",
      " - time: 1.509225606918335 - sq_loss: 0.0002406959974905476 - tot_loss: 1.7358727709997765 - acc: 0.7815560391730142 - val_acc: 0.7438072616219885\n",
      "Repeatition 1 Epoch 55 / 500 \n",
      " - time: 1.5744612216949463 - sq_loss: 0.00022549426648765802 - tot_loss: 1.6785843515681336 - acc: 0.7846844396082698 - val_acc: 0.7461825585341024\n",
      "Repeatition 1 Epoch 56 / 500 \n",
      " - time: 1.5033342838287354 - sq_loss: 0.0002114472445100546 - tot_loss: 1.6513578647573013 - acc: 0.7869967355821545 - val_acc: 0.7488971835765185\n",
      "Repeatition 1 Epoch 57 / 500 \n",
      " - time: 1.5794477462768555 - sq_loss: 0.0001984319678740576 - tot_loss: 1.6062773630237643 - acc: 0.7899891186071817 - val_acc: 0.7512724804886325\n",
      "Repeatition 1 Epoch 58 / 500 \n",
      " - time: 1.5439958572387695 - sq_loss: 0.00018632999854162335 - tot_loss: 1.5517910806829605 - acc: 0.7929815016322089 - val_acc: 0.7533084492704445\n",
      "Repeatition 1 Epoch 59 / 500 \n",
      " - time: 1.5879135131835938 - sq_loss: 0.00017494680650997907 - tot_loss: 1.505580372428085 - acc: 0.7969260065288357 - val_acc: 0.7563624024431626\n",
      "Repeatition 1 Epoch 60 / 500 \n",
      " - time: 1.5594639778137207 - sq_loss: 0.00016433050041086972 - tot_loss: 1.4463437350514141 - acc: 0.7997823721436343 - val_acc: 0.7590770274855786\n",
      "Repeatition 1 Epoch 61 / 500 \n",
      " - time: 1.5494129657745361 - sq_loss: 0.00015447367331944406 - tot_loss: 1.4144731537235202 - acc: 0.8026387377584331 - val_acc: 0.7600950118764845\n",
      "Repeatition 1 Epoch 62 / 500 \n",
      " - time: 1.5476689338684082 - sq_loss: 0.00014528953761328012 - tot_loss: 1.376329455197265 - acc: 0.8064472252448314 - val_acc: 0.7617916525279945\n",
      "Repeatition 1 Epoch 63 / 500 \n",
      " - time: 1.5169382095336914 - sq_loss: 0.00013669599138665944 - tot_loss: 1.359401781719498 - acc: 0.80930359085963 - val_acc: 0.7641669494401085\n",
      "Repeatition 1 Epoch 64 / 500 \n",
      " - time: 1.5207200050354004 - sq_loss: 0.00012866774341091514 - tot_loss: 1.3194644164495912 - acc: 0.8127040261153428 - val_acc: 0.7662029182219205\n",
      "Repeatition 1 Epoch 65 / 500 \n",
      " - time: 1.533022403717041 - sq_loss: 0.00012109716044506058 - tot_loss: 1.280024773544028 - acc: 0.8148803046789989 - val_acc: 0.7689175432643366\n",
      "Repeatition 1 Epoch 66 / 500 \n",
      " - time: 1.5371475219726562 - sq_loss: 0.00011404679389670491 - tot_loss: 1.219180371157563 - acc: 0.8174646354733406 - val_acc: 0.7712928401764506\n",
      "Repeatition 1 Epoch 67 / 500 \n",
      " - time: 1.536689281463623 - sq_loss: 0.00010748806380433962 - tot_loss: 1.2129847214764595 - acc: 0.8186887921653971 - val_acc: 0.7743467933491687\n",
      "Repeatition 1 Epoch 68 / 500 \n",
      " - time: 1.5111842155456543 - sq_loss: 0.00010124113759957254 - tot_loss: 1.1966979902917956 - acc: 0.8223612622415669 - val_acc: 0.7760434340006787\n",
      "Repeatition 1 Epoch 69 / 500 \n",
      " - time: 1.5363514423370361 - sq_loss: 9.539624443277717e-05 - tot_loss: 1.1518717261333222 - acc: 0.8258977149075082 - val_acc: 0.7794367153036986\n",
      "Repeatition 1 Epoch 70 / 500 \n",
      " - time: 1.5599746704101562 - sq_loss: 8.992112998384982e-05 - tot_loss: 1.1437129369696777 - acc: 0.8287540805223068 - val_acc: 0.7804546996946047\n",
      "Repeatition 1 Epoch 71 / 500 \n",
      " - time: 1.5454933643341064 - sq_loss: 8.475468348478898e-05 - tot_loss: 1.1089432991457215 - acc: 0.8333786724700761 - val_acc: 0.7824906684764167\n",
      "Repeatition 1 Epoch 72 / 500 \n",
      " - time: 1.5470948219299316 - sq_loss: 7.992921018740162e-05 - tot_loss: 1.063685787198665 - acc: 0.8366430903155604 - val_acc: 0.7848659653885307\n",
      "Repeatition 1 Epoch 73 / 500 \n",
      " - time: 1.5338289737701416 - sq_loss: 7.538408681284636e-05 - tot_loss: 1.0347995089059623 - acc: 0.8385473340587595 - val_acc: 0.7858839497794368\n",
      "Repeatition 1 Epoch 74 / 500 \n",
      " - time: 1.5075554847717285 - sq_loss: 7.114915933925658e-05 - tot_loss: 1.0017212120164913 - acc: 0.8411316648531012 - val_acc: 0.7879199185612488\n",
      "Repeatition 1 Epoch 75 / 500 \n",
      " - time: 1.5621020793914795 - sq_loss: 6.716522329952568e-05 - tot_loss: 1.0062159212143342 - acc: 0.8439880304678999 - val_acc: 0.7879199185612488\n",
      "Repeatition 1 Epoch 76 / 500 \n",
      " - time: 1.5262782573699951 - sq_loss: 6.343665882013738e-05 - tot_loss: 0.9795517295292484 - acc: 0.8465723612622416 - val_acc: 0.7896165592127588\n",
      "Repeatition 1 Epoch 77 / 500 \n",
      " - time: 1.5266075134277344 - sq_loss: 5.996336039970629e-05 - tot_loss: 0.9266295718962283 - acc: 0.8488846572361263 - val_acc: 0.7926705123854768\n",
      "Repeatition 1 Epoch 78 / 500 \n",
      " - time: 1.533432960510254 - sq_loss: 5.6686716561671346e-05 - tot_loss: 0.910608041663636 - acc: 0.8516050054406964 - val_acc: 0.7947064811672888\n",
      "Repeatition 1 Epoch 79 / 500 \n",
      " - time: 1.5247488021850586 - sq_loss: 5.35666367795784e-05 - tot_loss: 0.9143123208755242 - acc: 0.8526931447225244 - val_acc: 0.7977604343400068\n",
      "Repeatition 1 Epoch 80 / 500 \n",
      " - time: 1.5771443843841553 - sq_loss: 5.0657363317441195e-05 - tot_loss: 0.8904269230301907 - acc: 0.8560935799782372 - val_acc: 0.7997964031218188\n",
      "Repeatition 1 Epoch 81 / 500 \n",
      " - time: 1.5107781887054443 - sq_loss: 4.797205838258378e-05 - tot_loss: 0.8601148607453979 - acc: 0.8585418933623504 - val_acc: 0.8035290125551409\n",
      "Repeatition 1 Epoch 82 / 500 \n",
      " - time: 1.5269582271575928 - sq_loss: 4.5463260903488845e-05 - tot_loss: 0.8304035716491853 - acc: 0.860310119695321 - val_acc: 0.8042076688157448\n",
      "Repeatition 1 Epoch 83 / 500 \n",
      " - time: 1.5606701374053955 - sq_loss: 4.307183553464711e-05 - tot_loss: 0.8336634162947121 - acc: 0.8616702937976061 - val_acc: 0.8055649813369529\n",
      "Repeatition 1 Epoch 84 / 500 \n",
      " - time: 1.526859998703003 - sq_loss: 4.075899050803855e-05 - tot_loss: 0.8228705395381439 - acc: 0.8628944504896626 - val_acc: 0.8059043094672549\n",
      "Repeatition 1 Epoch 85 / 500 \n",
      " - time: 1.5320072174072266 - sq_loss: 3.864577956846915e-05 - tot_loss: 0.7845520737873812 - acc: 0.8649347116430903 - val_acc: 0.8076009501187649\n",
      "Repeatition 1 Epoch 86 / 500 \n",
      " - time: 1.5309538841247559 - sq_loss: 3.662587550934404e-05 - tot_loss: 0.7792610733608853 - acc: 0.8668389553862894 - val_acc: 0.8089582626399728\n",
      "Repeatition 1 Epoch 87 / 500 \n",
      " - time: 1.5142724514007568 - sq_loss: 3.471551099210046e-05 - tot_loss: 0.7683396134252689 - acc: 0.8692872687704026 - val_acc: 0.8106549032914828\n",
      "Repeatition 1 Epoch 88 / 500 \n",
      " - time: 1.536081075668335 - sq_loss: 3.2885414839256555e-05 - tot_loss: 0.7385082627877182 - acc: 0.8707834602829162 - val_acc: 0.8113335595520869\n",
      "Repeatition 1 Epoch 89 / 500 \n",
      " - time: 1.5587499141693115 - sq_loss: 3.1184616091195494e-05 - tot_loss: 0.7186717990130091 - acc: 0.8718715995647442 - val_acc: 0.8106549032914828\n",
      "Repeatition 1 Epoch 90 / 500 \n",
      " - time: 1.536372184753418 - sq_loss: 2.958538243547082e-05 - tot_loss: 0.7318461026909517 - acc: 0.8730957562568009 - val_acc: 0.8133695283338989\n",
      "Repeatition 1 Epoch 91 / 500 \n",
      " - time: 1.5369105339050293 - sq_loss: 2.81146294582868e-05 - tot_loss: 0.7164806180765027 - acc: 0.8745919477693145 - val_acc: 0.8150661689854088\n",
      "Repeatition 1 Epoch 92 / 500 \n",
      " - time: 1.478635311126709 - sq_loss: 2.6686282581067644e-05 - tot_loss: 0.6882344922144057 - acc: 0.8754080522306855 - val_acc: 0.8171021377672208\n",
      "Repeatition 1 Epoch 93 / 500 \n",
      " - time: 1.5535588264465332 - sq_loss: 2.5312074285466224e-05 - tot_loss: 0.7017027147157933 - acc: 0.8774483133841132 - val_acc: 0.8181201221581269\n",
      "Repeatition 1 Epoch 94 / 500 \n",
      " - time: 1.516695261001587 - sq_loss: 2.4038197807385586e-05 - tot_loss: 0.674872155984076 - acc: 0.8778563656147987 - val_acc: 0.819138106549033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 95 / 500 \n",
      " - time: 1.5365240573883057 - sq_loss: 2.2852857000543736e-05 - tot_loss: 0.6758381530571569 - acc: 0.8792165397170838 - val_acc: 0.8201560909399389\n",
      "Repeatition 1 Epoch 96 / 500 \n",
      " - time: 1.5289278030395508 - sq_loss: 2.1750716769020073e-05 - tot_loss: 0.6470453441211248 - acc: 0.8804406964091404 - val_acc: 0.821174075330845\n",
      "Repeatition 1 Epoch 97 / 500 \n",
      " - time: 1.50816011428833 - sq_loss: 2.0680938177974895e-05 - tot_loss: 0.6499386846801372 - acc: 0.8819368879216539 - val_acc: 0.823549372242959\n",
      "Repeatition 1 Epoch 98 / 500 \n",
      " - time: 1.5091423988342285 - sq_loss: 1.9696028175530955e-05 - tot_loss: 0.6485999948811241 - acc: 0.8831610446137106 - val_acc: 0.8245673566338649\n",
      "Repeatition 1 Epoch 99 / 500 \n",
      " - time: 1.5410206317901611 - sq_loss: 1.877481372503098e-05 - tot_loss: 0.6157357398565182 - acc: 0.8847932535364527 - val_acc: 0.825246012894469\n",
      "Repeatition 1 Epoch 100 / 500 \n",
      " - time: 1.562300205230713 - sq_loss: 1.7889882656163536e-05 - tot_loss: 0.6198733804305903 - acc: 0.8857453754080522 - val_acc: 0.826942653545979\n",
      "Repeatition 1 Epoch 101 / 500 \n",
      " - time: 1.537822961807251 - sq_loss: 1.7074073184630834e-05 - tot_loss: 0.5884485174348129 - acc: 0.8868335146898803 - val_acc: 0.828978622327791\n",
      "Repeatition 1 Epoch 102 / 500 \n",
      " - time: 1.527496337890625 - sq_loss: 1.6291949577862397e-05 - tot_loss: 0.5639564426264769 - acc: 0.8876496191512514 - val_acc: 0.829657278588395\n",
      "Repeatition 1 Epoch 103 / 500 \n",
      " - time: 1.5522279739379883 - sq_loss: 1.5523417459917255e-05 - tot_loss: 0.557934575579111 - acc: 0.888873775843308 - val_acc: 0.831014591109603\n",
      "Repeatition 1 Epoch 104 / 500 \n",
      " - time: 1.5239815711975098 - sq_loss: 1.483748565078713e-05 - tot_loss: 0.5687509781087101 - acc: 0.890233949945593 - val_acc: 0.833729216152019\n",
      "Repeatition 1 Epoch 105 / 500 \n",
      " - time: 1.5437169075012207 - sq_loss: 1.4171167094900738e-05 - tot_loss: 0.5669415981560633 - acc: 0.8911860718171926 - val_acc: 0.833729216152019\n",
      "Repeatition 1 Epoch 106 / 500 \n",
      " - time: 1.5497395992279053 - sq_loss: 1.3535781363316346e-05 - tot_loss: 0.5737647944143873 - acc: 0.8922742110990207 - val_acc: 0.835086528673227\n",
      "Repeatition 1 Epoch 107 / 500 \n",
      " - time: 1.5331499576568604 - sq_loss: 1.2946806236868724e-05 - tot_loss: 0.5332736773636952 - acc: 0.8925462459194777 - val_acc: 0.836104513064133\n",
      "Repeatition 1 Epoch 108 / 500 \n",
      " - time: 1.5362699031829834 - sq_loss: 1.2404607332427986e-05 - tot_loss: 0.5221816108301027 - acc: 0.8939064200217628 - val_acc: 0.836443841194435\n",
      "Repeatition 1 Epoch 109 / 500 \n",
      " - time: 1.5154554843902588 - sq_loss: 1.1880348210979719e-05 - tot_loss: 0.5147524145235138 - acc: 0.8952665941240479 - val_acc: 0.838140481845945\n",
      "Repeatition 1 Epoch 110 / 500 \n",
      " - time: 1.5103626251220703 - sq_loss: 1.1389215615054127e-05 - tot_loss: 0.49593986790137023 - acc: 0.8958106637649619 - val_acc: 0.8391584662368511\n",
      "Repeatition 1 Epoch 111 / 500 \n",
      " - time: 1.517301321029663 - sq_loss: 1.0915154234680813e-05 - tot_loss: 0.5186322968853574 - acc: 0.8967627856365615 - val_acc: 0.8411944350186631\n",
      "Repeatition 1 Epoch 112 / 500 \n",
      " - time: 1.5196897983551025 - sq_loss: 1.0473876500327606e-05 - tot_loss: 0.5360889132688271 - acc: 0.8978509249183896 - val_acc: 0.8428910756701731\n",
      "Repeatition 1 Epoch 113 / 500 \n",
      " - time: 1.5472261905670166 - sq_loss: 1.0042863323178608e-05 - tot_loss: 0.4861567372537934 - acc: 0.8986670293797606 - val_acc: 0.8445877163216831\n",
      "Repeatition 1 Epoch 114 / 500 \n",
      " - time: 1.52296781539917 - sq_loss: 9.634532034397125e-06 - tot_loss: 0.5148387661988068 - acc: 0.8996191512513602 - val_acc: 0.8449270444519851\n",
      "Repeatition 1 Epoch 115 / 500 \n",
      " - time: 1.513411283493042 - sq_loss: 9.265893822885118e-06 - tot_loss: 0.46522243305338407 - acc: 0.9000272034820457 - val_acc: 0.845945028842891\n",
      "Repeatition 1 Epoch 116 / 500 \n",
      " - time: 1.5501859188079834 - sq_loss: 8.920969776227139e-06 - tot_loss: 0.47328232185179786 - acc: 0.9007072905331882 - val_acc: 0.8456057007125891\n",
      "Repeatition 1 Epoch 117 / 500 \n",
      " - time: 1.560647964477539 - sq_loss: 8.5752972154296e-06 - tot_loss: 0.48865172954111813 - acc: 0.9008433079434167 - val_acc: 0.846284356973193\n",
      "Repeatition 1 Epoch 118 / 500 \n",
      " - time: 1.5177299976348877 - sq_loss: 8.256942237494513e-06 - tot_loss: 0.4819222556333784 - acc: 0.9013873775843307 - val_acc: 0.8476416694944011\n",
      "Repeatition 1 Epoch 119 / 500 \n",
      " - time: 1.5029680728912354 - sq_loss: 7.949724022182636e-06 - tot_loss: 0.45475097677945087 - acc: 0.9026115342763874 - val_acc: 0.8493383101459111\n",
      "Repeatition 1 Epoch 120 / 500 \n",
      " - time: 1.5444283485412598 - sq_loss: 7.668737453059293e-06 - tot_loss: 0.46287707182017357 - acc: 0.9027475516866159 - val_acc: 0.8506956226671191\n",
      "Repeatition 1 Epoch 121 / 500 \n",
      " - time: 1.5410358905792236 - sq_loss: 7.387530331470771e-06 - tot_loss: 0.4605382825468496 - acc: 0.903563656147987 - val_acc: 0.8517136070580251\n",
      "Repeatition 1 Epoch 122 / 500 \n",
      " - time: 1.5384836196899414 - sq_loss: 7.123383511498105e-06 - tot_loss: 0.4526988804533971 - acc: 0.904651795429815 - val_acc: 0.8523922633186292\n",
      "Repeatition 1 Epoch 123 / 500 \n",
      " - time: 1.542612075805664 - sq_loss: 6.8791209741903e-06 - tot_loss: 0.4428779642265681 - acc: 0.9050598476605005 - val_acc: 0.8530709195792331\n",
      "Repeatition 1 Epoch 124 / 500 \n",
      " - time: 1.527144193649292 - sq_loss: 6.643317647103686e-06 - tot_loss: 0.4261791600699212 - acc: 0.9061479869423286 - val_acc: 0.8544282321004412\n",
      "Repeatition 1 Epoch 125 / 500 \n",
      " - time: 1.5506346225738525 - sq_loss: 6.427938842534786e-06 - tot_loss: 0.44478823397224687 - acc: 0.9062840043525572 - val_acc: 0.8554462164913471\n",
      "Repeatition 1 Epoch 126 / 500 \n",
      " - time: 1.548459529876709 - sq_loss: 6.229683094716165e-06 - tot_loss: 0.4593018232992847 - acc: 0.9073721436343852 - val_acc: 0.8561248727519511\n",
      "Repeatition 1 Epoch 127 / 500 \n",
      " - time: 1.5455434322357178 - sq_loss: 6.040131211193511e-06 - tot_loss: 0.43995644040421666 - acc: 0.9084602829162133 - val_acc: 0.8578215134034611\n",
      "Repeatition 1 Epoch 128 / 500 \n",
      " - time: 1.5459294319152832 - sq_loss: 5.855139079358196e-06 - tot_loss: 0.42033227239295456 - acc: 0.9090043525571273 - val_acc: 0.8588394977943672\n",
      "Repeatition 1 Epoch 129 / 500 \n",
      " - time: 1.5370078086853027 - sq_loss: 5.669343863701215e-06 - tot_loss: 0.42978505890641827 - acc: 0.9096844396082698 - val_acc: 0.8595181540549711\n",
      "Repeatition 1 Epoch 130 / 500 \n",
      " - time: 1.514132022857666 - sq_loss: 5.502096882992191e-06 - tot_loss: 0.41568952205693677 - acc: 0.9111806311207835 - val_acc: 0.8605361384458772\n",
      "Repeatition 1 Epoch 131 / 500 \n",
      " - time: 1.5057790279388428 - sq_loss: 5.346576472220477e-06 - tot_loss: 0.39628542702644154 - acc: 0.911588683351469 - val_acc: 0.8625721072276892\n",
      "Repeatition 1 Epoch 132 / 500 \n",
      " - time: 1.5439412593841553 - sq_loss: 5.206932655710261e-06 - tot_loss: 0.3982502939148844 - acc: 0.9121327529923831 - val_acc: 0.8618934509670851\n",
      "Repeatition 1 Epoch 133 / 500 \n",
      " - time: 1.540952205657959 - sq_loss: 5.0695534810074605e-06 - tot_loss: 0.41016357629396794 - acc: 0.9134929270946681 - val_acc: 0.8632507634882932\n",
      "Repeatition 1 Epoch 134 / 500 \n",
      " - time: 1.5516293048858643 - sq_loss: 4.940250619256403e-06 - tot_loss: 0.3897318916157815 - acc: 0.9140369967355821 - val_acc: 0.8642687478791992\n",
      "Repeatition 1 Epoch 135 / 500 \n",
      " - time: 1.5614242553710938 - sq_loss: 4.809352958545787e-06 - tot_loss: 0.38955835042281706 - acc: 0.9148531011969532 - val_acc: 0.8649474041398032\n",
      "Repeatition 1 Epoch 136 / 500 \n",
      " - time: 1.5303571224212646 - sq_loss: 4.6808213483018335e-06 - tot_loss: 0.39830495287483814 - acc: 0.9155331882480957 - val_acc: 0.8656260604004072\n",
      "Repeatition 1 Epoch 137 / 500 \n",
      " - time: 1.5257861614227295 - sq_loss: 4.5685760596825276e-06 - tot_loss: 0.3823989008753301 - acc: 0.9159412404787813 - val_acc: 0.8666440447913132\n",
      "Repeatition 1 Epoch 138 / 500 \n",
      " - time: 1.5002918243408203 - sq_loss: 4.458544026419986e-06 - tot_loss: 0.39063223846888206 - acc: 0.9164853101196954 - val_acc: 0.8680013573125213\n",
      "Repeatition 1 Epoch 139 / 500 \n",
      " - time: 1.5284409523010254 - sq_loss: 4.351442839833908e-06 - tot_loss: 0.397060435478096 - acc: 0.9174374319912949 - val_acc: 0.8696979979640312\n",
      "Repeatition 1 Epoch 140 / 500 \n",
      " - time: 1.5353350639343262 - sq_loss: 4.250127858540509e-06 - tot_loss: 0.37535304652264756 - acc: 0.9177094668117519 - val_acc: 0.8700373260943333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 141 / 500 \n",
      " - time: 1.5575246810913086 - sq_loss: 4.149294454691699e-06 - tot_loss: 0.3900971885162505 - acc: 0.9183895538628944 - val_acc: 0.8703766542246352\n",
      "Repeatition 1 Epoch 142 / 500 \n",
      " - time: 1.5306744575500488 - sq_loss: 4.062597326992545e-06 - tot_loss: 0.3949882592582412 - acc: 0.919069640914037 - val_acc: 0.8717339667458432\n",
      "Repeatition 1 Epoch 143 / 500 \n",
      " - time: 1.535310983657837 - sq_loss: 3.981378995376872e-06 - tot_loss: 0.358503751802175 - acc: 0.9194776931447225 - val_acc: 0.8720732948761453\n",
      "Repeatition 1 Epoch 144 / 500 \n",
      " - time: 1.5357539653778076 - sq_loss: 3.899241619365057e-06 - tot_loss: 0.36373997633344857 - acc: 0.9200217627856365 - val_acc: 0.8724126230064473\n",
      "Repeatition 1 Epoch 145 / 500 \n",
      " - time: 1.5430245399475098 - sq_loss: 3.816328899119981e-06 - tot_loss: 0.38949571572906905 - acc: 0.9207018498367792 - val_acc: 0.8727519511367492\n",
      "Repeatition 1 Epoch 146 / 500 \n",
      " - time: 1.5340983867645264 - sq_loss: 3.744715058928705e-06 - tot_loss: 0.3639676301714587 - acc: 0.9209738846572362 - val_acc: 0.8727519511367492\n",
      "Repeatition 1 Epoch 147 / 500 \n",
      " - time: 1.5204224586486816 - sq_loss: 3.683071099658264e-06 - tot_loss: 0.3476917608822703 - acc: 0.9217899891186072 - val_acc: 0.8730912792670512\n",
      "Repeatition 1 Epoch 148 / 500 \n",
      " - time: 1.52644681930542 - sq_loss: 3.6222727430867963e-06 - tot_loss: 0.33869942067057934 - acc: 0.9223340587595212 - val_acc: 0.8751272480488632\n",
      "Repeatition 1 Epoch 149 / 500 \n",
      " - time: 1.4979784488677979 - sq_loss: 3.556267301974003e-06 - tot_loss: 0.35366011957221133 - acc: 0.9227421109902068 - val_acc: 0.8764845605700713\n",
      "Repeatition 1 Epoch 150 / 500 \n",
      " - time: 1.5333504676818848 - sq_loss: 3.4890831557277124e-06 - tot_loss: 0.3334449346971269 - acc: 0.9230141458106638 - val_acc: 0.8775025449609772\n",
      "Repeatition 1 Epoch 151 / 500 \n",
      " - time: 1.5431005954742432 - sq_loss: 3.4290469557163306e-06 - tot_loss: 0.37088007378511634 - acc: 0.9234221980413493 - val_acc: 0.8781812012215813\n",
      "Repeatition 1 Epoch 152 / 500 \n",
      " - time: 1.5293951034545898 - sq_loss: 3.37312826559355e-06 - tot_loss: 0.345983083022098 - acc: 0.9236942328618063 - val_acc: 0.8781812012215813\n",
      "Repeatition 1 Epoch 153 / 500 \n",
      " - time: 1.504875659942627 - sq_loss: 3.319054485473316e-06 - tot_loss: 0.3457000834690831 - acc: 0.9241022850924918 - val_acc: 0.8785205293518833\n",
      "Repeatition 1 Epoch 154 / 500 \n",
      " - time: 1.4932167530059814 - sq_loss: 3.2688733426766703e-06 - tot_loss: 0.34911799336188665 - acc: 0.9249183895538629 - val_acc: 0.8788598574821853\n",
      "Repeatition 1 Epoch 155 / 500 \n",
      " - time: 1.5727791786193848 - sq_loss: 3.2239483971352456e-06 - tot_loss: 0.3755409524321536 - acc: 0.9254624591947769 - val_acc: 0.8795385137427892\n",
      "Repeatition 1 Epoch 156 / 500 \n",
      " - time: 1.5162394046783447 - sq_loss: 3.1817980925552547e-06 - tot_loss: 0.35748923484894135 - acc: 0.926006528835691 - val_acc: 0.8805564981336953\n",
      "Repeatition 1 Epoch 157 / 500 \n",
      " - time: 1.514352560043335 - sq_loss: 3.139697128062835e-06 - tot_loss: 0.32491163837357107 - acc: 0.926278563656148 - val_acc: 0.8812351543942993\n",
      "Repeatition 1 Epoch 158 / 500 \n",
      " - time: 1.5196900367736816 - sq_loss: 3.0986361707618926e-06 - tot_loss: 0.3197390339927111 - acc: 0.926550598476605 - val_acc: 0.8815744825246012\n",
      "Repeatition 1 Epoch 159 / 500 \n",
      " - time: 1.5111496448516846 - sq_loss: 3.058290303670219e-06 - tot_loss: 0.33891153525334516 - acc: 0.9269586507072906 - val_acc: 0.8822531387852053\n",
      "Repeatition 1 Epoch 160 / 500 \n",
      " - time: 1.5172369480133057 - sq_loss: 3.018277084265719e-06 - tot_loss: 0.3662296326117698 - acc: 0.9275027203482046 - val_acc: 0.8829317950458093\n",
      "Repeatition 1 Epoch 161 / 500 \n",
      " - time: 1.545107126235962 - sq_loss: 2.981590569106629e-06 - tot_loss: 0.3253257675676835 - acc: 0.9279107725788901 - val_acc: 0.8832711231761113\n",
      "Repeatition 1 Epoch 162 / 500 \n",
      " - time: 1.5599040985107422 - sq_loss: 2.938261786766816e-06 - tot_loss: 0.3295890229564833 - acc: 0.9287268770402611 - val_acc: 0.8842891075670173\n",
      "Repeatition 1 Epoch 163 / 500 \n",
      " - time: 1.5369799137115479 - sq_loss: 2.9002865176153136e-06 - tot_loss: 0.3326193653415359 - acc: 0.9289989118607181 - val_acc: 0.8849677638276213\n",
      "Repeatition 1 Epoch 164 / 500 \n",
      " - time: 1.5415942668914795 - sq_loss: 2.87138027488254e-06 - tot_loss: 0.32315320203333187 - acc: 0.9296789989118607 - val_acc: 0.8856464200882254\n",
      "Repeatition 1 Epoch 165 / 500 \n",
      " - time: 1.5465834140777588 - sq_loss: 2.843001539076795e-06 - tot_loss: 0.3288667000255856 - acc: 0.9298150163220892 - val_acc: 0.8859857482185273\n",
      "Repeatition 1 Epoch 166 / 500 \n",
      " - time: 1.5554814338684082 - sq_loss: 2.8101833322580205e-06 - tot_loss: 0.3153788448558714 - acc: 0.9303590859630033 - val_acc: 0.8870037326094333\n",
      "Repeatition 1 Epoch 167 / 500 \n",
      " - time: 1.5673573017120361 - sq_loss: 2.7805458557850216e-06 - tot_loss: 0.3173196962798812 - acc: 0.9307671381936888 - val_acc: 0.8866644044791313\n",
      "Repeatition 1 Epoch 168 / 500 \n",
      " - time: 1.5646586418151855 - sq_loss: 2.7511966891324846e-06 - tot_loss: 0.32087419348351176 - acc: 0.9310391730141458 - val_acc: 0.8887003732609433\n",
      "Repeatition 1 Epoch 169 / 500 \n",
      " - time: 1.5603632926940918 - sq_loss: 2.7247390335105592e-06 - tot_loss: 0.2998681874451137 - acc: 0.9311751904243744 - val_acc: 0.8897183576518494\n",
      "Repeatition 1 Epoch 170 / 500 \n",
      " - time: 1.5582449436187744 - sq_loss: 2.697596073630848e-06 - tot_loss: 0.3088599899766926 - acc: 0.9314472252448314 - val_acc: 0.8900576857821514\n",
      "Repeatition 1 Epoch 171 / 500 \n",
      " - time: 1.5381875038146973 - sq_loss: 2.67228369921213e-06 - tot_loss: 0.33891716833745633 - acc: 0.9322633297062024 - val_acc: 0.8920936545639634\n",
      "Repeatition 1 Epoch 172 / 500 \n",
      " - time: 1.5760793685913086 - sq_loss: 2.6488519324630033e-06 - tot_loss: 0.33132075280758144 - acc: 0.9329434167573449 - val_acc: 0.8924329826942654\n",
      "Repeatition 1 Epoch 173 / 500 \n",
      " - time: 1.5577514171600342 - sq_loss: 2.629406935739098e-06 - tot_loss: 0.3375865210471005 - acc: 0.933487486398259 - val_acc: 0.8927723108245673\n",
      "Repeatition 1 Epoch 174 / 500 \n",
      " - time: 1.5446703433990479 - sq_loss: 2.606334646770847e-06 - tot_loss: 0.3240975151011831 - acc: 0.933759521218716 - val_acc: 0.8927723108245673\n",
      "Repeatition 1 Epoch 175 / 500 \n",
      " - time: 1.584975242614746 - sq_loss: 2.587898279671208e-06 - tot_loss: 0.2917108722803441 - acc: 0.9338955386289445 - val_acc: 0.8941296233457754\n",
      "Repeatition 1 Epoch 176 / 500 \n",
      " - time: 1.5577270984649658 - sq_loss: 2.5682909381430363e-06 - tot_loss: 0.2934629011961398 - acc: 0.9341675734494015 - val_acc: 0.8948082796063793\n",
      "Repeatition 1 Epoch 177 / 500 \n",
      " - time: 1.5603771209716797 - sq_loss: 2.5484987418167293e-06 - tot_loss: 0.29118669743251147 - acc: 0.9347116430903155 - val_acc: 0.8954869358669834\n",
      "Repeatition 1 Epoch 178 / 500 \n",
      " - time: 1.5539634227752686 - sq_loss: 2.5292565624113195e-06 - tot_loss: 0.3136010276417913 - acc: 0.9352557127312296 - val_acc: 0.8958262639972854\n",
      "Repeatition 1 Epoch 179 / 500 \n",
      " - time: 1.5763356685638428 - sq_loss: 2.5101251139858505e-06 - tot_loss: 0.30226188735453263 - acc: 0.9356637649619152 - val_acc: 0.8961655921275874\n",
      "Repeatition 1 Epoch 180 / 500 \n",
      " - time: 1.5351498126983643 - sq_loss: 2.4915352696552873e-06 - tot_loss: 0.28384909105464473 - acc: 0.9360718171926007 - val_acc: 0.8971835765184933\n",
      "Repeatition 1 Epoch 181 / 500 \n",
      " - time: 1.5332491397857666 - sq_loss: 2.468113052600529e-06 - tot_loss: 0.2833116882223443 - acc: 0.9364798694232862 - val_acc: 0.8975229046487954\n",
      "Repeatition 1 Epoch 182 / 500 \n",
      " - time: 1.5464937686920166 - sq_loss: 2.4504711291228887e-06 - tot_loss: 0.325140950493342 - acc: 0.9366158868335147 - val_acc: 0.8978622327790974\n",
      "Repeatition 1 Epoch 183 / 500 \n",
      " - time: 1.5599734783172607 - sq_loss: 2.4323651359736687e-06 - tot_loss: 0.3117505172170425 - acc: 0.9371599564744287 - val_acc: 0.8978622327790974\n",
      "Repeatition 1 Epoch 184 / 500 \n",
      " - time: 1.5507848262786865 - sq_loss: 2.420906184852356e-06 - tot_loss: 0.3230950341952692 - acc: 0.9377040261153428 - val_acc: 0.8992195453003053\n",
      "Repeatition 1 Epoch 185 / 500 \n",
      " - time: 1.5560708045959473 - sq_loss: 2.4069590836006682e-06 - tot_loss: 0.3064637886489656 - acc: 0.9381120783460283 - val_acc: 0.9002375296912114\n",
      "Repeatition 1 Epoch 186 / 500 \n",
      " - time: 1.5600974559783936 - sq_loss: 2.390414465480717e-06 - tot_loss: 0.2925957625814384 - acc: 0.9383841131664853 - val_acc: 0.9009161859518154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 187 / 500 \n",
      " - time: 1.5631699562072754 - sq_loss: 2.375923486397369e-06 - tot_loss: 0.283376238364653 - acc: 0.9389281828073993 - val_acc: 0.9012555140821175\n",
      "Repeatition 1 Epoch 188 / 500 \n",
      " - time: 1.5498361587524414 - sq_loss: 2.3586421775689814e-06 - tot_loss: 0.3015429371363467 - acc: 0.9396082698585418 - val_acc: 0.9032914828639295\n",
      "Repeatition 1 Epoch 189 / 500 \n",
      " - time: 1.5698273181915283 - sq_loss: 2.3418024284183048e-06 - tot_loss: 0.32238074361115565 - acc: 0.9397442872687704 - val_acc: 0.9039701391245334\n",
      "Repeatition 1 Epoch 190 / 500 \n",
      " - time: 1.567765712738037 - sq_loss: 2.3268962650035974e-06 - tot_loss: 0.3111160112984592 - acc: 0.9398803046789989 - val_acc: 0.9039701391245334\n",
      "Repeatition 1 Epoch 191 / 500 \n",
      " - time: 1.5888638496398926 - sq_loss: 2.31744843404158e-06 - tot_loss: 0.30473634475181655 - acc: 0.9405603917301415 - val_acc: 0.9039701391245334\n",
      "Repeatition 1 Epoch 192 / 500 \n",
      " - time: 1.5811541080474854 - sq_loss: 2.3072984731697943e-06 - tot_loss: 0.29873439521836787 - acc: 0.941240478781284 - val_acc: 0.9043094672548354\n",
      "Repeatition 1 Epoch 193 / 500 \n",
      " - time: 1.5640645027160645 - sq_loss: 2.293385477969423e-06 - tot_loss: 0.2943073949850987 - acc: 0.9421926006528836 - val_acc: 0.9043094672548354\n",
      "Repeatition 1 Epoch 194 / 500 \n",
      " - time: 1.5611560344696045 - sq_loss: 2.282725063196267e-06 - tot_loss: 0.2814429670688874 - acc: 0.9426006528835691 - val_acc: 0.9043094672548354\n",
      "Repeatition 1 Epoch 195 / 500 \n",
      " - time: 1.564326286315918 - sq_loss: 2.2713591079082107e-06 - tot_loss: 0.2678286256738094 - acc: 0.9430087051142546 - val_acc: 0.9046487953851374\n",
      "Repeatition 1 Epoch 196 / 500 \n",
      " - time: 1.574296474456787 - sq_loss: 2.256892457808135e-06 - tot_loss: 0.2983720639168599 - acc: 0.9431447225244831 - val_acc: 0.9046487953851374\n",
      "Repeatition 1 Epoch 197 / 500 \n",
      " - time: 1.5635356903076172 - sq_loss: 2.245729319838574e-06 - tot_loss: 0.30376160355809745 - acc: 0.9434167573449401 - val_acc: 0.9049881235154394\n",
      "Repeatition 1 Epoch 198 / 500 \n",
      " - time: 1.5502753257751465 - sq_loss: 2.233573923149379e-06 - tot_loss: 0.299929407897654 - acc: 0.9440968443960827 - val_acc: 0.9056667797760435\n",
      "Repeatition 1 Epoch 199 / 500 \n",
      " - time: 1.538738489151001 - sq_loss: 2.220932401542086e-06 - tot_loss: 0.26997056009247977 - acc: 0.9442328618063112 - val_acc: 0.9083814048184594\n",
      "Repeatition 1 Epoch 200 / 500 \n",
      " - time: 1.504230260848999 - sq_loss: 2.2097447072155774e-06 - tot_loss: 0.2754881967071796 - acc: 0.9443688792165397 - val_acc: 0.9087207329487614\n",
      "Repeatition 1 Epoch 201 / 500 \n",
      " - time: 1.5367894172668457 - sq_loss: 2.2004596758051775e-06 - tot_loss: 0.281516799158382 - acc: 0.9442328618063112 - val_acc: 0.9080420766881574\n",
      "Repeatition 1 Epoch 202 / 500 \n",
      " - time: 1.5590786933898926 - sq_loss: 2.190660779888276e-06 - tot_loss: 0.24668392416181284 - acc: 0.9450489662676823 - val_acc: 0.9093993892093655\n",
      "Repeatition 1 Epoch 203 / 500 \n",
      " - time: 1.5497338771820068 - sq_loss: 2.179925331802224e-06 - tot_loss: 0.31401007218794064 - acc: 0.9451849836779108 - val_acc: 0.9093993892093655\n",
      "Repeatition 1 Epoch 204 / 500 \n",
      " - time: 1.5294642448425293 - sq_loss: 2.166415924875764e-06 - tot_loss: 0.2970588093685045 - acc: 0.9458650707290533 - val_acc: 0.9100780454699695\n",
      "Repeatition 1 Epoch 205 / 500 \n",
      " - time: 1.5472204685211182 - sq_loss: 2.1542766717175255e-06 - tot_loss: 0.27028362592497857 - acc: 0.9464091403699674 - val_acc: 0.9097387173396675\n",
      "Repeatition 1 Epoch 206 / 500 \n",
      " - time: 1.5471751689910889 - sq_loss: 2.145750613635755e-06 - tot_loss: 0.27490997098094816 - acc: 0.9464091403699674 - val_acc: 0.9097387173396675\n",
      "Repeatition 1 Epoch 207 / 500 \n",
      " - time: 1.549644947052002 - sq_loss: 2.136986040568445e-06 - tot_loss: 0.2875905796756548 - acc: 0.9468171926006529 - val_acc: 0.9107567017305734\n",
      "Repeatition 1 Epoch 208 / 500 \n",
      " - time: 1.5475530624389648 - sq_loss: 2.1266146177367773e-06 - tot_loss: 0.2614739188747581 - acc: 0.9472252448313384 - val_acc: 0.9117746861214795\n",
      "Repeatition 1 Epoch 209 / 500 \n",
      " - time: 1.5362968444824219 - sq_loss: 2.1179785107960925e-06 - tot_loss: 0.28142129900503576 - acc: 0.9474972796517954 - val_acc: 0.9114353579911775\n",
      "Repeatition 1 Epoch 210 / 500 \n",
      " - time: 1.5322558879852295 - sq_loss: 2.1106766325829085e-06 - tot_loss: 0.282291410948174 - acc: 0.9474972796517954 - val_acc: 0.9117746861214795\n",
      "Repeatition 1 Epoch 211 / 500 \n",
      " - time: 1.5288443565368652 - sq_loss: 2.104673285430181e-06 - tot_loss: 0.29075135324025503 - acc: 0.9476332970620239 - val_acc: 0.9121140142517815\n",
      "Repeatition 1 Epoch 212 / 500 \n",
      " - time: 1.5006213188171387 - sq_loss: 2.094534693242167e-06 - tot_loss: 0.2661858819267593 - acc: 0.9476332970620239 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 213 / 500 \n",
      " - time: 1.5442562103271484 - sq_loss: 2.086085260089021e-06 - tot_loss: 0.31183533379230255 - acc: 0.9480413492927094 - val_acc: 0.9121140142517815\n",
      "Repeatition 1 Epoch 214 / 500 \n",
      " - time: 1.520117998123169 - sq_loss: 2.081151706079254e-06 - tot_loss: 0.2721799455641918 - acc: 0.9483133841131665 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 215 / 500 \n",
      " - time: 1.543224573135376 - sq_loss: 2.0721845430671237e-06 - tot_loss: 0.2768203762311767 - acc: 0.948449401523395 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 216 / 500 \n",
      " - time: 1.5275535583496094 - sq_loss: 2.064503178189625e-06 - tot_loss: 0.29141547583021143 - acc: 0.948721436343852 - val_acc: 0.9124533423820834\n",
      "Repeatition 1 Epoch 217 / 500 \n",
      " - time: 1.5576236248016357 - sq_loss: 2.0550162389554316e-06 - tot_loss: 0.2978026811751615 - acc: 0.948993471164309 - val_acc: 0.9127926705123854\n",
      "Repeatition 1 Epoch 218 / 500 \n",
      " - time: 1.5196247100830078 - sq_loss: 2.046102281383355e-06 - tot_loss: 0.25830163695624897 - acc: 0.9494015233949945 - val_acc: 0.9131319986426875\n",
      "Repeatition 1 Epoch 219 / 500 \n",
      " - time: 1.5487432479858398 - sq_loss: 2.038089860434411e-06 - tot_loss: 0.25905855353547835 - acc: 0.9496735582154516 - val_acc: 0.9131319986426875\n",
      "Repeatition 1 Epoch 220 / 500 \n",
      " - time: 1.5310287475585938 - sq_loss: 2.0280299395381007e-06 - tot_loss: 0.2669510333321288 - acc: 0.9503536452665942 - val_acc: 0.9138106549032915\n",
      "Repeatition 1 Epoch 221 / 500 \n",
      " - time: 1.5156748294830322 - sq_loss: 2.022345142904669e-06 - tot_loss: 0.255373944530648 - acc: 0.9504896626768227 - val_acc: 0.9141499830335935\n",
      "Repeatition 1 Epoch 222 / 500 \n",
      " - time: 1.526876449584961 - sq_loss: 2.0156376194790937e-06 - tot_loss: 0.24766327495819063 - acc: 0.9511697497279652 - val_acc: 0.9141499830335935\n",
      "Repeatition 1 Epoch 223 / 500 \n",
      " - time: 1.5053110122680664 - sq_loss: 2.0092470549570862e-06 - tot_loss: 0.2721456615881799 - acc: 0.9513057671381937 - val_acc: 0.9144893111638955\n",
      "Repeatition 1 Epoch 224 / 500 \n",
      " - time: 1.5403213500976562 - sq_loss: 2.001711663979222e-06 - tot_loss: 0.264604161804451 - acc: 0.9515778019586507 - val_acc: 0.9155072955548015\n",
      "Repeatition 1 Epoch 225 / 500 \n",
      " - time: 1.5378246307373047 - sq_loss: 1.995051434278139e-06 - tot_loss: 0.26712511031061403 - acc: 0.9518498367791077 - val_acc: 0.9155072955548015\n",
      "Repeatition 1 Epoch 226 / 500 \n",
      " - time: 1.5028350353240967 - sq_loss: 1.9903820884792367e-06 - tot_loss: 0.26921570523652427 - acc: 0.9518498367791077 - val_acc: 0.9158466236851035\n",
      "Repeatition 1 Epoch 227 / 500 \n",
      " - time: 1.5162465572357178 - sq_loss: 1.9854912807204528e-06 - tot_loss: 0.2579711879860973 - acc: 0.9518498367791077 - val_acc: 0.9155072955548015\n",
      "Repeatition 1 Epoch 228 / 500 \n",
      " - time: 1.5463061332702637 - sq_loss: 1.9767817320825998e-06 - tot_loss: 0.26145844359647086 - acc: 0.9518498367791077 - val_acc: 0.9155072955548015\n",
      "Repeatition 1 Epoch 229 / 500 \n",
      " - time: 1.5238873958587646 - sq_loss: 1.9710885226231767e-06 - tot_loss: 0.31665077146481835 - acc: 0.9521218715995647 - val_acc: 0.9161859518154055\n",
      "Repeatition 1 Epoch 230 / 500 \n",
      " - time: 1.5553696155548096 - sq_loss: 1.9646497548819752e-06 - tot_loss: 0.26644420809155456 - acc: 0.9521218715995647 - val_acc: 0.9158466236851035\n",
      "Repeatition 1 Epoch 231 / 500 \n",
      " - time: 1.5399062633514404 - sq_loss: 1.957800805030274e-06 - tot_loss: 0.24444968485094698 - acc: 0.9521218715995647 - val_acc: 0.9161859518154055\n",
      "Repeatition 1 Epoch 232 / 500 \n",
      " - time: 1.5414295196533203 - sq_loss: 1.9489098121994175e-06 - tot_loss: 0.2726623657071272 - acc: 0.9521218715995647 - val_acc: 0.9168646080760094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 233 / 500 \n",
      " - time: 1.5455470085144043 - sq_loss: 1.941805066962843e-06 - tot_loss: 0.24223369094374192 - acc: 0.9526659412404788 - val_acc: 0.9172039362063115\n",
      "Repeatition 1 Epoch 234 / 500 \n",
      " - time: 1.561743974685669 - sq_loss: 1.9345147848071065e-06 - tot_loss: 0.23783104036778724 - acc: 0.9529379760609358 - val_acc: 0.9172039362063115\n",
      "Repeatition 1 Epoch 235 / 500 \n",
      " - time: 1.5077307224273682 - sq_loss: 1.9280810192867648e-06 - tot_loss: 0.2797846101943833 - acc: 0.9532100108813928 - val_acc: 0.9175432643366135\n",
      "Repeatition 1 Epoch 236 / 500 \n",
      " - time: 1.5525171756744385 - sq_loss: 1.9220738067815546e-06 - tot_loss: 0.27638131618839523 - acc: 0.9537540805223068 - val_acc: 0.9192399049881235\n",
      "Repeatition 1 Epoch 237 / 500 \n",
      " - time: 1.559889554977417 - sq_loss: 1.915822167575243e-06 - tot_loss: 0.2620695076456556 - acc: 0.9533460282916213 - val_acc: 0.9192399049881235\n",
      "Repeatition 1 Epoch 238 / 500 \n",
      " - time: 1.5543115139007568 - sq_loss: 1.9098963548458414e-06 - tot_loss: 0.2808357662120784 - acc: 0.9536180631120783 - val_acc: 0.9185612487275195\n",
      "Repeatition 1 Epoch 239 / 500 \n",
      " - time: 1.549755334854126 - sq_loss: 1.9069926793235936e-06 - tot_loss: 0.263545649943179 - acc: 0.9544341675734495 - val_acc: 0.9185612487275195\n",
      "Repeatition 1 Epoch 240 / 500 \n",
      " - time: 1.5703060626983643 - sq_loss: 1.9007858327313443e-06 - tot_loss: 0.3012359250699461 - acc: 0.9549782372143635 - val_acc: 0.9185612487275195\n",
      "Repeatition 1 Epoch 241 / 500 \n",
      " - time: 1.5610508918762207 - sq_loss: 1.8950698859043769e-06 - tot_loss: 0.24969697096245191 - acc: 0.955930359085963 - val_acc: 0.9189005768578216\n",
      "Repeatition 1 Epoch 242 / 500 \n",
      " - time: 1.5581190586090088 - sq_loss: 1.8898640519182663e-06 - tot_loss: 0.28130500283658577 - acc: 0.956474428726877 - val_acc: 0.9189005768578216\n",
      "Repeatition 1 Epoch 243 / 500 \n",
      " - time: 1.551865577697754 - sq_loss: 1.8835769424185855e-06 - tot_loss: 0.24697389164260564 - acc: 0.9568824809575626 - val_acc: 0.9195792331184255\n",
      "Repeatition 1 Epoch 244 / 500 \n",
      " - time: 1.5885086059570312 - sq_loss: 1.8777127479552291e-06 - tot_loss: 0.24503828799179317 - acc: 0.9572905331882481 - val_acc: 0.9199185612487275\n",
      "Repeatition 1 Epoch 245 / 500 \n",
      " - time: 1.558903455734253 - sq_loss: 1.8682773088585236e-06 - tot_loss: 0.2752377790036782 - acc: 0.9574265505984766 - val_acc: 0.9199185612487275\n",
      "Repeatition 1 Epoch 246 / 500 \n",
      " - time: 1.5375146865844727 - sq_loss: 1.8641439964994788e-06 - tot_loss: 0.24627168472959227 - acc: 0.9575625680087051 - val_acc: 0.9212758737699356\n",
      "Repeatition 1 Epoch 247 / 500 \n",
      " - time: 1.552626371383667 - sq_loss: 1.8571154214441776e-06 - tot_loss: 0.2453986375994628 - acc: 0.9578346028291621 - val_acc: 0.9212758737699356\n",
      "Repeatition 1 Epoch 248 / 500 \n",
      " - time: 1.5128557682037354 - sq_loss: 1.8507948880142067e-06 - tot_loss: 0.2493223804168032 - acc: 0.9585146898803046 - val_acc: 0.9212758737699356\n",
      "Repeatition 1 Epoch 249 / 500 \n",
      " - time: 1.5705699920654297 - sq_loss: 1.844036887632683e-06 - tot_loss: 0.24988799852699906 - acc: 0.9589227421109902 - val_acc: 0.9216152019002375\n",
      "Repeatition 1 Epoch 250 / 500 \n",
      " - time: 1.543311595916748 - sq_loss: 1.8404263073534821e-06 - tot_loss: 0.24885670691305428 - acc: 0.9590587595212187 - val_acc: 0.9209365456396336\n",
      "Repeatition 1 Epoch 251 / 500 \n",
      " - time: 1.5244696140289307 - sq_loss: 1.8351472590438789e-06 - tot_loss: 0.23768536994189482 - acc: 0.9593307943416758 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 252 / 500 \n",
      " - time: 1.5289490222930908 - sq_loss: 1.8296969983566669e-06 - tot_loss: 0.24044630839758252 - acc: 0.9593307943416758 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 253 / 500 \n",
      " - time: 1.5098440647125244 - sq_loss: 1.824206265155226e-06 - tot_loss: 0.2566271275837133 - acc: 0.9593307943416758 - val_acc: 0.9226331862911435\n",
      "Repeatition 1 Epoch 254 / 500 \n",
      " - time: 1.5132954120635986 - sq_loss: 1.81824225364835e-06 - tot_loss: 0.25489470167723116 - acc: 0.9596028291621328 - val_acc: 0.9222938581608415\n",
      "Repeatition 1 Epoch 255 / 500 \n",
      " - time: 1.5160574913024902 - sq_loss: 1.8137715187549475e-06 - tot_loss: 0.3018184002424533 - acc: 0.9596028291621328 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 256 / 500 \n",
      " - time: 1.5164034366607666 - sq_loss: 1.809502919059014e-06 - tot_loss: 0.24607310399689108 - acc: 0.9598748639825898 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 257 / 500 \n",
      " - time: 1.5282325744628906 - sq_loss: 1.804559019547014e-06 - tot_loss: 0.26835009961456713 - acc: 0.9605549510337323 - val_acc: 0.9219545300305395\n",
      "Repeatition 1 Epoch 258 / 500 \n",
      " - time: 1.5260422229766846 - sq_loss: 1.7974308548218687e-06 - tot_loss: 0.2524507246947225 - acc: 0.9609630032644179 - val_acc: 0.9222938581608415\n",
      "Repeatition 1 Epoch 259 / 500 \n",
      " - time: 1.5519230365753174 - sq_loss: 1.7925302699950407e-06 - tot_loss: 0.249213700886334 - acc: 0.9610990206746464 - val_acc: 0.9222938581608415\n",
      "Repeatition 1 Epoch 260 / 500 \n",
      " - time: 1.5480096340179443 - sq_loss: 1.7866138932731701e-06 - tot_loss: 0.2811414513136432 - acc: 0.9615070729053319 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 261 / 500 \n",
      " - time: 1.510530710220337 - sq_loss: 1.7820563016357482e-06 - tot_loss: 0.2347316184129582 - acc: 0.9616430903155604 - val_acc: 0.9233118425517476\n",
      "Repeatition 1 Epoch 262 / 500 \n",
      " - time: 1.5395479202270508 - sq_loss: 1.7779168501874665e-06 - tot_loss: 0.24766937504490905 - acc: 0.9616430903155604 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 263 / 500 \n",
      " - time: 1.550802230834961 - sq_loss: 1.773796043380571e-06 - tot_loss: 0.2393026713109183 - acc: 0.9623231773667029 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 264 / 500 \n",
      " - time: 1.5587730407714844 - sq_loss: 1.7682364159554709e-06 - tot_loss: 0.28255582325392314 - acc: 0.9623231773667029 - val_acc: 0.9236511706820495\n",
      "Repeatition 1 Epoch 265 / 500 \n",
      " - time: 1.5565824508666992 - sq_loss: 1.7616550849197665e-06 - tot_loss: 0.2772562585857017 - acc: 0.9627312295973884 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 266 / 500 \n",
      " - time: 1.5390491485595703 - sq_loss: 1.7552075632920605e-06 - tot_loss: 0.23401097087932854 - acc: 0.9627312295973884 - val_acc: 0.9239904988123515\n",
      "Repeatition 1 Epoch 267 / 500 \n",
      " - time: 1.5271711349487305 - sq_loss: 1.7518638060209923e-06 - tot_loss: 0.27012287448612415 - acc: 0.9627312295973884 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 268 / 500 \n",
      " - time: 1.5412437915802002 - sq_loss: 1.7461946981711662e-06 - tot_loss: 0.2592186669138892 - acc: 0.9628672470076169 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 269 / 500 \n",
      " - time: 1.5664470195770264 - sq_loss: 1.7435135077903396e-06 - tot_loss: 0.24502139264317346 - acc: 0.9630032644178455 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 270 / 500 \n",
      " - time: 1.5388457775115967 - sq_loss: 1.7397608189639868e-06 - tot_loss: 0.2548632876117658 - acc: 0.9628672470076169 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 271 / 500 \n",
      " - time: 1.508021593093872 - sq_loss: 1.7342498495054315e-06 - tot_loss: 0.25380346576243973 - acc: 0.9632752992383025 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 272 / 500 \n",
      " - time: 1.5450916290283203 - sq_loss: 1.7304456605415908e-06 - tot_loss: 0.25348094394446097 - acc: 0.9630032644178455 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 273 / 500 \n",
      " - time: 1.5285987854003906 - sq_loss: 1.724093976918084e-06 - tot_loss: 0.2586498721132813 - acc: 0.963411316648531 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 274 / 500 \n",
      " - time: 1.5387499332427979 - sq_loss: 1.7194206520798616e-06 - tot_loss: 0.2535863449517297 - acc: 0.963683351468988 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 275 / 500 \n",
      " - time: 1.5288724899291992 - sq_loss: 1.714841346256435e-06 - tot_loss: 0.26738238850706875 - acc: 0.963683351468988 - val_acc: 0.9243298269426535\n",
      "Repeatition 1 Epoch 276 / 500 \n",
      " - time: 1.5169081687927246 - sq_loss: 1.7104829339587013e-06 - tot_loss: 0.26898182030303186 - acc: 0.9638193688792165 - val_acc: 0.9246691550729556\n",
      "Repeatition 1 Epoch 277 / 500 \n",
      " - time: 1.519552230834961 - sq_loss: 1.7038829582816106e-06 - tot_loss: 0.21341181984120272 - acc: 0.9638193688792165 - val_acc: 0.9253478113335596\n",
      "Repeatition 1 Epoch 278 / 500 \n",
      " - time: 1.5225777626037598 - sq_loss: 1.6998070577756152e-06 - tot_loss: 0.2633909521195186 - acc: 0.9638193688792165 - val_acc: 0.9256871394638616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 279 / 500 \n",
      " - time: 1.5100905895233154 - sq_loss: 1.695276182545058e-06 - tot_loss: 0.2435681880511078 - acc: 0.9640914036996736 - val_acc: 0.9256871394638616\n",
      "Repeatition 1 Epoch 280 / 500 \n",
      " - time: 1.5295839309692383 - sq_loss: 1.6917774701141752e-06 - tot_loss: 0.23541617812637838 - acc: 0.9646354733405876 - val_acc: 0.9256871394638616\n",
      "Repeatition 1 Epoch 281 / 500 \n",
      " - time: 1.5235512256622314 - sq_loss: 1.6881493820619653e-06 - tot_loss: 0.24447600694172245 - acc: 0.9646354733405876 - val_acc: 0.9256871394638616\n",
      "Repeatition 1 Epoch 282 / 500 \n",
      " - time: 1.5493237972259521 - sq_loss: 1.6859498828125652e-06 - tot_loss: 0.2612692066479356 - acc: 0.9647714907508161 - val_acc: 0.9267051238547676\n",
      "Repeatition 1 Epoch 283 / 500 \n",
      " - time: 1.5523765087127686 - sq_loss: 1.6807440488264547e-06 - tot_loss: 0.24354366918990245 - acc: 0.9647714907508161 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 284 / 500 \n",
      " - time: 1.5190036296844482 - sq_loss: 1.6751105249568354e-06 - tot_loss: 0.23842247529503524 - acc: 0.9649075081610446 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 285 / 500 \n",
      " - time: 1.5398836135864258 - sq_loss: 1.6706623000573018e-06 - tot_loss: 0.2637341868259746 - acc: 0.9650435255712732 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 286 / 500 \n",
      " - time: 1.5181584358215332 - sq_loss: 1.6665912880853284e-06 - tot_loss: 0.25632784591523716 - acc: 0.9653155603917302 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 287 / 500 \n",
      " - time: 1.5033366680145264 - sq_loss: 1.6643647313685506e-06 - tot_loss: 0.26318074483763 - acc: 0.9653155603917302 - val_acc: 0.9267051238547676\n",
      "Repeatition 1 Epoch 288 / 500 \n",
      " - time: 1.533639907836914 - sq_loss: 1.6619848111076863e-06 - tot_loss: 0.240336504689866 - acc: 0.9658596300326442 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 289 / 500 \n",
      " - time: 1.541666030883789 - sq_loss: 1.6574859955653665e-06 - tot_loss: 0.23415347840089584 - acc: 0.9653155603917302 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 290 / 500 \n",
      " - time: 1.5300672054290771 - sq_loss: 1.6528904325241456e-06 - tot_loss: 0.2530006298050731 - acc: 0.9655875952121872 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 291 / 500 \n",
      " - time: 1.547799825668335 - sq_loss: 1.6490862435603049e-06 - tot_loss: 0.24783508314603253 - acc: 0.9664036996735582 - val_acc: 0.9273837801153716\n",
      "Repeatition 1 Epoch 292 / 500 \n",
      " - time: 1.5372343063354492 - sq_loss: 1.643915652493888e-06 - tot_loss: 0.2549319926135487 - acc: 0.9664036996735582 - val_acc: 0.9270444519850696\n",
      "Repeatition 1 Epoch 293 / 500 \n",
      " - time: 1.5382304191589355 - sq_loss: 1.6402335631937603e-06 - tot_loss: 0.26637959756696006 - acc: 0.9668117519042437 - val_acc: 0.9284017645062775\n",
      "Repeatition 1 Epoch 294 / 500 \n",
      " - time: 1.5441842079162598 - sq_loss: 1.6348550389011507e-06 - tot_loss: 0.2774011328208772 - acc: 0.9665397170837867 - val_acc: 0.9284017645062775\n",
      "Repeatition 1 Epoch 295 / 500 \n",
      " - time: 1.557884693145752 - sq_loss: 1.6313994137817645e-06 - tot_loss: 0.2663764208136028 - acc: 0.9666757344940152 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 296 / 500 \n",
      " - time: 1.55790114402771 - sq_loss: 1.6280454246953013e-06 - tot_loss: 0.24228511332580815 - acc: 0.9670837867247007 - val_acc: 0.9294197488971836\n",
      "Repeatition 1 Epoch 297 / 500 \n",
      " - time: 1.548152208328247 - sq_loss: 1.6249902046183706e-06 - tot_loss: 0.25641717761023664 - acc: 0.9676278563656148 - val_acc: 0.9311163895486936\n",
      "Repeatition 1 Epoch 298 / 500 \n",
      " - time: 1.5433189868927002 - sq_loss: 1.6217285292441375e-06 - tot_loss: 0.2737167403671732 - acc: 0.9673558215451578 - val_acc: 0.9297590770274856\n",
      "Repeatition 1 Epoch 299 / 500 \n",
      " - time: 1.552473545074463 - sq_loss: 1.6178286159629351e-06 - tot_loss: 0.2616244059838646 - acc: 0.9677638737758433 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 300 / 500 \n",
      " - time: 1.5459325313568115 - sq_loss: 1.6126948594319401e-06 - tot_loss: 0.24867864547624485 - acc: 0.9678998911860718 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 301 / 500 \n",
      " - time: 1.5272560119628906 - sq_loss: 1.607551780580252e-06 - tot_loss: 0.29060633035634975 - acc: 0.9678998911860718 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 302 / 500 \n",
      " - time: 1.5264496803283691 - sq_loss: 1.6037184877859545e-06 - tot_loss: 0.25443419411202584 - acc: 0.9678998911860718 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 303 / 500 \n",
      " - time: 1.4993977546691895 - sq_loss: 1.6008438024073257e-06 - tot_loss: 0.28407301374553295 - acc: 0.9681719260065288 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 304 / 500 \n",
      " - time: 1.5048294067382812 - sq_loss: 1.595550656929845e-06 - tot_loss: 0.27402663001739125 - acc: 0.9678998911860718 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 305 / 500 \n",
      " - time: 1.5197854042053223 - sq_loss: 1.5930396557450877e-06 - tot_loss: 0.26146913811560246 - acc: 0.9683079434167573 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 306 / 500 \n",
      " - time: 1.5083391666412354 - sq_loss: 1.5895067235760507e-06 - tot_loss: 0.25246662868452496 - acc: 0.9683079434167573 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 307 / 500 \n",
      " - time: 1.526097059249878 - sq_loss: 1.5862621012274758e-06 - tot_loss: 0.2363516742338856 - acc: 0.9684439608269858 - val_acc: 0.9297590770274856\n",
      "Repeatition 1 Epoch 308 / 500 \n",
      " - time: 1.4921846389770508 - sq_loss: 1.5825148693693336e-06 - tot_loss: 0.23485061421677944 - acc: 0.9684439608269858 - val_acc: 0.9300984051577876\n",
      "Repeatition 1 Epoch 309 / 500 \n",
      " - time: 1.552706241607666 - sq_loss: 1.5794748833286576e-06 - tot_loss: 0.2617285026674434 - acc: 0.9685799782372143 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 310 / 500 \n",
      " - time: 1.5312504768371582 - sq_loss: 1.5755496178826434e-06 - tot_loss: 0.22441997679836323 - acc: 0.9687159956474428 - val_acc: 0.9307770614183916\n",
      "Repeatition 1 Epoch 311 / 500 \n",
      " - time: 1.5177268981933594 - sq_loss: 1.573746317262703e-06 - tot_loss: 0.2728677086711002 - acc: 0.9687159956474428 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 312 / 500 \n",
      " - time: 1.5333411693572998 - sq_loss: 1.5704171119068633e-06 - tot_loss: 0.25303088449940514 - acc: 0.9688520130576714 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 313 / 500 \n",
      " - time: 1.5154151916503906 - sq_loss: 1.5668705373172997e-06 - tot_loss: 0.2431049112831989 - acc: 0.9689880304678999 - val_acc: 0.9311163895486936\n",
      "Repeatition 1 Epoch 314 / 500 \n",
      " - time: 1.5483150482177734 - sq_loss: 1.5634814189979807e-06 - tot_loss: 0.24630092283449923 - acc: 0.9689880304678999 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 315 / 500 \n",
      " - time: 1.5079963207244873 - sq_loss: 1.5600421647832263e-06 - tot_loss: 0.25444384198296355 - acc: 0.9691240478781284 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 316 / 500 \n",
      " - time: 1.507897138595581 - sq_loss: 1.5555111758658313e-06 - tot_loss: 0.24911096467540794 - acc: 0.9689880304678999 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 317 / 500 \n",
      " - time: 1.5451018810272217 - sq_loss: 1.5506318504776573e-06 - tot_loss: 0.24740049451867563 - acc: 0.969532100108814 - val_acc: 0.9317950458092976\n",
      "Repeatition 1 Epoch 318 / 500 \n",
      " - time: 1.514075517654419 - sq_loss: 1.5480951560675749e-06 - tot_loss: 0.2874468353264694 - acc: 0.9693960826985855 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 319 / 500 \n",
      " - time: 1.5016570091247559 - sq_loss: 1.544882366033562e-06 - tot_loss: 0.24741734974681417 - acc: 0.9696681175190425 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 320 / 500 \n",
      " - time: 1.5296056270599365 - sq_loss: 1.5398932191601489e-06 - tot_loss: 0.2443173677475734 - acc: 0.9696681175190425 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 321 / 500 \n",
      " - time: 1.5074727535247803 - sq_loss: 1.5352329683082644e-06 - tot_loss: 0.28120604173199926 - acc: 0.969804134929271 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 322 / 500 \n",
      " - time: 1.533266544342041 - sq_loss: 1.530155714135617e-06 - tot_loss: 0.24500898312227726 - acc: 0.970348204570185 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 323 / 500 \n",
      " - time: 1.5763161182403564 - sq_loss: 1.5258285657182569e-06 - tot_loss: 0.2280890107886444 - acc: 0.9707562568008705 - val_acc: 0.9314557176789956\n",
      "Repeatition 1 Epoch 324 / 500 \n",
      " - time: 1.5821952819824219 - sq_loss: 1.5228162055791472e-06 - tot_loss: 0.260349337913266 - acc: 0.971164309031556 - val_acc: 0.9321343739395996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 325 / 500 \n",
      " - time: 1.6026277542114258 - sq_loss: 1.5197263110167114e-06 - tot_loss: 0.2646959993636333 - acc: 0.971164309031556 - val_acc: 0.9321343739395996\n",
      "Repeatition 1 Epoch 326 / 500 \n",
      " - time: 1.5627024173736572 - sq_loss: 1.517013629381836e-06 - tot_loss: 0.264669472047232 - acc: 0.971436343852013 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 327 / 500 \n",
      " - time: 1.552095651626587 - sq_loss: 1.5145415090955794e-06 - tot_loss: 0.24930346074830645 - acc: 0.9715723612622416 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 328 / 500 \n",
      " - time: 1.5600299835205078 - sq_loss: 1.5096683227966423e-06 - tot_loss: 0.28992743313868274 - acc: 0.9718443960826986 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 329 / 500 \n",
      " - time: 1.5246543884277344 - sq_loss: 1.5056735946927802e-06 - tot_loss: 0.2532202761570339 - acc: 0.9717083786724701 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 330 / 500 \n",
      " - time: 1.5635347366333008 - sq_loss: 1.5030158238005242e-06 - tot_loss: 0.264577669371147 - acc: 0.9718443960826986 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 331 / 500 \n",
      " - time: 1.5451476573944092 - sq_loss: 1.5002999589341925e-06 - tot_loss: 0.27207137215736044 - acc: 0.9722524483133841 - val_acc: 0.9321343739395996\n",
      "Repeatition 1 Epoch 332 / 500 \n",
      " - time: 1.5385801792144775 - sq_loss: 1.4972151802794542e-06 - tot_loss: 0.25562327149588526 - acc: 0.9722524483133841 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 333 / 500 \n",
      " - time: 1.5395305156707764 - sq_loss: 1.4937933201508713e-06 - tot_loss: 0.2494113184242961 - acc: 0.9722524483133841 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 334 / 500 \n",
      " - time: 1.5335071086883545 - sq_loss: 1.491139755671611e-06 - tot_loss: 0.2661862664134125 - acc: 0.9723884657236126 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 335 / 500 \n",
      " - time: 1.5453050136566162 - sq_loss: 1.4871623079670826e-06 - tot_loss: 0.25344059843942546 - acc: 0.9725244831338411 - val_acc: 0.9324737020699015\n",
      "Repeatition 1 Epoch 336 / 500 \n",
      " - time: 1.5478112697601318 - sq_loss: 1.4837416983937146e-06 - tot_loss: 0.24511749318427523 - acc: 0.9725244831338411 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 337 / 500 \n",
      " - time: 1.5497539043426514 - sq_loss: 1.4794229628023459e-06 - tot_loss: 0.24358774015571605 - acc: 0.9723884657236126 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 338 / 500 \n",
      " - time: 1.554253101348877 - sq_loss: 1.4766195590709685e-06 - tot_loss: 0.25925845624528865 - acc: 0.9726605005440696 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 339 / 500 \n",
      " - time: 1.5368525981903076 - sq_loss: 1.4741186760147684e-06 - tot_loss: 0.2601977968085549 - acc: 0.9729325353645266 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 340 / 500 \n",
      " - time: 1.5371205806732178 - sq_loss: 1.4721890693181194e-06 - tot_loss: 0.23592903180594504 - acc: 0.9732045701849836 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 341 / 500 \n",
      " - time: 1.5368425846099854 - sq_loss: 1.4695409618070698e-06 - tot_loss: 0.2374042534791938 - acc: 0.9732045701849836 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 342 / 500 \n",
      " - time: 1.5317480564117432 - sq_loss: 1.465799300603976e-06 - tot_loss: 0.2402639043759054 - acc: 0.9730685527747551 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 343 / 500 \n",
      " - time: 1.5384984016418457 - sq_loss: 1.462104705751699e-06 - tot_loss: 0.26297989128592025 - acc: 0.9730685527747551 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 344 / 500 \n",
      " - time: 1.5040884017944336 - sq_loss: 1.4580609786207788e-06 - tot_loss: 0.2188645759695831 - acc: 0.9732045701849836 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 345 / 500 \n",
      " - time: 1.5681390762329102 - sq_loss: 1.4554874496752745e-06 - tot_loss: 0.2558528968505511 - acc: 0.9733405875952121 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 346 / 500 \n",
      " - time: 1.5375730991363525 - sq_loss: 1.452082983632863e-06 - tot_loss: 0.2416791544808623 - acc: 0.9734766050054406 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 347 / 500 \n",
      " - time: 1.5245378017425537 - sq_loss: 1.4492562740997528e-06 - tot_loss: 0.2544884978141182 - acc: 0.9734766050054406 - val_acc: 0.9328130302002036\n",
      "Repeatition 1 Epoch 348 / 500 \n",
      " - time: 1.5146026611328125 - sq_loss: 1.446883516109665e-06 - tot_loss: 0.26245317742867424 - acc: 0.9734766050054406 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 349 / 500 \n",
      " - time: 1.5300078392028809 - sq_loss: 1.4434261856877129e-06 - tot_loss: 0.2368180199635752 - acc: 0.9737486398258978 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 350 / 500 \n",
      " - time: 1.5364794731140137 - sq_loss: 1.440060259483289e-06 - tot_loss: 0.25007309242605746 - acc: 0.9737486398258978 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 351 / 500 \n",
      " - time: 1.5289478302001953 - sq_loss: 1.437665900994034e-06 - tot_loss: 0.25426949756193995 - acc: 0.9737486398258978 - val_acc: 0.9331523583305056\n",
      "Repeatition 1 Epoch 352 / 500 \n",
      " - time: 1.5285472869873047 - sq_loss: 1.4358395219460363e-06 - tot_loss: 0.2543533404644194 - acc: 0.9738846572361263 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 353 / 500 \n",
      " - time: 1.5456490516662598 - sq_loss: 1.4324509720609058e-06 - tot_loss: 0.2685222296794425 - acc: 0.9740206746463548 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 354 / 500 \n",
      " - time: 1.5487010478973389 - sq_loss: 1.4279955848905956e-06 - tot_loss: 0.25607247097623453 - acc: 0.9737486398258978 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 355 / 500 \n",
      " - time: 1.5373473167419434 - sq_loss: 1.4249661717258277e-06 - tot_loss: 0.26599711829856965 - acc: 0.9738846572361263 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 356 / 500 \n",
      " - time: 1.5124762058258057 - sq_loss: 1.4212325822882121e-06 - tot_loss: 0.2395132731229852 - acc: 0.9741566920565833 - val_acc: 0.9334916864608076\n",
      "Repeatition 1 Epoch 357 / 500 \n",
      " - time: 1.5502772331237793 - sq_loss: 1.4172430837788852e-06 - tot_loss: 0.23961733594561796 - acc: 0.9742927094668118 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 358 / 500 \n",
      " - time: 1.5546157360076904 - sq_loss: 1.4148118907542084e-06 - tot_loss: 0.24569892141890115 - acc: 0.9742927094668118 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 359 / 500 \n",
      " - time: 1.5422942638397217 - sq_loss: 1.4134751609162777e-06 - tot_loss: 0.2868144359849163 - acc: 0.9744287268770403 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 360 / 500 \n",
      " - time: 1.5227100849151611 - sq_loss: 1.4127688245935133e-06 - tot_loss: 0.24155621645236547 - acc: 0.9744287268770403 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 361 / 500 \n",
      " - time: 1.533522129058838 - sq_loss: 1.410452568961773e-06 - tot_loss: 0.2414818417030089 - acc: 0.9744287268770403 - val_acc: 0.9345096708517137\n",
      "Repeatition 1 Epoch 362 / 500 \n",
      " - time: 1.527578353881836 - sq_loss: 1.408698608429404e-06 - tot_loss: 0.25461748198349365 - acc: 0.9744287268770403 - val_acc: 0.9338310145911096\n",
      "Repeatition 1 Epoch 363 / 500 \n",
      " - time: 1.559471845626831 - sq_loss: 1.405710463586729e-06 - tot_loss: 0.2368638773491636 - acc: 0.9744287268770403 - val_acc: 0.9341703427214116\n",
      "Repeatition 1 Epoch 364 / 500 \n",
      " - time: 1.5630214214324951 - sq_loss: 1.4013745612828643e-06 - tot_loss: 0.24845377258715473 - acc: 0.9744287268770403 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 365 / 500 \n",
      " - time: 1.535689353942871 - sq_loss: 1.3984957831780775e-06 - tot_loss: 0.24849902193988704 - acc: 0.9744287268770403 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 366 / 500 \n",
      " - time: 1.5218088626861572 - sq_loss: 1.3958152749182773e-06 - tot_loss: 0.25309390738833937 - acc: 0.9745647442872688 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 367 / 500 \n",
      " - time: 1.5508224964141846 - sq_loss: 1.3930647355664405e-06 - tot_loss: 0.26327040968627724 - acc: 0.9748367791077258 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 368 / 500 \n",
      " - time: 1.5466046333312988 - sq_loss: 1.3911964060753235e-06 - tot_loss: 0.22095786243404536 - acc: 0.9749727965179543 - val_acc: 0.9345096708517137\n",
      "Repeatition 1 Epoch 369 / 500 \n",
      " - time: 1.5498974323272705 - sq_loss: 1.3883133078707033e-06 - tot_loss: 0.26146393557859327 - acc: 0.9747007616974973 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 370 / 500 \n",
      " - time: 1.5269668102264404 - sq_loss: 1.3856035820936086e-06 - tot_loss: 0.2859250732784071 - acc: 0.9748367791077258 - val_acc: 0.9341703427214116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 371 / 500 \n",
      " - time: 1.5043187141418457 - sq_loss: 1.3816587625115062e-06 - tot_loss: 0.24747989825701833 - acc: 0.9749727965179543 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 372 / 500 \n",
      " - time: 1.5452423095703125 - sq_loss: 1.3791614037472755e-06 - tot_loss: 0.25739010538980844 - acc: 0.9751088139281828 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 373 / 500 \n",
      " - time: 1.4992966651916504 - sq_loss: 1.3760086403635796e-06 - tot_loss: 0.28896592722042813 - acc: 0.9751088139281828 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 374 / 500 \n",
      " - time: 1.5565192699432373 - sq_loss: 1.37273980271857e-06 - tot_loss: 0.23576797247196613 - acc: 0.9752448313384113 - val_acc: 0.9348489989820156\n",
      "Repeatition 1 Epoch 375 / 500 \n",
      " - time: 1.526789665222168 - sq_loss: 1.3695730558538344e-06 - tot_loss: 0.2443896600538764 - acc: 0.9752448313384113 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 376 / 500 \n",
      " - time: 1.5285792350769043 - sq_loss: 1.3660511513080564e-06 - tot_loss: 0.26445647831933616 - acc: 0.9753808487486398 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 377 / 500 \n",
      " - time: 1.5438942909240723 - sq_loss: 1.363497290185478e-06 - tot_loss: 0.27479651982079556 - acc: 0.9753808487486398 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 378 / 500 \n",
      " - time: 1.5492467880249023 - sq_loss: 1.3616380556413787e-06 - tot_loss: 0.25132412504544277 - acc: 0.9757889009793254 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 379 / 500 \n",
      " - time: 1.5445396900177002 - sq_loss: 1.359307702841761e-06 - tot_loss: 0.2521250690765937 - acc: 0.9757889009793254 - val_acc: 0.9351883271123176\n",
      "Repeatition 1 Epoch 380 / 500 \n",
      " - time: 1.5364220142364502 - sq_loss: 1.3559816807173775e-06 - tot_loss: 0.26645492834973084 - acc: 0.9757889009793254 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 381 / 500 \n",
      " - time: 1.5347745418548584 - sq_loss: 1.3541877024181304e-06 - tot_loss: 0.2950009246994978 - acc: 0.9760609357997824 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 382 / 500 \n",
      " - time: 1.57185697555542 - sq_loss: 1.3523748521038215e-06 - tot_loss: 0.2516395732391863 - acc: 0.9761969532100109 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 383 / 500 \n",
      " - time: 1.5256946086883545 - sq_loss: 1.3501463627108024e-06 - tot_loss: 0.24483173470652364 - acc: 0.9761969532100109 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 384 / 500 \n",
      " - time: 1.585495948791504 - sq_loss: 1.3478583014148171e-06 - tot_loss: 0.26062984553948754 - acc: 0.9763329706202394 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 385 / 500 \n",
      " - time: 1.558234691619873 - sq_loss: 1.3461939261105726e-06 - tot_loss: 0.26201185467074106 - acc: 0.9763329706202394 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 386 / 500 \n",
      " - time: 1.4938819408416748 - sq_loss: 1.3439902204481768e-06 - tot_loss: 0.2776724794712324 - acc: 0.9763329706202394 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 387 / 500 \n",
      " - time: 1.530731439590454 - sq_loss: 1.3410308383754455e-06 - tot_loss: 0.26020200354307654 - acc: 0.9763329706202394 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 388 / 500 \n",
      " - time: 1.5449244976043701 - sq_loss: 1.3397606153375818e-06 - tot_loss: 0.26491816542718505 - acc: 0.9766050054406964 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 389 / 500 \n",
      " - time: 1.5404515266418457 - sq_loss: 1.3381120425037807e-06 - tot_loss: 0.26985215323133716 - acc: 0.9766050054406964 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 390 / 500 \n",
      " - time: 1.5483410358428955 - sq_loss: 1.332939746134798e-06 - tot_loss: 0.2515903104763857 - acc: 0.9764689880304679 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 391 / 500 \n",
      " - time: 1.5124304294586182 - sq_loss: 1.331447151642351e-06 - tot_loss: 0.24394942116988316 - acc: 0.9766050054406964 - val_acc: 0.9355276552426196\n",
      "Repeatition 1 Epoch 392 / 500 \n",
      " - time: 1.5645513534545898 - sq_loss: 1.329800511484791e-06 - tot_loss: 0.24880354759394807 - acc: 0.9766050054406964 - val_acc: 0.9358669833729216\n",
      "Repeatition 1 Epoch 393 / 500 \n",
      " - time: 1.5293827056884766 - sq_loss: 1.3282815416459925e-06 - tot_loss: 0.23982972418252846 - acc: 0.9768770402611534 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 394 / 500 \n",
      " - time: 1.544285535812378 - sq_loss: 1.325594212175929e-06 - tot_loss: 0.2512301129080372 - acc: 0.9767410228509249 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 395 / 500 \n",
      " - time: 1.576063871383667 - sq_loss: 1.323902665717469e-06 - tot_loss: 0.27330253151587813 - acc: 0.9770130576713819 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 396 / 500 \n",
      " - time: 1.5277142524719238 - sq_loss: 1.3220684422776685e-06 - tot_loss: 0.2465226139799368 - acc: 0.9771490750816104 - val_acc: 0.9362063115032236\n",
      "Repeatition 1 Epoch 397 / 500 \n",
      " - time: 1.5419104099273682 - sq_loss: 1.319769012297911e-06 - tot_loss: 0.22749932602718737 - acc: 0.9772850924918389 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 398 / 500 \n",
      " - time: 1.5115468502044678 - sq_loss: 1.3176301081330166e-06 - tot_loss: 0.2604526380098391 - acc: 0.9776931447225244 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 399 / 500 \n",
      " - time: 1.5161449909210205 - sq_loss: 1.315612962571322e-06 - tot_loss: 0.2906005657972477 - acc: 0.9774211099020674 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 400 / 500 \n",
      " - time: 1.5066845417022705 - sq_loss: 1.3138088661435177e-06 - tot_loss: 0.27828450407490646 - acc: 0.9774211099020674 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 401 / 500 \n",
      " - time: 1.5643775463104248 - sq_loss: 1.3113005934428656e-06 - tot_loss: 0.2497365568791694 - acc: 0.9772850924918389 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 402 / 500 \n",
      " - time: 1.542722225189209 - sq_loss: 1.308988998971472e-06 - tot_loss: 0.25560060444434995 - acc: 0.9771490750816104 - val_acc: 0.9368849677638276\n",
      "Repeatition 1 Epoch 403 / 500 \n",
      " - time: 1.5397396087646484 - sq_loss: 1.3058262311460567e-06 - tot_loss: 0.26675437849455497 - acc: 0.9774211099020674 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 404 / 500 \n",
      " - time: 1.5570948123931885 - sq_loss: 1.3024988447796204e-06 - tot_loss: 0.24753298415346148 - acc: 0.9776931447225244 - val_acc: 0.9365456396335257\n",
      "Repeatition 1 Epoch 405 / 500 \n",
      " - time: 1.553830862045288 - sq_loss: 1.299350401495758e-06 - tot_loss: 0.2758707378618195 - acc: 0.9776931447225244 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 406 / 500 \n",
      " - time: 1.5287463665008545 - sq_loss: 1.2969047702426906e-06 - tot_loss: 0.26965868519515857 - acc: 0.97810119695321 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 407 / 500 \n",
      " - time: 1.4929885864257812 - sq_loss: 1.2944840364070842e-06 - tot_loss: 0.2669878282882978 - acc: 0.9772850924918389 - val_acc: 0.9372242958941296\n",
      "Repeatition 1 Epoch 408 / 500 \n",
      " - time: 1.5650835037231445 - sq_loss: 1.2926335557494895e-06 - tot_loss: 0.23914161623320984 - acc: 0.97810119695321 - val_acc: 0.9375636240244316\n",
      "Repeatition 1 Epoch 409 / 500 \n",
      " - time: 1.559159517288208 - sq_loss: 1.2906730262329802e-06 - tot_loss: 0.22206027335069445 - acc: 0.9782372143634385 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 410 / 500 \n",
      " - time: 1.5453104972839355 - sq_loss: 1.2884753459729836e-06 - tot_loss: 0.2664006873783591 - acc: 0.9783732317736671 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 411 / 500 \n",
      " - time: 1.551680088043213 - sq_loss: 1.2859396747444407e-06 - tot_loss: 0.28331569028865466 - acc: 0.9786452665941241 - val_acc: 0.9382422802850356\n",
      "Repeatition 1 Epoch 412 / 500 \n",
      " - time: 1.5209600925445557 - sq_loss: 1.2838758038924425e-06 - tot_loss: 0.2670318103229148 - acc: 0.9782372143634385 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 413 / 500 \n",
      " - time: 1.5945987701416016 - sq_loss: 1.2812455452149152e-06 - tot_loss: 0.249198307496874 - acc: 0.9785092491838956 - val_acc: 0.9382422802850356\n",
      "Repeatition 1 Epoch 414 / 500 \n",
      " - time: 1.548166036605835 - sq_loss: 1.277618821404758e-06 - tot_loss: 0.2572540218744188 - acc: 0.9783732317736671 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 415 / 500 \n",
      " - time: 1.5566983222961426 - sq_loss: 1.277016053791158e-06 - tot_loss: 0.2576568849447072 - acc: 0.9785092491838956 - val_acc: 0.9382422802850356\n",
      "Repeatition 1 Epoch 416 / 500 \n",
      " - time: 1.545036792755127 - sq_loss: 1.276425109608681e-06 - tot_loss: 0.267579272516945 - acc: 0.9789173014145811 - val_acc: 0.9389209365456397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 417 / 500 \n",
      " - time: 1.525364637374878 - sq_loss: 1.2741688806272577e-06 - tot_loss: 0.27433306179865724 - acc: 0.9785092491838956 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 418 / 500 \n",
      " - time: 1.5605030059814453 - sq_loss: 1.2710212331512594e-06 - tot_loss: 0.2788358410156193 - acc: 0.9785092491838956 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 419 / 500 \n",
      " - time: 1.5466809272766113 - sq_loss: 1.2693615190073615e-06 - tot_loss: 0.2378488039329718 - acc: 0.9786452665941241 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 420 / 500 \n",
      " - time: 1.5655007362365723 - sq_loss: 1.2677738823185791e-06 - tot_loss: 0.24204416038473386 - acc: 0.9787812840043526 - val_acc: 0.9379029521547336\n",
      "Repeatition 1 Epoch 421 / 500 \n",
      " - time: 1.564507246017456 - sq_loss: 1.264866682504362e-06 - tot_loss: 0.2639622797305887 - acc: 0.9785092491838956 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 422 / 500 \n",
      " - time: 1.545454978942871 - sq_loss: 1.2613712669917732e-06 - tot_loss: 0.24054380071134007 - acc: 0.9789173014145811 - val_acc: 0.9385816084153377\n",
      "Repeatition 1 Epoch 423 / 500 \n",
      " - time: 1.541795015335083 - sq_loss: 1.2596302667589043e-06 - tot_loss: 0.2587023311280907 - acc: 0.9790533188248096 - val_acc: 0.9389209365456397\n",
      "Repeatition 1 Epoch 424 / 500 \n",
      " - time: 1.5707833766937256 - sq_loss: 1.2561532685140264e-06 - tot_loss: 0.26808017811868057 - acc: 0.9790533188248096 - val_acc: 0.9392602646759416\n",
      "Repeatition 1 Epoch 425 / 500 \n",
      " - time: 1.5111396312713623 - sq_loss: 1.2522621091193287e-06 - tot_loss: 0.2668176529251407 - acc: 0.9791893362350381 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 426 / 500 \n",
      " - time: 1.5470836162567139 - sq_loss: 1.2493275107772206e-06 - tot_loss: 0.26996441519558756 - acc: 0.9790533188248096 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 427 / 500 \n",
      " - time: 1.5623044967651367 - sq_loss: 1.2483367299864767e-06 - tot_loss: 0.25409038222992253 - acc: 0.9791893362350381 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 428 / 500 \n",
      " - time: 1.566331386566162 - sq_loss: 1.2482661304602516e-06 - tot_loss: 0.25763293218755035 - acc: 0.9793253536452666 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 429 / 500 \n",
      " - time: 1.5581130981445312 - sq_loss: 1.2470935644159908e-06 - tot_loss: 0.261805290217878 - acc: 0.9797334058759521 - val_acc: 0.9395995928062436\n",
      "Repeatition 1 Epoch 430 / 500 \n",
      " - time: 1.512544870376587 - sq_loss: 1.2445360653146054e-06 - tot_loss: 0.27883292172920804 - acc: 0.9797334058759521 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 431 / 500 \n",
      " - time: 1.5505683422088623 - sq_loss: 1.2424646911313175e-06 - tot_loss: 0.2798712761328592 - acc: 0.9797334058759521 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 432 / 500 \n",
      " - time: 1.512925624847412 - sq_loss: 1.2393376209729468e-06 - tot_loss: 0.26078707880796914 - acc: 0.9798694232861807 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 433 / 500 \n",
      " - time: 1.5068340301513672 - sq_loss: 1.2368318493827246e-06 - tot_loss: 0.2546434726555411 - acc: 0.9798694232861807 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 434 / 500 \n",
      " - time: 1.5292034149169922 - sq_loss: 1.234320961884805e-06 - tot_loss: 0.26582437016241167 - acc: 0.9797334058759521 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 435 / 500 \n",
      " - time: 1.5348258018493652 - sq_loss: 1.2311436421441613e-06 - tot_loss: 0.2587268715425619 - acc: 0.9798694232861807 - val_acc: 0.9409569053274517\n",
      "Repeatition 1 Epoch 436 / 500 \n",
      " - time: 1.5315213203430176 - sq_loss: 1.2283795740586356e-06 - tot_loss: 0.2775663039184013 - acc: 0.9800054406964092 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 437 / 500 \n",
      " - time: 1.5621306896209717 - sq_loss: 1.2271949572095764e-06 - tot_loss: 0.24539006408845943 - acc: 0.9800054406964092 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 438 / 500 \n",
      " - time: 1.533876895904541 - sq_loss: 1.2255682122486178e-06 - tot_loss: 0.27459639327655117 - acc: 0.9800054406964092 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 439 / 500 \n",
      " - time: 1.5370523929595947 - sq_loss: 1.2236149586897227e-06 - tot_loss: 0.26349351211190575 - acc: 0.9800054406964092 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 440 / 500 \n",
      " - time: 1.522845983505249 - sq_loss: 1.222814034917974e-06 - tot_loss: 0.2634998410203653 - acc: 0.9800054406964092 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 441 / 500 \n",
      " - time: 1.5078809261322021 - sq_loss: 1.219785076500557e-06 - tot_loss: 0.27426906610407187 - acc: 0.9800054406964092 - val_acc: 0.9399389209365456\n",
      "Repeatition 1 Epoch 442 / 500 \n",
      " - time: 1.5416910648345947 - sq_loss: 1.2171484513601172e-06 - tot_loss: 0.29328215963065984 - acc: 0.9800054406964092 - val_acc: 0.9402782490668476\n",
      "Repeatition 1 Epoch 443 / 500 \n",
      " - time: 1.5264575481414795 - sq_loss: 1.2143042340539978e-06 - tot_loss: 0.2690078201277841 - acc: 0.9800054406964092 - val_acc: 0.9419748897183576\n",
      "Repeatition 1 Epoch 444 / 500 \n",
      " - time: 1.5534663200378418 - sq_loss: 1.2122245607315563e-06 - tot_loss: 0.2938084815650166 - acc: 0.9800054406964092 - val_acc: 0.9406175771971497\n",
      "Repeatition 1 Epoch 445 / 500 \n",
      " - time: 1.538987636566162 - sq_loss: 1.210978325616452e-06 - tot_loss: 0.24443077386154277 - acc: 0.9800054406964092 - val_acc: 0.9412962334577536\n",
      "Repeatition 1 Epoch 446 / 500 \n",
      " - time: 1.5390827655792236 - sq_loss: 1.209321112582984e-06 - tot_loss: 0.250433515419318 - acc: 0.9800054406964092 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 447 / 500 \n",
      " - time: 1.5565011501312256 - sq_loss: 1.20743766274245e-06 - tot_loss: 0.26403272826588964 - acc: 0.9801414581066377 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 448 / 500 \n",
      " - time: 1.5255100727081299 - sq_loss: 1.2048215012328e-06 - tot_loss: 0.22840430101125886 - acc: 0.9800054406964092 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 449 / 500 \n",
      " - time: 1.5475399494171143 - sq_loss: 1.2029651088596438e-06 - tot_loss: 0.2501637283220739 - acc: 0.9801414581066377 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 450 / 500 \n",
      " - time: 1.5168869495391846 - sq_loss: 1.2003813480987446e-06 - tot_loss: 0.2565145791637735 - acc: 0.9801414581066377 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 451 / 500 \n",
      " - time: 1.5458061695098877 - sq_loss: 1.1990725852228934e-06 - tot_loss: 0.2822718028040674 - acc: 0.9801414581066377 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 452 / 500 \n",
      " - time: 1.559607744216919 - sq_loss: 1.1967653108513332e-06 - tot_loss: 0.26024293718540514 - acc: 0.9801414581066377 - val_acc: 0.9423142178486597\n",
      "Repeatition 1 Epoch 453 / 500 \n",
      " - time: 1.5356254577636719 - sq_loss: 1.1960315760006779e-06 - tot_loss: 0.26139452938313124 - acc: 0.9802774755168662 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 454 / 500 \n",
      " - time: 1.5403058528900146 - sq_loss: 1.19391529551649e-06 - tot_loss: 0.23951234136335042 - acc: 0.9802774755168662 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 455 / 500 \n",
      " - time: 1.5117428302764893 - sq_loss: 1.1917500160052441e-06 - tot_loss: 0.25286561427120136 - acc: 0.9806855277475517 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 456 / 500 \n",
      " - time: 1.5278782844543457 - sq_loss: 1.190050397781306e-06 - tot_loss: 0.25257800413145093 - acc: 0.9804134929270947 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 457 / 500 \n",
      " - time: 1.5610237121582031 - sq_loss: 1.187797352031339e-06 - tot_loss: 0.25593174741939695 - acc: 0.9805495103373232 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 458 / 500 \n",
      " - time: 1.557443618774414 - sq_loss: 1.185958808491705e-06 - tot_loss: 0.25191907036299055 - acc: 0.9805495103373232 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 459 / 500 \n",
      " - time: 1.5456416606903076 - sq_loss: 1.1844716709674685e-06 - tot_loss: 0.2911950112969097 - acc: 0.9806855277475517 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 460 / 500 \n",
      " - time: 1.5568032264709473 - sq_loss: 1.1822154419860453e-06 - tot_loss: 0.2611150025564575 - acc: 0.9806855277475517 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 461 / 500 \n",
      " - time: 1.5515804290771484 - sq_loss: 1.1800744914580719e-06 - tot_loss: 0.2647289269992217 - acc: 0.9806855277475517 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 462 / 500 \n",
      " - time: 1.5428543090820312 - sq_loss: 1.177961507892178e-06 - tot_loss: 0.24152951430362402 - acc: 0.9806855277475517 - val_acc: 0.9429928741092637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeatition 1 Epoch 463 / 500 \n",
      " - time: 1.5394253730773926 - sq_loss: 1.1757907714127214e-06 - tot_loss: 0.2856916470368085 - acc: 0.9806855277475517 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 464 / 500 \n",
      " - time: 1.562849521636963 - sq_loss: 1.174335011455696e-06 - tot_loss: 0.2296665353148839 - acc: 0.9806855277475517 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 465 / 500 \n",
      " - time: 1.5673339366912842 - sq_loss: 1.1731010545190657e-06 - tot_loss: 0.2748834876592321 - acc: 0.9805495103373232 - val_acc: 0.9426535459789617\n",
      "Repeatition 1 Epoch 466 / 500 \n",
      " - time: 1.5761148929595947 - sq_loss: 1.1708992815329111e-06 - tot_loss: 0.2344555945600093 - acc: 0.9813656147986942 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 467 / 500 \n",
      " - time: 1.5525107383728027 - sq_loss: 1.1697030686264043e-06 - tot_loss: 0.2753794760101025 - acc: 0.9806855277475517 - val_acc: 0.9429928741092637\n",
      "Repeatition 1 Epoch 468 / 500 \n",
      " - time: 1.5395011901855469 - sq_loss: 1.1689596703945426e-06 - tot_loss: 0.26219714779341663 - acc: 0.9808215451577802 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 469 / 500 \n",
      " - time: 1.5470645427703857 - sq_loss: 1.1671295396809e-06 - tot_loss: 0.25304963910075795 - acc: 0.9810935799782372 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 470 / 500 \n",
      " - time: 1.5020601749420166 - sq_loss: 1.1650635087789851e-06 - tot_loss: 0.2937740256148489 - acc: 0.9813656147986942 - val_acc: 0.9433322022395657\n",
      "Repeatition 1 Epoch 471 / 500 \n",
      " - time: 1.5438523292541504 - sq_loss: 1.1630797871475806e-06 - tot_loss: 0.25219610937079384 - acc: 0.9815016322089227 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 472 / 500 \n",
      " - time: 1.5237154960632324 - sq_loss: 1.1621842759268475e-06 - tot_loss: 0.27155061777909895 - acc: 0.9813656147986942 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 473 / 500 \n",
      " - time: 1.562021255493164 - sq_loss: 1.1606822454268695e-06 - tot_loss: 0.2564648198361077 - acc: 0.9813656147986942 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 474 / 500 \n",
      " - time: 1.5435798168182373 - sq_loss: 1.1591941984079313e-06 - tot_loss: 0.2983267560678353 - acc: 0.9813656147986942 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 475 / 500 \n",
      " - time: 1.5332026481628418 - sq_loss: 1.1555022183529218e-06 - tot_loss: 0.266676512121931 - acc: 0.9815016322089227 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 476 / 500 \n",
      " - time: 1.5294232368469238 - sq_loss: 1.1534846180438763e-06 - tot_loss: 0.2836973128419187 - acc: 0.9815016322089227 - val_acc: 0.9436715303698676\n",
      "Repeatition 1 Epoch 477 / 500 \n",
      " - time: 1.5478854179382324 - sq_loss: 1.151419951384014e-06 - tot_loss: 0.26587620465912964 - acc: 0.9816376496191512 - val_acc: 0.9440108585001696\n",
      "Repeatition 1 Epoch 478 / 500 \n",
      " - time: 1.5700352191925049 - sq_loss: 1.1490584483908606e-06 - tot_loss: 0.26629159889632525 - acc: 0.9817736670293797 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 479 / 500 \n",
      " - time: 1.5316975116729736 - sq_loss: 1.1470001481939107e-06 - tot_loss: 0.256746100120107 - acc: 0.9816376496191512 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 480 / 500 \n",
      " - time: 1.5271213054656982 - sq_loss: 1.1452458466010285e-06 - tot_loss: 0.24485217640754886 - acc: 0.9815016322089227 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 481 / 500 \n",
      " - time: 1.5272581577301025 - sq_loss: 1.1442090226410073e-06 - tot_loss: 0.24648902511969872 - acc: 0.9817736670293797 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 482 / 500 \n",
      " - time: 1.5175724029541016 - sq_loss: 1.1426149058024748e-06 - tot_loss: 0.2687078945501016 - acc: 0.9819096844396082 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 483 / 500 \n",
      " - time: 1.5191166400909424 - sq_loss: 1.1407258853068925e-06 - tot_loss: 0.2691330330247834 - acc: 0.9817736670293797 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 484 / 500 \n",
      " - time: 1.544121503829956 - sq_loss: 1.1384859135432635e-06 - tot_loss: 0.28610093536218884 - acc: 0.9821817192600653 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 485 / 500 \n",
      " - time: 1.5419771671295166 - sq_loss: 1.136474793383968e-06 - tot_loss: 0.2850083011094817 - acc: 0.9819096844396082 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 486 / 500 \n",
      " - time: 1.5355756282806396 - sq_loss: 1.1344562835802208e-06 - tot_loss: 0.25278122849495466 - acc: 0.9820457018498367 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 487 / 500 \n",
      " - time: 1.525573492050171 - sq_loss: 1.1330736242598505e-06 - tot_loss: 0.27643296701525966 - acc: 0.9820457018498367 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 488 / 500 \n",
      " - time: 1.528357744216919 - sq_loss: 1.1311517482681666e-06 - tot_loss: 0.24805108927861008 - acc: 0.9821817192600653 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 489 / 500 \n",
      " - time: 1.5332348346710205 - sq_loss: 1.1302518032607622e-06 - tot_loss: 0.28442722185019953 - acc: 0.9820457018498367 - val_acc: 0.9443501866304717\n",
      "Repeatition 1 Epoch 490 / 500 \n",
      " - time: 1.5331346988677979 - sq_loss: 1.1285991377008031e-06 - tot_loss: 0.25258903103585606 - acc: 0.9819096844396082 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 491 / 500 \n",
      " - time: 1.5259263515472412 - sq_loss: 1.127096766140312e-06 - tot_loss: 0.24857400878048086 - acc: 0.9819096844396082 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 492 / 500 \n",
      " - time: 1.5176379680633545 - sq_loss: 1.1248413329667528e-06 - tot_loss: 0.2860663585960501 - acc: 0.9821817192600653 - val_acc: 0.9453681710213777\n",
      "Repeatition 1 Epoch 493 / 500 \n",
      " - time: 1.520927906036377 - sq_loss: 1.1237375474593136e-06 - tot_loss: 0.24902322441161173 - acc: 0.9820457018498367 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 494 / 500 \n",
      " - time: 1.5198349952697754 - sq_loss: 1.1223928595427424e-06 - tot_loss: 0.22818895053046395 - acc: 0.9819096844396082 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 495 / 500 \n",
      " - time: 1.4776179790496826 - sq_loss: 1.1209313015569933e-06 - tot_loss: 0.23598125056074393 - acc: 0.9820457018498367 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 496 / 500 \n",
      " - time: 1.5302739143371582 - sq_loss: 1.1187689779035281e-06 - tot_loss: 0.2703226570953774 - acc: 0.9820457018498367 - val_acc: 0.9446895147607737\n",
      "Repeatition 1 Epoch 497 / 500 \n",
      " - time: 1.5043554306030273 - sq_loss: 1.1172618314958527e-06 - tot_loss: 0.25543727133096006 - acc: 0.9820457018498367 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 498 / 500 \n",
      " - time: 1.5337297916412354 - sq_loss: 1.1166183639943483e-06 - tot_loss: 0.2953765353096003 - acc: 0.9823177366702938 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 499 / 500 \n",
      " - time: 1.5135090351104736 - sq_loss: 1.1152820889037685e-06 - tot_loss: 0.2560597773995372 - acc: 0.9825897714907508 - val_acc: 0.9450288428910757\n",
      "Repeatition 1 Epoch 500 / 500 \n",
      " - time: 1.5017063617706299 - sq_loss: 1.1146128144901013e-06 - tot_loss: 0.2517544703440513 - acc: 0.9825897714907508 - val_acc: 0.9450288428910757\n",
      "CR_1 = 0.17665842270710058   CR_2 = 0.17592699696476163\n",
      "/home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization\n"
     ]
    }
   ],
   "source": [
    "########### parameter setup\n",
    "#df = pd.DataFrame()\n",
    "#df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "niter = 500\n",
    "rank = 80\n",
    "tau = 3\n",
    "gamma = 0.5\n",
    "rho = 0.5\n",
    "alpha = 1\n",
    "\n",
    "\n",
    "\n",
    "print (\"rank=\",rank, \"tau=\",tau, \"gamma=\",gamma, \"rho=\",rho, \"alpha\",alpha)\n",
    "\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)\n",
    "\n",
    "results = torch.zeros(1, 5, niter)\n",
    "\n",
    "\n",
    "\n",
    "for Out_iter in range(1):\n",
    "    rank_initial = 400\n",
    "    seed = 10 + 10*Out_iter\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "    d0 = 561 #561 =3*11*17\n",
    "\n",
    "    d1 =  1024    # 2^10\n",
    "    d2 =  1024  \n",
    "    d3 = 1024\n",
    "    d4 = 512      # 2^9\n",
    "    d5 = 512\n",
    "    d6 = 6 \n",
    "\n",
    "\n",
    "    W1 = 0.18*init.kaiming_uniform_(torch.empty(d1, d0, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "    W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "    factors1 = tensor_train(W1_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "    b1 = 0*torch.ones(d1, 1, device=device) # 0 is stable\n",
    "\n",
    "\n",
    "    W2 = 0.18*init.kaiming_uniform_(torch.empty(d2, d1, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy())\n",
    "    factors2 = tensor_train(W2_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    # we have 9 rank_initial (r1,...,r9) here plus 2 of 1s (r0 & r10).\n",
    "    # factors: set of tensor cores\n",
    "    # http://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "    # http://tensorly.org/stable/modules/generated/tensorly.decomposition.tensor_train.html#tensorly.decomposition.tensor_train\n",
    "    W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "    # tt_to_tensor(factors):Re-assembles ‘factors’, which represent a tensor in TT format into the corresponding full tensor\n",
    "    #      facros: list of 3d-arrays tt-cores           output_tensor: ndarray      \n",
    "    b2 = 0*torch.ones(d2, 1, device=device)\n",
    "\n",
    "\n",
    "    W3 = 0.18*init.kaiming_uniform_(torch.empty(d3, d2, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "    factors3 = tensor_train(W3_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "    b3 = 0*torch.ones(d3, 1, device=device)\n",
    "\n",
    "    W4 = 0.18*init.kaiming_uniform_(torch.empty(d4, d3, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2)) # 8 number of 4s, 2 number of 8s\n",
    "    W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    factors4 = tensor_train(W4_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "    b4 = 0*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    W5 = 0.18*init.kaiming_uniform_(torch.empty(d5, d4, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4)) # 8 number of 4s, 2 number of 8s\n",
    "    W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())\n",
    "    factors5 = tensor_train(W5_tl_tensor, (1, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial, rank_initial,1))\n",
    "    W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "    b5 = 0*torch.ones(d5, 1, device=device)\n",
    "\n",
    "\n",
    "    W6 = 0.18*init.kaiming_uniform_(torch.empty(d6, d5, device=device), a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    b6 = 0*torch.ones(d6, 1, device=device)\n",
    "\n",
    "    # W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "    # W4_torch_tensor = W4.reshape((50,30,K))\n",
    "    # W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())\n",
    "    # core4, tucker_factors4 = tucker(W4_tl_tensor, rank=(40,28,K), init='svd', tol=10e-5, random_state=12345)\n",
    "    # W4_tl_tensor_rec = tl.tucker_to_tensor((core4, tucker_factors4))\n",
    "    # b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "    U1 = torch.addmm(b1.repeat(1, N), W1, X_train)\n",
    "    V1 = nn.ReLU()(U1)\n",
    "    U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "    V2 = nn.ReLU()(U2)\n",
    "    U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "    V3 = nn.ReLU()(U3)\n",
    "    U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    V4 = nn.ReLU()(U4)\n",
    "    U5 = torch.addmm(b5.repeat(1, N), W5, V4)\n",
    "    V5 = nn.ReLU()(U5)\n",
    "    U6 = torch.addmm(b6.repeat(1, N), W6, V5)\n",
    "    V6 = U6 \n",
    "    # U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "    # V4 = U4\n",
    "\n",
    "\n",
    "\n",
    "    # Iterations\n",
    "    print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "    for k in range(niter):\n",
    "        start = time.time()\n",
    "\n",
    " # update for last layer\n",
    "        # update V4\n",
    "        V6 = (y_one_hot + gamma*U6 + alpha*V6)/(1 + gamma + alpha)\n",
    "\n",
    "        # update U4 \n",
    "        U6 = (gamma*V6 + rho*(torch.mm(W6,V5) + b6.repeat(1,N)))/(gamma + rho)\n",
    "\n",
    "        # update W4 and b4\n",
    "        W6, b6 = updateWb_org(U6,V5,W6,b6,alpha,rho)\n",
    "        # W3_torch_tensor = W3.reshape((d3,4,4,4,4,4,4))\n",
    "        # W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())\n",
    "        # factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,1))\n",
    "        # W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    "\n",
    "        # update for 5th layer\n",
    "        # update V3\n",
    "        V5 = updateV(U5,U6,W6,b6,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U5 = relu_prox(V5,(rho*torch.addmm(b5.repeat(1,N), W5, V4) + alpha*U5)/(rho + alpha),(rho + alpha)/gamma,d5,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W5, b5 = updateWb(U5,V4,W5,b5,W5_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W5_torch_tensor = W5.reshape((4,4,4,4,4,4,4,4,4))\n",
    "        W5_tl_tensor = tl.tensor(W5_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors5 = tensor_train(W5_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W5_tl_tensor_rec = tt_to_tensor(factors5)\n",
    "\n",
    "\n",
    "  # update for 4th layer\n",
    "        # update V3\n",
    "        V4 = updateV(U4,U5,W5,b5,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U4 = relu_prox(V4,(rho*torch.addmm(b4.repeat(1,N), W4, V3) + alpha*U4)/(rho + alpha),(rho + alpha)/gamma,d4,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W4, b4 = updateWb(U4,V3,W4,b4,W4_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W4_torch_tensor = W4.reshape((4,4,4,4,4,4,4,4,4,2))\n",
    "        W4_tl_tensor = tl.tensor(W4_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors4 = tensor_train(W4_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W4_tl_tensor_rec = tt_to_tensor(factors4)\n",
    "\n",
    "  # update for 3nd layer\n",
    "        # update V3\n",
    "        V3 = updateV(U3,U4,W4,b4,rho,gamma)\n",
    "\n",
    "        # update U3\n",
    "        U3 = relu_prox(V3,(rho*torch.addmm(b3.repeat(1,N), W3, V2) + alpha*U3)/(rho + alpha),(rho + alpha)/gamma,d3,N)\n",
    "\n",
    "        # update W3 and b3\n",
    "        W3, b3 = updateWb(U3,V2,W3,b3,W3_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W3_torch_tensor = W3.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W3_tl_tensor = tl.tensor(W3_torch_tensor.cpu().numpy())  # transfer tensorly package\n",
    "        factors3 = tensor_train(W3_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        #set of tensor cores\n",
    "        W3_tl_tensor_rec = tt_to_tensor(factors3)\n",
    "\n",
    " # update for 2nd layer\n",
    "        # update V2\n",
    "        V2 = updateV(U2,U3,W3,b3,rho,gamma)\n",
    "\n",
    "        # update U2\n",
    "        U2 = relu_prox(V2,(rho*torch.addmm(b2.repeat(1,N), W2, V1) + alpha*U2)/(rho + alpha),(rho + alpha)/gamma,d2,N)\n",
    "\n",
    "        # update W2 and b2\n",
    "        W2, b2 = updateWb(U2,V1,W2,b2,W2_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update (TTD)   \n",
    "        W2_torch_tensor = W2.reshape((4,4,4,4,4,4,4,4,4,4))\n",
    "        W2_tl_tensor = tl.tensor(W2_torch_tensor.cpu().numpy()) \n",
    "        factors2 = tensor_train(W2_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W2_tl_tensor_rec = tt_to_tensor(factors2)\n",
    "\n",
    "\n",
    "# update for 1st layer\n",
    "        # update V1\n",
    "        V1 = updateV(U1,U2,W2,b2,rho,gamma)\n",
    "\n",
    "        # update U1\n",
    "        U1 = relu_prox(V1,(rho*torch.addmm(b1.repeat(1,N), W1, X_train) + alpha*U1)/(rho + alpha),(rho + alpha)/gamma,d1,N)\n",
    "\n",
    "        # update W1 and b1\n",
    "        W1, b1 = updateWb(U1,X_train,W1,b1,W1_tl_tensor_rec, alpha,rho,tau)\n",
    "\n",
    "        # G update\n",
    "        W1_torch_tensor = W1.reshape((6,22,34,2,2,2,2,2,2,2))\n",
    "        W1_tl_tensor = tl.tensor(W1_torch_tensor.cpu().numpy())\n",
    "        factors1 = tensor_train(W1_tl_tensor, (1,rank,rank,rank,rank,rank,rank,rank,rank,rank,1))\n",
    "        W1_tl_tensor_rec = tt_to_tensor(factors1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # prediction for trainning data\n",
    "        a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_train))\n",
    "        #a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train))\n",
    "        a4_train = nn.ReLU()(torch.addmm(b4.repeat(1, N), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_train))\n",
    "        a5_train = nn.ReLU()(torch.addmm(b5.repeat(1, N), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_train))\n",
    "        #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        pred = torch.argmax(torch.addmm(b6.repeat(1, N), W6, a5_train), dim=0)\n",
    "        # check argmax and addmm, dim=0\n",
    "\n",
    " #Prediction for test data\n",
    "        a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), X_test))\n",
    "        #a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test))\n",
    "        a4_test = nn.ReLU()(torch.addmm(b4.repeat(1, N_test), torch.as_tensor(W4_tl_tensor_rec,device=device).reshape((d4, d3)).float(), a3_test))\n",
    "        a5_test = nn.ReLU()(torch.addmm(b5.repeat(1, N_test), torch.as_tensor(W5_tl_tensor_rec,device=device).reshape((d5, d4)).float(), a4_test))\n",
    "        pred_test = torch.argmax(torch.addmm(b6.repeat(1, N_test), W6, a5_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_train))\n",
    "        # # a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_train))\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), torch.as_tensor(W1_tl_tensor_rec,device=device).reshape((d1, d0)).float(), x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), torch.as_tensor(W2_tl_tensor_rec,device=device).reshape((d2, d1)).float(), a1_test))\n",
    "        # # a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)), a2_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), torch.as_tensor(W3_tl_tensor_rec,device=device).reshape((d3, d2)).float(), a2_test), dim=0)\n",
    "\n",
    "        # a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, N), W1, x_train))\n",
    "        # a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, N), W2, a1_train))\n",
    "\n",
    "        # #print(torch.addmm(b4.repeat(1, N), W4, a3_train))\n",
    "        # pred = torch.argmax(torch.addmm(b3.repeat(1, N), W3, a2_train), dim=0)\n",
    "\n",
    "        # a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, N_test), W1, x_test))\n",
    "        # a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, N_test), W2, a1_test))\n",
    "        # pred_test = torch.argmax(torch.addmm(b3.repeat(1, N_test), W3, a2_test), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   #emperical loss\n",
    "        loss1[k] = gamma/2*torch.pow(torch.dist(V6,y_one_hot,2),2).cpu().numpy()\n",
    "        # torch.pow:Takes the power of each element in input with exponent and returns a tensor with the result.\n",
    "        # torch.disk: Returns the p-norm of (input - other)\n",
    "        # Eq (5) in paper\n",
    "        loss2[k] = loss1[k] + rho/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, X_train),U1,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b5.repeat(1,N), W5, V4),U5,2),2).cpu().numpy() \\\n",
    "        +rho/2*torch.pow(torch.dist(torch.addmm(b6.repeat(1,N), W6, V5),U6,2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V1,nn.ReLU()(U1),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V2,nn.ReLU()(U2),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V3,nn.ReLU()(U3),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V4,nn.ReLU()(U4),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V5,nn.ReLU()(U5),2),2).cpu().numpy() \\\n",
    "        + gamma/2*torch.pow(torch.dist(V6,U6,2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W1.reshape((6,22,34,2,2,2,2,2,2,2)),torch.as_tensor(W1_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W2.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W2_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W3.reshape((4,4,4,4,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W4.reshape((4,4,4,4,4,4,4,4,4,2)),torch.as_tensor(W4_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "        +tau/2*torch.pow(torch.dist(W5.reshape((4,4,4,4,4,4,4,4,4)),torch.as_tensor(W5_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \\\n",
    "\n",
    "        # +tau/2*torch.pow(torch.dist(W3.reshape((d3,4,4,4,4,4,4)),torch.as_tensor(W3_tl_tensor_rec,device=device).float(),2),2).cpu().numpy() \n",
    "        # +tau/2*torch.pow(torch.dist(W4.reshape((50,30,K)),torch.as_tensor(W4_tl_tensor_rec,device=device),2),2).cpu().numpy() \n",
    "\n",
    "        # compute training accuracy\n",
    "        correct_train = pred == y_train-1\n",
    "        accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "\n",
    "        # compute validation accuracy\n",
    "        correct_test = pred_test == y_test-1\n",
    "        accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "\n",
    "        # compute training time\n",
    "        stop = time.time()\n",
    "        duration = stop - start\n",
    "        time1[k] = duration\n",
    "\n",
    "        # print results\n",
    "        print('Repeatition', Out_iter + 1, 'Epoch', k + 1, '/', niter, '\\n', \n",
    "              '-', 'time:', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "              '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])\n",
    "\n",
    "##############\n",
    "############## compute CR\n",
    "    factors1_shape=[f.shape for f in factors1]\n",
    "    Sum_of_variables_factors1=sum(list(x*y*z for x,y,z in factors1_shape))\n",
    "    factors2_shape=[f.shape for f in factors2]\n",
    "    Sum_of_variables_factors2=sum(list(x*y*z for x,y,z in factors2_shape))\n",
    "    factors3_shape=[f.shape for f in factors3]\n",
    "    Sum_of_variables_factors3=sum(list(x*y*z for x,y,z in factors3_shape))\n",
    "    factors4_shape=[f.shape for f in factors4]\n",
    "    Sum_of_variables_factors4=sum(list(x*y*z for x,y,z in factors4_shape))\n",
    "    factors5_shape=[f.shape for f in factors5]\n",
    "    Sum_of_variables_factors5=sum(list(x*y*z for x,y,z in factors5_shape))\n",
    "\n",
    "    total_variabels=Sum_of_variables_factors1+Sum_of_variables_factors2+Sum_of_variables_factors3+Sum_of_variables_factors4+Sum_of_variables_factors5\n",
    "\n",
    "    CR_1=((total_variabels)+(d5*d6))/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5+d5*d6)\n",
    "    CR_2=(total_variabels)/(d0*d1+d1*d2+d2*d3+d3*d4+d4*d5)\n",
    "    print(\"CR_1 = \"+str(CR_1)+\"   \"+\"CR_2 = \" +str(CR_2))\n",
    "\n",
    "\n",
    "    results[Out_iter,0,:] = torch.tensor(loss1)\n",
    "    results[Out_iter,1,:] = torch.tensor(loss2)\n",
    "    results[Out_iter,2,:] = torch.tensor(accuracy_train)\n",
    "    results[Out_iter,3,:] = torch.tensor(accuracy_test)\n",
    "    results[Out_iter,4,:] = torch.tensor(time1)\n",
    "    CR=(CR_1,CR_2)\n",
    "\n",
    "#     #this postion to add new row into existing table\n",
    "#         df=pd.read_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv')\n",
    "#         new_row = {'rank':rank, 'CR_1':CR_1, 'CR_2':CR_2, 'tau':tau, 'gamma':gamma, 'rho':rho, 'alpha':alpha, \\\n",
    "#                    'loss1':loss1[niter-1], 'loss2':loss2[niter-1], 'accuracy_train':accuracy_train[niter-1], \\\n",
    "#                    'accuracy_test':accuracy_test[niter-1], 'time':time1[niter-1],'seed':seed} \n",
    "#         df=df.append(new_row,ignore_index=True)\n",
    "#         df.to_csv('C:/Users/Mark/Desktop/HAR_5layers_rank40_100times.csv',index=False)\n",
    "\n",
    "\n",
    "filename= \"KaimingUniform_\" + \"niter_\"+ str(niter) + \"rank_\" + str(rank) + \"tau_\" + str(tau) + \"gamma_\" + str(gamma) + \\\n",
    "\"rho_\" + str(rho) + \"alpha_\" + str(alpha) + \".mat\"\n",
    "from scipy.io import savemat\n",
    "%cd /home/c/cl237/TenBCD/UCI HAR/5 hidden layers/Different Initialization/\n",
    "savemat (filename, {'results': torch.Tensor.numpy(results), 'Compression Ratio':CR})\n",
    "#this position to save table into matlab\n",
    "#df.to_csv('C:/Users/Mark/Desktop/result_compress_123_layer_highrank.csv')\n",
    "##Changing Folder\n",
    " #%cd '/content/gdrive/MyDrive/Colab/Tensor-BCD-for-DNN/Experiments/DataSaved'\n",
    " #savemat(\"ThreeLayer_rank160.mat\", {'results': torch.Tensor.numpy(results)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e5c2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133d333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
